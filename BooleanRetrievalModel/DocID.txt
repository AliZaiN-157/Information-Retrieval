{"1": "OVERVIEW A historical perspective of explainable Artificial Intelligence Roberto Confalonieri1| Ludovik Coba1| Benedikt Wagner2| Tarek R. Besold3 1Faculty of Computer Science, Free University of Bozen-Bolzano, Bozen-Bolzano, Italy 2Research Centre for Machine Learning, City University, London, UK 3Neurocat GmbH, Berlin, Germany Correspondence Roberto Confalonieri, Faculty ofComputer Science, Free University ofBozen-Bolzano, Dominikanerplatz3, Bozen-Bolzano I-39100, Italy.Email: roberto.confalonieri@unibz.itAbstract Explainability in Artificial Intelligence (AI) has been revived as a topic ofactive research by the need of conveying safety and trust to users in the \u201chow\u201dand \u201cwhy\u201dof automated decision-making in different applications such as autonomous driving, medical diagnosis, or banking and finance. While explainability in AI has recently received significant attention, the ori- gins of this line of work go back several decades to when AI systems weremainly developed as (knowledge-based) expert systems. Since then, the defini- tion, understanding, and implementation of explainability have been picked up in several lines of research work, namely, expert systems, machine learn- ing, recommender systems, and in approaches to neural-symbolic learning and reasoning, mostly happening during different periods of AI history. In this article, we present a historical perspective of Explainable Artificial Intelli- gence. We discuss how explainability was mainly conceived in the past, howit is understood in the present and, how it might be understood in the future. We conclude the article by proposing criteria for explanations that we believe will play a crucial role in the development of human-understandable explain- able systems. This article is categorized under: Fundamental Concepts of Data and Knowledge > Explainable AI Technologies > Artificial Intelligence KEYWORDS explainable AI, explainable recommender systems, interpretable machine learning, neural- symbolic reasoning 1|INTRODUCTION As of 2020, explainability has been identified as a key factor for adoption of AI systems in a wide range of contexts (Doshi-Velez & Kim, 2017; Lipton, 2018; Ribeiro, Singh, & Guestrin, 2016a). Discussion accompanying the increasinglycommon deployment of intelligent systems in application domains such as autonomous vehicles and transportation, medical diagnosis, or insurance and financial services have shown that when decisions are taken or suggested byReceived: 22 November 2019 Revised: 18 September 2020 Accepted: 21 September 2020 DOI: 10.1002/widm.1391 This is an open access article under the terms of the Creative Commons Attribution License, which permits use, distribution and reproduction in any me dium, provided the original work is properly cited. \u00a9 2020 The Authors. WIREs Data Mining and Knowledge Discovery published by Wiley Periodicals LLC. WIREs Data Mining Knowl Discov. 2021;11:e1391. wires.wiley.com/dmkd 1o f2 1 https://doi.org/10.1002/widm.1391 automated systems, it is essential for practical, social, and \u2014with increasing frequency \u2014legal reasons that an explana- tion can be provided to users, developers, and regulators. As a case in point, the European Union's General Data Protection Regulation (GDPR) stipulates a right to obtain \u201cmeaningful information about the logic involved \u201d\u2014commonly interpreted as a \u201cright to an explanation \u201d1\u2014for con- sumers affected by an automatic decision (Parliament and Council of the European Union, 2016).2 The reasons for equipping intelligent systems with explanatory capabilities are not limited to issues of user rights and of technology acceptance, though. Explainability is also required by designers and developers to enhance system robustness and to enable diagnostics to prevent bias, unfairness, and discrimination, as well as to increase trust by allusers in whyandhow decisions are made. Being able to provide an explanation of why a certain decision was made, has thus become a desirable property of intelligent systems (Doran, Schulz, & Besold, 2017). Explanations should help users in understanding the model of thesystem, in order to maintain it, and to use it effectively; they should also assist the user when debugging the model toprevent and rectify incorrect conclusions. In addition, explanations can serve educational purposes and be helpful for people in discovering and understanding novel concepts in an application domain. Finally, explanations are related to users' trust and persuasion, they should convey a sense of actionability, and convince users that the system's decisionsare the most convenient for them. Notwithstanding, there is no clear agreement about what an explanation is, nor what a good explanation entails. Its manifestations have been studied across different incarnation of AI systems and disciplines. The first notions ofexplainability in Artificial Intelligence had subsided together with that in expert systems after the mid-1980s (Buchanan & Shortliffe, 1984; Wick & Thompson, 1992), and have been brought back into the focus by recent successes in machine learning technology (Guidotti et al., 2018), for both autonomous (Nunes & Jannach, 2017) and human-in-the-loop systems (Holzinger, 2016; Holzinger, Plass, et al., 2019), with applications in recommender systems (Tintarev & Masthof, 2015), and approaches of neural-symbolic learning and reasoning (Garcez et al., 2015). In this article, we look at the literature of Explainable Artificial Intelligence (XAI) from a historical perspective of traditional approaches as well as approaches currently being developed. The relevant literature is vast, and this articledoes not aim to be a complete overview of the XAI literature. For each of the perspectives, the reader can find more comprehensive literature reviews in machine learning and Deep Learning (Arrieta et al., 2020; Fernandez, Herrera, Cordon, Jose del Jesus, & Marcelloni, 2019; Guidotti et al., 2018; Mueller, Hoffman, Clancey, Emrey, & Klein, 2019),recommender systems (Nunes & Jannach, 2017; Tintarev & Masthof, 2015), and Neural-Symbolic Approaches (Garcez et al., 2015). The aim of the article is rather to provide an overview and discuss how different notions of explainability (resp. format of explanations) have been conceived, and to provide several examples. The main contributions of this article are: To provide an overview of XAI, and how it is understood in expert systems, machine learning, recommender systems, and neural-symbolic learning and reasoning approaches. To provide the reader with a wide range of references, (s)he can use to gain a deeper understanding in the topic of XAI. The article is organized as follows. In Section 2, we give an overview of the different notions of explainability that are subsequently addressed from different perspectives throughout the article. Section 3 describes two notions of expla- nations prominently represented in the expert system literature, namely explanations as line of reasoning and as problem-solving activities. In Section 4, we present how the notion of explanation is commonly understood in machinelearning, as well as a few examples of such explanations. Section 5 discusses how explanations are conceptualized in the context of recommender systems. Section 6 identifies the increasingly popular perspective of Neural-Symbolic Learning and Reasoning as promising approach to explainability in AI systems. Section 7 provides a critical discussionand comparison of the different notions of explainability mentioned throughout the article, and introduces general desiderata for explainability and a set of challenges for the development of human-understandable explainable AI sys- tems. Section 8 concludes the article. 2|WHAT IS A (GOOD) EXPLANATION? Defining what an explanation is remains a still open research question. In particular, determining the criteria for a good explanation as of today is an active debate in various fields, including cognitive science, computer science, psychology,2o f2 1 CONFALONIERI ET AL .  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License and philosophy (Confalonieri et al., 2019; Guidotti et al., 2018; Hoffman, Mueller, Klein, & Litman, 2018; Lipton, 2018; Lombrozo, 2016; Miller, 2019). Miller (2019) articulates the link between discussion in the social sciences and explainability in AI, providing an in- depth survey on research on explanations in philosophy, psychology, and cognitive science. Three major findings were highlighted. First, explanations are counterfactual , and humans tend to understand why a certain event happened instead of some other events. Second, explanations are selective and focus on one or two possible causes \u2014instead of all possible causes \u2014for a decision or recommendation; that is, explanations should not overwhelm the user with too much information. Third, explanations are a social conversation and interaction for the purpose of transferring knowledge, implying that the explainer must be able to leverage the mental model of the explainee while engaging in the explana- tion process. While according to Miller (2019) these three points are key properties when building useful explanations, the different notions of explainability prevalent in XAI only recently started to take them into account. Psychology researchers have studied and defined properties of explanations that are human-oriented. For instance, Lombrozo (2016) suggested that one needs to differentiate between distinct possible goals for explainability, while highlighting why and how human explanatory cognition provides crucial constraints for the design of XAI systems. Hilton (1990) pointed out that explanations imply social interactions, and that for machine-generated explanations, it isessential to associate semantic information with an explanation (or its components) for effective knowledge transmis- sion to human users. Kulesza et al. (2013) investigated the relationship between certain properties of generated explana- tions and the fidelity of users' mental models, finding that completeness ultimately appears to be more important thansoundness, and that oversimplification is detrimental to users' trust in an explanation. Work in computer science hitherto focused to the most part on the mechanistic aspects of how explanations are generated (Guidotti et al., 2018). This includes not only approaches in machine learning and recommender systems,but also in knowledge-based systems. The types of explanations these systems are able to create \u2014and, consequently, their properties \u2014mainly depend on the type of reasoning employed in the system, namely, symbolic, subsymbolic, or hybrid. 3 Symbolic reasoning systems draw conclusions or explain why a certain hypothesis holds based on a knowledge base\u2014usually encoded as a set of production or symbolic rules \u2014and an inference mechanism, such as deduction, abduction, or analogical reasoning (Doyle, Tsymbal, & Cunningham, 2003; Lacave & Diez, 2004; Mitchell, Keller, & Kedar-Cabelli, 1986). Explanations in these systems consist of either descriptions coupled to the reasoning trace of thesystem, or descriptions more coupled to the story behind the decision-making process of the system (Buchanan & Shortliffe, 1984; Wick & Thompson, 1992). In either case, metrics and desirable properties for these explanations are, for instance, accuracy ,adaptability , and comprehensibility . While these explanations are typically meant to be a precise reconstruction of the system behavior, they also should be adaptable to match different user profiles. Indeed, lay users might be more interested in a less accurate but more understandable explanation, whereas expert users might prefer more technical and precise explanation formats. Subsymbolic (or connectionist) reasoning systems are, generally speaking, those that rely on machine learning models in which representations are in most cases distributed and processing occurs simultaneously in multiple parallel channels. Unfortunately, these properties frequently bring about a certain black-box nature of the corresponding models. As a consequence, explanations in these systems often take the form of interpretable models that approximateor try to mimic the behavior of the black-box (Andrews, Diederich, & Tickle, 1995; Guidotti et al., 2018). An interpret- able model allows users to understand how decisions are made by means of local or global post-hoc explanations (Guidotti et al., 2018). Such interpretable models are typically evaluated using metrics such as accuracy and fidelity . These metrics measure to what extent an interpretable model is able to maintain competitive levels of accuracy with respect to the original black-box model, and to what extent the model is able to accurately imitate a black-box predictor respectively. Additional metrics targetting the notion of causability of explanations have recently been introduced by (Holzinger, Langs, et al., 2019; Holzinger, Carrington, & M\u00fcller, 2020). Causability refers to the extent to which an explanation achieves a certain level of causal understanding in a specified context of use and is measured in terms of effectiveness, efficiency, satisfaction related to causal understanding and its transparency for a user. As an additionalclass of explanation approaches predominantly for black-box models, methods providing explanations based on coun-terfactuals (i.e., hypothetical input examples that show how a different decision or prediction could have been obtained) recently also moved into the focus of active research (see e.g., Mothilal, Sharma, & Tan, 2020). A particular category of sub-symbolic reasoning systems are recommender systems. There is no clear consensus in the recommender systems literature on what makes for a good explanation (Nilashi, Jannach, & bin Ibrahim, O., Esfahani, M. D.,, & Ahmadi, H., 2016; Nunes & Jannach, 2017; Tintarev & Masthof, 2015). In fact, an explanation onCONFALONIERI ET AL . 3o f2 1  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License the recommendation can have different goals, and impact decision-makers differently (Coba, Rook, et al., 2019). For example, a tailored explanation can persuade or help a user in finding an item more efficiently (Tintarev &Masthof, 2015). When implementing an explanation, a usual approach is to first determine its objective. For instance, stakeholders might be interested in delivering persuasive explanations, since they increase the probability of acceptance or purchase of a recommended item (Nunes & Jannach, 2017). Trustworthiness is another desired property of an expla- nation, since users tend to return to and reuse systems that they trust (L. Chen & Pu, 2005). Moreover, efficient ,effective , and satisfying explanations help the users in deciding fast and making good decisions and increase the ease of use, respectively (Tintarev & Masthof, 2015). Transparency fosters the understandability for the user of the underlying logic of the advice-giving systems, and scrutability allows the user to tell that the system is wrong. These properties are often correlated. For instance, transparent explanations should also be comprehensible, and are known to convey trust. For a detailed discussion about the relationships between characteristics we refer the reader to (Balog & Radlinski, 2020). Hybrid or neural-symbolic systems are those systems that combine symbolic and sub-symbolic reasoning (Garcez et al., 2015). The sub-symbolic system is able to build predictive models using connectionist machine learning and processing large amounts of data, while the symbolic system is equipped with a rich representation of domain knowl- edge and can be used for higher-level, structured reasoning. These symbolic elements are used by the system to explainthe decisions made by the sub-symbolic components. Also here, accuracy andfidelity are, once more, important metrics to measure the performance of an interpretable model; whereas consistency andcomprehensibility are desirable proper- ties of the produced explanations from the explainee's point of view. The domain knowledge can serve as basis forcommon-sense reasoning, and supports knowledge abstraction, refinement, and injection (Confalonieri, Eppe, Schorlemmer, Kutz, & Pen \u02dcaloza, R.,, & Plaza, E., 2018; Lehmann & Hitzler, 2010). As such, the system has not only the capability to create explanations for the sub-symbolic parts, but also to change the explanations' level of accuracyand technicality depending on the user profile. Furthermore, the system can refine the extracted knowledge, and inject it back to the sub-symbolic system to improve its performance (Garcez, Broda, & Gabbay, 2001). 3|EXPLANATIONS IN EXPERT SYSTEMS Expert or knowledge-based systems are software systems augmented by expert or domain knowledge. They are consid- ered as one of the first instantiations of AI systems. They were developed to support humans in making decisions in sev- eral domains (Doyle et al., 2003; Lacave & Diez, 2004; Mitchell et al., 1986; Wick & Thompson, 1992). An expert system consists of a knowledge base encoding the domain knowledge, usually modeled as a set of produc- tion rules, a rule interpreter or reasoner that makes use of the knowledge base, and an interface through which the user can query the system for knowledge. In the literature on expert systems, explanations are mainly understood in one of two ways: an explanation as a line of reasoning, or as a problem-solving activity. 3.1 |Explanations as lines of reasoning Seeing an explanation as a line of reasoning means mainly understanding it as a trace of the way that production or inference rules are used by the system to make a certain decision. While this kind of explanation mainly accommodatesthe need of knowledge engineers to understand whether the system's reasoning is technically sound, it (or slight vari- ants of it) can also be provided as an explanation to domain experts (Buchanan & Shortliffe, 1984; Mitchell et al., 1986). The most famous instantiation of a system that was able to provide this kind of explanation is MYCIN (Buchanan & Shortliffe, 1984). MYCIN is a rule-based system with consultation capabilities developed in the 1970s, created with the aim to provide doctors with diagnostic and therapeutic advice about patients with an infection. MYCIN's expertise con- sists of a static knowledge base containing domain specific knowledge of an expert, as well as factual knowledge aboutthe particular problem under consideration. The domain or expert knowledge is modeled by means of production rules (see Table 1), which are used to provide diagnosis solutions to specific cases. That is, the user provides some knowledge about a specific patient as input, and the system uses this knowledge to instantiate rules and to make the diagnosis corresponding to the specific case. The explanation capability in MYCIN consists of a general question answering module and a reasoning-status checker. The former answers simple English language questions concerning the system's decision in a consultation, or4o f2 1 CONFALONIERI ET AL .  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License about the system's general knowledge. The latter provides explanations about the line of reasoning followed by the system. The question answering module accepts a set of predefined questions that allow an expert user to query the dynamic knowledge or rationale with respect to the rules, parameters, values, and contexts used in a specific consultation. On the other hand, the reasoning status checker allows the user to go deeper into the sequence of rules that are used. Thequestion answering module accepts two basic explanation commands: a why command, by which the user can ascend the reasoning chain and explore higher-goals: and a how command, by which the user can descend the chain of infer- ences exploring how a goal was achieved. Although the provisioning of explanations as lines of reasoning of why certain decisions were \u201clogically \u201dmade improves the interpretability of expert systems, humans, when asked to account for complex reasoning, tend to also reconstruct a story that describes the problem-solving behind the decision. That is, they might reconstruct an explana-tion that fits their level of knowledge and expertise. For instance, a lay user will not benefit much from a very technicalexplanation, compared to a domain expert or a knowledge engineer. This is what motivated the reconceptualization of explanations as a problem-solving activity by itself as we will discuss in the next section. 3.2 |Explanations as a problem-solving activity Conceiving of explanations as problem-solving activities means not only re-constructing the line of reasoning of the sys- tem, but also taking into account different levels of abstraction. These could range from very technical to more explana- tory explanation formats accommodating different user profiles. The adaptability of explanations to different types of users can be achieved by de-coupling the explanation capability from the main reasoning functionality, and by focusing the explanation on the problem-solving knowledge used to solve a certain task (Hassling, Clancey, & Runnels, 1984; Wick & Thompson, 1992). An example of an expert system exhibiting this adaptability is Rex (Wick & Thompson, 1992). Rex was designed to provide explanations of how an expert system moves from the data of a particular case to a final conclusion (a line of explanation) by building a \u201cstory \u201das an abstract of the expert systems reasoning. Rex was an inde- pendent component from the expert system used, provided that an interface as well as two knowledge bases existed: aknowledge specification and explanatory knowledge. The former acted as an interface between the knowledge of the expert system and the knowledge of the explanation system, and it covered the problem-solving expertise used to solve problems within the domain. The latter was knowledge used to create an explanation. The explanation model of Rex is shown in Figure 1. The model takes a set of reasoning cues , and a set of constraints as input. The reasoning cues consist of knowledge used and inferred by the expert system during the resolution of a cer- tain case. This knowledge is filtered by a set of problem constraints that decide which of these reasoning cues are avail-able to the explanation system. The selected reasoning cues are then mapped to the knowledge specification of thedomain, the screener . The knowledge specification ( spec) is the common ground between the expert system and the explanatory system and it is a high-level representation of the domain. It allows the explanation system to abstract from the procedural details of the expert system. The knowledge specification consists of transitions between hypotheses,where any transition requires the satisfaction of some goals and the existence of some reasoning cues. At this step, only some of the transitions might be enabled, thus only some hypotheses can be inferred, and become available to theTABLE 1 Example of a MYCIN rule, in both its logical internal formand English translationPREMISE: (AND (SAME CNTXT GRAM GRAMNEG) (SAME CNTXT MORPH ROD)(SAME CNTXT AIR ANAEROBIC)) ACTION: (CONCLUDE CNTXT IDENTITY BACTEROIDES TALLY .6) IF: (1) The gram stain of the organism is gramneg, (2) The morphology of the organism is rod, and (3) The aerobicity of the organism is anaerobic THEN: There is suggestive evidence (.6) that The identity of the organism is bacteroidesCONFALONIERI ET AL . 5o f2 1  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License explanatory knowledge. The explainer can finally build an explanation line by taking into account the knowledge speci- fication and the explanatory knowledge. The explanatory knowledge is a key component of the explanation process (see Figure 1). It models cues, goals, and hypotheses. Transitions among these elements are modeled through scripts. Scripts are represented using a frame-based language. The explainer tries to find an explanation \u201cplan\u201dusing only transitions whose hypotheses can be proven. The search of the explanation plan is carried out backward from the final conclusion until reaching the empty hypothesis.Each state in the explanation plan corresponds to an explanation that uses cues and a hypothesis as data, establishes other cues and a hypothesis as conclusions, and traverses certain edges in the knowledge specification. Once an explanation is found, the story-teller organizes it into a consistent flow from data to conclusions. Then, it presents the explanation as a story according to a grammar that models the memory structure built during human story-understanding. The basic idea is to extract the information concerning the structure of each hypothesis transition from the line of explanation. Each transition is formatted as a story-tree with a setting, theme, plot, and resolution. Thestory-tree is then converted to textual description by the verbalizer that fills in a template with the problem description, goal description, movement description, and the conclusion of the expert system. A line of explanation in Rex looks like the explanation shown in Figure 2. 4|EXPLANATIONS IN MACHINE LEARNING While some machine learning models can be considered interpretable by design, namely decision trees, decision rules, and decision tables,4the majority of machine learning models work as black-boxes . Given an input, a black-box returnsReasoning Cues Spec Line of  Explanation Explanatory\u00a0 Knowledge Story ExplanationScreener Explainer Story\u00a0 Teller Verbalizer End-UserExpert system Problem Constraints Solution Constraints FIGURE 1 Explanation capability as a problem-solving activity (left) and example of explanatory knowledge (right) (Wick & Thompson, 1992) FIGURE 2 Example of a line of explanation in Rex (Wick & Thompson, 1992)6o f2 1 CONFALONIERI ET AL .  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License the result of a decision task (classification, prediction, recommendation, etc.), but it does not reveal sufficient details about its internal behavior, resulting in an opaque decision model. For this reason, explainability in machine learningis formulated as the problem of finding an interpretable model that approximates the black-box model as much as pos- sible, typically seeking high fidelity . The literature about explainable or interpretable machine learning is vast. A recent survey on interpretable machine learning methods and techniques can be found in (Guidotti et al., 2018). There, a classification of explanation models is proposed: Global methods: The extraction of an explainable counterpart from a black-box model aims at providing an overall approximation of the behavior of the black-box, such that all decisions made by the latter can be tracked in terms of interpretable mechanisms, for example, (Craven & Shaolin, 1995; Frost & Hinton, 2017). Local methods: Explanations are built for the decisions made by a black-box model over specific outcomes/instances of a dataset. In this sense, interpretable local models are considered a local approximation of how the black-box works. This kind of explanations can vary greatly depending on the instance considered, for example (Kim, Rodin, & Shah, 2014; Ribeiro, Singh, & Guestrin, 2016b; Ribeiro, Singh, & Guestrin, 2018). Introspective methods: Explanations are built by relating inputs to outputs of a black-box model. For instance, expla- nations can consist of saliency masks for Deep Neural Network models in image classification (such as Convolutional Neural Networks [CNNs]), for example (Hendricks et al., 2016; Park et al., 2016; Same, Wigand, & M\u00fcller, 2019) orgroups of input \u2013output tokens that are causally related, for example, (Alvarez-Melisa & Jackova, 2017). In the following, we present some global and local explanation methods: PDPs (partial dependence plots), LIME (local interpretable model-agnostic explanations; Ribeiro et al., 2016b), and SHAP (Shapley Additive explanations; Lundberg & Lee, 2017). Furthermore, we dedicate a section to counterfactual explanations (Mothilal et al., 2020; Watcher, Mittelstadt, & Russell, 2018). 4.1 |Global explanations The goal of extracting explanations via an interpretable global model is to automatically generate general representa- tions of the black-box model and its relationship to features of the dataset is has been trained on. One possible strategy is to generate symbolic representations of all decisions made by the complex model and represent it in a directly inter-pretable way. An example of this is the extraction of decision trees, for example (Craven & Shavlik, 1995; Frosst & Hinton, 2017), and decision rules from a trained neural network, for example (Odense & Garcez, 2017; Zhou, Jiang, & Chen, 2003), or the extraction of feature importance vectors, for example, (Lou, Caruana, & Gehrke, 2012; Lou,Caruana, Gehrke, & Hooker, 2013), from noninterpretable models. 5In some other cases, the interpretable model is a refinement of previous models, which were used to build the black box, such as in the case of Knowledge Neural Net- works (Towell & Shavlik, 1993). A different example can be found in PDPs Friedman (2000), which compute the effect of various variables in the predicted outcome of a machine learning model. This effect can be linear (as in linear regression) or more complex. PDP works by marginalizing the machine learning model output over the distribution of features so that the function shows the relationship between the features one is interested in, and the predicted outcome. PDP works well when onewants to explain two or three features (since it generates 2-D and 3-D plots) and when the features are uncorrelated. In other cases, Accumulated Local Effect plots are used. They work with the conditional instead of the marginal distribu- tion (Apley & Zhu, 2016). Figure 3 shows an example of these explanations. 4.2 |Local explanations In local explanation methods, the individual predictions of a black-box model can be approximated by generating local surrogate models that are intrinsically interpretable. This strategy has been implemented for instance in LIME; Ribeiro et al., 2016b). The LIME approach exploits the fact that the trained black-box model can be queried multiple times about the predictions of particular instances. By perturbing the data used for training, LIME generates a new dataset after feeding the black-box model with perturbedCONFALONIERI ET AL . 7o f2 1  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License data and creates a new interpretable model from the predictions made over the new dataset. The local surrogate model is weighted by the proximity of the perturbed instances to the original ones such that it has a high local fidelity. Methods like LIME generate explanations by creating surrogate models that are interpretable and have a low num- ber of features in order to keep the complexity of the interpretable model low. Figure 4 shows an example of a local explanation extracted by LIME. In the example, the predicted variable is explained using a linear regression. However, the sampling method used to train the interpretable model is not applicable to situations in which feature spaces are high dimensional or when black-box model decision boundaries are complex. In these scenarios, more fea- tures have to be taken into account in order to increase local fidelity, to the detriment of interpretability. An extension of the method, which uses rules instead of surrogate models, has recently been proposed by the authors of LIME. The method, called ANCHOR (Ribeiro et al., 2018), uses the same perturbation space as LIME and constructs explanations by adapting their coverage to the model structure. In this regard, explanations have a well-defined boundary in terms of their faithfulness to the black-box model. 4.3 |Counterfactual explanations A counterfactual explanation provides \u201cwhat-if \u201dinformation in terms of which alterations of the input features could change the output of a predictive model. A counterfactual explanation is then defined as the smallest change to the FIGURE 3 Explanations as partial dependence plots \u2014PDPs (left) and Accumulated Local Effect \u2014ALE (right) showing how temperature, humidity, and wind speed affect the predicted number of rented bicycles on a given day (Molnar, 2019). Due to correlationbetween temperature and humidity, the PDP shows a smaller decrease in predicted number of bikes for high temperature or high humidity compared to the ALE plots. The example shows that when features of a machine learning model are correlated, PDPs are not very accurate and cannot be trusted (Apley & Zhu, 2016) FIGURE 4 Local explanation extracted through LIME in the Boston dataset (Harrison & Rubinfeld, 1978). The dataset contains information collected by the U.S Census Service concerning housing in the area of Boston, Massachusetts. On the left, the median value of owner-occupied homes in $1000's (the predicted value), is explained using a linear regression model using 5 over 14 features (RM, averagenumber of rooms per dwelling; TAX, full-value property-tax rate per $10; 000; NOX, nitric oxides concentration; LSTAT, % lower status of the population; PTRATIO, pupil-teacher ratio by town). On the right, the local explanation in the form of a linear regression using the mentioned features can be appreciated8o f2 1 CONFALONIERI ET AL .  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License \u201cworld \u201d(as captured by the input data) that can be made to obtain a desired outcome (Wachter, Mittelstadt, & Russell, 2018); for example, You were denied a loan because your annual income was \u00a330,000. If your income had been \u00a345,000, you would have been offered a loan . In this scenario, the borrower receives information regarding why the loan was denied but also will be informed as to what she should do in order to change this outcome. One of the issues that has to be addressed when generating counterfactuals is that some features might not be changeable (e.g., a person's gender, race, or birth-place). Hence it becomes crucial to present counterfactuals that are indeed actionable in the application domain. An actionable example, thus, refers to what can concretely be done next in order to change the outcome of a given decision. For a counterfactual to be actionable it has to meet four properties:proximity, obeying user constraints, sparsity, and causal constraints (Mothilal et al., 2020). Furthermore, presenting users with a set of diversified examples (i.e., a range of suggested actions) can help them shed light on how the system works, and can ease the adoption of these changes. Unlike explanation methods that depend on approximating the classifier's decision boundary (Ribeiro et al., 2016a), counterfactual explanations have the advantage that they are more human understandable (Mothilal et al., 2020), and that they are always truthful with respect to the underlying model by giving direct outputs of the algorithm (Wachter, Mittelstadt, & Russell, 2018). These properties might prove to be particularly useful in the context of explainability andthe GDPR. An approach to generating counterfactuals was proposed in (Wachter, Mittelstadt, & Russell, 2018). Soon after, the importance of diversity also in counterfactuals was acknowledged by (Russell, 2019), who correspondingly proposed amethod to generate diversified counterfactuals for linear models. More recently, Mothilal et al. (2020) proposed Diverse Counterfactual Explanations (DiCE), a novel-model agnostic approach for generating counterfactual examples that are both actionable and diverse. 6An example of counterfactual explanations using DiCE can be seen in Figure 5. 5|EXPLANATIONS IN RECOMMENDER SYSTEMS Recommender systems make use of a large variety of models as back-end engines to serve customized recommenda- tions to users. Such models can be based on Collaborative Filtering, which include Matrix Factorisation (MF; Koren, Bell, & Volinsky, 2009) and all its variants, for example, singular value decomposition (SVD; Nati & Jaakkola, 2003) ornonnegative matrix factorisation (NMF; Lee & Seung, 1999), Nearest Neighbors, and methods based on embeddings such as Deep Learning (Wang, He, Feng, Nie, & Chua, 2018) or Knowledge-based Embeddings for Recommendation (Zhang, Ai, Chen, & Wang, 2018). Explanations in recommender systems is a popular topic and has received considerable attention in recent years (Nunes & Jannach, 2017; Tintarev & Masthof, 2015). Most of the corresponding work aims to answer the question of why a particular recommendation has been served. This answer can take into account many different aspects used bythe recommendation algorithm, such as past interactions characteristics, or contextual information, for example, loca-tion of the user, his or her social context, or the time the recommendation is provided. FIGURE 5 Example of counterfactual explanations with DiCE (Mothilal et al., 2020). In this example, a neural network was trained to predict the income of a person based on the above eight features (age, work-class, etc.). The first table represents the original query, wherethe model computed a negative outcome. The second table represents the counterfactual examplesCONFALONIERI ET AL . 9o f2 1  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License Explainable recommendation systems can be broadly classified into two categories: model-based and post-hoc. The first tackle the mechanistic part of the recommendation, aiming at explaining the way the algorithm proposes a particu-lar recommended item, while the latter analyze the output of a trained recommender in order to infer an explanation for all (recent) recommendations served. The following subsections provide a brief overview on current state-of-the-art explainable recommender models, and present some forms of explanations meant to increase persuasiveness, effectiveness, efficiency, user satisfaction, and efficiency in platforms that serve recommendations. 5.1 |Explainable recommender system models One of the most widespread methods which recommendation engines are based on is MF. Factorisation models rely on latent representations of users and items so as to predict either the item(s) with the highest chance to be interacted with, or the rating of an item given by a user. Problems arise when trying to explain the latent factors that contribute to the prediction: the exact meaning of each factor is generally unknown and therefore more information about user inter-ests and item characteristics is required. Explicit factor models (EFM; Zhang, 2015) take into account information pro- vided by the user about features of items that she might be interested in (through reviews and explicit feedback) and map them to the latent factors used in the (matrix or tensor) factorization part. Tensor factorization is an extension ofEFM's, where the cube user-item-features is used to predict ratings with embedded explanations in terms of features (X. Chen, Qin, Zhang, & Xu, 2016). Implicit feedback for explaining a recommendation has also been proposed by means of neighborhood-based explanations: in these models a recommended item comes with an explanation of thestyle \u201cx% similar users viewed this item, \u201dwhich can be extracted thanks to an explainability regularizer that forces user and item latent vectors to be close if x% of users have interacted with the same item. There are other approaches to explaining recommendations, which are based on the use of external knowledge of items in order to provide personalized explanations on new recommendations. Knowledge-based explanations for rec-ommender systems (Catherine, Mazaitis, Esk\u00e9nazi, & Cohen, 2017) make use of knowledge graphs that relate item properties and users' behavior in terms of their past interactions with items. With such graphs, different paths can con- nect a particular user to a particular item (i.e., the graph relationships) in the form of links (either views, purchases, orcategory), the building blocks of the provided explanations. On a similar note, if user-item relationships are represented as graphs, graph theory can provide insights about how users behave in terms of their interests on different items. For instance, Heckel and Vlachos (2016) proposed a method to compute coclustering to find similar users in terms of theirinterests and similar items in terms of their properties using an user-item bipartite graph. Explanations can then be retrieved by using shared information between users, considering the purchase/interaction behavior of similar users on recommended items as the core of the explanation. A different approach to explaining the performance of a recommender engine is to consider it as a black-box that can be probed so as to extract statistical features of recommendations (Peake & Wang, 2018). Explanations can then highlight what percentage of the users have behaved similarly and therefore can provide the confidence on the recom- mendation to be effective. Besides, the black-box can be approximated by an interpretable version of the recommenderengine, for example, association rules or similarity-based models, that can preserve high accuracy while being intrinsi- cally interpretable (Singh & Anand, 2018). Finally, there recently has been a surge in the number of deep learning-based recommender models deployed in rec- ommender engines (He et al., 2017). Many deep learning techniques, such as CNNs; Seo, Huang, Yang, & Liu, 2017) or Recurrent Neural Networks and Long-Short Term Memory networks (RNN-LSTM) (Hidasi & Karatzoglou, 2018) are used to implement different recommendation strategies, such as sequential recommendations (LSTMs) or context-aware rec-ommendations using user reviews. Attention-based methods are used to highlight the importance of words used in user reviews of past interactions in order to provide explanations about new recommendations. These algorithms use natural language generation in the explanations that can also take into account visual features of the items of interest. 5.2 |Explanation styles in recommender systems Herlocker, Konstan, and Riedl (2000) compared a large number of different styles of explanations and found that rating histograms generally were users' preferred mechanism for rendering the data behind the recommendations transparent.10 of 21 CONFALONIERI ET AL .  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License Supporting these results, these visual explanations of user styles have proven to be popular in many studies ever since (Bilgic & Mooney, 2005; Cosley, Lam, Albert, Konstan, & Riedl, 2003). Recently, a study using the visual rating histo-gram paradigm specifically identified user-based explanations and high mean rating values as the most popular styles (Kouki, Schaffer, Pujara, O'Donovan, & Getoor, 2017). Friedrich and Zanker (2011) proposed a taxonomy to classify different approaches to generate explanations for rec- ommendations. Among the types of explanations in their taxonomy, there are collaborative explanations. These are explanations that justify recommendations based on the amount as well as the concrete values of ratings that derive from similar users, where similarity is typically determined based on similar behavior and preference expressions dur-ing past interactions. The explanation taxonomy proposed by (Papadimitriou, Symeonidis, & Manolopoulos, 2012) extends this classifica- tion by making a distinction based on the three fundamental concepts used for explaining recommendations, which areusers ,items , and item features . They can be used to denote the following explanation styles: User Style, which provides explanations based on similar users, Item Style, which is based on choices made by users on similar items, and Feature Style, which explains the recommendation based on item features (content). Please note, that any combination of the aforementioned styles is then categorized as a multi-dimensional hybrid explanation style. For the User Style, several collaborative filtering recommender systems, such as the one used by Amazon in their online stores, adopted the following style of justification: \u201cCustomers who bought item Xalso bought items Y,Z,\u2026.\u201d This is called User style (Bilgic & Mooney, 2005) as it is based on users performing similar actions like buying or rating items (see also Figure 6). Regarding the Item style of explanation, justifications are of the form: \u201cItem Yis rec- ommended because you highly rated or bought item X,Z,\u2026.\u201dThus, the system depicts those items that is, X,Z,\u2026, that mostly influenced the recommendation of item Y. Bilgic and Mooney (2005) claimed that the Item style is preferable over the User style, because it allows users to accurately formulate their true opinion about an item. In case of Feature style explanations, the description of items is exploited to determine a match between a current recommended item and observed user interests. For instance, restaurants may be described by features such as location, cuisine, and cost.If a user has demonstrated a preference for Chinese cuisine and Chinese restaurants are recommended, then explana- tions will note the Chinese cuisine or the restaurants' cost aspects. As part of the work in Coba, Zanker, Rook, & Symeonidis (2018), the authors tested users' preference for different explanation styles in a study. They found that User Style explanations were the most preferred. In later studies, they also provided evidence that perception of explanations relates to personality characteristics, and they proposed model-based approaches to further personalize explanations (Coba, Rook, et al., 2019; Coba, Symeonidis, et al., 2019). 6|EXPLANATIONS IN NEURAL-SYMB OLIC LEARNING AND REASONING Neural-Symbolic Learning and Reasoning seeks to integrate principles from neural network learning with logical rea- soning (Garcez et al., 2015). Although neural networks and symbolic systems are frequently painted as two irreconcil- able paradigms, the differences actually are more subtle and less fundamental than frequently presumed. Symbolic systems operate on the symbolic level where reasoning is performed over abstract, discrete entities follow- ing logical rules. A common goal of work on symbolic systems is to model (certain aspects of) common-sense reasoning, for example, the kind of reasoning humans do in their everyday lives, which is considered to automatically allow for Rating Number of Neighbours 0 0 0 10 23FIGURE 6 Example of an explanation interface visualizing a User style explanation using the explainability power of nearest neighbors for a target user (Coba, Symeonidis, et al., 2019)CONFALONIERI ET AL . 11 of 21  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License better explainability. Neural networks, on the other hand, operate in the sub-symbolic (or connectionist) level. Individ- ual neurons do not necessarily represent a readily recognizable concept, or any discrete concept at all. Instead, theyoften model statistical regularities present in the training dataset, imbuing the system with statistical predictive capabil- ities rather than allowing it to perform sound abstract reasoning. As discussed by Besold, Garcez, Bader, et al. (2017), the integration between both levels could, therefore, bridge low-level information processing such as frequentlyencountered in perception and pattern recognition with reasoning and explanation on a higher, more cognitive level of abstraction. Achieving this integration promises a range of benefits such as representations, which are abstract, reusable, and general-purpose. Having these readily available could directly allow to tackle some of the pressing issues with current deep learning practices. While the data efficiency and sample complexity of deep learning systems tend to be very com- putationally demanding and data-heavy, symbolic approaches are less difficult in that aspect. Furthermore, deep learn-ing approaches often do not generalize well out of the sample distribution and prove to be a limited foundation fortransfer learning, whereas symbolic representation can help to overcome these limitations. Last and most importantly in this context, deep learning systems lack transparency while symbolic approaches can be designed in such a way as to follow a humanly comprehensible decision-making process (see, e.g., Garcez et al., 2019; Muggleton, Schmid, Zeller,Tamaddoni-Nezhad, & Besold, 2018). 6.1 |The neural-symbolic integration cycle Figure 7 illustrates the general idea underlying neural-symbolic approaches. On one side, there is a symbolic system, both writable and readable by human experts. On the other side, we have a neural network capable of taking full advantage of connectionist training methods. The iterative loop between both sides allows for the embedding of sym- bolic (expert) knowledge into the sub-symbolic model as well as for the extraction of learned and refined knowledgefrom the connectionist model, which can drive the data-based modification and fine-tuning of predefined rules(see e.g., Besold, Garcez, Stenning, et al., 2017). This cycle already hints at the four main pillars of neural-symbolic systems: representation, extraction, reasoning, and learning. Knowledge representation provides the mapping between the integrated symbolism and connectionism.The different forms of representations can be divided into rule-based, formula-based, and embeddings. As previously mentioned, the aim is to extract symbolic knowledge given a trained neural network for explaining and reasoning aims. There have also been efforts at integrating neural-symbolic systems into the immediate process of learning. InductiveLogic Programming (ILP), for example, develops a logic program directly from examples (Fran\u00e7a, Zaverucha, & Garcez, 2014). In addition to this, learning with logical constraints generally has shown to be beneficial for improving the data efficiency (Garnelo & Shanahan, 2019). These constraints can, for example, be integrated as a logic networkmodule on top of a regular neural network. As a consequence, models can further learn relations in-between the innerabstractions as well as guiding the model to explain its prediction. Reasoning is another essential goal of neural- symbolic systems. Successful integration aim to perform symbolic reasoning on the knowledge learned during the train- ing phase (Garcez et al., 2001). Complementing Deep Learning systems by integrating symbolic representations such as Knowledge Graphs can serve as a lingua franca between humans and AI systems. Sarker, Xie, Doran, Raymer, and Hitzler (2017) propose that methods for explanations should be seen as interactive systems. The authors present a method that enables active FIGURE 7 Illustration of the neural-symbolic cycle12 of 21 CONFALONIERI ET AL .  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License monitoring for classifiers where humans can act on given explanations. These interactive approaches become increas- ingly relevant as they provide not only extracted information, but also the ability to act on this information. Againstthat backdrop symbolic representation are taken to be vital as enablers of human-intelligible explanations. Similarly, Futia and Vetr\u00f2 (2020) state that hybrid methods will further allow for explanations targeted at nonexperts based on querying and reasoning mechanisms, which are at the core of the integrated semantic components. 6.2 |Explanations via knowledge extraction Staying close to the neural-symbolic cycle, most traditional approaches to explainability in neural-symbolic systems aim to generate a set of symbolic rules that approximates the behavior of a sub-symbolic model. The task of generating \u2014usually by via some form of learning \u2014these rules is known as knowledge extraction (Towell & Shavlik, 1993). The extraction process seeks to optimize for different metrics and criteria, namely, accuracy, fidelity, consistency, and comprehensibility. On the one hand, accuracy (i.e., a measure for the performance of the rules on the original test sets) and fidelity metrics (i.e., a measure for the ability of the rules to replicate the behavior of theoriginal sub-symbolic model) relate to performance dimensions of the extracted interpretable model. On the other hand, consistency and comprehensibility are related to the consumer of the rules: rules should be precisely representing the underlying model, but should also be easy to understand and use. This usually requires a trade-off between consis-tency and comprehensibility. The extracted rules can then be used to revise and consolidate available background knowledge (often taking the form of domain knowledge). This background knowledge can be used not only to provide meaningful semantics for theexplanations \u2014facilitating, in this way, human-machine interactions \u2014but can also be injected back into the sub- symbolic model itself in order to improve its performance (Ziegler et al., 2017). Returning to the task of knowledge extraction, two main approaches are commonly considered: one of the decom- positional , the other one pedagogical . Algorithms falling of the first type extract rules directly from the structure and weights of the sub-symbolic model. This is usually achieved by first extracting rules that approximate the behavior of each connectionist unit. Then, these unit-level rules are aggregated to form the composite rule base of the neural net- work as a whole (Andrews et al., 1995). To extract rules in such a way, these methods need access to the internal layersof the sub-symbolic model. Often this access cannot be obtained (e.g., due to intellectual property considerations), but one might still need and want to be able to extract explanations. Algorithms belonging to the class of pedagogical approaches overcome this limitation. They treat the sub-symbolic model as an \u201coracle, \u201dand extract information from input \u2013output pairings. A prime example for a pedagogical approach to knowledge extraction is Trepan (Craven & Shavlik, 1995). Trepan is a tree induction algorithm that recursively extracts decision trees from statistical classifiers, originally intended in particular for use with feed-forward neural networks (but as the original classifier is treated like ageneric oracle within the algorithm, Trepan can be considered in principle agnostic to the type of sub-symbolic model at hand). Craven and Shavlik (1995)'s approach can be seen as an extension of the ID2-of-3 algorithm (Murphy & Pazzani, 1991), a method for building decision trees from data based on \u201cm-of-n \u201drules \u2014that is, mout ofnspecified conditions must be true to send an example down a particular branch. These tests are usually built by a greedy search algorithm that starts from the single feature that maximizes information gain, and iteratively adds features to the test until information gain is no longer improved by doing so. Trepan combines this with the idea ofusing a trained machine learning classifier as oracle, in its original version targeting multi-layer perceptrons (MLPs). At each splitting step, the oracle's predicted labels are used instead of the known real labels from the input dataset. Figure 8 shows an example of a Trepan tree extracted from a trained MLP. The use of the classifier as oracle servestwo purposes: first, it helps to avoid overfitting to outliers in the training data. Second, and more importantly, it helps to build deeper trees. While Trepan extracts trees from sub-symbolic models by approximating the models to an arbitrarily close degree without having direct access to their architecture and units, there is still the problem of assessing to what extent theextracted trees are human-understandable. Recent work measured human understandability of decision trees using syntactic and cognitive metrics (Huysmans et al., 2011; Piltaver, Lu \u0161trek, Gams, & Martinc ?i/C19c-Ip \u0161i/C19c, 2016). Building on these, Confalonieri, Weyde, et al. (2020) also showed how human understandability of surrogate decision trees can beenhanced by using and integrating domain knowledge, for example, in the form of ontologies, in the decision tree extraction.CONFALONIERI ET AL . 13 of 21  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 7|DISCUSSION The historical overview provided in this article hints at a categorization of explanations. This categorization relies on the reasoning characteristics of the underlying decision system, namely, symbolic, sub-symbolic, and hybrid. Expert systems were one of the first realizations of applied AI, where the aim was to build systems able to aid humans in decision-making activities in very specific domains. Making these systems operative required a knowledgeacquisition effort in which domain knowledge had to be formally specified. This knowledge formalization was essential to develop intelligent systems able to reason, draw new conclusions, and to generate explanations. Explanations in these systems consisted of either descriptions coupled to the reasoning trace of the system, or descriptions decoupledfrom the reasoning itself, but more focused on the story behind the decision-making process itself. Since knowledge inexpert systems in most cases aimed at modeling (some aspects of) common-sense reasoning, explanations generated by these systems were usually human-understandable. Nonetheless, acquiring and modeling domain knowledge is a com- plex task, and it is subject to human interpretation and the point of view that the modeler decides to capture. Machine learning was introduced to alleviate this knowledge acquisition problem. Machine learning algorithms are indeed capable of identifying data patterns from (in most cases) large amounts of data, but this often happens at the price of creating black-box models. An explanation in these systems is mainly understood as an interpretable modelthat approximates the behavior of the underlying black-box. Explanations of this type allow users to understand why a certain conclusion or recommendation is made, by means of local, global, introspective, or counterfactual explanations. Whereas these explanations seek to maximize metrics such as accuracy (i.e., the performance of the extracted interpret- able model on the test sets), fidelity (i.e., the ability of the extracted interpretable model to replicate the behavior of the black-box model), they also have to be understandable by human users. Clearly, accuracy and understandability often compete with each other, and a reasonable trade-off must be found. For instance, a very technical and precise explana-tion (e.g., in equation form) may be appropriate for a data scientist, but not for a lay person, who prefers possibly a lessaccurate but more comprehensible representation format of the explanation. Most explainability methods nowadays are not powerful enough to give guarantees about truthfulness and closeness of the explanation with respect to the underlying model. Most metrics currently in place are lacking a reliable way ofexpressing this uncertainty. For instance, the measured fidelity is supposed to be a satisfactory proxy of closeness of the representation to the underlying model. However, this metric is limited in its capacity and capability to find FIGURE 8 Trepan tree extracted from a trained neural network predicting diabetes risk based on thePima Indians dataset (Smith, Everhart, Dickson, Knowler, & Johannes, 1988)14 of 21 CONFALONIERI ET AL .  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License semantically meaningful representations that allow for transparent reasoning, as it is solely optimizing for resemblance of the explained model. Aspects of understandability of explanations for lay users has for a long time been overlooked. As also pointed out in (Bhatt et al., 2020), the majority of deployments do not focus on the end-users, who are affected by the model, but rather on machine learning engineers, who use explainability to debug the model itself. In practice, thereis a gap between explainability and the goal of transparency, since explanations primarily serve \u201cinternal \u201dstake- holders rather than \u201cexternal \u201dones. To bridge this gap, explanations need to be human-understandable and adapt- able to different stakeholders (Ribera & Lapedriza, 2019). Trustworthy systems need to target explanations fordifferent types of user, taking into account their different goals, and providing relevant and selected (customized) information to them. This requires an approach to explainable AI that starts from a user-centered perspective. Related to this, guidelines behind Responsible AI establishing that fairness, accountability and privacy (especiallyrelated to data fusion) should be considered when implementing AI models in real environments have been dis-cussed in (Arrieta et al., 2020). Finally, while explainability has been addressed in some form or another since the mid-1980, its general under- standing and definition(s) are still under discussion. In particular, proposing a set of global desiderata for explanationsappears to be challenging, since these properties often depend on the application domain. Notwithstanding, we con- clude our discussion by pointing out some desiderata that, we believe, should be taken into account for the develop- ment of XAI systems, particularly putting the user at the heart of the entire explainability enterprise: Causal: Knowing what relationship there is between input and output, or between input features can foster human- understandable explanations. However, causal explanations are largely lacking in the machine learning literature,with only few exceptions such as (Chattopadhyay, Manupriya, Sarkar, & Balasubramanian, 2019). A related problem is then how to measure the causal understanding of an explanation (causability) (Holzinger, Langs, et al., 2019). While this is always possible for explanations of human statements, as the explanation is per-se related to a humanmodel, measuring the causal understanding of an explanation of a machine statement has to be based on a causalmodel, which is not the case for most machine learning algorithms (Holzinger et al., 2020). Counterfactual: Reviewed empirical evidence indicates that humans psychologically prefer counterfactual or contras- tive explanations (Miller, 2019). For instance, people do not ask why event Phappened, but rather why event Phap- pened instead of some event Q. It is thus important to provide explanations that are both contrastive and direct. Some preliminary steps have been taken in this direction, for example, (Mothilal et al., 2020). Issues related to the diversity and proximity of counterfactuals arise in designing counterfactual explanations. Social: Interactive transfer of knowledge is required in which information is tailored according to the recipient's background and level of expertise. Explanations can be conceived of as involving one or more explainers and explainees engaging in information transfer through dialogue, visual representation, or other means (Hilton, 1990).Conversational or argumentative processes can enhance user's inspection of explanations, and increasing user's trustin the system. Selective: Explanations do not always need to be complex representations of the real world. They should be epistemi- cally relevant for the explainee. The informational content of explanations has to be selected according to the user'sbackground and needs, as humans do not expect the complete cause of an event. Clearly, this depends on the stake- holders' profiles. For instance, explaining a medical diagnosis to a doctor requires a level of technicality, which, pre- sumably, is not necessary for most lay users. Transparent: Explanations should help the explainee in understanding the underlying logic of the decision system, and possibly identifying that the system is wrong. Nonetheless, explanations can sometimes be used to learn about the model or the training data. Therefore, a trade-off between transparency and privacy must be found when generat-ing explanations. Generally, methods to address these concerns will have to be developed for training a differentially private model that is able generate local and global explanations. Harder, Bauer, and Park (2020) is an example of methods of this kind. Semantic: If explanations are symbolically grounded \u2014by means of ontologies, conceptual networks, or knowledge graphs \u2014they can support common-sense reasoning. Formal representation and reasoning can in turn enact various forms of knowledge manipulation, such as abstraction and refinement (Confalonieri et al., 2018; Confalonieri, Galliani, et al., 2020; Keet, 2007; Lehmann & Hitzler, 2010; Troquard et al., 2018). These forms of manipulation canplay an important role when one wants to develop a system able to provide personalized explanations matching dif- ferent stakeholder profiles.CONFALONIERI ET AL . 15 of 21  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License Interactive: Explanations should be interactive, allowing the explainee to revise and consolidate some previous back- ground knowledge. The background knowledge can be used not only to provide meaningful semantics for the expla-nations, facilitating, in this way, human-machine knowledge interactions, but also injected back to the underlying model to improve its performances (e.g., Kulesza, Burnett, Wong, & Stumpf, 2015). More generally, if one cares about finding ways of success ful communication between humans and AI systems, esta- blishing a common ground of inherent log ic from the ground up appears reasonabl e. This common ground can be facilitated by the modularity that integrates perception at the sub-symbo lic level and reasoning at the sy mbolic level. Recent advance- ments in AI demonstrate robust solutions for many perception t a s k s .H o w e v e r ,t oe n f o r c es o m eu n d e r s t a n d i n go ft h em o d e l at a fundamental level, logical integra tion using symbolic repres entations will play an important role in the future. 8|CONCLUSION We reviewed the literature on explainability in AI, and provided a historical overview of how the notion of explanation has been conceived from traditional to more recent perspectives, namely in the context of expert systems, of machine learning, of recommender systems, and of neural-symbolic learning and reasoning. The main goal of this article was not to provide a comprehensive review of the literature on XAI, which can be found in, for example, (Andrews et al., 1995; Arrieta et al., 2020; Fernandez et al., 2019; Guidotti et al., 2018; Mueller et al., 2019; Nunes & Jannach, 2017; Tintarev & Masthof, 2015). We aimed, instead, at describing different notions of explanations, examples thereof, as well as properties, and metrics used to evaluate explanations. The article, thus, con-tains a wide range of references that the reader can use to \u201cnavigate \u201dthrough different notions of explanations, and gain a deeper understanding of the topic of explainable AI. In providing this historical overview, we analyzed the different notions of explanation to understand what makes for a good explanation. While we are unable to provide a single answer, one conclusion that can be drawn is that forexplanations to be human-understandable, they need to be user-centric explanations. To this end, we proposed some desiderata for explanations, that, in our opinion, are crucial for the development of human-understandable explana- tions, and, in general, of explainable intelligent systems. ACKNOWLEDGMENTS The authors want to thank Daniel Malagarriga for many valuable discussions regarding topics covered in this article. Asignificant part of the work has been carried out at Alpha Health, Telef\u00f3nica Innovaci\u00f3n Alpha, Barcelona, Spain. The authors thank the Department of Innovation, Research and University of the Autonomous Province of Bozen/Bolzano for covering the Open Access publication costs. CONFLICT OF INTEREST The authors have declared no conflict of interest for this article. AUTHOR CONTRIBUTIONS Roberto Confalonieri: Conceptualization; investigation; project administration; writing-original draft; writing-review and editing. Ludovik Coba: Investigation; writing-original draft; writing-review and editing. Benedikt Wagner: Investigation; writing-original draft; writing-review and editing. Tarek Richard Besold: Project administration; writing-review and editing. ORCID Roberto Confalonieri https://orcid.org/0000-0003-0936-2123 Tarek R. Besold https://orcid.org/0000-0002-8002-0049 ENDNOTES 1The right to explanation refers to the right of end-users and, more generally, service consumers, to ask for explana- tions of why a certain decision was reached by an AI system, such as in the case of loan allowance by a bank, recom- mendations, and medical diagnosis. For a different point of view on this, please refer to Wachter, Mittelstadt, and Floridi (2017).16 of 21 CONFALONIERI ET AL .  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 2Regulation (EU) 2016/679 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) [2016] OJ L119/1. 3The categorization of explanations based on the type of system (sub-symbolic, symbolic, and hybrid) also relates toMichie (1988)'s criteria for machine learning: weak, strong and ultra-strong. Michie's aim was to provide operationalcriteria for various qualities of machine learning that include not only predictive performance but also comprehensi- bility of learned knowledge. His weak criterion identifies the case in which the machine learner produces improved predictive performance with increasing amounts of data. The strong criterion additionally requires the learning sys-tem to provide its hypotheses in symbolic form. Last, the ultra-strong criterion extends the strong criterion by requir- ing the learner to teach the hypothesis to a human, whose performance is consequently increased to a level beyond that of the human studying the training data alone. 4A different problem is then to decide how much these models are human understandable; see for example Huysmans,Dejaeger, Mues, Vanthienen, and Baesens (2011) for a comparison of the comprehensibility of decision tables, trees,and rules. 5In Section 6, we will have a closer look at Trepan (Craven & Shavlik, 1995) as a concrete example. Trepan is a globalexplanation method that extracts decision trees from neural networks. The discussion has been relegated to Section 6 as Trepan can also be considered a neural-symbolic approach. 6Here, novelty and diversity are concepts that relate to (serendipitous) information discovery which have been studied,among others, in the fields of information search and recommender systems (Clarke et al., 2008; Vargas & Castells, 2011). RELATED WIREs ARTICLES Causability and explainability of artificial intelligence in medicine REFERENCES Alvarez-Melis, D., & Jaakkola, T. S. (2017). A causal framework for explaining the predictions of black-box sequence-to-sequence models. CoRR , abs/1707.01943. Andrews, R., Diederich, J., & Tickle, A. B. (1995). Survey and critique of techniques for extracting rules from trained artificial neural net- works. Knowledge-Based Systems ,8(6), 373 \u2013389. Apley, D. W., & Zhu, J. (2016). Visualizing the effects of predictor variables in black box supervised learning models. CoRR , abs/1612.08468. Arrieta, A. B., Rodr\u00b4 iguez, N. D., Ser, J. D., Bennetot, A., Tabik, S., Barbado, A., \u2026Herrera, F. (2020). Explainable artificial intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information Fusion ,58,8 2\u2013115 Retrieved from https://doi. org/10.1016/j.inffus.2019.12.012 Balog, K., & Radlinski, F. (2020). Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations . Proceedings of the 43rd International ACM Sigir Conference on Research and Development in Information Retrieval. Besold, T. R., Garcez, A. d., Stenning, K., van der Torre, L., & van Lambalgen, M. (2017). Reasoning in non-probabilistic uncertainty: Logic programming and neural-symbolic computing as examples. Minds and Machines ,27(1), 37 \u201377. Besold, T. R., Garcez, A. S., Bader, S., Bowman, H., Domingos, P. M., Hitzler, P., . . . Zaverucha, G. (2017). Neural-symbolic learning and rea- soning: A survey and interpretation. CoRR , abs/1711.03902. Bhatt, U., Xiang, A., Sharma, S., Weller, A., Taly, A., Jia, Y., . . . Eckersley, P. (2020). Explainable Machine Learning in Deployment . Proceed- ings of the 2020 Conference on Fairness, Accountability, and Transparency. pp. 648 \u2013657. Association for Computing Machinery: New York, NY. Retrieved from https://doi.org/10.1145/3351095.3375624 Bilgic, M., & Mooney, R. J. (2005). Explaining Recommendations: Satisfaction vs. Promotion . Proceedings of Beyond Personalization 2005: A Workshop on the Next Stage of Recommender Systems Research at the 2005 International Conference on Intelligent user Interfaces. pp. 13 \u201318. Buchanan, B. G., & Shortliffe, E. H. (1984). Rule based expert systems: The MYCIN experiments of the Stanford heuristic programming project , Boston: Addison-Wesley Longman Publishing Co., Inc. Catherine, R., Mazaitis, K., Esk\u00e9nazi, M., & Cohen, W. W. (2017). Explainable Entity-based Recommendations with Knowledge Graphs . Pro- ceedings of the Poster Track of the 11th ACM Conference on Recommender Systems (RecSys 2017). Chattopadhyay, A., Manupriya, P., Sarkar, A., & Balasubramanian, V. N. (2019). Neural Network Attributions: A Causal Perspective .I n K. Chaudhuri and R. Salakhutdinov (Eds.), Proceedings of the 36th International Conference on Machine Learning . Vol. 97, pp. 981 \u2013990. Long Beach, CA: PMLR. Retrieved from http://proceedings.mlr.press/v97/chattopadhyay19a.html Chen, L., & Pu, P. (2005). Trust Building in Recommender Agents . Proceedings of the Workshop on Web Personalization, Recommender Sys- tems and Intelligent User Interfaces at the 2nd International Conference on e-Business and Telecommunication Networks. pp. 135 \u2013145.CONFALONIERI ET AL . 17 of 21  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License Chen, X., Qin, Z., Zhang, Y., & Xu, T. (2016). Learning to Rank Features for Recommendation Over Multiple Categories . Proceedings of the 39th International ACM Sigir Conference on Research and Development in Information Retrieval. pp. 305 \u2013314. ACM: New York, NY. Clarke, C. L. A., Kolla, M., Cormack, G. V., Vechtomova, O., Ashkan, A., B\u00fcttcher, S., & MacKinnon, I. (2008). Novelty and Diversity in Infor- mation Retrieval Evaluation . Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval \u2014SIGIR'08, 659. doi: https://doi.org/10.1145/1390334.1390446 Coba, L., Rook, L., Zanker, M., & Symeonidis, P. (2019). Decision Making Strategies Differ in the Presence of Collaborative Explanations . Pro- ceedings of the 24th International Conference on Intelligent User Interfaces \u2014IUI'19. pp. 291 \u2013302. New York, NY: ACM Press. doi: https://doi.org/10.1145/3301275.3302304 Coba, L., Symeonidis, P., & Zanker, M. (2019). Personalised novel and explainable matrix factorisation. Data Knowledge Engineering ,122, 142\u2013158. Coba, L., Zanker, M., Rook, L., & Symeonidis, P. (2018). Exploring Users 'Perception ofCollaborative Explanation Styles . 2018 IEEE 20th Con- ference on Business Informatics (CBI), pp. 70 \u201378. Retrieved from http://arxiv.org/abs/1805.00977. doi: https://doi.org/10.1109/CBI.2018. 00017 Confalonieri, R., Besold, T. R., Weyde, T., Creel, K., Lombrozo, T., Mueller, S. T., & Shafto, P. (2019). What Makes a Good Explanation? Cog- nitive Dimensions of Explaining Intelligent Machines . In A. K. Goel, C. M. Seifert, & C. Freksa (Eds.), Proceedings of the 41th Annual Meeting of the Cognitive Science Society, CogSci 2019: Creativity + Cognition + Computation. pp. 25 \u201326. Montreal, Canada. cog- nitivesciencesociety.org. Retrieved from https://mindmodeling.org/cogsci2019/papers/0013/index.html Confalonieri, R., Eppe, M., Schorlemmer, M., Kutz, O., & Pen \u02dcaloza, R., & Plaza, E. (2018). Upward refinement operators for conceptual blending in the description logic EL++.Annals of Mathematics and Artificial Intelligence ,82(1), 69 \u201399. Confalonieri, R., Galliani, P., Kutz, O., Porello, D., Righetti, G., & Troquard, N. (2020). Towards Even More Irresistible Axiom Weakening . S. Borgwardt & T. Meyer (Eds.). Proceedings of the 33rd International Workshop on Description Logics (DL 2020) Colocated with the17th International Conference on Principles of Knowledge Representation and Reasoning (KR 2020). Vol. 2663. Rhodes, Greece. CEUR-WS.org. Retrieved from http://ceur-ws.org/Vol-2663/paper-8.pdf Confalonieri, R., Weyde, T., Besold, T. R., & del Prado Mart\u00edn, F. M. (2020). Trepan Reloaded: A Knowledge-driven Approach to Explaining Black-box Models . Proceedings of the 24th European Conference on Artificial Intelligence. Vol. 325, pp. 2457 \u20132464). IOS Press. doi: https://doi.org/10.3233/FAIA200378 Cosley, D., Lam, S. K., Albert, I., Konstan, J. A., & Riedl, J. (2003). Is Seeing Believing? How Recommender System Interfaces Affect Users 'Opin- ions. Proceedings of the Conference on Human Factors in Computing Systems (CHI'03). Vol. 5, pp. 585 \u2013592. Craven, M. W., & Shavlik, J. W. (1995). Extracting tree-structured representations of trained networks. In Neural Information Processing Sys- tems (pp. 24 \u201330). Cambridge, MA: MIT Press. Doran, D., Schulz, S., & Besold, T. R. (2017). What Does Explainable AI Really Mean? A New Conceptualization of Perspectives . Proceedings of the 1st International Workshop on Comprehensibility and Explanation in AI and ML Colocated with AI*IA 2017 (Vol. 2071 ). Available from CEUR-WS.org. Doshi-Velez, F., & Kim, B. (2017). Towards a rigorous science of interpretable machine learning. CoRR ,abs/1702.08608 . Doyle, D., Tsymbal, A., & Cunningham, P. (2003). A review of explanation and explanation in case-based reasoning (Technical Report). Dub- lin: Trinity College Dublin, Department of Computer Science. Fernandez, A., Herrera, F., Cordon, O., Jose del Jesus, M., & Marcelloni, F. (2019). Evolutionary fuzzy Systems for Explainable Artificial Intelligence: Why, when, what for, and where to? Computational Intelligence Magazine ,14(1), 69 \u201381. https://doi.org/10.1109/MCI.2018. 2881645 Fran\u00e7a, M. V., Zaverucha, G., & Garcez, A. S. (2014). Fast relational learning using bottom clause Propositionalization with artificial neural networks. Machine Learning ,94(1), 81 \u2013104. Friedman, J. H. (2000). Greedy function approximation: A gradient boosting machine. Annals of Statistics ,29, 1189 \u20131232. Friedrich, G., & Zanker, M. (2011). A taxonomy for generating explanations in recommender systems. AI Magazine ,32(3), 90. Retrieved from https://aaai.org/ojs/index.php/aimagazine/article/view/2365. https://doi.org/10.1609/aimag.v32i3.2365 Frosst, N., & Hinton, G. E. (2017). Distilling a Neural Network Into a Soft Decision Tree . Proceedings of the First International Workshop on Comprehensibility and Explanation in AI and ML 2017 colocated with 16th International Conference of the Italian Association for Arti-ficial Intelligence (AI*IA 2017). CEUR Workshop Proceedings. Vol. 2071. Futia, G., & Vetr\u00f2, A. (2020). On the integration of knowledge graphs into deep learning models for a more comprehensible AI \u2014Three chal- lenges for future research. Information ,11(2), 122. Retrieved from https://doi.org/10.3390/info11020122. https://doi.org/10.3390/ info11020122 Garcez, A. S., Besold, T. R., De Raedt, L., Foldiak, P., Hitzler, P., Icard, T., . . . Silver, D. L. (2015). Neural-symbolic Learning and Reasoning: Contributions and Challenges . AAAI Spring Symposium \u2014Technical Report. Garcez, A. S., Broda, K., & Gabbay, D. M. (2001). Symbolic knowledge extraction from trained neural networks: A sound approach. Artificial Intelligence , 125(1\u20132), 155 \u2013207. Garcez, A. S., Gori, M., Lamb, L. C., Serafini, L., Spranger, M., & Tran, S. N. (2019). Neural-symbolic computing: An effective methodology for principled integration of machine learning and reasoning. CoRR , abs/1905.06088. Garnelo, M., & Shanahan, M. (2019). Reconciling deep learning with symbolic artificial intelligence: Representing objects and relations. Cur- rent Opinion in Behavioral Sciences ,29,1 7\u201323.18 of 21 CONFALONIERI ET AL .  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License Guidotti, R., Monreale, A., Ruggieri, S., Turini, F., Giannotti, F., & Pedreschi, D. (2018). A survey of methods for explaining black box models. ACM Computing Surveys ,51(5), 1 \u201342. Harder, F., Bauer, M., & Park, M. (2020). Interpretable and Differentially Private Predictions . The Thirty-fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAISymposium on Educational Advances in Artificial Intelligence, EAAI 2020. pp. 4083 \u20134090. New York, NY: AAAI Press. Retrieved from https://aaai.org/ojs/index.php/AAAI/article/view/5827 Harrison, D., & Rubinfeld, D. L. (1978). Hedonic housing prices and the demand for clean air. Journal of Environmental Economics and Man- agement ,5(1), 81 \u2013102. Hasling, D. W., Clancey, W. J., & Rennels, G. (1984). Strategic explanations for a diagnostic consultation system. International Journal of Man-Machine Studies ,20(1), 3 \u201319. He, X., Liao, L., Zhang, H., Nie, L., Hu, X., & Chua, T.-S. (2017). Neural Collaborative Filtering . Proceedings of the 26th International Confer- ence on World Wide Web. pp. 173 \u2013182. Heckel, R., & Vlachos, M. (2016). Interpretable recommendations via overlapping co-clusters. CoRR ,abs/1604.02071 . Hendricks, L. A., Akata, Z., Rohrbach, M., Donahue, J., Schiele, B., & Darrell, T. (2016). Generating visual explanations. In B. Leibe, J. Matas, N. Sebe, & M. Welling (Eds.), Computer vision \u2013ECCV 2016 (pp. 3 \u201319). Cham: Springer International Publishing. Herlocker, J. L., Konstan, J. A., & Riedl, J. (2000). Explaining Collaborative Filtering Recommendations . Proceedings of the 2000 ACM Confer- ence on Computer Supported Cooperative Work \u2014CSCW'00. pp. 241 \u2013250. Hidasi, B., & Karatzoglou, A. (2018). Recurrent Neural Networks with Top-k Gains for Session-based Recommendations . Proceedings of the 27th ACM International Conference on Information and Knowledge Management. pp. 843 \u2013852. New York, NY: ACM. Hilton, D. J. (1990). Conversational processes and causal explanation. Psychological Bulletin ,107,6 5\u201381. Hoffman, R. R., Mueller, S. T., Klein, G., & Litman, J. (2018). Metrics for explainable AI: Challenges and prospects. CoRR , abs/1812.04608. Holzinger, A. (2016). Interactive machine learning for health informatics: When do we need the human-in-the-loop? Brain Informatics ,3, 119\u2013131. Retrieved from http://www.springer.com/computer/ai/journal/40708. https://doi.org/10.1007/s40708-016-0042-6 Holzinger, A., Carrington, A., & M\u00fcller, H. (2020). Measuring the quality of explanations: The system causability scale (SCS). KI\u2014K\u00fcnstliche Intelligenz (German Journal of Artificial intelligence) ,34, 193\u2013198. https://doi.org/10.1007/s13218-020-00636-z Holzinger, A., Langs, G., Denk, H., Zatloukal, K., & M\u00fcller, H. (2019). Causability and explainability of artificial intelligence in medicine. WIREs Data Mining and Knowledge Discovery ,9(4), e1312 Retrieved from https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1312 Holzinger, A., Plass, M., Kickmeier-Rust, M., Holzinger, K., Cris \u00b8an, G. C., Pintea, C. M., & Palade, V. (2019). Interactive machine learning: Experimental evidence for the human in the algorithmic loop. Applied Intelligence ,49(7), 2401 \u20132414. https://doi.org/10.1007/s10489-018- 1361-5 Huysmans, J., Dejaeger, K., Mues, C., Vanthienen, J., & Baesens, B. (2011). An empirical evaluation of the comprehensibility of decision table, tree and rule based predictive models. Decision Support Systems ,51(1), 141 \u2013154. Keet, C. M. (2007). Enhancing Comprehension of Ontologies and Conceptual Models Through Abstractions . Proceedings of the 10th Congress of the Italian Association for Artificial Intelligence (ai*ia 2007). pp. 813 \u2013821. Kim, B., Rudin, C., & Shah, J. (2014). The Bayesian Case Model: A Generative Approach for Case-Based Reasoning and Prototype Classification . Proceedings of the 27th International Conference on Neural Information Processing Systems. Vol. 2. pp. 1952 \u20131960. Cambridge, MA: MIT Press. Koren, Y., Bell, R., & Volinsky, C. (2009). Matrix factorization techniques for recommender systems. Computer ,42(8), 42 \u201349. Kouki, P., Schaffer, J., Pujara, J., O'Donovan, J., & Getoor, L. (2017). User Preferences for Hybrid Explanations . Proceedings of the Eleventh ACM Conference on Recommender Systems \u2014RecSys'17. pp. 84 \u201388. Kulesza, T., Burnett, M., Wong, W.-K., & Stumpf, S. (2015). Principles of Explanatory Debugging to Personalize Interactive Machine Learning . Proceedings of the 20th International Conference on Intelligent User Interfaces. pp. 126 \u2013137. New York, NY: Association for Computing Machinery. https://doi.org/10.1145/2678025.2701399 Kulesza, T., Stumpf, S., Burnett, M., Yang, S., Kwan, I., & Wong, W.-K. (2013). Too Much, Too Little, or Just Right? Ways Explanations Impact End Users 'Mental Models . 2013 IEEE Symposium on Visual Languages and Human Centric Computing. pp. 3 \u201310. Lacave, C., & Diez, F. J. (2004). A review of explanation methods for heuristic expert systems. The Knowledge Engineering Review ,19(2), 133\u2013146. Retrieved from. https://doi.org/10.1017/S0269888904000190 Lee, D. D., & Seung, H. S. (1999). Learning the parts of objects by nonnegative matrix factorization. Nature ,401, 788\u2013791. Lehmann, J., & Hitzler, P. (2010). Concept learning in description logics using refinement operators. Machine Learning ,78(1\u20132), 203 \u2013250. Lipton, Z. C. (2018). The mythos of model interpretability. Queue ,16(3), 30:31 \u201330:57. Lombrozo, T. (2016). Explanatory preferences shape learning and inference. Trends in Cognitive Sciences ,20(10), 748 \u2013759. Lou, Y., Caruana, R., & Gehrke, J. (2012). Intelligible Models for Classification and Regression . Proceedings of the 18th ACM KDD. pp. 150 \u2013158. ACM. Lou, Y., Caruana, R., Gehrke, J., & Hooker, G. (2013). Accurate Intelligible Models with Pairwise Interactions . Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. pp. 623 \u2013631. ACM. Lundberg, S. M., & Lee, S.-I. (2017). A unified approach to interpreting model predictions. In I. Guyon, et al. (Eds.), Advances in neural infor- mation processing systems (Vol. 30, pp. 4765 \u20134774). Red Hook, NY: Curran Associates, Inc. Michie, D. (1988). Machine Learning in the Next Five Years . Proceedings of the 3rd European Conference on European Working Session on Learning. pp. 107 \u2013122. Marshfield, MA: Pitman Publishing, Inc.CONFALONIERI ET AL . 19 of 21  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License Miller, T. (2019). Explanation in artificial intelligence: Insights from the social sciences. Artificial Intelligence ,267,1\u201338. Retrieved from http://www.sciencedirect.com/science/article/pii/S0004370218305988. https://doi.org/10.1016/j.artint.2018.07.007 Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. (1986). Explanation-based generalization: A unifying view. Machine Learning ,1(1), 47\u201380 Retrieved from http://dx.doi.org/10.1023/A:1022691120807 Molnar, C. (2019). Interpretable machine learning. Retrieved from https://christophm.github.io/interpretable-ml-book/Mothilal, R. K., Sharma, A., & Tan, C. (2020). Explaining Machine Learning Classifiers Through Diverse Counterfactual Explanations . FAT* 2020\u2014Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. pp. 607 \u2013617. New York, NY: Association for Computing Machinery. doi: https://doi.org/10.1145/3351095.3372850 Mueller, S. T., Hoffman, R. R., Clancey, W. J., Emrey, A., & Klein, G. (2019). Explanation in human-AI systems: A literature meta-review, synopsis of key ideas and publications, and bibliography for explainable AI. CoRR ,abs/1902.01876 . Retrieved from http://arxiv.org/abs/ 1902.01876 Muggleton, S. H., Schmid, U., Zeller, C., Tamaddoni-Nezhad, A., & Besold, T. (2018). Ultra-strong machine learning: Comprehensibility of programs learned with ilp. Machine Learning ,107(7), 1119 \u20131140. Murphy, P. M., & Pazzani, M. J. (1991). ID2-of-3: Constructive Induction of M-of-N Concepts for Discriminators in Decision Trees . Machine Learning Proceedings 1991. Nati, N. S., & Jaakkola, T. (2003). Weighted Low-rank Approximations . 20th International Conference on Machine Learning. pp. 720 \u2013727. AAAI Press. Nilashi, M., Jannach, D., & bin Ibrahim, O., Esfahani, M. D., & Ahmadi, H. (2016). Recommendation quality, transparency, and website quality for trust-building in recommendation agents. Electronic Commerce Research and Applications ,19,7 0\u201384. Nunes, I., & Jannach, D. (2017). A systematic review and taxonomy of explanations in decision support and recommender systems. User Modeling and User-Adapted Interaction ,27(3-5), 393 \u2013444. Retrieved from http://link.springer.com/10.1007/ s11257-017-9195-0http:// ls13-www.cs.tu-dortmund.de/homepage/publications/jannach/Journal UMUAI 2017 2.pdf. https://doi.org/10.1007/s11257-017-9195-0 Odense, S., & Garcez, A. S. (2017). Extracting m of n rules from restricted boltzmann machines. In A. Lintas, S. Rovetta, P. F. Verschure, & A. E. Villa (Eds.), Artificial neural networks and machine learning \u2014ICANN 2017 (pp. 120 \u2013127). Cham: Springer International Publishing. Papadimitriou, A., Symeonidis, P., & Manolopoulos, Y. (2012). A genralized taxonomy of explanations styles for traditional and social recom- mender systems. Data Mining and Knowledge Discovery ,24(3), 555 \u2013583. Retrieved from https://link.springer.com/content/pdf/10. 10072Fs10618-011-0215-0.pdf. https://doi.org/10.1007/s10618-011-0215-0 Park, D. H., Hendricks, L. A., Akata, Z., Schiele, B., Darrell, T., & Rohrbach, M. (2016). Attentive explanations: Justifying decisions and pointing to the evidence. CoRR , abs/1612.04757. Parliament and Council of the European Union. (2016). General data protection regulation.Peake, G., & Wang, J. (2018. Explanation mining: Post hoc interpretability of latent factor models for recommendation systems. Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. pp. 2060 \u20132069. New York, NY: Association for Computing Machinery. Retrieved from http://dl.acm.org/doi/10.1145/3219819.3220072. doi: https://doi.org/10.1145/3219819.3220072 Piltaver, R., Lu \u0161trek, M., Gams, M., & Martinc ?i/C19c-Ip \u0161i/C19c, S. (2016). What makes classification trees comprehensible? Expert Systems with Appli- cations ,62(C, 333 \u2013346. Ribeiro, M. T., Singh, S., & Guestrin, C. (2016a). Model-agnostic interpretability of machine learning. CoRR , abs/1606.05386. Ribeiro, M. T., Singh, S., & Guestrin, C. (2016b). Why Should I Trust You?: Explaining the Predictions of Any Classifier . Proceedings of the 22nd International Conference on Knowledge Discovery and Data Mining. pp. 1135 \u20131144. ACM. Ribeiro, M. T., Singh, S., & Guestrin, C. (2018). Anchors: High-precision model-agnostic explanations. In AAAI (pp. 1527 \u20131535). New Orleans, Louisiana: AAAI Press. Ribera, M., & Lapedriza, \u00c0. (2019). Can We Do Better Explanations? A Proposal of User-Centered Explainable AI . Joint Proceedings of the ACM IUI 2019 Workshops Colocated with the 24th ACM Conference on Intelligent User Interfaces (ACM IUI 2019). Vol. 2327.CEUR-WS.org. Russell, C. (2019). Efficient Search for Diverse Coherent Explanations . Fat* 2019 \u2014Proceedings of the 2019 Conference on Fairness, Account- ability, and Transparency. pp. 20 \u201328. doi: https://doi.org/10.1145/3287560.3287569 Samek, W., Montavon, G., Vedaldi, A., Hansen, L. K., & M\u00fcller, K.-R. (2019). Explainable artificial intelligence: Understanding, visualizing and interpreting deep learning models , Basel, Switzerland: Springer International Publishing. Sarker, M. K., Xie, N., Doran, D., Raymer, M., & Hitzler, P. (2017). Explaining Trained Neural Networks with Semantic Web Technologies: First Steps . Ceur Workshop Proceedings. Seo, S., Huang, J., Yang, H., & Liu, Y. (2017). Interpretable Convolutional Neural Networks with Dual Local and Global Attention for Review Rating Prediction . Proceedings of the Eleventh ACM Conference on Recommender Systems. pp. 297 \u2013305. New York, NY: ACM. Singh, J., & Anand, A. (2018). Posthoc interpretability of learning to rank models using secondary training data. arXiv :1806.11330. Smith, J. W., Everhart, J. E., Dickson, W. C., Knowler, W. C., & Johannes, R. S. (1988). Using the ADAP Learning Algorithm to Forecast the Onset of Diabetes Mellitus . Proceedings \u2014Annual Symposium on Computer Applications in Medical Care. Tintarev, N., & Masthof, J. (2015). Explaining recommendations: Design and evaluation. In Recommender systems handbook (pp. 217 \u2013253). Boston, MA: Springer. https://doi.org/10.1007/978-1-4899-7637-6 Towell, G. G., & Shavlik, J. W. (1993). Extracting refined rules from knowledge-based neural networks. Machine Learning ,13(1), 71 \u2013101.20 of 21 CONFALONIERI ET AL .  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License Troquard, N., Confalonieri, R., Galliani, P., Pe\u00f1aloza, R., Porello, D., & Kutz, O. (2018). Repairing Ontologies via Axiom Weakening .I nS .A . McIlraith & K. Q. Weinberger (Eds.), Proceedings of the Thirty-second AAAI Conference on Artificial Intelligence, (AAAI-18),pp. 1981 \u20131988. New Orleans, Louisiana. AAAI Press. Retrieved from https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/ 17189 Vargas, S., & Castells, P. (2011). Rank and Relevance in Novelty and Diversity Metrics for Recommender Systems . Proceedings of the Fifth ACM Conference on Recommender Systems \u2014RECSYS'11. p. 109. New York, NY: ACM Press. doi: https://doi.org/10.1145/2043932.2043955 Wachter, S., Mittelstadt, B., & Floridi, L. (2017). Why a right to explanation of automated decision-making does not exist in the general data protection regulation. International Data Privacy Law ,7(2), 76 \u201399. https://doi.org/10.1093/idpl/ipx005 Wachter, S., Mittelstadt, B., & Russell, C. (2018). Counterfactual explanations without opening the black box: Automated decisions and the GDPR. Harvard Journal of Law & Technology ,31(2), 841 \u2013887. Wang, X., He, X., Feng, F., Nie, L., & Chua, T. (2018). TEM: Tree-Enhanced Embedding Model for Explainable Recommendation . Proceedings of the 2018 World Wide Web Conference. pp. 1543 \u20131552. Wick, M. R., & Thompson, W. B. (1992, March). Reconstructive expert system explanation. Artificial Intelligence ,54(1\u20132), 33 \u201370. Zhang, Y. (2015). Incorporating Phrase-level Sentiment Analysis on Textual Reviews for Personalized Recommendation . Proceedings of the Eighth ACM International Conference on Web Search and Data Mining. pp. 435 \u2013440. New York, NY: ACM. Zhang, Y., Ai, Q., Chen, X., & Wang, P. (2018). Learning over knowledge-base embeddings for recommendation. CoRR ,abs/1803.06540 . Zhou, Z.-H., Jiang, Y., & Chen, S.-F. (2003). Extracting symbolic rules from trained neural network ensembles. AI Communications ,16 (1), 3 \u201315. Ziegler, K., Caelen, O., Garchery, M., Granitzer, M., He-Guelton, L., Jurgovsky, J., . . . Zwicklbauer, S. (2017). Injecting Semantic Background Knowledge into Neural Networks Using Graph Embeddings . 2017 IEEE 26th International Conference on Enabling Technologies: Infra- structure for Collaborative Enterprises (WETICE). pp. 200 \u2013205. How to cite this article: Confalonieri R, Coba L, Wagner B, Besold TR. A historical perspective of explainable Artificial Intelligence. WIREs Data Mining Knowl Discov . 2021;11:e1391. https://doi.org/10.1002/widm.1391CONFALONIERI ET AL . 21 of 21  19424795, 2021, 1, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391 by INASP/HINARI - PAKISTAN, Wiley Online Library on [05/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License ", "11": "A timely and accurate heart failure diagnosis  is the gateway to effective treatment that  can improve quality of life and prognosis  for patients;1 however, almost 80% of  people receive an initial diagnosis following  emergency admission to hospital.2 This is  distressing for patients and families, costly  to the NHS, and usually denotes progression  to a later stage of disease. The British Heart  Foundation has called for earlier diagnosis  of heart failure to be prioritised,3 but what  are the challenges for primary care? HEART FAILURE BURDEN Around a million people in England  are living with heart failure, and nearly  200 000 are newly diagnosed each year.4  Patients typically experience increasing  breathlessness, fatigue, and leg swelling,  which can impair their quality of life. The  outlook following a heart failure diagnosis  is worse than many common cancers  and survival rates have not improved  substantially in the last two decades.5 The  NHS spends around \u00a32 billion per year on  heart failure care, with most of the cost  incurred through emergency department  attendance, prolonged hospital stay, and  frequent readmissions.1 Families and  carers are also impacted and can often play  a vital role in supporting patients following  diagnosis. TREATABLE CONDITION Heart failure is categorised according to  left ventricular ejection fraction to guide  management: heart failure with reduced  ejection fraction (HFrEF) and heart  failure with preserved ejection fraction  (HFpEF).1 There is a substantial evidence  base for HFrEF treatments, such as  angiotensin-converting enzyme inhibitors,  beta-?blockers, and mineralocorticoid  receptor antagonists, which can improve  quality of life, reduce hospital admissions,  and increase survival. Newer drugs  such as sacubitril/valsartan, ivabradine,  and most recently sodium-?glucose cotransporter-2 (SGLT2) inhibitors, are  also available for specialist initiation.  Prognostically beneficial treatments for  HFpEF have been limited until recently  when SGLT2 inhibitors dapagliflozin and  empagliflozin showed promising results in  clinical trials.6 Treatment of valvular heart  disease and arrhythmias is also important  if a correctable cause of heart failure is  found. For all types of heart failure, diuretic  therapy is vital to relieve fluid overload. NATRIURETIC PEPTIDE TESTING The National Institute for Health and  Care Excellence (NICE) chronic heart  failure guideline recommends that  patients presenting to primary care with  symptoms suggestive of heart failure  undergo natriuretic peptide testing.1 B-type  natriuretic peptide (BNP) and NT-proBNP  are both clinically available and perform  similarly for diagnosis.7 If the natriuretic  peptide level is raised, the patient requires  referral for echocardiography and further  assessment by a specialist to confirm the  diagnosis of heart failure. Thresholds for  referral differ between European and NICE  guidelines, and this is further explored in  our accompanying diagnostic accuracy  study in this edition of the BJGP .8 A very  high natriuretic peptide level is associated  with an increased risk of hospitalisation and  worse prognosis, so NICE recommends  patients with a NT-proBNP level >2000 ng/L  be seen within 2 weeks, and all patients  with a NT-proBNP >400  ng/L be seen  within 6 weeks.1 DIAGNOSTIC DELAYS The pathway to heart failure diagnosis is complex, however, and dependent on  patient, clinician, and system factors  that can lead to delays. The mean age at  diagnosis is 77 years, and most patients  have other long-term conditions and take  several medications.4 The main symptoms  of heart failure are also common, with a  variety of causes, and awareness of the  condition among the public is limited.  Qualitative interviews with people recently  diagnosed with heart failure found  participants \u2018normalised\u2019 symptoms such  as breathlessness, putting it down to old  age or another condition, which led to a  delay in accessing medical services.9 The  term \u2018heart failure\u2019 itself was perceived to  be frightening and often misunderstood. There is also evidence of delays between  patients first presenting to primary care  with symptoms and subsequent referral  to specialist services.10 Clinicians may  initially link common symptoms such as  breathlessness to existing disorders (for  example, lung disease) and optimise  management before considering an  alternative diagnosis. A normal natriuretic  peptide level can be helpful to rule out a  heart failure diagnosis but universal access  to rapid testing is needed. A recent large  study using primary care data to analyse  trends in natriuretic peptide testing between  2004 and 2018 showed testing increased  during the study period, with NT-proBNP  being the favoured test. However, only one  in four patients had a natriuretic peptide test  prior to heart failure diagnosis.11  There are also capacity issues in  echocardiography services, and analysis of  primary care data showed that timeframes  recommended by NICE for patients to  receive a formal heart failure diagnosis  through imaging and specialist assessment  were not being achieved in practice.10 RAISING AWARENESS  Despite being a malignant condition,  prioritisation has not been given to  improving understanding of heart failure Earlier heart failure diagnosis in primary careEditorials 4  British Journal of General Practice, January 2023\u201cThe British Heart Foundation has called for earlier  diagnosis of heart failure to be prioritised, but what are  the challenges for primary care?\u201d \u201cDespite being a malignant condition, prioritisation has  not been given to improving understanding of heart  failure among the public.\u201damong the public. Cancer awareness  campaigns have successfully highlighted  the symptoms of common cancers and  a similar approach could be helpful in  heart failure to encourage symptomatic  patients to seek help. Inspired by the \u2018FAST\u2019  acronym for stroke, we created BEAT-HF  \u2014 Breathless, Exhausted, Ankle Swelling,  Time for a simple blood test12 \u2014 with the  aim to raise awareness among the public,  patients, and healthcare workers in  primary and secondary care to consider a  diagnosis of heart failure. The patient-led  heart failure charity Pumping Marvellous  Foundation is successfully leading the  BEAT-HF campaign and we hope the  acronym will be adopted more generally  across the healthcare system. ACHIEVING EARLIER DIAGNOSIS Heart failure is a common, costly,  yet treatable clinical syndrome; but  while guidelines offer clear pathways  for diagnosis, the complexity and  multimorbidity of patients in primary  care means the reality of the diagnostic  journey is far more challenging. Changes across the patient pathway are required  to prevent admissions to hospital and  facilitate diagnosis at a more treatable  stage. Greater public awareness of heart  failure symptoms, clinicians considering  the diagnosis in patients with new-onset  or worsening breathlessness, increasing  use of natriuretic peptide testing to  inform decision making, investment in  echocardiography capacity, and access  to rapid diagnostic referral pathways are  all needed to achieve earlier diagnosis in  primary care. Clare J Taylor,  (ORCID: 0000-0001-8926-2581), GP and National  Institute for Health and Care Research Academic  Clinical Lecturer, Nuffield Department of Primary  Care Health Sciences, University of Oxford, Oxford. Provenance Commissioned; not externally peer reviewed.  Competing interests Clare J Taylor reports personal fees from Roche  outside the submitted work. DOI: https://doi.org/10.3399/bjgp23X731481ADDRESS FOR CORRESPONDENCE Clare J Taylor Nuffield Department of Primary Care Health Sciences,  Radcliffe Primary Care Building, Radcliffe Observatory  Quarter, University of Oxford, Woodstock Road, Oxford  OX2 6GG, UK. Email: clare.taylor@phc.ox.ac.uk  @clarejtaylor British Journal of General Practice, January 2023  5REFERENCES 1. National Institute for Health and Care  Excellence. Chronic heart failure in adults:  diagnosis and management. NG106.  London:  NICE, 2018. www.nice/org.uk/guidance/ng106  (accessed 5 Dec 2022). 2. Bottle A, Kim D, Aylin P , et al . Routes to diagnosis  of heart failure: observational study using linked  data in England. Heart  2018; 104(7): 600\u2013605. 3. British Heart Foundation. Heart failure: a  blueprint for change.  https://www.bhf.org.uk/-/ media/files/health-intelligence/heart-failure- a-blueprint-for-change.pdf (accessed 5 Dec  2022). 4. Conrad N, Judge A, Tran J, et al . Temporal  trends and patterns in heart failure incidence: a  population-based study of 4 million individuals.  Lancet  2018; 391(10120): 572\u2013580. 5. Taylor CJ, Ord\u00f3\u00f1ez-Mena JM, Roalfe AK, et  al. Trends in survival after a diagnosis of heart  failure in the United Kingdom 2000\u20132017:  population based cohort study. BMJ  2019; 364:   I223. 6. Vaduganathan M, Docherty KF, Claggett BL,  et al . SGLT-2 inhibitors in patients with heart  failure: a comprehensive meta-analysis of five  randomised controlled trials. Lancet 2022;  400(10354): 757\u2013767. 7. Booth RA, Hill SA, Don-Wauchope A, et al .  Performance of BNP and NT-proBNP for  diagnosis of heart failure in primary care  patients: a systematic review. Heart Fail Rev   2014; 19(4): 439\u2013451. 8. Taylor CJ, Ord\u00f3\u00f1ez-Mena JM, Lay-Flurrie SL, et  al. Natriuretic peptide testing and heart failure  diagnosis in primary care: diagnostic accuracy  study. Br J Gen Pract  2022; DOI: https://doi. org/10.3399/BJGP.2022.0278. 9. Taylor CJ, Hobbs FD, Marshall T, et al . From  breathless to failure: symptom onset and  diagnostic meaning in patients with heart failure  \u2014 a qualitative study. BMJ Open  2017; 7(3):   e013648. 10. Hayhoe B, Kim D, Aylin PP , et al . Adherence  to guidelines in management of symptoms  suggestive of heart failure in primary care. Heart   2019; 105(9): 678\u2013685. 11. Roalfe AK, Lay-Flurrie SL, Ord\u00f3\u00f1ez-Mena JM, et  al. Long term trends in natriuretic peptide testing  for heart failure in UK primary care: a cohort  study. Eur Heart J  2021; 43(9): 881\u2013891. 12. Taylor CJ, Hartshorne-Evans N,  Satchithananda D, Hobbs FDR. FASTer  diagnosis: time to BEAT heart failure. BJGP  Open  2021; DOI: https://doi.org/10.3399/ BJGPO.2021.0006.\u201cInspired by the \u2018FAST\u2019 acronym for stroke, we created  BEAT-HF \u2014 Breathless, Exhausted, Ankle Swelling,  Time for a simple blood test \u2014 with the aim to raise  awareness among the public, patients, and healthcare  workers in primary and secondary care to consider a  diagnosis of heart failure.\u201d", "12": "25 years of time series forecasting Jan G. De Gooijera,1, Rob J. Hyndmanb,* aDepartment of Quantitative Economics, University of Amsterdam, Roetersstraat 11, 1018 WB Amsterdam, The Netherlands bDepartment of Econometrics and Business Statistics, Monash University, VIC 3800, Australia Abstract We review the past 25 years of research into time series forecasting. In this silver jubilee issue, we naturally highlight results published in journals managed by the International Institute of Forecasters ( Journal of Forecasting 1982\u20131985 and International Journal of Forecasting 1985\u20132005). During this period, over one third of all papers published in these journals concerned time series forecasting. We also review highly influential works on time series forecasting that have been published elsewhere during this period. Enormous progress has been made in many areas, but we find that there are a large number oftopics in need of further development. We conclude with comments on possible future research directions in this field.D2006 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved. Keywords: Accuracy measures; ARCH; ARIMA; Combining; Count data; Densities; Exponential smoothing; Kalman filter; Long memory; Multivariate; Neural nets; Nonlinearity; Prediction intervals; Regime-switching; Robustness; Seasonality; State space; Structural models; Transfer function; Univariate; VAR 1. Introduction The International Institute of Forecasters (IIF) was established 25 years ago and its silver jubilee provides an opportunity to review progress on time seriesforecasting. We highlight research published injournalsspons oredbytheInstitute ,althoughwealso cover key publications in other journals. In 1982, theIIF set up the Journal of Forecasting (JoF), publishedwith John Wiley and Sons. After a break with Wileyin 1985, 2the IIF decided to start the International Journal of Forecasting (IJF), published with Elsevier since 1985. This paper provides a selective guide tothe literature on time series forecasting, covering theperiod 1982\u20132005 and summarizing over 940 papersincluding about 340 papers published under the bIIF- flag Q. The proportion of papers that concern time series forecasting has been fairly stable over time. Wealso review key papers and books published else- where that have been highly influential to various developments in the field. The works referenced 0169-2070/$ - see front matter D2006 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved. doi:10.1016/j. ijforecast .2006.01.001* Corresponding author. Tel.: +61 3 9905 2358; fax: +61 3 9905 5474. E-mail  addresses:  j.g.degooijer @uva.n l(J.G.DeGooijer), Rob.Hyndm an@buseco.m onash.edu. au(R.J.Hyndman). 1Tel.: +31 20 525 4244; fax: +31 20 525 4349.2The IIF was involved with JoF issue 44:1 (1985).International Journal of Forecasting 22 (2006) 443\u2013473 www.elsevier.com/locate/ijforecastcomprise 380 journal papers and 20 books and monographs. It was felt to be convenient to first classify the papers according to the models (e.g., exponentialsmoothing, ARIMA) introduced in the time seriesliterature, rather than putting papers under a headingassociated with a particular method. For instance,Bayesian methods in general can be applied to all models. Papers not concerning a particular model were then classified according to the various problems(e.g., accuracy measures, combining) they address. Inonly a few cases was a subjective decision needed onour part to classify a paper under a particular sectionheading. To facilitate a quick overview in a particularfield, the papers are listed in alphabetical order undereach of the section headings. Determining what to include and what not to include in the list of references has been a problem.There may be papers that we have missed and papersthat are also referenced by other authors in this SilverAnniversary issue. As such the review is somewhatbselective Q, although this does not imply that a particular paper is unimportant if it is not reviewed. The review is not intended to be critical, but rather a (brief) historical and personal tour of the main developments. Still, a cautious reader may detectcertain areas where the fruits of 25 years of intensiveresearch interest has been limited. Conversely, clearexplanations for many previously anomalous timeseries forecasting results have been provided by theend of 2005. Section 13 discusses some currentresearch directions that hold promise for the future, but of course the list is far from exhaustive. 2. Exponential smoothing 2.1. Preamble Twenty-five years ago, exponential smoothing methods were often considered a collection of ad hoc techniques for extrapolating various types ofunivariate time series. Although exponential smooth-ing methods were widely used in business andindustry, they had received little attention fromstatisticians and did not have a well-developedstatistical foundation. These methods originated inthe 1950s and 1960s with the work of Brown (1959,1963) ,Holt (1957, reprinted 2004) ,a n d Winters (1960) .Pegels (1969) provided a simple but useful classification of the trend and the seasonal patternsdepending on whether they are additive (linear) ormultiplicative (nonlinear). Muth (1960) was the first to suggest a statistical foundation for simple exponential smoothing (SES)by demonstrating that it provided the optimal fore- casts for a random walk plus noise. Further steps towards putting exponential smoothing within astatistical framework were provided by Box and Jenkins (1970) ,Roberts (1982) , and Abraham and Ledolter (1983, 1986) , who showed that some linear exponential smoothing forecasts arise as special casesof ARIMA models. However, these results did notextend to any nonlinear exponential smoothing methods. Exponential smoothing methods received a boost from two papers published in 1985, which laid thefoundation for much of the subsequent work in thisarea. First, Gardner (1985) provided a thorough review and synthesis of work in exponential smooth-ing to that date and extended Pegels\u2019 classification toinclude damped trend. This paper brought together a lot of existing work which stimulated the use of these methods and prompted a substantial amount ofadditional research. Later in the same year, Snyder (1985) showed that SES could be considered as arising from an innovation state space model (i.e., amodel with a single source of error). Although thisinsight went largely unnoticed at the time, in recentyears it has provided the basis for a large amount of work on state space models underlying exponential smoothing methods. Most of the work since 1980 has involved studying the empirical properties of the methods (e.g., Barto- lomei & Sweet, 1989; Makridakis & Hibon, 1991 ), proposals for new methods of estimation or initiali-zation ( Ledolter & Abraham, 1984 ), evaluation of the forecasts ( McClain, 1988; Sweet & Wilson, 1988 ), or has concerned statistical models that can be consid- ered to underly the methods (e.g., McKenzie, 1984 ). The damped multiplicative methods of Taylor (2003) provide the only genuinely new exponential smooth-ing methods over this period. There have, of course,been numerous studies applying exponential smooth-ing methods in various contexts including computercomponents ( Gardner, 1993 ), air passengers ( Grubb &J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 444Masa, 2001 ), and production planning ( Miller & Liberatore, 1993 ). TheHyndman, Koehler, Snyder, and Grose (2002) taxonomy (extended by Taylor, 2003 ) provides a helpful categorization for describing the variousmethods. Each method consists of one of five typesof trend (none, additive, damped additive, multiplica-tive, and damped multiplicative) and one of three types of seasonality (none, additive, and multiplica- tive). Thus, there are 15 different methods, the bestknown of which are SES (no trend, no seasonality),Holt\u2019s linear method (additive trend, no seasonality),Holt\u2013Winters\u2019 additive method (additive trend, addi-tive seasonality), and Holt\u2013Winters\u2019 multiplicativemethod (additive trend, multiplicative seasonality). 2.2. Variations Numerous variations on the original methods have been proposed. For example, Carreno and Madina- veitia (1990) and Williams and Miller (1999) pro- posed modifications to deal with discontinuities, andRosas and Guerrero (1994) looked at exponential smoothing forecasts subject to one or more con- straints. There are also variations in how and when seasonal components should be normalized. Lawton (1998) argued for renormalization of the seasonal indices at each time period, as it removes bias inestimates of level and seasonal components. Slightlydifferent normalization schemes were given byRoberts (1982) and McKenzie (1986) .Archibald and Koehler (2003) developed new renormalization equations that are simpler to use and give the same point forecasts as the original methods. One useful variation, part way between SES and Holt\u2019s method, is SES with drift. This is equivalent toHolt\u2019s method with the trend parameter set to zero.Hyndman and Billah (2003) showed that this method was also equivalent to Assimakopoulos and Nikolo- poulos (2000) bTheta method Qwhen the drift param- eter is set to half the slope of a linear trend fitted to the data. The Theta method performed extremely well inthe M3-competition, although why this particularchoice of model and parameters is good has not yetbeen determined. There has been remarkably little work in developing multivariate versions of the exponential smoothingmethods for forecasting. One notable exception isPfeffermann and Allon (1989) who looked at Israeli tourism data. Multivariate SES is used for processcontrol charts (e.g., Pan, 2005 ), where it is called bmultivariate exponentially weighted moving averages Q, but here the focus is not on forecasting. 2.3. State space models Ord, Koehler, and Snyder (1997) built on the work ofSnyder (1985) by proposing a class of innovation state space models which can be considered asunderlying some of the exponential smoothing meth-ods. Hyndman et al. (2002) and Taylor (2003) extended this to include all of the 15 exponentialsmoothing methods. In fact, Hyndman et al. (2002) proposed two state space models for each method, corresponding to the additive error and the multipli- cative error cases. These models are not unique andother related state space models for exponentialsmoothing methods are presented in Koehler, Snyder, and Ord (2001) and Chatfield, Koehler, Ord, and Snyder (2001) . It has long been known that some ARIMA models give equivalent forecasts to the linearexponential smoothing methods. The significance of the recent work on innovation state space models is that the nonlinear exponential smoothing methods canalso be derived from statistical models. 2.4. Method selection Gardner and McKenzie (1988) provided some simple rules based on the variances of differenced time series for choosing an appropriate exponential smoothing method. Tashman and Kruk (1996) com- pared these rules with others proposed by Collopy and Armstrong (1992) and an approach based on the BIC. Hyndman et al. (2002) also proposed an information criterion approach, but using the underlying state space models. 2.5. Robustness The remarkably good forecasting performance of exponential smoothing methods has been addressedby several authors. Satchell and Timmermann (1995) andChatfield et al. (2001) showed that SES is optimal for a wide range of data generating processes. In asmall simulation study, Hyndman (2001) showed thatJ.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 445simple exponential smoothing performed better than first order ARIMA models because it is not so subjectto model selection problems, particularly when dataare non-normal. 2.6. Prediction intervals One of the criticisms of exponential smoothing methods 25 years ago was that there was no way to produce prediction intervals for the forecasts. The firstanalytical approach to this problem was to assume thatthe series were generated by deterministic functions oftime plus white noise ( Brown, 1963; Gardner, 1985; McKenzie, 1986; Sweet, 1985 ). If this was so, a regression model should be used rather than expo-nential smoothing methods; thus, Newbold and Bos (1989) strongly criticized all approaches based on this assumption. Other authors sought to obtain prediction intervals via the equivalence between exponential smoothingmethods and statistical models. Johnston and Harrison (1986) found forecast variances for the simple and Holt exponential smoothing methods for state spacemodels with multiple sources of errors. Yar and Chatfield (1990) obtained prediction intervals for the additive Holt\u2013Winters\u2019 method by deriving theunderlying equivalent ARIMA model. Approximateprediction intervals for the multiplicative Holt\u2013Win-ters\u2019 method were discussed by Chatfield and Yar (1991) , making the assumption that the one-step- ahead forecast errors are independent. Koehler et al. (2001) also derived an approximate formula for the forecast variance for the multiplicative Holt\u2013Winters\u2019 method, differing from Chatfield and Yar (1991) only in how the standard deviation of the one-step-aheadforecast error is estimated. Ord et al. (1997) andHyndman et al. (2002) used the underlying innovation state space model tosimulate future sample paths, and thereby obtainedprediction intervals for all the exponential smoothing methods. Hyndman, Koehler, Ord, and Snyder (2005) used state space models to derive analytical prediction intervals for 15 of the 30 methods,including all the commonly used methods. Theyprovide the most comprehensive algebraic approachto date for handling the prediction distributionproblem for the majority of exponential smoothingmethods.2.7. Parameter space and model properties It is common practice to restrict the smoothing parameters to the range 0 to 1. However, now thatunderlying statistical models are available, the natural(invertible) parameter space for the models can beused instead. Archibald (1990) showed that it is possible for smoothing parameters within the usual intervals to produce non-invertible models. Conse- quently, when forecasting, the impact of change in thepast values of the series is non-negligible. Intuitively,such parameters produce poor forecasts and theforecast performance deteriorates. Lawton (1998) also discussed this problem. 3. ARIMA models 3.1. Preamble Early attempts to study time series, particularly in the 19th century, were generally characterized by theidea of a deterministic world. It was the majorcontribution of Yule (1927) which launched the notion of stochasticity in time series by postulating that every time series can be regarded as the realization of astochastic process. Based on this simple idea, anumber of time series methods have been developedsince then. Workers such as Slutsky, Walker, Yaglom,and Yule first formulated the concept of autoregres-sive (AR) and moving average (MA) models. Wold\u2019sdecomposition theorem led to the formulation and solution of the linear forecasting problem of Kolmo- gorov (1941) . Since then, a considerable body of literature has appeared in the area of time series,dealing with parameter estimation, identification,model checking, and forecasting; see, e.g., Newbold (1983) for an early survey. The publication Time Series Analysis: Forecasting and Control byBox and Jenkins (1970) 3integrated the existing knowledge. Moreover, these authors developed a coherent, versatile three-stage iterative 3The book by Box, Jenkins, and Reinsel (1994) with Gregory Reinsel as a new co-author is an updated version of the bclassic Q Box and Jenkins (1970) text. It includes new material on intervention analysis, outlier detection, testing for unit roots, andprocess control.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 446cycle for time series identification, estimation, and verification (rightly known as the Box\u2013Jenkinsapproach). The book has had an enormous impacton the theory and practice of modern time seriesanalysis and forecasting. With the advent of thecomputer, it popularized the use of autoregressiveintegrated moving average (ARIMA) models and theirextensions in many areas of science. Indeed, forecast- ing discrete time series processes through univariate ARIMA models, transfer function (dynamic regres-sion) models, and multivariate (vector) ARIMAmodels has generated quite a few IJFpapers. Often these studies were of an empirical nature, using one ormore benchmark methods/models as a comparison.Without pretending to be complete, Table 1 gives a list of these studies. Naturally, some of these studies aremore successful than others. In all cases, the forecasting experiences reported are valuable. Theyhave also been the key to new developments, whichmay be summarized as follows. 3.2. Univariate The success of the Box\u2013Jenkins methodology is founded on the fact that the various models can, between them, mimic the behaviour of diverse typesof series\u2014and do so adequately without usuallyrequiring very many parameters to be estimated inthe final choice of the model. However, in the mid-sixties, the selection of a model was very much amatter of the researcher\u2019s judgment; there was noalgorithm to specify a model uniquely. Since then, Table 1 A list of examples of real applications Dataset Forecast horizon Benchmark Reference Univariate ARIMA Electricity load (min) 1\u201330 min Wiener filter Di Caprio, Genesio, Pozzi, and Vicino (1983) Quarterly automobile insurance paid claim costs8 quarters Log-linear regression Cummins and Griepentrog (1985) Daily federal funds rate 1 day Random walk Hein and Spudeck (1988) Quarterly macroeconomic data 1\u20138 quarters Wharton model Dhrymes and Peristiani (1988) Monthly department store sales 1 month Simple exponential smoothing Geurts and Kelly (1986 ,1990) , Pack (1990) Monthly demand for telephone services 3 years Univariate state space Grambsch and Stahel (1990) Yearly population totals 20\u201330 years Demographic models Pflaumer (1992) Monthly tourism demand 1\u201324 months Univariate state space, multivariate state spacedu Preez and Witt (2003) Dynamic regression/transfer function Monthly telecommunications traffic 1 month Univariate ARIMA Layton, Defris, and Zehnwirth (1986) Weekly sales data 2 years n.a. Leone (1987) Daily call volumes 1 week Holt\u2013Winters Bianchi, Jarrett, and Hanumara (1998) Monthly employment levels 1\u201312 months Univariate ARIMA Weller (1989) Monthly and quarterly consumption of natural gas1 month/1 quarter Univariate ARIMA Liu and Lin (1991) Monthly electricity consumption 1\u20133 years Univariate ARIMA Harris and Liu (1993) VARIMA Yearly municipal budget data Yearly (in-sample) Univariate ARIMA Downs and Rocke (1983) Monthly accounting data 1 month Regression, univariate, ARIMA, transfer functionHillmer, Larcker, and Schroeder (1983) Quarterly macroeconomic data 1\u201310 quarters Judgmental methods, univariate ARIMAO\u00a8ller (1985) Monthly truck sales 1\u201313 months Univariate ARIMA, Holt\u2013Winters Heuts and Bronckers (1988) Monthly hospital patient movements 2 years Univariate ARIMA, Holt\u2013Winters Lin (1989) Quarterly unemployment rate 1\u20138 quarters Transfer function Edlund and Karlsson (1993)J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 447many techniques and methods have been suggested to add mathematical rigour to the search process of anARMA model, including Akaike\u2019s information crite-rion (AIC), Akaike\u2019s final prediction error (FPE), andthe Bayes information criterion (BIC). Often thesecriteria come down to minimizing (in-sample) one-step-ahead forecast errors, with a penalty term foroverfitting. FPE has also been generalized for multi- step-ahead forecasting (see, e.g., Bhansali, 1996, 1999 ), but this generalization has not been utilized by applied workers. This also seems to be the casewith criteria based on cross-validation and split-sample validation (see, e.g., West, 1996 ) principles, making use of genuine out-of-sample forecast errors;seePen\u02dca and Sa \u00b4nchez (2005) for a related approach worth considering. There are a number of methods (cf. Box et al., 1994 ) for estimating the parameters of an ARMA model. Although these methods are equivalentasymptotically, in the sense that estimates tend tothe same normal distribution, there are large differ-ences in finite sample properties. In a comparativestudy of software packages, Newbold, Agiakloglou, and Miller (1994) showed that this difference can be quite substantial and, as a consequence, may influ- ence forecasts. They recommended the use of fullmaximum likelihood. The effect of parameter esti-mation errors on the probability limits of the forecastswas also noticed by Zellner (1971) . He used a Bayesian analysis and derived the predictive distri-bution of future observations by treating the param-eters in the ARMA model as random variables. More recently, Kim (2003) considered parameter estimation and forecasting of AR models in small samples. Hefound that (bootstrap) bias-corrected parameter esti-mators produce more accurate forecasts than the leastsquares estimator. Landsman and Damodaran (1989) presented evidence that the James-Stein ARIMAparameter estimator improves forecast accuracyrelative to other methods, under an MSE loss criterion. If a time series is known to follow a univariate ARIMA model, forecasts using disaggregated obser-vations are, in terms of MSE, at least as good asforecasts using aggregated observations. However, inpractical applications, there are other factors to beconsidered, such as missing values in disaggregatedseries. Both Ledolter (1989) and Hotta (1993)analyzed the effect of an additive outlier on the forecast intervals when the ARIMA model parametersare estimated. When the model is stationary, Hotta and Cardoso Neto (1993) showed that the loss of efficiency using aggregated data is not large, even ifthe model is not known. Thus, prediction could bedone by either disaggregated or aggregated models. The problem of incorporating external (prior) information in the univariate ARIMA forecasts has been considered by Cholette (1982) ,Guerrero (1991) , andde Alba (1993) . As an alternative to the univariate ARIMA methodology, Parzen (1982) proposed the ARARMA methodology. The key idea is that a time series istransformed from a long-memory AR filter to a short-memory filter, thus avoiding the bharsher Qdifferenc- ing operator. In addition, a different approach to the dconventional TBox\u2013Jenkins identification step is used. In the M-competition ( Makridakis et al., 1982 ), the ARARMA models achieved the lowest MAPE for longer forecast horizons. Hence, it issurprising to find that, apart from the paper by Meade and Smith (1985) , the ARARMA methodology has not really taken off in applied work. Its ultimate value may perhaps be better judged by assessing the study byMeade (2000) who compared the forecasting performance of an automated and non-automatedARARMA method. Automatic univariate ARIMA modelling has been shown to produce one-step-ahead forecasts as accu-rate as those produced by competent modellers ( Hill & Fildes, 1984; Libert, 1984; Poulos, Kvanli, & Pavur, 1987; Texter & Ord, 1989 ). Several software vendors have implemented automated time seriesforecasting methods (including multivariate methods);see, e.g., Geriner and Ord (1991) ,Tashman and Leach (1991) , and Tashman (2000) . Often these methods act as black boxes. The technology of expert systems(Me\u00b4lard & Pasteels, 2000 ) can be used to avoid this problem. Some guidelines on the choice of an automatic forecasting method are provided by Chat- field (1988) . Rather than adopting a single AR model for all forecast horizons, Kang (2003) empirically investi- gated the case of using a multi-step-ahead forecastingAR model selected separately for each horizon. Theforecasting performance of the multi-step-ahead pro-cedure appears to depend on, among other things,J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 448optimal order selection criteria, forecast periods, forecast horizons, and the time series to be forecast. 3.3. Transfer function The identification of transfer function models can be difficult when there is more than one inputvariable. Edlund (1984) presented a two-step method for identification of the impulse response function when a number of different input variables arecorrelated. Koreisha (1983) established various rela- tionships between transfer functions, causal implica-tions, and econometric model specification. Gupta (1987) identified the major pitfalls in causality testing. Using principal component analysis, a parsimoniousrepresentation of a transfer function model was suggested by del Moral and Valderrama (1997) . Krishnamurthi, Narayan, and Raj (1989) showed how more accurate estimates of the impact ofinterventions in transfer function models can beobtained by using a control variable. 3.4. Multivariate The vector ARIMA (VARIMA) model is a multivariate generalization of the univariate ARIMAmodel. The population characteristics of VARMAprocesses appear to have been first derived byQuenouille (1957) , although software to implement them only became available in the 1980s and 1990s.Since VARIMA models can accommodate assump-tions on exogeneity and on contemporaneous relation- ships, they offered new challenges to forecasters and policymakers. Riise and Tj\u00f8stheim (1984) addressed the effect of parameter estimation on VARMAforecasts. Cholette and Lamy (1986) showed how smoothing filters can be built into VARMA models.The smoothing prevents irregular fluctuations inexplanatory time series from migrating to the forecastsof the dependent series. To determine the maximum forecast horizon of VARMA processes, De Gooijer and Klein (1991) established the theoretical properties of cumulated multi-step-ahead forecasts and cumulat-ed multi-step-ahead forecast errors. Lu\u00a8tkepohl (1986) studied the effects of temporal aggregation andsystematic sampling on forecasting, assuming thatthe disaggregated (stationary) variable follows aVARMA process with unknown order. Later, Bidar-kota (1998) considered the same problem but with the observed variables integrated rather than stationary. Vector autoregressions (VARs) constitute a special case of the more general class of VARMA models. Inessence, a VAR model is a fairly unrestricted(flexible) approximation to the reduced form of awide variety of dynamic econometric models. VARmodels can be specified in a number of ways. Funke (1990) presented five different VAR specifications and compared their forecasting performance usingmonthly industrial production series. Dhrymes and Thomakos (1998) discussed issues regarding the identification of structural VARs. Hafer and Sheehan (1989) showed the effect on VAR forecasts of changes in the model structure. Explicit expressions for VARforecasts in levels are provided by Arin\u02dco and Franses (2000) ;s e ea l s o Wieringa and Horva \u00b4th (2005) . Hansson, Jansson, and Lo \u00a8f (2005) used a dynamic factor model as a starting point to obtain forecastsfrom parsimoniously parametrized VARs. In general, V AR models tend to suffer from doverfitting Twith too many free insignificant param- eters. As a result, these models can provide poor out-of-sample forecasts, even though within-sample fit- ting is good; see, e.g., Liu, Gerlow, and Irwin (1994) andSimkins (1995) . Instead of restricting some of the parameters in the usual way, Litterman (1986) and others imposed a prior distribution on the parameters,expressing the belief that many economic variablesbehave like a random walk. BVAR models have beenchiefly used for macroeconomic forecasting ( Artis & Zhang, 1990; Ashley, 1988; Holden & Broomhead, 1990; Kunst & Neusser, 1986 ), for forecasting market shares ( Ribeiro Ramos, 2003 ), for labor market forecasting ( LeSage & Magura, 1991 ), for business forecasting ( Spencer, 1993 ), or for local economic forecasting ( LeSage, 1989 ).Kling and Bessler (1985) compared out-of-sample forecasts of several then-known multivariate time series methods, includingLitterman\u2019s BVAR model. TheEngle and Granger (1987) concept of cointe- gration has raised various interesting questions re-garding the forecasting ability of error correctionmodels (ECMs) over unrestricted VARs and BVARs.Shoesmith (1992) ,Shoesmith (1995) ,Tegene and Kuchler (1994) ,a n d Wang and Bessler (2004) provided empirical evidence to suggest that ECMsoutperform VARs in levels, particularly over longerJ.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 449forecast horizons. Shoesmith (1995) , and later Villani (2001) , also showed how Litterman\u2019s (1986) Bayesian approach can improve forecasting with cointegratedVARs. Reimers (1997) studied the forecasting perfor- mance of seasonally cointegrated vector time seriesprocesses using an ECM in fourth differences. Poskitt (2003) discussed the specification of cointegrated VA RM A s ys t ems . Chevillon and Hendry (2005) analyzed the relationship between direct multi-step estimation of stationary and nonstationary VARs andforecast accuracy. 4. Seasonality The oldest approach to handling seasonality in time series is to extract it using a seasonal decomposition procedure such as the X-11 method. Over the past 25years, the X-11 method and its variants (including themost recent version, X-12-ARIMA, Findley, Monsell, Bell, Otto, & Chen, 1998 ) have been studied extensively. One line of research has considered the effect of using forecasting as part of the seasonal decomposi- tion method. For example, Dagum (1982) andHuot, Chiu, and Higginson (1986) looked at the use of forecasting in X-11-ARIMA to reduce the size ofrevisions in the seasonal adjustment of data, andPfeffermann, Morry, and Wong (1995) explored the effect of the forecasts on the variance of the trend andseasonally adjusted values. Quenneville, Ladiray, and Lefranc \u00b8ois (2003) took a different perspective and looked at forecasts implied by the asymmetric moving average filters in the X-11method and its variants. A third approach has been to look at the effectiveness of forecasting using seasonally adjusteddata obtained from a seasonal decomposition method.Miller and Williams (2003, 2004) showed that greater forecasting accuracy is obtained by shrinking the seasonal component towards zero. The commentaries on the latter paper ( Findley, Wills, & Monsell, 2004; Hyndman, 2004; Koehler, 2004; Ladiray & Quenne-ville, 2004; Ord, 2004 ) gave several suggestions regarding the implementation of this idea. In addition to work on the X-11 method and its variants, there have also been several new methods forseasonal adjustment developed, the most importantbeing the model based approach of TRAMO-SEATS (Go\u00b4mez & Maravall, 2001; Kaiser & Maravall, 2005 ) and the nonparametric method STL ( Cleveland, Cleveland, McRae, & Terpenning, 1990 ). Another proposal has been to use sinusoidal models ( Simmons, 1990 ). When forecasting several similar series, With- ycombe (1989) showed that it can be more efficient to estimate a combined seasonal component from the group of series, rather than individual seasonalpatterns. Bunn and Vassilopoulos (1993) demonstrat- ed how to use clustering to form appropriate groupsfor this situation, and Bunn and Vassilopoulos (1999) introduced some improved estimators for the groupseasonal indices. Twenty-five years ago, unit root tests had only recently been invented and seasonal unit root tests were yet to appear. Subsequently, there has beenconsiderable work done on the use and implementa-tion of seasonal unit root tests including Hylleberg and Pagan (1997) ,Taylor (1997) , and Franses and Koehler (1998) .Paap, Franses, and Hoek (1997) and Clements and Hendry (1997) studied the forecast performance of models with unit roots, especially in the context of level shifts. Some authors have cautioned against the wide- spread use of standard seasonal unit root models foreconomic time series. Osborn (1990) argued that deterministic seasonal components are more common in economic series than stochastic seasonality. Franses and Romijn (1993) suggested that seasonal roots in periodic models result in better forecasts. Periodic time series models were also explored by Wells (1997) ,Herwartz (1997) , and Novales and de Fruto (1997) , all of whom found that periodic models can lead to improved forecast performance compared tonon-periodic models under some conditions. Fore-casting of multivariate periodic ARMA processes isconsidered by Ullah (1993) . Several papers have compared various seasonal models empirically. Chen (1997) explored the robust- ness properties of a structural model, a regressionmodel with seasonal dummies, an ARIMA model, andHolt\u2013Winters\u2019 method, and found that the latter twoyield forecasts that are relatively robust to modelmisspecification. Noakes, McLeod, and Hipel (1985) , Albertson and Aylen (1996) ,Kulendran and King (1997) ,a n d Franses and van Dijk (2005) eachJ.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 450compared the forecast performance of several season- al models applied to real data. The best performingmodel varies across the studies, depending on whichmodels were tried and the nature of the data. Thereappears to be no consensus yet as to the conditionsunder which each model is preferred. 5. State space and structural models and the Kalman filter At the start of the 1980s, state space models were only beginning to be used by statisticians forforecasting time series, although the ideas had beenpresent in the engineering literature since Kalman\u2019s (1960) ground-breaking work. State space models provide a unifying framework in which any linear time series model can be written. The key forecastingcontribution of Kalman (1960) was to give a recursive algorithm (known as the Kalman filter)for computing forecasts. Statisticians became inter-ested in state space models when Schweppe (1965) showed that the Kalman filter provides an efficientalgorithm for computing the one-step-ahead predic- tion errors and associated variances needed to produce the likelihood function. Shumway and Stoffer (1982) combined the EM algorithm with the Kalman filter to give a general approach to forecast-ing time series using state space models, includingallowing for missing observations. A particular class of state space models, known asbdynamic linear models Q(DLM), was introduced byHarrison and Stevens (1976) , who also proposed a Bayesian approach to estimation. Fildes (1983) compared the forecasts obtained using Harrison andStevens method with those from simpler methodssuch as exponential smoothing, and concluded thatthe additional complexity did not lead to improvedforecasting performance. The modelling and esti-mation approach of Harrison and Stevens was further developed by West, Harrison, and Migon (1985) and West and Harrison (1989) .Harvey (1984, 1989) extended the class of models and followed a non-Bayesian approach to estimation. Healso renamed the models bstructural models Q, al- though in later papers he uses the term bunobserved component models Q.Harvey (2006) provides a com- prehensive review and introduction to this class ofmodels including continuous-time and non-Gaussian variations. These models bear many similarities with expo- nential smoothing methods, but have multiple sourcesof random error. In particular, the bbasic structural model Q(BSM) is similar to Holt\u2013Winters\u2019 method for seasonal data and includes level, trend and seasonalcomponents. Ray (1989) discussed convergence rates for the linear growth structural model and showed that theinitial states (usually chosen subjectively) have a non-negligible impact on forecasts. Harvey and Snyder (1990) proposed some continuous-time structural models for use in forecasting lead time demand forinventory control. Proietti (2000) discussed several variations on the BSM, compared their properties and evaluated the resulting forecasts. Non-Gaussian structural models have been the subject of a large number of papers, beginning withthe power steady model of Smith (1979) with further development by West et al. (1985) . For example, these models were applied to forecasting time series ofproportions by Grunwald, Raftery, and Guttorp (1993) and to counts by Harvey and Fernandes (1989) . However, Grunwald, Hamza, and Hyndman (1997) showed that most of the commonly used models havethe substantial flaw of all sample paths converging toa constant when the sample space is less than thewhole real line, making them unsuitable for anythingother than point forecasting. Another class of state space models, known as bbalanced state space models Q, has been used primarily for forecasting macroeconomic time series. Mittnik (1990) provided a survey of this class of models, and Vinod and Basu (1995) obtained forecasts of consumption, income, and interest ratesusing balanced state space models. These modelshave only one source of random error and subsumevarious other time series models including ARMAXmodels, ARMA models, and rational distributed lag models. A related class of state space models are the bsingle source of error Qmodels that underly expo- nential smoothing methods; these were discussed inSection 2. As well as these methodological developments, there have been several papers proposing innovativestate space models to solve practical forecastingproblems. These include Coomes (1992) who used aJ.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 451state space model to forecast jobs by industry for local regions and Patterson (1995) who used a state space approach for forecasting real personal disposableincome. Amongst this research on state space models, Kalman filtering, and discrete/continuous-time struc-tural models, the books by Harvey (1989) ,West and Harrison (1989) , and Durbin and Koopman (2001) have had a substantial impact on the time series literature. However, forecasting applications of thestate space framework using the Kalman filter havebeen rather limited in the IJF. In that sense, it is perhaps not too surprising that even today, sometextbook authors do not seem to realize that theKalman filter can, for example, track a nonstationaryprocess stably. 6. Nonlinear models 6.1. Preamble Compared to the study of linear time series, the development of nonlinear time series analysis and forecasting is still in its infancy. The beginning of nonlinear time series analysis has been attributed toV olterra (1930) . He showed that any continuous nonlinear function in tcould be approximated by a finite Volterra series. Wiener (1958) became interested in the ideas of functional series representation andfurther developed the existing material. Although theprobabilistic properties of these models have been studied extensively, the problems of parameter esti- mation, model fitting, and forecasting have beenneglected for a long time. This neglect can largelybe attributed to the complexity of the proposedWiener model and its simplified forms like thebilinear model ( Poskitt & Tremayne, 1986 ). At the time, fitting these models led to what were insur-mountable computational difficulties. Although linearity is a useful assumption and a powerful tool in many areas, it became increasinglyclear in the late 1970s and early 1980s that linearmodels are insufficient in many real applications. Forexample, sustained animal population size cycles (thewell-known Canadian lynx data), sustained solarcycles (annual sunspot numbers), energy flow, andamplitude\u2013frequency relations were found not to besuitable for linear models. Accelerated by practical demands, several useful nonlinear time series modelswere proposed in this same period. De Gooijer and Kumar (1992) provided an overview of the develop- ments in this area to the beginning of the 1990s. Theseauthors argued that the evidence for the superiorforecasting performance of nonlinear models is patchy. One factor that has probably retarded the wide- spread reporting of nonlinear forecasts is that up to that time it was not possible to obtain closed-formanalytical expressions for multi-step-ahead forecasts.However, by using the so-called Chapman\u2013Kolmo-gorov relationship, exact least squares multi-step-ahead forecasts for general nonlinear AR models can,in principle, be obtained through complex numericalintegration. Early examples of this approach are reported by Pemberton (1987) and Al-Qassem and Lane (1989) . Nowadays, nonlinear forecasts are obtained by either Monte Carlo simulation or bybootstrapping. The latter approach is preferred sinceno assumptions are made about the distribution of theerror process. The monograph by Granger and Tera \u00a8svirta (1993) has boosted new developments in estimating, evaluat- ing, and selecting among nonlinear forecasting models for economic and financial time series. A goodoverview of the current state-of-the-art is IJFSpecial Issue 20:2 (2004). In their introductory paper, Clem- ents, Franses, and Swanson (2004) outlined a variety of topics for future research. They concluded thatb...the day is still long off when simple, reliable, and easy to use nonlinear model specification, estimation, and forecasting procedures will be readily available Q. 6.2. Regime-switching models The class of (self-exciting) threshold AR (SETAR) models has been prominently promoted through thebooks by Tong (1983, 1990) . These models, which are piecewise linear models in their most basic form, have attracted some attention in the IJF.Clements and Smith (1997) compared a number of methods for obtaining multi-step-ahead forecasts for univariatediscrete-time SETAR models. They concluded thatforecasts made using Monte Carlo simulation aresatisfactory in cases where it is known that thedisturbances in the SETAR model come from asymmetric distribution. Otherwise, the bootstrapJ.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 452method is to be preferred. Similar results were reported byDe Gooijer and Vidiella-i-Anguera (2004) for threshold VAR models. Brockwell and Hyndman (1992) obtained one-step-ahead forecasts for univari- ate continuous-time threshold AR models (CTAR).Since the calculation of multi-step-ahead forecastsfrom CTAR models involves complicated higherdimensional integration, the practical use of CTARs is limited. The out-of-sample forecast performance of various variants of SETAR models relative to linearmodels has been the subject of several IJF papers,including Astatkie, Watts, and Watt (1997) ,Boero and Marrocu (2004) , and Enders and Falk (1998) . One drawback of the SETAR model is that the dynamics change discontinuously from one regime tothe other. In contrast, a smooth transition AR (STAR) model allows for a more gradual transition between the different regimes. Sarantis (2001) found evidence that STAR-type models can improve upon linear ARand random walk models in forecasting stock prices atboth short-term and medium-term horizons. Interest-ingly, the recent study by Bradley and Jansen (2004) seems to refute Sarantis\u2019 conclusion. Can forecasts for macroeconomic aggregates like total output or total unemployment be improved by using a multi-level panel smooth STAR model fordisaggregated series? This is the key issue examinedbyFok, van Dijk, and Franses (2005) . The proposed STAR model seems to be worth investigating in moredetail since it allows the parameters that govern theregime-switching to differ across states. Based onsimulation experiments and empirical findings, the authors claim that improvements in one-step-ahead forecasts can indeed be achieved. Franses, Paap, and Vroomen (2004) proposed a threshold AR(1) model that allows for plausibleinference about the specific values of the parameters.The key idea is that the values of the AR parameterdepend on a leading indicator variable. The resultingmodel outperforms other time-varying nonlinear models, including the Mar kov regime-switching model, in terms of forecasting. 6.3. Functional-coefficient model A functional coefficient AR (FCAR or FAR) model is an AR model in which the AR coefficients areallowed to vary as a measurable smooth function ofanother variable, such as a lagged value of the time series itself or an exogenous variable. The FCARmodel includes TAR and STAR models as specialcases, and is analogous to the generalized additivemodel of Hastie and Tibshirani (1991) .Chen and Tsay (1993) proposed a modeling procedure using ideas from both parametric and nonparametric statistics.The approach assumes little prior information on model structure without suffering from the bcurse of dimensionality Q; see also Cai, Fan, and Yao (2000) . Harvill and Ray (2005) presented multi-step-ahead forecasting results using univariate and multivariatefunctional coefficient (V)FCAR models. Theseauthors restricted their comparison to three forecastingmethods: the nai \u00a8ve plug-in predictor, the bootstrap predictor, and the multi-stage predictor. Both simula- tion and empirical results indicate that the bootstrap method appears to give slightly more accurate forecastresults. A potentially useful area of future research iswhether the forecasting power of VFCAR models canbe enhanced by using exogenous variables. 6.4. Neural nets An artificial neural network (ANN) can be useful for nonlinear processes that have an unknownfunctional relationship and as a result are difficult tofit (Darbellay & Slama, 2000 ). The main idea with ANNs is that inputs, or dependent variables, getfiltered through one or more hidden layers each ofwhich consist of hidden units, or nodes, before theyreach the output variable. The intermediate output is related to the final output. Various other nonlinear models are specific versions of ANNs, where morestructure is imposed; see JoF Special Issue 17:5/6 (1998) for some recent studies. One major application area of ANNs is forecasting; seeZhang, Patuwo, and Hu (1998) and Hippert, Pedreira, and Souza (2001) for good surveys of the literature. Numerous studies outside the IJF have documented the successes of ANNs in forecasting financial data. However, in two editorials in thisJournal ,Chatfield (1993, 1995) questioned whether ANNs had been oversold as a miracle forecastingtechnique. This was followed by several papersdocumenting that nai \u00a8ve models such as the random walk can outperform ANNs (see, e.g., Callen, Kwan, Yip, & Yuan, 1996; Church & Curram, 1996; Conejo,J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 453Contreras, Espi \u00b4nola, & Plazas, 2005; Gorr, Nagin, & Szczypula, 1994; Tkacz, 2001 ). These observations are consistent with the results of Adya and Collopy (1998) evaluating the effectiveness of ANN-based forecasting in 48 studies done between 1988 and1994. Gorr (1994) and Hill, Marquez, OConnor, and Remus (1994) suggested that future research should investigate and better define the border between where ANNs and btraditional Qtechniques outperform one other. That theme is explored by several authors.Hill et al. (1994) noticed that ANNs are likely to work best for high frequency financial data and Balkin and Ord (2000) also stressed the importance of a long time series to ensure optimal results from training ANNs.Qi (2001) pointed out that ANNs are more likely to outperform other methods when the input data is kept as current as possible, using recursive modelling (seealso Olson & Mossman, 2003 ). A general problem with nonlinear models is the bcurse of model complexity and model over-para- metrization Q. If parsimony is considered to be really important, then it is interesting to compare the out-of-sample forecasting performance of linear versus nonlinear models, using a wide variety of different model selection criteria. This issue was considered inquite some depth by Swanson and White (1997) . Their results suggested that a single hidden layerdfeed-forward TANN model, which has been by far the most popular in time series econometrics, offers auseful and flexible alternative to fixed specificationlinear models, particularly at forecast horizons greater than one-step-ahead. However, in contrast to Swanson and White, Heravi, Osborn, and Birchenhall (2004) found that linear models produce more accurateforecasts of monthly seasonally unadjusted Europeanindustrial production series than ANN models.Ghiassi, Saidane, and Zimbra (2005) presented a dynamic ANN and compared its forecasting perfor-mance against the traditional ANN and ARIMA models. Times change, and it is fair to say that the risk of over-parametrization and overfitting is now recog-nized by many authors; see, e.g., Hippert, Bunn, and Souza (2005) who use a large ANN (50 inputs, 15 hidden neurons, 24 outputs) to forecast daily electric-ity load profiles. Nevertheless, the question ofwhether or not an ANN is over-parametrized stillremains unanswered. Some potentially valuable ideas for building parsimoniously parametrized ANNs,using statistical inference, are suggested by Tera\u00a8svirta, van Dijk, and Medeiros (2005) . 6.5. Deterministic versus stochastic dynamics The possibility that nonlinearities in high-frequen- cy financial data (e.g., hourly returns) are produced by a low-dimensional deterministic chaotic process hasbeen the subject of a few studies published in the IJF. Cecen and Erkal (1996) showed that it is not possible to exploit deterministic nonlinear dependence in dailyspot rates in order to improve short-term forecasting.Lisi and Medio (1997) reconstructed the state space for a number of monthly exchange rates and, using a local linear method, approximated the dynamics of the system on that space. One-step-ahead out-of-sampleforecasting showed that their method outperforms arandom walk model. A similar study was performedbyCao and Soofi (1999) . 6.6. Miscellaneous A host of other, often less well known, nonlinear models have been used for forecasting purposes. Forinstance, Ludlow and Enders (2000) adopted Fourier coefficients to approximate the various types ofnonlinearities present in time series data. Herwartz (2001) extended the linear vector ECM to allow for asymmetries. Dahl and Hylleberg (2004) compared Hamilton\u2019s (2001) flexible nonlinear regression mod- el, ANNs, and two versions of the projection pursuit regression model. Time-varying AR models areincluded in a comparative study by Marcellino (2004) . The nonparametric, nearest-neighbour method was applied by Ferna\u00b4ndez-Rodri \u00b4guez, Sosvilla-Rivero, and Andrada-Fe \u00b4lix (1999) . 7. Long memory models When the integration parameter din an ARIMA process is fractional and greater than zero, the processexhibits long memory in the sense that observations along time-span apart have non-negligible dependence.Stationary long-memory models (0 bdb0.5), also termed fractionally differenced ARMA (FARMA) orJ.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 454fractionally integrated ARMA (ARFIMA) models, have been considered by workers in many fields; seeGranger and Joyeux (1980) for an introduction. One motivation for these studies is that many empiricaltime series have a sample autocorrelation functionwhich declines at a slower rate than for an ARIMAmodel with finite orders and integer d. The forecasting potential of fitted FARMA/ ARFIMA models, as opposed to forecast results obtained from other time series models, has been atopic of various IJFpapers and a special issue (2002, 18:2). Ray (1993a, 1993b) undertook such a compar- ison between seasonal FARMA/ARFIMA models andstandard (non-fractional) seasonal ARIMA models.The results show that higher order AR models arecapable of forecasting the longer term well when compared with ARFIMA models. Following Ray (1993a, 1993b) ,Smith and Yadav (1994) investigated the cost of assuming a unit difference when a series isonly fractionally integrated with dp1. Over-differenc- ing a series will produce a loss in forecastingperformance one-step-ahead, with only a limited lossthereafter. By contrast, under-differencing a series ismore costly with larger potential losses from fitting a mis-specified AR model at all forecast horizons. This issue is further explored by Andersson (2000) who showed that misspecification strongly affects theestimated memory of the ARFIMA model, using arule which is similar to the test of O\u00a8ller (1985) .Man (2003) argued that a suitably adapted ARMA(2,2) model can produce short-term forecasts that arecompetitive with estimated ARFIMA models. Multi- step-ahead forecasts of long-memory models have been developed by Hurvich (2002) and compared by Bhansali and Kokoszka (2002) . Many extensions of ARFIMA models and compar- isons of their relative forecasting performance havebeen explored. For instance, Franses and Ooms (1997) proposed the so-called periodic ARFIMA(0, d,0) mod- el where dcan vary with the seasonality parameter. Ravishanker and Ray (2002) considered the estimation and forecasting of multivariate ARFIMA models.Baillie and Chung (2002) discussed the use of linear trend-stationary ARFIMA models, while the paper byBeran, Feng, Ghosh and Sibbertsen (2002) extended this model to allow for nonlinear trends. Souza and Smith (2002) investigated the effect of different sampling rates, such as monthly versus quarterly data,on estimates of the long-memory parameter d.I na similar vein, Souza and Smith (2004) looked at the effects of temporal aggregation on estimates andforecasts of ARFIMA processes. Within the contextof statistical quality control, Ramjee, Crato, and Ray (2002) introduced a hyperbolically weighted moving average forecast-based control chart, designed specif-ically for nonstationary ARFIMA models. 8. ARCH/GARCH models A key feature of financial time series is that large (small) absolute returns tend to be followed by large(small) absolute returns, that is, there are periodswhich display high (low) volatility. This phenomenon is referred to as volatility clustering in econometrics and finance. The class of autoregressive conditionalheteroscedastic (ARCH) models, introduced by Engle (1982) , describe the dynamic changes in conditional variance as a deterministic (typically quadratic)function of past returns. Because the variance isknown at time t/C01, one-step-ahead forecasts are readily available. Next, multi-step-ahead forecasts can be computed recursively. A more parsimonious model than ARCH is the so-called generalized ARCH(GARCH) model ( Bollerslev, Engle, & Nelson, 1994; Taylor, 1987 ) where additional dependencies are permitted on lags of the conditional variance. AGARCH model has an ARMA-type representation, sothat the models share many properties. The GARCH family, and many of its extensions, are extensively surveyed in, e.g., Bollerslev, Chou, and Kroner (1992) ,Bera and Higgins (1993) , and Diebold and Lopez (1995). Not surprisingly many ofthe theoretical works have appeared in the economet-rics literature. On the other hand, it is interesting tonote that neither the IJF nor the JoF became an important forum for public ations on the relative forecasting performance of GARCH-type models or the forecasting performance of various other volatility models in general. As can be seen below, very fewIJF/JoF papers have dealt with this topic. Sabbatini and Linton (1998) showed that the simple (linear) GARCH(1,1) model provides a goodparametrization for the daily returns on the Swissmarket index. However, the quality of the out-of-sample forecasts suggests that this result should beJ.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 455taken with caution. Franses and Ghijsels (1999) stressed that this feature can be due to neglectedadditive outliers (AO). They noted that GARCHmodels for AO-corrected returns result in improvedforecasts of stock market volatility. Brooks (1998) finds no clear-cut winner when comparing one-step-ahead forecasts from standard (symmetric) GARCH-type models with those of various linear models and ANNs. At the estimation level, Brooks, Burke, and Persand (2001) argued that standard econometric software packages can produce widely varying results.Clearly, this may have some impact on the forecastingaccuracy of GARCH models. This observation is verymuch in the spirit of Newbold et al. (1994) , referenced in Section 3.2, for univariate ARMA models. OutsidetheIJF, multi-step-ahead prediction in ARMA models with GARCH in mean effects was considered by Karanasos (2001) . His method can be employed in the derivation of multi-step predictions from more com-plicated models, including multivariate GARCH. Using two daily exchange rates series, Galbraith and Kisinbay (2005) compared the forecast content functions both from the standard GARCH model andfrom a fractionally integrated GARCH (FIGARCH) model ( Baillie, Bollerslev, & Mikkelsen, 1996 ). Forecasts of conditional variances appear to haveinformation content of approximately 30 trading days.Another conclusion is that forecasts by autoregressiveprojection on past realized volatilities provide betterresults than forecasts based on GARCH, estimated byquasi-maximum likelihood, and FIGARCH models.This seems to confirm the earlier results of Bollerslev and Wright (2001) , for example. One often heard criticism of these models (FIGARCH and its general-izations) is that there is no economic rationale forfinancial forecast volatility having long memory. For amore fundamental point of criticism of the use oflong-memory models, we refer to Granger (2002) . Empirically, returns and conditional variance of the next period\u2019s returns are negatively correlated. That is, negative (positive) returns are generally associated with upward (downward) revisions of the conditionalvolatility. This phenomenon is often referred to asasymmetric volatility in the literature; see, e.g., Engle and Ng (1993) . It motivated researchers to develop various asymmetric GARCH-type models (includingregime-switching GARCH); see, e.g., Hentschel (1995) and Pagan (1996) for overviews. Awartaniand Corradi (2005) investigated the impact of asymmetries on the out-of-sample forecast ability ofdifferent GARCH models, at various horizons. Besides GARCH, many other models have been proposed for volatility-forecasting. Poon and Granger (2003) , in a landmark paper, provide an excellent and carefully conducted survey of the research in this areain the last 20 years. They compared the volatility forecast findings in 93 published and working papers. Important insights are provided on issues like forecastevaluation, the effect of data frequency on volatilityforecast accuracy, measurement of bactual volatility Q, the confounding effect of extreme values, and manymore. The survey found that option-implied volatilityprovides more accurate forecasts than time seriesmodels. Among the time series models (44 studies), there was no clear winner between the historical volatility models (including random walk, historicalaverages, ARFIMA, and various forms of exponentialsmoothing) and GARCH-type models (includingARCH and its various extensions), but both classesof models outperform the stochastic volatility model;see also Poon and Granger (2005) for an update on these findings. The Poon and Granger survey paper contains many issues for further study. For example, asymmetricGARCH models came out relatively well in theforecast contest. However, it is unclear to what extentthis is due to asymmetries in the conditional mean,asymmetries in the conditional variance, and/or asym-metries in high order conditional moments. Anotherissue for future research concerns the combination of forecasts. The results in two studies ( Doidge & Wei, 1998; Kroner, Kneafsey, & Claessens, 1995 ) find combining to be helpful, but another study ( Vasilellis & Meade, 1996 ) does not. It would also be useful to examine the volatility-forecasting performance ofmultivariate GARCH-type models and multivariatenonlinear models, incorporating both temporal andcontemporaneous dependencies; see also Engle (2002) for some further possible areas of new research. 9. Count data forecasting Count data occur frequently in business and industry, especially in inventory data where they areoften called bintermittent demand data Q. Consequent-J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 456ly, it is surprising that so little work has been done on forecasting count data. Some work has been done onad hoc methods for forecasting count data, but fewpapers have appeared on forecasting count time seriesusing stochastic models. Most work on count forecasting is based on Croston (1972) who proposed using SES to independently forecast the non-zero values of a series and the time between non-zero values. Willemain, Smart, Shockor, and DeSautels (1994) compared Croston\u2019s method to SES and found that Croston\u2019s method was morerobust, although these results were based on MAPEswhich are often undefined for count data. Theconditions under which Croston\u2019s method does betterthan SES were discussed in Johnston and Boylan (1996) .Willemain, Smart, and Schwarz (2004) pro- posed a bootstrap procedure for intermittent demand data which was found to be more accurate than eitherSES or Croston\u2019s method on the nine series evaluated. Evaluating count forecasts raises difficulties due to the presence of zeros in the observed data. Syntetos and Boylan (2005) proposed using the relative mean absolute error (see Section 10), while Willemain et al. (2004) recommended using the probability integral transform method of Diebold, Gunther, and Tay (1998) . Grunwald, Hyndman, Tedesco, and Tweedie (2000) surveyed many of the stochastic models for count time series, using simple first-order autoregres-sion as a unifying framework for the variousapproaches. One possible model, explored by Bra\u00a8nna\u00a8s (1995) , assumes the series follows a Poisson distri- bution with a mean that depends on an unobserved and autocorrelated process. An alternative integer-valued MA model was used by Bra\u00a8nna\u00a8s, Hellstro \u00a8m, and Nordstro \u00a8m (2002) to forecast occupancy levels in Swedish hotels. The forecast distribution can be obtained by simulation using any of these stochastic models, buthow to summarize the distribution is not obvious. Freeland and McCabe (2004) proposed using the median of the forecast distribution, and gave a methodfor computing confidence intervals for the entireforecast distribution in the case of integer-valuedautoregressive (INAR) models of order 1. McCabe and Martin (2005) further extended these ideas by presenting a Bayesian methodology for forecastingfrom the INAR class of models.A great deal of research on count time series has also been done in the biostatistical area (see, forexample, Diggle, Heagerty, Liang, & Zeger, 2002 ). However, this usually concentrates on the analysis ofhistorical data with adjustment for autocorrelatederrors, rather than using the models for forecasting.Nevertheless, anyone working in count forecastingought to be abreast of research developments in the biostatistical area also. 10. Forecast evaluation and accuracy measures A bewildering array of accuracy measures have been used to evaluate the performance of forecastingmethods. Some of them are listed in the early survey paper of Mahmoud (1984) . We first define the most common measures. LetY tdenote the observation at time tand Ft denote the forecast of Yt. Then define the forecast error as et=Yt/C0Ftand the percentage error as pt=100 et/Yt. An alternative way of scaling is to divide each error, by the error obtained with anotherstandard method of forecasting. Let r t=et/et* denote the relative error, where et* is the forecast error obtained from the base method. Usually, the basemethod is the bnai\u00a8ve method Qwhere F tis equal to the last observation. We use the notation mean( xt)t o denote the sample mean of { xt} over the period of interest (or over the series of interest). Analogously,we use median( x t) for the sample median and gmean( xt) for the geometric mean. The most com- monly used methods are defined in Table 2 on the following page, where the subscript b refers tomeasures obtained from the base method. Note that Armstrong and Collopy (1992) referred to RelMAE as CumRAE and that RelRMSE is alsoknown as Theil\u2019s Ustatistic ( Theil, 1966 , Chapter 2), and is sometimes called U2. In addition to these, the average ranking (AR) of a method relative to all other methods considered has sometimes been used. The evolution of measures of forecast accuracy and evaluation can be seen through the measures used toevaluate methods in the major comparative studies thathave been undertaken. In the original M-competition(Makridakis et al., 1982 ), measures used included the MAPE, MSE, AR, MdAPE, and PB. However, asChatfield (1988) andArmstrong and Collopy (1992)J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 457pointed out, the MSE is not appropriate for compar- isons between series as it is scale dependent. Fildes and Makridakis (1988) contained further discussion on this point. The MAPE also has problems when the serieshas values close to (or equal to) zero, as noted by Makridakis, Wheelwright, and Hyndman (1998, p.45) . Excessively large (or infinite) MAPEs were avoided inthe M-competitions by only including data that werepositive. However, this is an artificial solution that isimpossible to apply in all situations. In 1992, one issue of IJFcarried two articles and several commentaries on forecast evaluation meas-ures. Armstrong and Collopy (1992) recommended the use of relative absolute errors, especially the GMRAE and MdRAE, despite the fact that relativeerrors have infinite variance and undefined mean.They recommended bwinsorizing Qto trim extreme values which partially overcomes these problems, butwhich adds some complexity to the calculation and alevel of arbitrariness as the amount of trimming mustbe specified. Fildes (1992) also preferred the GMRAE although he expressed it in an equivalent form as the square root of the geometric mean of squared relativeerrors. This equivalence does not seem to have beennoticed by any of the discussants in the commentariesofAhlburg et al. (1992) . The study of Fildes, Hibon, Makridakis, and Meade (1998) , which looked at forecasting tele- communications data, used MAPE, MdAPE, PB,AR, GMRAE, and MdRAE, taking into account some of the criticism of the methods used for the M-competition. The M3-competition ( Makridakis & Hibon, 2000 ) used three different measures of accuracy: MdRAE, sMAPE, and sMdAPE. The bsymmetric Qmeasures were proposed by Makridakis (1993) in response to the observation that the MAPE and MdAPE have thedisadvantage that they put a heavier penalty onpositive errors than on negative errors. However,these measures are not as bsymmetric Qas their name suggests. For the same value of Y t, the value of 2|Yt/C0Ft|/(Yt+Ft) has a heavier penalty when fore- casts are high compared to when forecasts are low. SeeGoodwin and Lawton (1999) andKoehler (2001) for further discussion on this point. Notably, none of the major comparative studies have used relative measures (as distinct from meas-ures using relative errors) such as RelMAE or LMR.The latter was proposed by Thompson (1990) who argued for its use based on its good statistical properties. It was applied to the M-competition data inThompson (1991) . Apart from Thompson (1990) , there has been very little theoretical work on the statistical properties ofthese measures. One exception is Wun and Pearn (1991) who looked at the statistical properties of MAE. A novel alternative measure of accuracy is btime distance Q, which was considered by Granger and JeonTable 2 Commonly used forecast accuracy measures MSE Mean squared error =mean( et2) RMSE Root mean squared error =?????????? MSEp MAE Mean Absolute error =mean(| et|) MdAE Median absolute error =median(| et|) MAPE Mean absolute percentage error =mean(| pt|) MdAPE Median absolute percentage error =median(| pt|) sMAPE Symmetric mean absolute percentage error =mean(2| Yt/C0Ft|/(Yt+Ft)) sMdAPE Symmetric median absolute percentage error =median(2| Yt/C0Ft|/(Yt+Ft)) MRAE Mean relative absolute error =mean(| rt|) MdRAE Median relative absolute error =median(| rt|) GMRAE Geometric mean relative absolute error =gmean(| rt|) RelMAE Relative mean absolute error =MAE/MAE b RelRMSE Relative root mean squared error =RMSE/RMSE b LMR Log mean squared error ratio =log(RelMSE) PB Percentage better =100 mean( I{|rt|b1}) PB(MAE) Percentage better (MAE) =100 mean( I{MAE bMAE b}) PB(MSE) Percentage better (MSE) =100 mean( I{MSE bMSE b}) Here I{u}=1 if u is true and 0 otherwise.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 458(2003a, 2003b) . In this measure, the leading and lagging properties of a forecast are also captured.Again, this measure has not been used in any majorcomparative study. A parallel line of research has looked at statistical tests to compare foreca sting methods. An early contribution was Flores (1989) . The best known approach to testing differences between the accuracy of forecast methods is the Diebold and Mariano (1995) test. A size-corrected modification of this test was proposed by Harvey, Leybourne, and Newbold (1997) .McCracken (2004) looked at the effect of parameter estimation on such tests and provided a newmethod for adjusting for parameter estimation error. Another problem in forecast evaluation, and more serious than parameter estimation error, is bdata sharing Q\u2014the use of the same data for many different forecasting methods. Sullivan, Timmermann, and White (2003) proposed a bootstrap procedure designed to overcome the resulting distortion ofstatistical inference. An independent line of research has looked at the theoretical forecasting properties of time series mod-els. An important contribution along these lines was Clements and Hendry (1993) who showed that the theoretical MSE of a forecasting model was notinvariant to scale-preserving linear transformationssuch as differencing of the data. Instead, theyproposed the bgeneralized forecast error second moment Q(GFESM) criterion, which does not have this undesirable property. However, such measures aredifficult to apply empirically and the idea does not appear to be widely used. 11. Combining Combining forecasts, mixing, or pooling quan- titative 4forecasts obtained from very different time series methods and different sources of informa- tion has been studied for the past three decades. Important early contributions in this area weremade by Bates and Granger (1969) ,Newbold and Granger (1974) ,a n d Winkler and Makridakis(1983) . Compelling evidence on the relative effi- ciency of combined forecasts, usually defined interms of forecast error variances, was summarizedbyClemen (1989) in a comprehensive bibliography review. Numerous methods for selecting the combining weights have been proposed. The simple average isthe most widely used combining method (see Clem- en\u2019s review and Bunn, 1985 ), but the method does not utilize past information regarding the precision of theforecasts or the dependence among the forecasts.Another simple method is a linear mixture of theindividual forecasts with combining weights deter-mined by OLS (assuming unbiasedness) from thematrix of past forecasts and the vector of pastobservations ( Granger & Ramanathan, 1984 ). How- ever, the OLS estimates of the weights are inefficient due to the possible presence of serial correlation in thecombined forecast errors. Aksu and Gunter (1992) andGunter (1992) investigated this problem in some detail. They recommended the use of OLS combina-tion forecasts with the weights restricted to sum tounity. Granger (1989) provided several extensions of the original idea of Bates and Granger (1969) , including combining forecasts with horizons longer than one period. Rather than using fixed weights, Deutsch, Granger, and Tera \u00a8svirta (1994) allowed them to change through time using regime-switching models and STARmodels. Another time-dependent weighting schemewas proposed by Fiordaliso (1998) , who used a fuzzy system to combine a set of individual forecasts in a nonlinear way. Diebold and Pauly (1990) used Bayesian shrinkage techniques to allow the incorpo-ration of prior information into the estimation ofcombining weights. Combining forecasts from verysimilar models, with weights sequentially updated,was considered by Zou and Yang (2004) . Combining weights determined from time-invari- ant methods can lead to relatively poor forecasts if nonstationarity occurs among component forecasts. Miller, Clemen, and Winkler (1992) examined the effect of dlocation-shift Tnonstationarity on a range of forecast combination methods. Tentatively, they con-cluded that the simple average beats more complexcombination devices; see also Hendry and Clements (2002) for more recent results. The related topic of combining forecasts from linear and some nonlinear 4See Kamstra and Kennedy (1998) for a computationally convenient method of combining qualitative forecasts.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 459time series models, with OLS weights as well as weights determined by a time-varying method, wasaddressed by Terui and van Dijk (2002) . The shape of the combined forecast error distribu- tion and the corresponding stochastic behaviour wasstudied by de Menezes and Bunn (1998) andTaylor and Bunn (1999) . For non-normal forecast error distributions skewness emerges as a relevant criterion for specifying the method of combination. Some insights into why competing forecasts may befruitfully combined to produce a forecast superior toindividual forecasts were provided by Fang (2003) , using forecast encompassing tests. Hibon and Evge- niou (2005) proposed a criterion to select among forecasts and their combinations. 12. Prediction intervals and densities The use of prediction intervals, and more recently prediction densities, has become much more commonover the past 25 years as practitioners have come tounderstand the limitations of point forecasts. Animportant and thorough review of interval forecasts is given by Chatfield (1993) , summarizing the literature to that time. Unfortunately, there is still some confusion in terminology with many authors using bconfidence interval Qinstead of bprediction interval Q. A confidence interval is for a model parameter, whereas a predictioninterval is for a random variable. Almost always,forecasters will want prediction intervals\u2014intervals which contain the true values of future observations with specified probability. Most prediction intervals are based on an underlying stochastic model. Consequently, there has been a largeamount of work done on formulating appropriatestochastic models underlying some common forecast-ing procedures (see, e.g., Section 2 on exponentialsmoothing). The link between prediction interval formulae and the model from which they are derived has not alwaysbeen correctly observed. For example, the predictioninterval appropriate for a random walk model wasapplied by Makridakis and Hibon (1987) andLefran- c\u00b8ois (1989) to forecasts obtained from many other methods. This problem was noted by Koehler (1990) andChatfield and Koehler (1991) .With most model-based prediction intervals for time series, the uncertainty associated with modelselection and parameter estimation is not accountedfor. Consequently, the intervals are too narrow. Therehas been considerable research on how to makemodel-based prediction intervals have more realisticcoverage. A series of papers on using the bootstrap tocompute prediction intervals for an AR model has appeared beginning with Masarotto (1990) ,a n d including McCullough (1994, 1996) ,Grigoletto (1998) ,Clements and Taylor (2001) ,a n d Kim (2004b) . Similar procedures for other models have also been considered including ARIMA models(Pascual, Romo, & Ruiz, 2001, 2004, 2005; Wall & Stoffer, 2002 ), VAR ( Kim, 1999, 2004a ), ARCH (Reeves, 2005 ), and regression ( Lam & Veall, 2002 ). It seems likely that such bootstrap methods will become more widely used as computing speedsincrease due to their better coverage properties. When the forecast error distribution is non- normal, finding the entire forecast density is usefulas a single interval may no longer provide anadequate summary of the expected future. A reviewof density forecasting is provided by Tay and Wallis (2000) , along with several other articles in the same special issue of the JoF. Summarizing, a density forecast has been the subject of some interestingproposals including bfan charts Q(Wallis, 1999 ) and bhighest density regions Q(Hyndman, 1995 ). The use of these graphical summaries has grown rapidly inrecent years as density forecasts have becomerelatively widely used. As prediction intervals and forecast densities have become more commonly used, attention has turned totheir evaluation and testing. Diebold, Gunther, and Tay (1998) introduced the remarkably simple bprobability integral transform Qmethod, which can be used to evaluate a univariate density. This approachhas become widely used in a very short period of timeand has been a key research advance in this area. The idea is extended to multivariate forecast densities in Diebold, Hahn, and Tay (1999) . Other approaches to interval and density evaluation are given by Wallis (2003) who proposed chi-squared tests for both intervals and densities, and Clements and Smith (2002) who discussed some simple but powerful tests when evaluating multivariate forecastdensities.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 46013. A look to the future In the preceding sections, we have looked back at the time series forecasting history of the IJF, in the hope that the past may shed light on the present. Buta silver anniversary is also a good time to lookahead. In doing so, it is interesting to reflect on theproposals for research in time series forecasting identified in a set of related papers by Ord, Cogger, and Chatfield published in this Journal more than 15years ago. 5 Chatfield (1988) stressed the need for future research on developing multivariate methods with anemphasis on making them more of a practicalproposition. Ord (1988) also noted that not much work had been done on multiple time series models, including multivariate exponential smoothing. Eigh- teen years later, multivariate time series forecasting isstill not widely applied despite considerable theoret-ical advances in this area. We suspect that two reasonsfor this are: a lack of empirical research on robustforecasting algorithms for multivariate models, and alack of software that is easy to use. Some of themethods that have been suggested (e.g., VARIMA models) are difficult to estimate because of the large numbers of parameters involved. Others, such asmultivariate exponential smoothing, have not receivedsufficient theoretical attention to be ready for routineapplication. One approach to multivariate time seriesforecasting is to use dynamic factor models. Thesehave recently shown promise in theory ( Forni, Hallin, Lippi, & Reichlin, 2005; Stock & Watson, 2002 ) and application (e.g., Pen\u02dca & Poncela, 2004 ), and we suspect they will become much more widely used inthe years ahead. Ord (1988) also indicated the need for deeper research in forecasting methods based on nonlinearmodels. While many aspects of nonlinear models havebeen investigated in the IJF, they merit continued research. For instance, there is still no clear consensus that forecasts from nonlinear models substantivelyoutperform those from linear models (see, e.g., Stock & Watson, 1999 ). Other topics suggested by Ord (1988) include the need to develop model selection procedures that makeeffective use of both data and prior knowledge, andthe need to specify objectives for forecasts anddevelop forecasting systems that address those objec-tives. These areas are still in need of attention and we believe that future research will contribute tools to solve these problems. Given the frequent misuse of methods based on linear models with Gaussian i.i.d. distributed errors,Cogger (1988) argued that new developments in the area of drobust Tstatistical methods should receive more attention within the time series forecastingcommunity. A robust procedure is expected to work well when there are outliers or location shifts in the data that are hard to detect. Robust statistics can bebased on both parametric and nonparametric methods.An example of the latter is the Koenker and Bassett (1978) concept of regression quantiles investigated by Cogger. In forecasting, these can be applied asunivariate and multivariate conditional quantiles.One important area of application is in estimating risk management tools such as value-at-risk. Recently, Engle and Manganelli (2004) made a start in this direction, proposing a conditional value at risk model.We expect to see much future research in this area. A related topic in which there has been a great deal of recent research activity is density forecasting (seeSection 12), where the focus is on the probabilitydensity of future observations rather than the mean or variance. For instance, Yao and Tong (1995) proposed the concept of the conditional percentile predictioninterval. Its width is no longer a constant, as in thecase of linear models, but may vary with respect to theposition in the state space from which forecasts arebeing made; see also De Gooijer and Gannoun (2000) andPolonik and Yao (2000) . Clearly, the area of improved forecast intervals requires further research. This is in agreement with Armstrong (2001) who listed 23 principles in great need of research including item 14:13: bFor prediction intervals, incorporate the uncertainty associated withthe prediction of the explanatory variables Q. In recent years, non-Gaussian time series have begun to receive considerable attention and forecast-ing methods are slowly being developed. One 5Outside the IJF, good reviews on the past and future of time series methods are given by Dekimpe and Hanssens (2000) in marketing and by Tsay (2000) in statistics. Casella et al. (2000) discussed a large number of potential research topics in the theoryand methods of statistics. We daresay that some of these topics willattract the interest of time series forecasters.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 461particular area of non-Gaussian time series that has important applications is time series taking positivevalues only. Two important areas in finance in whichthese arise are realized volatility and the durationbetween transactions. Important contributions to datehave been Engle and Russell\u2019s (1998) bautoregressive conditional duration Qmodel and Andersen, Bollerslev, Diebold, and Labys (2003) . Because of the impor- tance of these applications, we expect much more work in this area in the next few years. While forecasting non-Gaussian time series with a continuous sample space has begun to receiveresearch attention, especially in the context offinance, forecasting time series with a discretesample space (such as time series of counts) is stillin its infancy (see Section 9). Such data are very prevalent in business and industry, and there are many unresolved theoretical and practical problems associ-ated with count forecasting; therefore, we also expectmuch productive research in this area in the nearfuture. In the past 15 years, some IJFauthors have tried to identify new important research topics. Both De Gooijer (1990) and Clements (2003) in two editorials, and Ord as a part of a discussion paper byDawes, Fildes, Lawrence, and Ord (1994) , suggested more work on combining forecasts.Although the topic has received a fair amount ofattention (see Section 11), there are still several openquestions. For instance, what is the bbest Qcombining method for linear and nonlinear models and whatprediction interval can be put around the combined forecast? A good starting point for further research in this area is Tera\u00a8svirta (2006) ; see also Armstrong (2001, items 12.5\u201312.7) . Recently, Stock and Watson (2004) discussed the dforecast combination puzzle T, namely the repeated empirical finding that simplecombinations such as averages outperform moresophisticated combinations which theory suggestsshould do better. This is an important practical issue that will no doubt receive further research attention in the future. Changes in data collection and storage will also lead to new research directions. For example, in thepast, panel data (called longitudinal data in biostatis-tics) have usually been available where the time seriesdimension thas been small whilst the cross-section dimension nis large. However, nowadays in manyapplied areas such as marketing, large datasets can be easily collected with nand tboth being large. Extracting features from megapanels of panel data isthe subject of bfunctional data analysis Q; see, e.g., Ramsay and Silverman (1997) . Yet, the problem of making multi-step-ahead forecasts based on functionaldata is still open for both theoretical and appliedresearch. Because of the increasing prevalence of this kind of data, we expect this to be a fruitful future research area. Large datasets also lend themselves to highly computationally intensive methods. While neuralnetworks have been used in forecasting for more thana decade now, there are many outstanding issuesassociated with their use and implementation, includ-ing when they are likely to outperform other methods. Other methods involving heavy computation (e.g., bagging and boosting) are even less understood in theforecasting context. With the availability of very largedatasets and high powered computers, we expect thisto be an important area of research in the comingyears. Looking back, the field of time series forecasting is vastly different from what it was 25 years ago when the IIF was formed. It has grown up with the advent of greater computing power, better statistical models,and more mature approaches to forecast calculationand evaluation. But there is much to be done, withmany problems still unsolved and many new prob-lems arising. When the IIF celebrates its Golden Anniversary in 25 years Ttime, we hope there will be another review paper summarizing the main developments in time series forecasting. Besides the topics mentionedabove, we also predict that such a review will shedmore light on Armstrong\u2019s 23 open research prob-lems for forecasters. In this sense, it is interesting tomention David Hilbert who, in his 1900 address tothe Paris International Congress of Mathematicians,listed 23 challenging problems for mathematicians of the 20th century to work on. Many of Hilbert\u2019s problems have resulted in an explosion of researchstemming from the confluence of several areas ofmathematics and physics. We hope that the ideas,problems, and observations presented in this reviewprovide a similar research impetus for those workingin different areas of time series analysis andforecasting.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 462Acknowledgments We are grateful to Robert Fildes and Andrey Kostenko for valuable comments. We also thank twoanonymous referees and the editor for many helpfulcomments and suggestions that resulted in a substan-tial improvement of this manuscript. References Section 2. Exponential smoothing Abraham, B., & Ledolter, J. (1983). Statistical methods for forecasting . New York 7John Wiley and Sons. Abraham, B., & Ledolter, J. (1986). Forecast functions implied by autoregressive integrated moving average models and other related forecast procedures. International Statistical Review ,54, 51\u201366. Archibald, B. C. (1990). Parameter space of the Holt\u2013Winters model. International Journal of Forecasting ,6, 199\u2013209. Archibald, B. C., & Koehler, A. B. (2003). Normalization of seasonal factors in Winters methods. International Journal of Forecasting ,19, 143\u2013148. Assimakopoulos, V., & Nikolopoulos, K. (2000). The theta model: A decomposition approach to forecasting. International Journal of Forecasting ,16, 521\u2013530. Bartolomei, S. M., & Sweet, A. L. (1989). A note on a comparison of exponential smoothing methods for forecasting seasonalseries. International Journal of Forecasting ,5, 111 \u2013 116. Box, G. E. P., & Jenkins, G. M. (1970). Time series analysis: Forecasting and control . San Francisco 7Holden Day (revised ed. 1976). Brown, R. G. (1959). Statistical forecasting for inventory control . New York 7McGraw-Hill. Brown, R. G. (1963). Smoothing, forecasting and prediction of discrete time series . Englewood Cliffs, NJ 7Prentice-Hall. Carreno, J., & Madinaveitia, J. (1990). A modification of time series forecasting methods for handling announced price increases. International Journal of Forecasting ,6, 479\u2013484. Chatfield, C., & Yar, M. (1991). Prediction intervals for multipli- cative Holt\u2013Winters. International Journal of Forecasting ,7, 31\u201337. Chatfield, C., Koehler, A. B., Ord, J. K., & Snyder, R. D. (2001). A new look at models for exponential smoothing. The Statistician , 50, 147\u2013159. Collopy, F., & Armstrong, J. S. (1992). Rule-based forecasting: Development and validation of an expert systems approach tocombining time series extrapolations. Management Science ,38, 1394\u20131414. Gardner Jr., E. S. (1985). Exponential smoothing: The state of the art.Journal of Forecasting ,4, 1\u201338. Gardner Jr., E. S. (1993). Forecasting the failure of component parts in computer systems: A case study. International Journal of Forecasting ,9, 245\u2013253.Gardner Jr., E. S., & McKenzie, E. (1988). Model identification in exponential smoothing. Journal of the Operational Research Society ,39, 863\u2013867. Grubb, H., & Masa, A. (2001). Long lead-time forecasting of UK air passengers by Holt\u2013Winters methods with damped trend. International Journal of Forecasting ,17, 71\u201382. Holt, C. C. (1957). Forecasting seasonals and trends by exponen- tially weighted averages. O.N.R. Memorandum 52/1957, Carnegie Institute of Technology. Reprinted with discussion in2004. International Journal of Forecasting ,20, 5\u201313. Hyndman, R. J. (2001). It Ts time to move from what to why. International Journal of Forecasting ,17, 567\u2013570. Hyndman, R. J., & Billah, B. (2003). Unmasking the Theta method. International Journal of Forecasting ,19, 287\u2013290. Hyndman, R. J., Koehler, A. B., Snyder, R. D., & Grose, S. (2002). A state space framework for automatic forecasting using exponential smoothing methods. International Journal of Forecasting ,18, 439\u2013454. Hyndman, R. J., Koehler, A. B., Ord, J. K., & Snyder, R. D. (2005). Prediction intervals for exponential smoothing state spacemodels. Journal of Forecasting ,24, 17\u201337. Johnston, F. R., & Harrison, P. J. (1986). The variance of lead- time demand. Journal of Operational Research Society ,37, 303\u2013308. Koehler, A. B., Snyder, R. D., & Ord, J. K. (2001). Forecasting models and prediction intervals for the multiplicative Holt\u2013 Winters method. International Journal of Forecasting ,17, 269\u2013286. Lawton, R. (1998). How should additive Holt\u2013Winters esti- mates be corrected? International Journal of Forecasting , 14, 393\u2013 403. Ledolter, J., & Abraham, B. (1984). Some comments on the initialization of exponential smoothing. Journal of Forecasting , 3, 79\u201384. Makridakis, S., & Hibon, M. (1991). Exponential smoothing: The effect of initial values and loss functions on post-sampleforecasting accuracy. International Journal of Forecasting ,7, 317\u2013330. McClain, J. G. (1988). Dominant tracking signals. International Journal of Forecasting ,4, 563\u2013572. McKenzie, E. (1984). General exponential smoothing and the equivalent ARMA process. Journal of Forecasting ,3, 333\u2013344. McKenzie, E. (1986). Error analysis for Winters additive seasonal forecasting system. International Journal of Forecasting ,2, 373\u2013382. Miller, T., & Liberatore, M. (1993). Seasonal exponential smooth- ing with damped trends. An application for production planning.International Journal of Forecasting ,9 , 509\u2013515. Muth, J. F. (1960). Optimal properties of exponentially weighted forecasts. Journal of the American Statistical Association ,55, 299\u2013306. Newbold, P., & Bos, T. (1989). On exponential smoothing and the assumption of deterministic trend plus white noise data- generating models. International Journal of Forecasting ,5, 523\u2013527. Ord, J. K., Koehler, A. B., & Snyder, R. D. (1997). Estimation and prediction for a class of dynamic nonlinear statisticalJ.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 463models. Journal of the American Statistical Association ,92, 1621\u20131629. Pan, X. (2005). An alternative approach to multivariate EWMA control chart. Journal of Applied Statistics ,32, 695\u2013705. Pegels, C. C. (1969). Exponential smoothing: Some new variations. Management Science ,12, 311\u2013315. Pfeffermann, D., & Allon, J. (1989). Multivariate exponential smoothing: Methods and practice. International Journal of Forecasting ,5, 83\u201398. Roberts, S. A. (1982). A general class of Holt\u2013Winters type forecasting models. Management Science ,28, 808\u2013820. Rosas, A. L., & Guerrero, V. M. (1994). Restricted forecasts using exponential smoothing techniques. International Journal of Forecasting ,10, 515\u2013527. Satchell, S., & Timmermann, A. (1995). On the optimality of adaptive expectations: Muth revisited. International Journal of Forecasting ,11, 407\u2013416. Snyder, R. D. (1985). Recursive estimation of dynamic linear statistical models. Journal of the Royal Statistical Society (B) , 47, 272\u2013276. Sweet, A. L. (1985). Computing the variance of the forecast error for the Holt\u2013Winters seasonal models. Journal of Forecasting , 4, 235\u2013243. Sweet, A. L., & Wilson, J. R. (1988). Pitfalls in simulation-based evaluation of forecast monitoring schemes. International Jour- nal of Forecasting ,4, 573\u2013579. Tashman, L., & Kruk, J. M. (1996). The use of protocols to select exponential smoothing procedures: A reconsideration of fore-casting competitions. International Journal of Forecasting ,12, 235\u2013253. Taylor, J. W. (2003). Exponential smoothing with a damped multiplicative trend. International Journal of Forecasting ,19, 273\u2013289. Williams, D. W., & Miller, D. (1999). Level-adjusted exponential smoothing for modeling planned discontinuities. International Journal of Forecasting ,15, 273\u2013289. Winters, P. R. (1960). Forecasting sales by exponentially weighted moving averages. Management Science ,6, 324\u2013342. Yar, M., & Chatfield, C. (1990). Prediction intervals for the Holt\u2013 Winters forecasting procedure. International Journal of Fore- casting ,6, 127\u2013137. Section 3. ARIMA de Alba, E. (1993). Constrained forecasting in autoregressive time series models: A Bayesian analysis. International Journal of Forecasting ,9, 95\u2013108. Arin\u02dco, M. A., & Franses, P. H. (2000). Forecasting the levels of vector autoregressive log-transformed time series. International Journal of Forecasting ,16, 111 \u2013 116. Artis, M. J., & Zhang, W. (1990). BV AR forecasts for the G-7. International Journal of Forecasting ,6, 349\u2013362. Ashley, R. (1988). On the relative worth of recent macroeconomic forecasts. International Journal of Forecasting ,4, 363\u2013376. Bhansali, R. J. (1996). Asymptotically efficient autoregressive model selection for multistep prediction. Annals of the Institute of Statistical Mathematics ,48, 577\u2013602.Bhansali, R. J. (1999). Autoregressive model selection for multistep prediction. Journal of Statistical Planning and Inference ,78, 295\u2013305. Bianchi, L., Jarrett, J., & Hanumara, T. C. (1998). Improving forecasting for telemarketing centers by ARIMA modeling with interventions. International Journal of Forecasting ,14, 497\u2013504. Bidarkota, P. V. (1998). The comparative forecast performance of univariate and multivariate models: An application to realinterest rate forecasting. International Journal of Forecasting , 14, 457\u2013468. Box, G. E. P., & Jenkins, G. M. (1970). Time series analysis: Forecasting and control . San Francisco 7Holden Day (revised ed. 1976). Box, G. E. P., Jenkins, G. M., & Reinsel, G. C. (1994). Time series analysis: Forecasting and control (3rd ed.). Englewood Cliffs, NJ7Prentice Hall. Chatfield, C. (1988). What is the dbest Tmethod of forecasting? Journal of Applied Statistics ,15, 19\u201338. Chevillon, G., & Hendry, D. F. (2005). Non-parametric direct multi- step estimation for forecasting economic processes. Internation- al Journal of Forecasting ,21, 201\u2013218. Cholette, P. A. (1982). Prior information and ARIMA forecasting. Journal of Forecasting ,1, 375\u2013383. Cholette, P. A., & Lamy, R. (1 986). Multivariate ARIMA forecasting of irregular time series. International Journal of Forecasting ,2, 201\u2013216. Cummins, J. D., & Griepentrog, G. L. (1985). Forecasting automobile insurance paid claims using econometric andARIMA models. International Journal of Forecasting ,1, 203\u2013215. De Gooijer, J. G., & Klein, A. (1991). On the cumulated multi-step- ahead predictions of vector autoregressive moving average processes. International Journal of Forecasting ,7, 501\u2013513. del Moral, M. J., & Valderrama, M. J. (1997). A principal component approach to dynamic regression models. Interna- tional Journal of Forecasting ,13, 237\u2013244. Dhrymes, P. J., & Peristiani, S. C. (1988). A comparison of the forecasting performance of WEFA and ARIMA time seriesmethods. International Journal of Forecasting ,4, 81\u2013101. Dhrymes, P. J., & Thomakos, D. (1998). Structural VAR, MARMA and open economy models. International Journal of Forecast- ing,14, 187\u2013198. Di Caprio, U., Genesio, R., Pozzi, S., & Vicino, A. (1983). Short term load forecasting in electric power systems: A comparison of ARMA models and extended Wiener filtering. Journal of Forecasting ,2, 59\u201376. Downs, G. W., & Rocke, D. M. (1983). Municipal budget forecasting with multiv ariate ARMA models. Journal of Forecasting ,2, 377\u2013387. du Preez, J., & Witt, S. F. (2003). Univariate versus multivariate time series forecasting: An application to international tourism demand. International Journal of Forecasting ,19, 435\u2013451. Edlund, P. -O. (1984). Identification of the multi-input Box\u2013 Jenkins transfer function model. Journal of Forecasting ,3, 297\u2013308.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 464Edlund, P. -O., & Karlsson, S. (1993). Forecasting the Swedish unemployment rate. VAR vs. transfer function modelling.International Journal of Forecasting ,9, 61\u201376. Engle, R. F., & Granger, C. W. J. (1987). Co-integration and error correction: Representation, estimation, and testing. Econometr- ica,55, 1057\u20131072. Funke, M. (1990). Assessing the forecasting accuracy of monthly vector autoregressive models: The case of five OECD countries. International Journal of Forecasting ,6, 363\u2013378. Geriner, P. T., & Ord, J. K. (1991). Automatic forecasting using explanatory variables: A comparative study. International Journal of Forecasting ,7, 127\u2013140. Geurts, M. D., & Kelly, J. P. (1986). Forecasting retail sales using alternative models. International Journal of Forecasting ,2, 261\u2013272. Geurts, M. D., & Kelly, J. P. (1990). Comments on: In defense of ARIMA modeling by D.J. Pack. International Journal of Forecasting ,6, 497\u2013499. Grambsch, P., & Stahel, W. A. (1990). Forecasting demand for special telephone services: A case study. International Journal of Forecasting ,6, 53\u201364. Guerrero, V. M. (1991). ARIMA forecasts with restrictions derived from a structural change. International Journal of Forecasting , 7, 339\u2013347. Gupta, S. (1987). Testing causality: Some caveats and a suggestion. International Journal of Forecasting ,3, 195\u2013209. Hafer, R. W., & Sheehan, R. G. (1989). The sensitivity of VAR forecasts to alternative lag structures. International Journal of Forecasting ,5, 399\u2013408. Hansson, J., Jansson, P., & Lo \u00a8f, M. (2005). Business survey data: Do they help in forecasting GDP growth? International Journal of Forecasting ,21, 377\u2013389. Harris, J. L., & Liu, L. -M. (1993). Dynamic structural analysis and forecasting of residential electricity consumption. International Journal of Forecasting ,9, 437\u2013455. Hein, S., & Spudeck, R. E. (1988). Forecasting the daily federal funds rate. International Journal of Forecasting ,4, 581\u2013591. Heuts, R. M. J., & Bronckers, J. H. J. M. (1988). Forecasting the Dutch heavy truck market: A multivariate approach. Interna- tional Journal of Forecasting ,4, 57\u201359. Hill, G., & Fildes, R. (1984). The accuracy of extrapolation methods: An automatic Box\u2013Jenkins package SIFT. Journal of Forecasting ,3, 319\u2013323. Hillmer, S. C., Larcker, D. F., & Schroeder, D. A. (1983). Forecasting accounting data: A multiple time-series analysis. Journal of Forecasting ,2, 389\u2013404. Holden, K., & Broomhead, A. (1990). An examination of vector autoregressive forecasts for the U.K. economy. International Journal of Forecasting ,6, 11\u201323. Hotta, L. K. (1993). The effect of additive outliers on the estimates from aggregated and disaggregated ARIMA models. Interna- tional Journal of Forecasting ,9, 85\u201393. Hotta, L. K., & Cardoso Neto, J. (1993). The effect of aggregation on prediction in ARIMA models. Journal of Time Series Analysis ,14, 261\u2013269. Kang, I. -B. (2003). Multi-period forecasting using different mo- dels for different horizons: An application to U.S. economictime series data. International Journal of Forecasting ,19, 387\u2013400. Kim, J. H. (2003). Forecasting autoregressive time series with bias- corrected parameter estimators. International Journal of Fore- casting ,19, 493\u2013502. Kling, J. L., & Bessler, D. A. (1985). A comparison of multivariate forecasting procedures for economic time series. International Journal of Forecasting ,1, 5\u201324. Kolmogorov, A. N. (1941). Stationary sequences in Hilbert space (in Russian). Bull. Math. Univ. Moscow ,2(6), 1\u201340. Koreisha, S. G. (1983). Causal implications: The linkage between time series and econometric modelling. Journal of Forecasting , 2, 151\u2013168. Krishnamurthi, L., Narayan, J., & Raj, S. P. (1989). Intervention analysis using control series and exogenous variables in a transfer function model: A case study. International Journal of Forecasting ,5, 21\u201327. Kunst, R., & Neusser, K. (1986). A forecasting comparison of some VAR techniques. International Journal of Forecasting ,2, 447\u2013456. Landsman, W. R., & Damodaran, A. (1989). A comparison of quarterly earnings per share forecast using James-Stein and unconditional least squares parameter estimators. International Journal of Forecasting ,5, 491\u2013500. Layton, A., Defris, L. V., & Zehnwirth, B. (1986). An inter- national comparison of economic leading indicators of tele- communication traffic. International Journal of Forecasting ,2, 413\u2013425. Ledolter, J. (1989). The effect of additive outliers on the forecasts from ARIMA models. International Journal of Forecasting ,5, 231\u2013240. Leone, R. P. (1987). Forecasting the effect of an environmental change on market performance: An intervention time-series. International Journal of Forecasting ,3, 463\u2013478. LeSage, J. P. (1989). Incorporating regional wage relations in local forecasting models with a Bayesian prior. International Journal of Forecasting ,5, 37\u201347. LeSage, J. P., & Magura, M. (1991). Using interindustry input\u2013 output relations as a Bayesian prior in employment forecastingmodels. International Journal of Forecasting ,7, 231\u2013238. Libert, G. (1984). The M-competition with a fully automatic Box\u2013 Jenkins procedure. Journal of Forecasting ,3, 325\u2013328. Lin, W. T. (1989). Modeling and forecasting hospital patient movements: Univariate and multiple time series approaches. International Journal of Forecasting ,5, 195\u2013208. Litterman, R. B. (1986). Forecasting with Bayesian vector autoregressions\u2014Five years of experience. Journal of Business and Economic Statistics ,4, 25\u201338. Liu, L. -M., & Lin, M. -W. (1991). Forecasting residential consumption of natural gas using monthly and quarterly timeseries. International Journal of Forecasting ,7, 3\u201316. Liu, T. -R., Gerlow, M. E., & Irwin, S. H. (1994). The performance of alternative VAR models in forecasting exchange rates. International Journal of Forecasting ,10, 419\u2013433. Lu\u00a8tkepohl, H. (1986). Comparison of predictors for temporally and contemporaneously aggregated time series. International Jour- nal of Forecasting ,2, 461\u2013475.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 465Makridakis, S., Andersen, A., Carbone, R., Fildes, R., Hibon, M., Lewandowski, R., et al. (1982). The accuracy of extrapolation(time series) methods: Results of a forecasting competition.Journal of Forecasting ,1, 111\u2013153. Meade, N. (2000). A note on the robust trend and ARARMA methodologies used in the M3 competition. International Journal of Forecasting ,16, 517\u2013519. Meade, N., & Smith, I. (1985). ARARMA vs ARIMA\u2014a study of the benefits of a new approach to forecasting. Omega ,13, 519\u2013534. Me\u00b4lard, G., & Pasteels, J. -M. (2000). Automatic ARIMA modeling including interventions, using time series expert software. International Journal of Forecasting ,16, 497\u2013508. Newbold, P. (1983). ARIMA model building and the time series analysis approach to forecasting. Journal of Forecasting ,2, 23\u201335. Newbold, P., Agiakloglou, C., & Miller, J. (1994). Adventures with ARIMA software. International Journal of Forecasting ,10, 573\u2013581. O\u00a8ller, L. -E. (1985). Macroeconomic forecasting with a vector ARIMA model. International Journal of Forecasting ,1, 143\u2013150. Pack, D. J. (1990). Rejoinder to: Comments on: In defense of ARIMA modeling by M.D. Geurts and J.P. Kelly. International Journal of Forecasting ,6, 501\u2013502. Parzen, E. (1982). ARARMA models for time series analysis and forecasting. Journal of Forecasting ,1, 67\u201382. Pen\u02dca, D., & Sa \u00b4nchez, I. (2005). Multifold predictive validation in ARMAX time series models. Journal of the American Statistical Association ,100, 135\u2013146. Pflaumer, P. (1992). Forecasting US population totals with the Box\u2013 Jenkins approach. International Journal of Forecasting ,8, 329\u2013338. Poskitt, D. S. (2003). On the specification of cointegrated autoregressive moving-average forecasting systems. Interna- tional Journal of Forecasting ,19, 503\u2013519. Poulos, L., Kvanli, A., & Pavur, R. (1987). A comparison of the accuracy of the Box\u2013Jenkins method with that of automatedforecasting methods. International Journal of Forecasting ,3, 261\u2013267. Quenouille, M. H. (1957). The analysis of multiple time-series (2nd ed. 1968). London 7Griffin. Reimers, H. -E. (1997). Forecasting of seasonal cointegrated processes. International Journal of Forecasting ,13 , 369\u2013380. Ribeiro Ramos, F. F. (2003). Forecasts of market shares from VAR and BV AR models: A comparison of their accuracy. Interna- tional Journal of Forecasting ,19, 95\u2013110. Riise, T., & Tj\u00f8stheim, D. (1984). Theory and practice of multivariate ARMA forecasting. Journal of Forecasting ,3, 309\u2013317. Shoesmith, G. L. (1992). Non-cointegration and causality: Impli- cations for VAR modeling. International Journal of Forecast- ing,8, 187\u2013199. Shoesmith, G. L. (1995). Multiple cointegrating vectors, error correction, and forecasting with Littermans model. International Journal of Forecasting ,11, 557\u2013567. Simkins, S. (1995). Forecasting with vector autoregressive (V AR) models subject to business cycle restrictions. International Journal of Forecasting ,11, 569\u2013583.Spencer, D. E. (1993). Developing a Bayesian vector autoregressive forecasting model. International Journal of Forecasting ,9, 407\u2013421. Tashman, L. J. (2000). Out-of sample tests of forecasting accuracy: A tutorial and review. International Journal of Forecasting ,16, 437\u2013450. Tashman, L. J., & Leach, M. L. (1991). Automatic forecasting software: A survey and evaluation. International Journal of Forecasting ,7, 209\u2013230. Tegene, A., & Kuchler, F. (1994). Evaluating forecasting models of farmland prices. International Journal of Forecasting ,10, 65\u201380. Texter, P. A., & Ord, J. K. (1989). Forecasting using automatic identification procedures: A comparative analysis. International Journal of Forecasting ,5, 209\u2013215. Villani, M. (2001). Bayesian prediction with cointegrated vector autoregression. International Journal of Forecasting ,17, 585\u2013605. Wang, Z., & Bessler, D. A. (2004). Forecasting performance of multivariate time series models with a full and reduced rank: Anempirical examination. International Journal of Forecasting , 20, 683\u2013695. Weller, B. R. (1989). National indicator series as quantitative predictors of small region monthly employment levels. Inter- national Journal of Forecasting ,5, 241\u2013247. West, K. D. (1996). Asymptotic inference about predictive ability. Econometrica ,68, 1084\u20131097. Wieringa, J. E., & Horva \u00b4th, C. (2005). Computing level-impulse responses of log-specified VAR systems. International Journal of Forecasting ,21, 279\u2013289. Yule, G. U. (1927). On the method of investigating periodicities in disturbed series, with special reference to Wo \u00a8lfer Ts sunspot numbers. Philosophical Transactions of the Royal Society London, Series A ,226, 267\u2013298. Zellner, A. (1971). An introduction to Bayesian inference in econometrics . New York 7Wiley. Section 4. Seasonality Albertson, K., & Aylen, J. (1996). Modelling the Great Lake freeze: Forecasting and seasonality in the market for ferrous scrap. International Journal of Forecasting ,12, 345\u2013359. Bunn, D. W., & Vassilopoulos, A. I. (1993). Using group seasonal indices in multi-item short-term forecasting. International Journal of Forecasting ,9, 517\u2013526. Bunn, D. W., & Vassilopoulos, A. I. (1999). Comparison of seasonal estimation methods in multi-item short-term forecast-ing.International Journal of Forecasting ,15, 431\u2013443. Chen, C. (1997). Robustness properties of some forecasting methods for seasonal time series: A Monte Carlo study.International Journal of Forecasting ,13, 269\u2013280. Clements, M. P., & Hendry, D. F. (1997). An empirical study of seasonal unit roots in forecasting. International Journal of Forecasting ,13, 341\u2013355. Cleveland, R. B., Cleveland, W. S., McRae, J. E., & Terpenning, I. (1990). STL: A seasonal-trend decomposition procedure based on Loess (with discussion). Journal of Official Statistics ,6, 3\u201373.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 466Dagum, E. B. (1982). Revisions of time varying seasonal filters. Journal of Forecasting ,1, 173\u2013187. Findley, D. F., Monsell, B. C., Bell, W. R., Otto, M. C., & Chen, B.- C. (1998). New capabilities and methods of the X-12-ARIMA seasonal adjustment program. Journal of Business and Eco- nomic Statistics ,16, 127\u2013152. Findley, D. F., Wills, K. C., & Monsell, B. C. (2004). Seasonal adjustment perspectives on damping seasonal factors: Shrinkage estimators for the X-12-ARIMA program. International Journal of Forecasting ,20, 551\u2013556. Franses, P. H., & Koehler, A. B. (1998). A model selection strategy for time series with increasing seasonal variation. International Journal of Forecasting ,14, 405\u2013414. Franses, P. H., & Romijn, G. (1993). Periodic integration in quarterly UK macroeconomic variables. International Journal of Forecasting ,9, 467\u2013476. Franses, P. H., & van Dijk, D. (2005). The forecasting performance of various models for seasonality and nonlinearity for quarterly industrial production. International Journal of Forecasting ,21, 87\u2013102. Go\u00b4mez, V., & Maravall, A. (2001). Seasonal adjustment and signal extraction in economic time series. In D. Pen \u02dca, G. C. Tiao, & R. S. Tsay (Eds.), Chapter 8 in a course in time series analysis . New York 7John Wiley and Sons. Herwartz, H. (1997). Performance of periodic error correction models in forecasting consumption data. International Journal of Forecasting ,13, 421\u2013431. Huot, G., Chiu, K., & Higginson, J. (1986). Analysis of revisions in the seasonal adjustment of data using X-11-ARIMAmodel-based filters. International Journal of Forecasting ,2, 217\u2013229. Hylleberg, S., & Pagan, A. R. (1997). Seasonal integration and the evolving seasonals model. International Journal of Forecasting , 13, 329\u2013340. Hyndman, R. J. (2004). The interaction between trend and seasonality. International Journal of Forecasting ,20, 561\u2013563. Kaiser, R., & Maravall, A. (2005). Combining filter design with model-based filtering (with an application to business-cycle estimation). International Journal of Forecasting ,21, 691\u2013710. Koehler, A. B. (2004). Comments on damped seasonal factors and decisions by potential users. International Journal of Forecast- ing,20, 565\u2013566. Kulendran, N., & King, M. L. (1997). Forecasting interna- tional quarterly tourist flows using error-correction and time-series models. International Journal of Forecasting ,13, 319\u2013327. Ladiray, D., & Quenneville, B. (2004). Implementation issues on shrinkage estimators for seasonal factors within the X-11 seasonal adjustment method. International Journal of Forecast- ing,20, 557\u2013560. Miller, D. M., & Williams, D. (2003). Shrinkage estimators of time series seasonal factors and their effect on forecasting accuracy. International Journal of Forecasting ,19, 669\u2013684. Miller, D. M., & Williams, D. (2004). Damping seasonal factors: Shrinkage estimators for seasonal factors within the X-11 seasonal adjustment method (with commentary). International Journal of Forecasting ,20, 529\u2013550.Noakes, D. J., McLeod, A. I., & Hipel, K. W. (1985). Forecasting monthly riverflow time series. International Journal of Fore- casting ,1, 179\u2013190. Novales, A., & de Fruto, R. F. (1997). Forecasting with time periodic models: A comparison with time invariant coefficient models. International Journal of Forecasting ,13, 393\u2013405. Ord, J. K. (2004). Shrinking: When and how? International Journal of Forecasting ,20, 567\u2013568. Osborn, D. (1990). A survey of seasonality in UK macroeconomic variables. International Journal of Forecasting ,6, 327\u2013336. Paap, R., Franses, P. H., & Hoek, H. (1997). Mean shifts, unit roots and forecasting seasonal time series. International Journal of Forecasting ,13, 357\u2013368. Pfeffermann, D., Morry, M., & Wong, P. (1995). Estimation of the variances of X-11 ARIMA seasonally adjusted estimators for a multiplicative decomposition and heteroscedastic variances. International Journal of Forecasting ,11, 271\u2013283. Quenneville, B., Ladiray, D., & Lefranc \u00b8ois, B. (2003). A note on Musgrave asymmetrical trend-cycle filters. International Jour- nal of Forecasting ,19, 727\u2013734. Simmons, L. F. (1990). Time-series decomposition using the sinusoidal model. International Journal of Forecasting ,6, 485\u2013495. Taylor, A. M. R. (1997). On the practical problems of computing seasonal unit root tests. International Journal of Forecasting , 13, 307\u2013318. Ullah, T. A. (1993). Forecasting of multivariate periodic autore- gressive moving-average process. Journal of Time Series Analysis ,14, 645\u2013657. Wells, J. M. (1997). Modelling seasonal patterns and long-run trends in U.S. time series. International Journal of Forecasting , 13, 407\u2013420. Withycombe, R. (1989). Forecasting with combined seasonal indices. International Journal of Forecasting ,5, 547\u2013552. Section 5. State space and structural models and the Kalman filter Coomes, P. A. (1992). A Kalman filter formulation for noisy regional job data. International Journal of Forecasting ,7, 473\u2013481. Durbin, J., & Koopman, S. J. (2001). Time series analysis by state space methods . Oxford 7Oxford University Press. Fildes, R. (1983). An evaluation of Bayesian forecasting. Journal of Forecasting ,2, 137\u2013150. Grunwald, G. K., Raftery, A. E., & Guttorp, P. (1993). Time series of continuous proportions. Journal of the Royal Statistical Society (B) ,55, 103\u2013116. Grunwald, G. K., Hamza, K., & Hyndman, R. J. (1997). Some properties and generalizations of nonnegative Bayesian time series models. Journal of the Royal Statistical Society (B) ,59, 615\u2013626. Harrison, P. J., & Stevens, C. F. (1976). Bayesian forecasting. Journal of the Royal Statistical Society (B) ,38, 205\u2013247. Harvey, A. C. (1984). A unified view of statistical forecast- ing procedures (with discussion). Journal of Forecasting ,3, 245\u2013283. Harvey, A. C. (1989). Forecasting, structural time series models and the Kalman filter . Cambridge 7Cambridge University Press.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 467Harvey, A. C. (2006). Forecasting with unobserved component time series models. In G. Elliot, C. W. J. Granger, & A. Timmermann(Eds.), Handbook of economic forecasting . Amsterdam 7Elsevier Science. Harvey, A. C., & Fernandes, C. (1989). Time series models for count or qualitative observations. Journal of Business and Economic Statistics ,7, 407\u2013422. Harvey, A. C., & Snyder, R. D. (1990). Structural time series models in inventory control. International Journal of Forecast- ing,6, 187\u2013198. Kalman, R. E. (1960). A new approach to linear filtering and prediction problems. Transactions of the ASME\u2014Journal of Basic Engineering ,82D, 35\u201345. Mittnik, S. (1990). Macroeconomic forecasting experience with balanced state space models. International Journal of Forecast- ing,6, 337\u2013345. Patterson, K. D. (1995). Forecasting the final vintage of real personal disposable income: A state space approach. Interna- tional Journal of Forecasting ,11, 395\u2013405. Proietti, T. (2000). Comparing seasonal components for structural time series models. International Journal of Forecasting ,16, 247\u2013260. Ray, W. D. (1989). Rates of convergence to steady state for the linear growth version of a dynamic linear model (DLM).International Journal of Forecasting ,5, 537\u2013545. Schweppe, F. (1965). Evaluation of likelihood functions for Gaussian signals. IEEE Transactions on Information Theory , 11(1), 61\u201370. Shumway, R. H., & Stoffer, D. S. (1982). An approach to time series smoothing and forecasting using the EM algorithm. Journal of Time Series Analysis ,3, 253\u2013264. Smith, J. Q. (1979). A generalization of the Bayesian steady forecasting model. Journal of the Royal Statistical Society, Series B ,41, 375\u2013387. Vinod, H. D., & Basu, P. (1995). Forecasting consumption, income and real interest rates from alternative state space models.International Journal of Forecasting ,11, 217\u2013231. West, M., & Harrison, P. J. (1989). Bayesian forecasting and dynamic models (2nd ed., 1997). New York 7Springer-Verlag. West, M., Harrison, P. J., & Migon, H. S. (1985). Dynamic generalized linear models and Bayesian forecasting (with discussion). Journal of the American Statistical Association , 80, 73\u201383. Section 6. Nonlinear Adya, M., & Collopy, F. (1998). How effective are neural networks at forecasting and prediction? A review and evaluation. Journal of Forecasting ,17, 481\u2013495. Al-Qassem, M. S., & Lane, J. A. (1989). Forecasting exponential autoregressive models of order 1. Journal of Time Series Analysis ,10, 95\u2013113. Astatkie, T., Watts, D. G., & Watt, W. E. (1997). Nested threshold autoregressive (NeTAR) models. International Journal of Forecasting ,13, 105\u2013116. Balkin, S. D., & Ord, J. K. (2000). Automatic neural network modeling for univariate time series. International Journal of Forecasting ,16, 509\u2013515.Boero, G., & Marrocu, E. (2004). The performance of SETAR models: A regime conditional evaluation of point, interval anddensity forecasts. International Journal of Forecasting ,20, 305\u2013320. Bradley, M. D., & Jansen, D. W. (2004). Forecasting with a nonlinear dynamic model of stock returns andindustrial production. International Journal of Forecasting , 20, 321\u2013342. Brockwell, P. J., & Hyndman, R. J. (1992). On continuous-time threshold autoregression. International Journal of Forecasting , 8, 157\u2013173. Cai, Z., Fan, J., & Yao, Q. (2000). Functional-coefficient regression models for nonlinear time series. Journal of the American Statistical Association ,95, 941\u2013956. Callen, J. F., Kwan, C. C. Y., Yip, P. C. Y., & Yuan, Y. (1996). Neural network forecasting of quarterly accounting earnings. International Journal of Forecasting ,12, 475\u2013482. Cao, L., & Soofi, A. S. (1999). Nonlinear deterministic forecasting of daily dollar exchange rates. International Journal of Forecasting ,15, 421\u2013430. Cecen, A. A., & Erkal, C. (1996). Distinguishing between stochastic and deterministic behavior in high frequency foreign rate returns: Can non-linear dynamics help forecasting? Internation- al Journal of Forecasting ,12, 465\u2013473. Chatfield, C. (1993). Neural network: Forecasting breakthrough or passing fad? International Journal of Forecasting ,9,1 \u2013 3 . Chatfield, C. (1995). Positive or negative. International Journal of Forecasting ,11, 501\u2013502. Chen, R., & Tsay, R. S. (1993). Functional-coefficient autoregres- sive models. Journal of the American Statistical Association , 88, 298\u2013308. Church, K. B., & Curram, S. P. (1996). Forecasting consumers expenditure: A comparison between econometric and neural network models. International Journal of Forecasting ,12, 255\u2013267. Clements, M. P., & Smith, J. (1997). The performance of alternative methods for SETAR models. International Journal of Fore- casting ,13, 463\u2013475. Clements, M. P., Franses, P. H., & Swanson, N. R. (2004). Forecasting economic and financial time-series with non-linear models. International Journal of Forecasting ,20, 169\u2013183. Conejo, A. J., Contreras, J., Espi \u00b4nola, R., & Plazas, M. A. (2005). Forecasting electricity pric es for a day-ahead pool-based electricity market. International Journal of Forecasting ,21, 435\u2013462. Dahl, C. M., & Hylleberg, S. (2004). Flexible regression models and relative forecast performance. International Journal of Forecasting ,20, 201\u2013217. Darbellay, G. A., & Slama, M. (2000). Forecasting the short-term demand for electricity: Do neural networks stand a betterchance? International Journal of Forecasting ,16, 71\u201383. De Gooijer, J. G., & Kumar, V. (1992). Some recent developments in non-linear time series modelling, testing and forecasting. International Journal of Forecasting ,8, 135\u2013156. De Gooijer, J. G., & Vidiella-i-Anguera, A. (2004). Forecasting threshold cointegrated systems. International Journal of Fore- casting ,20, 237\u2013253.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 468Enders, W., & Falk, B. (1998). Threshold-autoregressive, median- unbiased, and cointegration tests of purchasing power parity.International Journal of Forecasting ,14, 171\u2013186. Ferna\u00b4ndez-Rodri \u00b4guez, F., Sosvilla-Rivero, S., & Andrada-Fe \u00b4lix, J. (1999). Exchange-rate forecasts with simultaneous nearest- neighbour methods; evidence from the EMS. International Journal of Forecasting ,15, 383\u2013392. Fok, D. F., van Dijk, D., & Franses, P. H. (2005). Forecasting aggregates using panels of nonlinear time series. International Journal of Forecasting ,21, 785\u2013794. Franses, P. H., Paap, R., & Vroomen, B. (2004). Forecasting unemployment using an autoregression with censored latent effects parameters. International Journal of Forecasting ,20, 255\u2013271. Ghiassi, M., Saidane, H., & Zimbra, D. K. (2005). A dynamic artificial neural network model for forecasting series events. International Journal of Forecasting ,21, 341\u2013362. Gorr, W. (1994). Research prospective on neural network forecast- ing.International Journal of Forecasting ,10,1 \u2013 4 . Gorr, W., Nagin, D., & Szczypula, J. (1994). Comparative study of artificial neural network and statistical models for predictingstudent grade point averages. International Journal of Fore- casting ,10, 17\u201334. Granger, C. W. J., & Tera \u00a8svirta, T. (1993). Modelling nonlinear economic relationships . Oxford 7Oxford University Press. Hamilton, J. D. (2001). A parametric approach to flexible nonlinear inference. Econometrica ,69, 537\u2013573. Harvill, J. L., & Ray, B. K. (2005). A note on multi-step forecasting with functional coefficient autoregressive models. International Journal of Forecasting ,21, 717\u2013727. Hastie, T. J., & Tibshirani, R. J. (1991). Generalized additive models . London 7Chapman and Hall. Heravi, S., Osborn, D. R., & Birchenhall, C. R. (2004). Linear versus neural network forecasting for European industrial production series. International Journal of Forecasting ,20, 435\u2013446. Herwartz, H. (2001). Investigating the JPY/DEM-rate: Arbitrage opportunities and a case for asymmetry. International Journal of Forecasting ,17, 231\u2013245. Hill, T., Marquez, L., OConnor, M., & Remus, W. (1994). Artificial neural network models for forecasting and decision making.International Journal of Forecasting ,10, 5\u201315. Hippert, H. S., Pedreira, C. E., & Souza, R. C. (2001). Neural networks for short-term load forecasting: A review andevaluation. IEEE Transactions on Power Systems ,16, 44\u201355. Hippert, H. S., Bunn, D. W., & Souza, R. C. (2005). Large neural networks for electricity load forecasting: Are they overfitted?International Journal of Forecasting ,21, 425\u2013434. Lisi, F., & Medio, A. (1997). Is a random walk the best exchange rate predictor? International Journal of Forecasting ,13, 255\u2013267. Ludlow, J., & Enders, W. (2000). Estimating non-linear ARMA models using Fourier coefficients. International Journal of Forecasting ,16, 333\u2013347. Marcellino, M. (2004). Forecasting EMU macroeconomic variables. International Journal of Forecasting ,20, 359\u2013372. Olson, D., & Mossman, C. (2003). Neural network forecasts of Canadian stock returns using accounting ratios. International Journal of Forecasting ,19, 453\u2013465.Pemberton, J. (1987). Exact least squares multi-step prediction from nonlinear autoregressive models. Journal of Time Series Analysis ,8, 443\u2013448. Poskitt, D. S., & Tremayne, A. R. (1986). The selection and use of linear and bilinear time series models. International Journal of Forecasting ,2, 101\u2013114. Qi, M. (2001). Predicting US recessions with leading indicators via neural network models. International Journal of Forecasting , 17, 383\u2013401. Sarantis, N. (2001). Nonlinearities, cyclical behaviour and predict- ability in stock markets: International evidence. International Journal of Forecasting ,17, 459\u2013482. Swanson, N. R., & White, H. (1997). Forecasting economic time series using flexible versus fixed specification and linear versusnonlinear econometric models. International Journal of Fore- casting ,13, 439\u2013461. Tera\u00a8svirta, T. (2006). Forecasting economic variables with nonlinear models. In G. Elliot, C. W. J. Granger, & A. Timmermann (Eds.), Handbook of economic forecasting . Amsterdam 7Elsevier Science. Tkacz, G. (2001). Neural network forecasting of Canadian GDP growth. International Journal of Forecasting ,17, 57\u201369. Tong, H. (1983). Threshold models in non-linear time series analysis . New York 7Springer-Verlag. Tong, H. (1990). Non-linear time series: A dynamical system approach . Oxford 7Clarendon Press. Volterra, V. (1930). Theory of functionals and of integro-differential equations . New York 7Dover. Wiener, N. (1958). Non-linear problems in random theory . London 7 Wiley. Zhang, G., Patuwo, B. E., & Hu, M. Y. (1998). Forecasting with artificial networks: The state of the art. International Journal of Forecasting ,14, 35\u201362. Section 7. Long memory Andersson, M. K. (2000). Do long-memory models have long memory? International Journal of Forecasting ,16, 121\u2013124. Baillie, R. T., & Chung, S. -K. (2002). Modeling and forecas- ting from trend-stationary long memory models with applica-tions to climatology. International Journal of Forecasting ,18, 215\u2013226. Beran, J., Feng, Y., Ghosh, S., & Sibbertsen, P. (2002). On robust local polynomial estimation with long-memory errors. Interna- tional Journal of Forecasting ,18, 227\u2013241. Bhansali, R. J., & Kokoszka, P. S. (2002). Computation of the fore- cast coefficients for multistep prediction of long-range dependenttime series. International Journal of Forecasting ,18, 181\u2013206. Franses, P. H., & Ooms, M. (1997). A periodic long-memory model for quarterly UK inflation. International Journal of Forecasting , 13, 117\u2013126. Granger, C. W. J., & Joyeux, R. (1980). An introduction to long memory time series models and fractional differencing. Journal of Time Series Analysis ,1, 15\u201329. Hurvich, C. M. (2002). Multistep forecasting of long memory series using fractional exponential models. International Journal of Forecasting ,18, 167\u2013179.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 469Man, K. S. (2003). Long memory time series and short term forecasts. International Journal of Forecasting ,19, 477\u2013491. O\u00a8ller, L. -E. (1985). How far can changes in general business activity be forecasted? International Journal of Forecasting ,1, 135\u2013141. Ramjee, R., Crato, N., & Ray, B. K. (2002). A note on moving average forecasts of long memory processes with an application to quality control. International Journal of Forecasting ,18, 291\u2013297. Ravishanker, N., & Ray, B. K. (2002). Bayesian prediction for vector ARFIMA processes. International Journal of Forecast- ing,18, 207\u2013214. Ray, B. K. (1993a). Long-range forecasting of IBM product revenues using a seasonal fractionally differenced ARMA model. International Journal of Forecasting ,9, 255\u2013269. Ray, B. K. (1993b). Modeling long-memory processes for optimal long-range prediction. Journal of Time Series Analysis ,14, 511\u2013525. Smith, J., & Yadav, S. (1994). Forecasting costs incurred from unit differencing fractionally integrated processes. International Journal of Forecasting ,10, 507\u2013514. Souza, L. R., & Smith, J. (2002). Bias in the memory for different sampling rates. International Journal of Forecasting , 18, 299\u2013313. Souza, L. R., & Smith, J. (2004). Effects of temporal aggregation on estimates and forecasts of fractionally integrated processes: A Monte-Carlo study. International Journal of Forecasting ,20, 487\u2013502. Section 8. ARCH/GARCH Awartani, B. M. A., & Corradi, V. (2005). Predicting the volatility of the S&P-500 stock index via GARCH models: The role of asymmetries. International Journal of Forecasting , 21, 167\u2013183. Baillie, R. T., Bollerslev, T., & Mikkelsen, H. O. (1996). Fractionally integrated generalized autoregressive conditionalheteroskedasticity. Journal of Econometrics ,74, 3\u201330. Bera, A., & Higgins, M. (1993). ARCH models: Properties, esti- mation and testing. Journal of Economic Surveys ,7, 305\u2013365. Bollerslev, T., & Wright, J. H. (2001). High-frequency data, frequency domain inference, and volatility forecasting. Review of Economics and Statistics ,83, 596\u2013602. Bollerslev, T., Chou, R. Y., & Kroner, K. F. (1992). ARCH modeling in finance: A review of the theory and empirical evidence. Journal of Econometrics ,52, 5\u201359. Bollerslev, T., Engle, R. F., & Nelson, D. B. (1994). ARCH models. In R. F. Engle, & D. L. McFadden (Eds.), Handbook of econometrics, vol. IV (pp. 2959\u20133038). Amsterdam 7North- Holland. Brooks, C. (1998). Predicting stock index volatility: Can market volume help? Journal of Forecasting ,17, 59\u201380. Brooks, C., Burke, S. P., & Persand, G. (2001). Benchmarks and the accuracy of GARCH model estimation. International Journal of Forecasting ,17, 45\u201356. Diebold, F. X., & Lopez, J. (1995). Modeling volatility dynamics. In Kevin Hoover (Ed.), Macroeconometrics: developments, ten-sions and prospects (pp. 427\u2013472). Boston 7Kluwer Academic Press. Doidge, C., & Wei, J. Z. (1998). Volatility forecasting and the efficiency of the Toronto 35 index options market. Canadian Journal of Administrative Sciences ,15, 28\u201338. Engle, R. F. (1982). Autoregressive conditional heteroscedasticity with estimates of the variance of the United Kingdom inflation. Econometrica ,50, 987\u20131008. Engle, R. F. (2002). New frontiers for ARCH models. Manuscript prepared for the conference bModeling and Forecasting Finan- cial Volatility (Perth, Australia, 2001). Available at http://pages.stern.nyu.edu/~rengle Engle, R. F., & Ng, V. (1993). Measuring and testing the impact of news on volatility. Journal of Finance ,48, 1749\u20131778. Franses, P. H., & Ghijsels, H. (1999). Additive outliers, GARCH and forecasting volatility. International Journal of Forecasting , 15, 1\u20139. Galbraith, J. W., & Kisinbay, T. (2005). Content horizons for conditional variance forecasts. International Journal of Fore- casting ,21, 249\u2013260. Granger, C. W. J. (2002). Long memory, volatility, risk and distribution. Manuscript . San Diego 7University of California Availableathttp://www.cass.city.ac.uk/conferences/esrc2002/ Granger.pdf Hentschel, L. (1995). All in the family: Nesting symmetric and asymmetric GARCH models. Journal of Financial Economics , 39, 71\u2013104. Karanasos, M. (2001). Prediction in ARMA models with GARCH in mean effects. Journal of Time Series Analysis ,22, 555\u2013576. Kroner, K. F., Kneafsey, K. P., & Claessens, S. (1995). Forecasting volatility in commodity markets. Journal of Forecasting ,14, 77\u201395. Pagan, A. (1996). The econometrics of financial markets. Journal of Empirical Finance ,3, 15\u2013102. Poon, S. -H., & Granger, C. W. J. (2003). Forecasting volatility in financial markets: A review. Journal of Economic Literature , 41, 478\u2013539. Poon, S. -H., & Granger, C. W. J. (2005). Practical issues in forecasting volatility. Financial Analysts Journal ,61, 45\u201356. Sabbatini, M., & Linton, O. (1998). A GARCH model of the implied volatility of the Swiss market index from option prices. International Journal of Forecasting ,14, 199\u2013213. Taylor, S. J. (1987). Forecasting the volatility of currency exchange rates. International Journal of Forecasting ,3, 159\u2013170. Vasilellis, G. A., & Meade, N. (1996). Forecasting volatility for portfolio selection. Journal of Business Finance and Account- ing,23, 125\u2013143. Section 9. Count data forecasting Bra \u00a8nna \u00a8s, K. (1995). Prediction and control for a time-series count data model. International Journal of Forecasting ,11, 263\u2013270. Bra \u00a8nna \u00a8s, K., Hellstro \u00a8m, J., & Nordstro \u00a8m, J. (2002). A new approach to modelling and forecasting monthly guest nights in hotels. International Journal of Forecasting ,18, 19\u201330.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 470Croston, J. D. (1972). Forecasting and stock control for intermittent demands. Operational Research Quarterly ,23, 289\u2013303. Diebold, F. X., Gunther, T. A., & Tay, A. S. (1998). Evaluating density forecasts, with applications to financial risk manage- ment. International Economic Review ,39, 863\u2013883. Diggle, P. J., Heagerty, P., Liang, K. -Y., & Zeger, S. (2002). Analysis of longitudinal data (2nd ed.). Oxford 7Oxford University Press. Freeland, R. K., & McCabe, B. P. M. (2004). Forecasting discrete valued low count time series. International Journal of Fore- casting ,20, 427\u2013434. Grunwald, G. K., Hyndman, R. J., Tedesco, L. M., & Tweedie, R. L. (2000). Non-Gaussian conditional linear AR(1) models. Aus- tralian and New Zealand Journal of Statistics ,42, 479\u2013495. Johnston, F. R., & Boylan, J. E. (1996). Forecasting intermittent demand: A comparative evaluation of Croston Tmethod. International Journal of Forecasting ,12, 297\u2013298. McCabe, B. P. M., & Martin, G. M. (2005). Bayesian predictions of low count time series. International Journal of Forecasting ,21, 315\u2013330. Syntetos, A. A., & Boylan, J. E. (2005). The accuracy of intermittent demand estimates. International Journal of Fore- casting ,21, 303\u2013314. Willemain, T. R., Smart, C. N., Shockor, J. H., & DeSautels, P. A. (1994). Forecasting intermittent demand in manufacturing: Acomparative evaluation of Croston Ts method. International Journal of Forecasting ,10, 529\u2013538. Willemain, T. R., Smart, C. N., & Schwarz, H. F. (2004). A new approach to forecasting intermittent demand for service partsinventories. International Journal of Forecasting ,20, 375\u2013387. Section 10. Forecast evaluation and accuracy measures Ahlburg, D. A., Chatfield, C., Taylor, S. J., Thompson, P. A., Winkler, R. L., Murphy A. H., et al. (1992). A commentary on error measures. International Journal of Forecasting ,8, 99 \u2013 111. Armstrong, J. S., & Collopy, F. (1992). Error measures for generalizing about forecasting methods: Empirical comparisons. International Journal of Forecasting ,8, 69\u201380. Chatfield, C. (1988). Editorial: Apples, oranges and mean square error. International Journal of Forecasting ,4, 515\u2013518. Clements, M. P., & Hendry, D. F. (1993). On the limitations of comparing mean square forecast errors. Journal of Forecasting , 12, 617\u2013637. Diebold, F. X., & Mariano, R. S. (1995). Comparing predictive accuracy. Journal of Business and Economic Statistics ,13 , 253\u2013263. Fildes, R. (1992). The evaluation of extrapolative forecasting methods. International Journal of Forecasting ,8, 81\u201398. Fildes, R., & Makridakis, S. (1988). Forecasting and loss functions. International Journal of Forecasting ,4, 545\u2013550. Fildes, R., Hibon, M., Makridakis, S., & Meade, N. (1998). General- ising about univariate forecasting methods: Further empirical evidence. International Journal of Forecasting ,14, 339\u2013358. Flores, B. (1989). The utilization of the Wilcoxon test to compare forecasting methods: A note. International Journal of Fore- casting ,5, 529\u2013535.Goodwin, P., & Lawton, R. (1999). On the asymmetry of the symmetric MAPE. International Journal of Forecasting ,15, 405\u2013408. Granger, C. W. J., & Jeon, Y. (2003a). A time\u2013distance criterion for evaluating forecasting models. International Journal of Fore- casting ,19, 199\u2013215. Granger, C. W. J., & Jeon, Y. (2003b). Comparing forecasts of inflation using time distance. International Journal of Fore- casting ,19, 339\u2013349. Harvey, D., Leybourne, S., & Newbold, P. (1997). Testing the equality of prediction mean squared errors. International Journal of Forecasting ,13, 281\u2013291. Koehler, A. B. (2001). The asymmetry of the sAPE measure and other comments on the M3-competition. International Journal of Forecasting ,17, 570\u2013574. Mahmoud, E. (1984). Accuracy in forecasting: A survey. Journal of Forecasting ,3, 139\u2013159. Makridakis, S. (1993). Accuracy measures: Theoretical and practical concerns. International Journal of Forecasting ,9, 527\u2013529. Makridakis, S., & Hibon, M. (2000). The M3-competition: Results, conclusions and implications. International Journal of Fore- casting ,16, 451\u2013476. Makridakis, S., Andersen, A., Carbone, R., Fildes, R., Hibon, M., Lewandowski, R., et al. (1982). The accuracy of extrapolation(time series) methods: Results of a forecasting competition. Journal of Forecasting ,1, 111\u2013153. Makridakis, S., Wheelwright, S. C., & Hyndman, R. J. (1998). Forecasting: Methods and applications (3rd ed.). New York 7 John Wiley and Sons. McCracken, M. W. (2004). Parameter estimation and tests of equal forecast accuracy between non-nested models. International Journal of Forecasting ,20, 503\u2013514. Sullivan, R., Timmermann, A., & White, H. (2003). Forecast evaluation with shared data sets. International Journal of Forecasting ,19, 217\u2013227. Theil, H. (1966). Applied economic forecasting . Amsterdam 7North- Holland. Thompson, P. A. (1990). An MSE statistic for comparing forecast accuracy across series. International Journal of Forecasting ,6, 219\u2013227. Thompson, P. A. (1991). Evaluation of the M-competition forecasts via log mean squared error ratio. International Journal of Forecasting ,7, 331\u2013334. Wun, L. -M., & Pearn, W. L. (1991). Assessing the statistical characteristics of the mean absolute error of forecasting.International Journal of Forecasting ,7, 335\u2013337. Section 11. Combining Aksu, C., & Gunter, S. (1992). An empirical analysis of the accuracy of SA, OLS, ERLS and NRLS combination forecasts. International Journal of Forecasting ,8, 27\u201343. Bates, J. M., & Granger, C. W. J. (1969). Combination of forecasts. Operations Research Quarterly ,20, 451\u2013468. Bunn, D. W. (1985). Statistical efficiency in the linear combination of forecasts. International Journal of Forecasting ,1, 151\u2013163.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 471Clemen, R. T. (1989). Combining forecasts: A review and annotated biography (with discussion). International Journal of Forecast- ing,5, 559\u2013583. de Menezes, L. M., & Bunn, D. W. (1998). The persistence of specification problems in the distribution of combined forecast errors. International Journal of Forecasting ,14, 415\u2013426. Deutsch, M., Granger, C. W. J., & Tera \u00a8svirta, T. (1994). The combination of forecasts using changing weights. International Journal of Forecasting ,10, 47\u201357. Diebold, F. X., & Pauly, P. (1990). The use of prior information in forecast combination. International Journal of Forecasting ,6, 503\u2013508. Fang, Y. (2003). Forecasting combination and encompassing tests. International Journal of Forecasting ,19, 87\u201394. Fiordaliso, A. (1998). A nonlinear forecast combination method based on Takagi-Sugeno fuzzy systems. International Journal of Forecasting ,14, 367\u2013379. Granger, C. W. J. (1989). Combining forecasts\u2014twenty years later. Journal of Forecasting ,8, 167\u2013173. Granger, C. W. J., & Ramanathan, R. (1984). Improved methods of combining forecasts. Journal of Forecasting ,3, 197\u2013204. Gunter, S. I. (1992). Nonnegativity restricted least squares combinations. International Journal of Forecasting ,8, 45\u201359. Hendry, D. F., & Clements, M. P. (2002). Pooling of forecasts. Econometrics Journal ,5, 1\u201331. Hibon, M., & Evgeniou, T. (2005). To combine or not to combine: Selecting among forecasts and their combinations. International Journal of Forecasting ,21, 15\u201324. Kamstra, M., & Kennedy, P. (1 998). Combining qualitative forecasts using logit. International Journal of Forecasting ,14, 83\u201393. Miller, S. M., Clemen, R. T., & Winkler, R. L. (1992). The effect of nonstationarity on combined forecasts. International Journal of Forecasting ,7, 515\u2013529. Taylor, J. W., & Bunn, D. W. (1999). Investigating improvements in the accuracy of prediction intervals for combinations offorecasts: A simulation study. International Journal of Fore- casting ,15, 325\u2013339. Terui, N., & van Dijk, H. K. (2002). Combined forecasts from linear and nonlinear time series models. International Journal of Forecasting ,18, 421\u2013438. Winkler, R. L., & Makridakis, S. (1983). The combination of forecasts. Journal of the Royal Statistical Society (A) ,146, 150\u2013157. Zou, H., & Yang, Y. (2004). Combining time series models for forecasting. International Journal of Forecasting ,20, 69\u201384. Section 12. Prediction intervals and densities Chatfield, C. (1993). Calculating interval forecasts. Journal of Business and Economic Statistics ,11, 121\u2013135. Chatfield, C., & Koehler, A. B. (1991). On confusing lead time demand with h-period-ahead forecasts. International Journal of Forecasting ,7, 239\u2013240. Clements, M. P., & Smith, J. (2002). Evaluating multivariate forecast densities: A comparison of two approaches. Interna- tional Journal of Forecasting ,18, 397\u2013407.Clements, M. P., & Taylor, N. (2001). Bootstrapping prediction intervals for autoregressive models. International Journal of Forecasting ,17, 247\u2013267. Diebold, F. X., Gunther, T. A., & Tay, A. S. (1998). Evaluating density forecasts with applications to financial risk management. International Economic Review ,39, 863\u2013883. Diebold, F. X., Hahn, J. Y., & Tay, A. S. (1999). Multivariate density forecast evaluation and calibration in financial risk management: High-frequency returns in foreign exchange.Review of Economics and Statistics ,81, 661\u2013673. Grigoletto, M. (1998). Bootstrap prediction intervals for autore- gressions: Some alternatives. International Journal of Forecast- ing,14, 447\u2013456. Hyndman, R. J. (1995). Highest density forecast regions for non- linear and non-normal time series models. Journal of Forecast- ing,14, 431\u2013441. Kim, J. A. (1999). Asymptotic and bootstrap prediction regions for vector autoregression. International Journal of Forecasting ,15, 393\u2013403. Kim, J. A. (2004a). Bias-corrected bootstrap prediction regions for vector autoregression. Journal of Forecasting ,23, 141\u2013154. Kim, J. A. (2004b). Bootstrap prediction intervals for autoregression using asymptotically mean-unbiased estimators. International Journal of Forecasting ,20, 85\u201397. Koehler, A. B. (1990). An inappropriate prediction interval. International Journal of Forecasting ,6, 557\u2013558. Lam, J. -P., & Veall, M. R. (2002). Bootstrap prediction intervals for single period regression forecasts. International Journal of Forecasting ,18, 125\u2013130. Lefranc \u00b8ois, P. (1989). Confidence intervals for non-stationary forecast errors: Some empirical results for the series in the M-competition. International Journal of Forecasting ,5, 553\u2013557. Makridakis, S., & Hibon, M. (1987). Confidence intervals: An empirical investigation of the series in the M-competition.International Journal of Forecasting ,3, 489\u2013508. Masarotto, G. (1990). Bootstrap prediction intervals for autore- gressions. International Journal of Forecasting ,6, 229\u2013239. McCullough, B. D. (1994). Bootstrapping forecast intervals: An application to AR(p) models. Journal of Forecasting ,13, 51\u201366. McCullough, B. D. (1996). Consistent forecast intervals when the forecast-period exogenous variables are stochastic. Journal of Forecasting ,15, 293\u2013304. Pascual, L., Romo, J., & Ruiz, E. (2001). Effects of parameter estimation on prediction densities: A bootstrap approach.International Journal of Forecasting ,17, 83\u2013103. Pascual, L., Romo, J., & Ruiz, E. (2004). Bootstrap predictive inference for ARIMA processes. Journal of Time Series Analysis ,25, 449\u2013465. Pascual, L., Romo, J., & Ruiz, E. (2005). Bootstrap prediction intervals for power-transformed time series. International Journal of Forecasting ,21, 219\u2013236. Reeves, J. J. (2005). Bootstrap prediction intervals for ARCH models. International Journal of Forecasting ,21, 237\u2013248. Tay, A. S., & Wallis, K. F. (2000). Density forecasting: A survey. Journal of Forecasting ,19, 235\u2013254.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 472Wall, K. D., & Stoffer, D. S. (2002). A state space approach to bootstrapping conditional forecasts in ARMA models. Journal of Time Series Analysis ,23, 733\u2013751. Wallis, K. F. (1999). Asymmetric density forecasts of inflation and the Bank of England\u2019s fan chart. National Institute Economic Review ,167, 106\u2013112. Wallis, K. F. (2003). Chi-squared tests of interval and density forecasts, and the Bank of England fan charts. International Journal of Forecasting ,19, 165\u2013175. Section 13. A look to the future Andersen, T. G., Bollerslev, T., Diebold, F. X., & Labys, P. (2003). Modeling and forecasting realized volatility. Econometrica ,71, 579\u2013625. Armstrong, J. S. (2001). Suggestions for further research . www.forecastingprinciples.com/researchers.html Casella, G., et al., (Eds.). (2000). Vignettes for the year 2000. Journal of the American Statistical Association ,95,1269\u20131368. Chatfield, C. (1988). The future of time-series forecasting. International Journal of Forecasting ,4, 411\u2013419. Chatfield, C. (1997). Forecasting in the 1990s. The Statistician ,46, 461\u2013473. Clements, M. P. (2003). Editorial: Some possible directions for future research. International Journal of Forecasting ,19, 1\u20133. Cogger, K. C. (1988). Proposals for research in time series forecasting. International Journal of Forecasting ,4, 403\u2013410. Dawes, R., Fildes, R., Lawrence, M., & Ord, J. K. (1994). The past and the future of forecasting research. International Journal of Forecasting ,10, 151\u2013159. De Gooijer, J. G. (1990). Editorial: The role of time series analysis in forecasting: A personal view. International Journal of Forecasting ,6, 449\u2013451. De Gooijer, J. G., & Gannoun, A. (2000). Nonparametric conditional predictive regions for time series. Computational Statistics and Data Analysis ,33, 259\u2013275. Dekimpe, M. G., & Hanssens, D. M. (2000). Time-series models in marketing: Past, present and future. International Journal of Research in Marketing ,17, 183\u2013193. Engle, R. F., & Manganelli, S. (2004). CAViaR: Conditional autoregressive value at risk by regression quantiles. Journal of Business and Economic Statistics ,22, 367\u2013381.Engle, R. F., & Russell, J. R. (1998). Autoregressive conditional duration: A new model for irregularly spaced transactions data.Econometrica ,66 , 1127\u20131162. Forni, M., Hallin, M., Lippi, M., & Reichlin, L. (2005). The generalized dynamic factor model: One-sided estimation and forecasting. Journal of the American Statistical Association , 100, 830\u2013840. Koenker, R. W., & Bassett, G. W. (1978). Regression quantiles. Econometrica ,46, 33\u201350. Ord, J. K. (1988). Future developments in forecasting: The time series connexion. International Journal of Forecasting ,4, 389\u2013401. Pen\u02dca, D., & Poncela, P. (2004). Forecasting with nonstation- ary dynamic factor models. Journal of Econometrics ,119, 291\u2013321. Polonik, W., & Yao, Q. (2000). Conditional minimum volume predictive regions for stochastic processes. Journal of the American Statistical Association ,95, 509\u2013519. Ramsay, J. O., & Silverman, B. W. (1997). Functional data analysis (2nd ed. 2005). New York 7Springer-Verlag. Stock, J. H., & Watson, M. W. (1999). A comparison of linear and nonlinear models for forecasting macroeconomic time series. In R. F. Engle, & H. White (Eds.), Cointegration, causality and forecasting (pp. 1\u201344). Oxford 7Oxford University Press. Stock, J. H., & Watson, M. W. (2002). Forecasting using principal components from a large number of predictors. Journal of the American Statistical Association ,97, 1167\u20131179. Stock, J. H., & Watson, M. W. (2004). Combination forecasts of output growth in a seven-country data set. Journal of Forecasting ,23, 405\u2013430. Tera\u00a8svirta, T. (2006). Forecasting economic variables with nonlinear models. In G. Elliot, C. W. J. Granger, & A. Timmermann(Eds.), Handbook of economic forecasting. Amsterdam 7Elsevier Science. Tsay, R. S. (2000). Time series and forecasting: Brief history and future research. Journal of the American Statistical Association , 95, 638\u2013643. Yao, Q., & Tong, H. (1995). On initial-condition and prediction in nonlinear stochastic systems. Bulletin International Statistical Institute ,IP10.3 , 395\u2013412.J.G. De Gooijer, R.J. Hyndman / International Journal of Forecasting 22 (2006) 443\u2013473 473", "13": "SPECIAL ISSUE Machinelearningadvancesfortimeseries forecasting RicardoP.Masini1,2MarceloC.Medeiros3EduardoF.Mendes4 1CenterforStatisticsandMachine Learning,PrincetonUniversity,USA 2S\u00e3oPauloSchoolofEconomics,Getulio VargasFoundation,Brazil 3DepartmentofEconomics,Pontifical CatholicUniversityofRiodeJaneiro, Brazil 4SchoolofAppliedMathematics,Getulio VargasFoundation,Brazil Correspondence MarceloC.Medeiros,PontificalCatholic UniversityofRiodeJaneiro,RuaMarqu\u00eas deS\u00e3oVicente,225,G\u00e1vea,RiodeJaneiro, RJ,Brazil. Email:mcm@econ.puc-rio.br Fundinginformation CNPqandCAPES;ConselhoNacionalde DesenvolvimentoCient\u00edficoeTecnol\u00f3gicoAbstract In this paper, we survey the most recent advances in supervised machine learning (ML) and high- dimensional models for time-series forecasting. We considerbothlinearandnonlinearalternatives.Among the linear methods, we pay special attention to penal- izedregressionsandensembleofmodels.Thenonlinear methods considered in the paper include shallow and deep neural networks, in their feedforward and recurrent versions, and tree-based methods, such as random forests and boosted trees. We also consider ensembleandhybridmodelsbycombiningingredients fromdifferentalternatives.Testsforsuperiorpredictive ability are briefly reviewed. Finally, we discuss appli- cationofMLineconomicsandfinanceandprovidean illustrationwithhigh-frequencyfinancialdata. KEYWORDS bagging, boosting, deep learning, forecasting, machine learning, neural networks, nonlinear models, penalized regressions, ran- domforests,regressiontrees,regularization,sieveapproximation, statisticallearningtheory JEL CLASSIFICATION: C22 1INTRODUCTION Thispapersurveystherecentdevelopmentsinmachinelearning(ML)methodstoeconomicand financialtime-seriesforecasting.MLmethodshavebecomeanimportantestimation,modelselec- tion,andforecastingtoolforappliedresearchersinEconomicsandFinance.Withtheavailability 76\u00a92021JohnWiley&SonsLtd. JEconSurv. 2023;37:76\u2013111. wileyonlinelibrary.com/journal/joes MASINIetal. 77 ofvastdatasetsintheeraof BigData,producingreliableandrobustforecastsisofgreatimpor- tance.1 However,whatisML?Itiscertainlyabuzzwordwhichhasgainedalotofpopularityduring the last few years. There are a myriad of definitions in the literature and one of the most well establishedisfromtheartificialintelligencepioneerArthurL.SamuelwhodefinesMLas\u201cthe fieldofstudythatgivescomputerstheabilitytolearnwithoutbeingexplicitlyprogrammed.\u201d2We preferalessvaguedefinitionwhereMListhecombinationofautomatedcomputeralgorithms with powerful statistical methods to learn (discover) hidden patterns in rich data sets. In that sense,Statistical Learning Theory gives the statistical foundation of ML. Therefore, this paper is about Statistical Learning developments and not ML in general as we are going to focus on statisticalmodels.MLmethodscanbedividedintothreemajorgroups:supervised,unsupervised, andreinforcementlearning.Thissurveyisaboutsupervisedlearning,wherethetaskistolearn afunctionthatmapsaninput(explanatoryvariables)toanoutput(dependentvariable)basedon dataorganizedasinput\u2013outputpairs.Regressionmodels,forexample,belongtothisclass.Onthe otherhand,unsupervisedlearningisaclassofMLmethodsthatuncoverundetectedpatternsina datasetwithnopreexistinglabelsas,forexample,clusteranalysisordatacompressionalgorithms. Finally,inreinforcementlearning,anagentlearnstoperformcertainactionsinanenvironment whichleadittomaximumreward.Itdoessobyexplorationandexploitationofknowledgeitlearns byrepeatedtrialsofmaximizingthereward.Thisisthecoreofseveralartificialintelligencegame players(AlfaGo,forinstance)aswellasinsequentialtreatments,likeBanditproblems. The supervised ML methods presented here can be roughly divided in two groups. The first oneincludeslinearmodelsandisdiscussedinSection 2.Wefocusmainlyonspecificationsesti- matedbyregularization,alsoknownasshrinkage.SuchmethodsdatebackatleasttoTikhonov (1943).InStatisticsandEconometrics,regularizedestimatorsgainedattentionaftertheseminal papers by Willard James and Charles Stein who popularized the bias-variance trade-off in sta- tistical estimation (James & Stein, 1961;S t e i n ,1956). We start by considering the Ridge Regres- sionestimatorputforwardbyHoerlandKennard( 1970).Afterthat,wepresenttheleastabsolute shrinkageandselection(LASSO)estimatorofTibshirani( 1996)anditsmanyextensions.Wealso includeadiscussionofotherpenalties.Theoreticalderivationsandinferencefordependentdata arealsoreviewed. ThesecondgroupofMLtechniquesfocusesonnonlinearmodels.WecoverthistopicinSec- tion3andstartbypresentingaunifiedframeworkbasedonsievesemiparametricapproximation as in Grenander ( 1981). We continue by analyzing specific models as special cases of our gen- eralsetup.Morespecifically,wecoverfeedforwardneuralnetworks(NNs),bothintheirshallow anddeepversionsandrecurrentneuralnetworks(RNNs),andtree-basedmodelssuchasrandom forests(RFs)andboostedtrees.NNsareprobablyoneofthemostpopularMLmethods.Thesuc- cessispartlyduetothe,inouropinion,misguidedanalogytothefunctioningofthehumanbrain. Contrary to what has been boasted in the early literature, the empirical success of NN models comesfromamathematicalfactthatalinearcombinationofsufficientlymanysimplebasisfunc- tionsisabletoapproximateverycomplicatedfunctionsarbitrarilywellinsomespecificchoiceof metric.Regressiontreesonlyachievedpopularityafterthedevelopmentofalgorithmstoatten- uatetheinstabilityoftheestimatedmodels.AlgorithmslikeRandomForestsandBoostedTrees arenowinthetoolboxofappliedeconomists. Inadditiontothemodelsmentionedabove,wealsoincludeasurveyonensemble-basedmeth- odssuchasBaggingBreiman( 1996)andthecompletesubsetregression(CRS,Elliottetal., 2013, 2015).Furthermore,wegiveabriefintroductiontowhatwenamed\u201chybridmethods,\u201dwhereideas frombothlinearandnonlinearmodelsarecombinedtogeneratenewMLforecastingmethods.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 78 MASINIetal. Beforepresentinganempiricalillustrationofthemethods,wediscusstestsofsuperiorpredic- tiveabilityinthecontextofMLmethods. 1.1Generalframework Aquickwordonnotation:anuppercaseletterasin ??denotesarandomquantityasopposedtoa lowercaseletter ??whichdenotesadeterministic(nonrandom)quantity.Boldlettersasin ??and ??arereservedformultivariateobjectssuchasvectorandmatrices.Thesymbol ?\u00b7???for??=1 denotesthe????normofavector.Foraset ??,weuse |??|todenoteitscardinality. Givenasamplewith ??realizationsoftherandomvector (????,??' ??)',thegoalistopredict ????+h forhorizonsh=1,\u2026,?? .Throughoutthepaper,weconsiderthefollowingassumption: Assumption 1 (Data Generating Process (DGP)). Let {(????,??' ??)'}8 ??=1be a covariance-stationary stochasticprocesstakingvalueson R??+1. Therefore, we are excluding important nonstationary processes that usually appear in time- seriesapplications.Inparticular,unitrootandsometypesonlong-memoryprocessareexcluded byAssumption 1. For(usuallypredetermined)integers ??=1and??=0,definethe??-dimensionalvectorofpre- dictors????:=(????-1,\u2026,????-??,??' ??,\u2026,??' ??-??)'where??=??+??(??+1) and consider the following directforecastingmodel: ????+h=??h(????)+????+h, h=1,\u2026,??, ??=1,\u2026,??, (1) where??h:R???Ris an unknown (measurable) function and ????+h:=????+h-??h(????)is assumedtobezeromeanandfinitevariance.3 Themodel??hcouldbetheconditionalexpectationfunction, ??h(??)=??(????+h|????=?? ),orsim- plythebestlinearprojectionof ????+hontothespacespannedby ????.Regardlessofthemodelchoice, ourtargetbecomes ??h,forh=1,\u2026,?? .As??hisunknown,itshouldbeestimatedfromdata.The targetfunction ??hcanbeasinglemodeloranensembleofdifferentspecificationsanditcanalso changesubstantiallyforeachforecastinghorizon. Given an estimate \u02c6??hfor??h, the next step is to evaluate the forecasting method by estimat- ingitspredictionaccuracy.Mostmeasuresofpredictionaccuracyderivefromtherandomquan- tity?h(????):=|\u02c6??h(????)-??h(????)|.Forinstance,theterm predictionconsistency referstoestimators suchthat?h(????)???0as???8wheretheprobabilityistakentobeunconditional;asopposed toitsconditional counterpartwhichisgivenby ?h(????)???0,wheretheprobabilitylawiscondi- tionalon????=????.Clearly,ifthelatterholdsfor(almost)every ????thentheformerholdsbythelaw ofiteratedexpectation. Othermeasuresofpredictionaccuracycanbederivedfromthe ???norminducedbyeitherthe unconditionalprobabilitylaw ??|?h(????)|??ortheconditionalone ??(|?h(????)|??|????=????)for??=1. Byfar,themostusedarethe (conditional)meanabsolutelypredictionerror (????????)when??=1and (conditional)meansquaredpredictionerror (????????) when??=2, or the(conditional)rootmean squaredpredictionerror (??????????), which is simply thesquare root of ????????. Those measuresof predictionaccuracybasedonthe ???normsarestrongerthanpredictionconsistencyinthesense  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 79 thattheirconvergencetozeroassamplesizeincreasesimpliespredictionconsistencybyMarkov\u2019s inequality. Thisapproachstemsfromcastingeconomicforecastingasadecisionproblem.Underthechoice ofalossfunction,thegoalistoselect ??hfromafamilyofcandidatemodelsthatminimizesthe expectedpredictivelossorrisk.Givenanestimate \u02c6??hfor??h,thenextstepistoevaluatethefore- castingmethodbyestimatingitsrisk.Themostcommonlyusedlossesaretheabsoluteerrorand squarederror,correspondingto ?1and?2riskfunctions,respectively.SeeGrangerandMachina (2006)forreferencesofadetailedexpositionofthistopic,ElliottandTimmermann( 2008)fora discussionoftheroleofthelossfunctioninforecasting,andElliottandTimmermann( 2016)for amorerecentreview. 1.2Summaryofthepaper Apartfromthisbriefintroduction,thepaperisorganizedasfollows.Section 2reviewspenalized linearregressionmodels.NonlinearMLmodelsarediscussedinSection 3.Ensembleandhybrid methodsarepresentedinSection 4.Section5brieflydiscussestestsforsuperiorpredictiveabil- ity. An empirical application is presented in Section 6. Finally, we conclude and discuss some directionsforfutureresearchinSection 7. 2PENALIZEDLINEARMODELS Weconsiderthefamilyoflinearmodelswhere ??(??)=??' 0??in(1)foravectorofunknownparam- eters??0?R??. Notice that we drop the subscript hfor clarity. However, the model as well as theparameter ??0havetobeunderstoodforparticularvalueoftheforecastinghorizon h.These modelscontemplateaseriesofwell-knownspecificationsintime-seriesanalysis,suchaspredic- tiveregressions,autoregressivemodelsoforder ??,????(??),autoregressivemodelswithexogenous variables,??????(??),andautoregressivemodelswithdynamiclags ??????(??,??),amongmanyothers (Hamilton, 1994).Inparticular,( 1)becomes ????+h=??' 0????+????+h, h=1,\u2026,??, ??=1,\u2026,??, (2) whereundersquaredloss, ??0isidentifiedbythebestlinearprojectionof ????+honto????whichis welldefinedwhenever ??:=??(??????' ??)isnonsingular.Inthatcase, ????+hisorthogonalto ????bycon- structionandthispropertyisexploitedtoderiveestimationproceduressuchastheordinaryleast squares(OLS).However,when ??>??(andsometimes ??\u00bb??)theOLSestimatorisnotuniqueas thesamplecounterpartof ??isrankdeficient.Infact,wecancompletelyoverfitwhenever ??=??. Penalizedlinearregressionarisesinthesettingwheretheregressionparameterisnotuniquely defined. It is usually the case when ??is large, possibly larger than the number of observations ??,and/orwhencovariatesarehighlycorrelated.Thegeneralideaistorestrictthesolutionofthe OLS problem to a ball around the origin. It can be shown that, although biased, the restricted solutionhassmallermeansquarederror(MSE),whencomparedtotheunrestrictedOLS(Hastie etal.,2009,Chap.3andChap.6).  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 80 MASINIetal. Inpenalizedregressions,theestimator \u02c6??fortheunknownparametervector ??0minimizesthe Lagrangianform ??(??)=??-h? ??=1( ????+h-??'????)2+??(??), =???-???? ?2 2+??(??),(3) where??:=(??h+1,\u2026????)',??:=(??1,\u2026????-h)',and??(??):=??(??;??,??,??) =0isapenaltyfunc- tion that depends on a tuning parameter ??=0, that controls the trade-off between the good- nessoffitandtheregularizationterm.If ??=0,wehaveaclassicalunrestrictedregression,since ??(??;0,??,??)=0 .Thepenaltyfunctionmayalsodependonasetofextrahyperparameters ??,as wellasonthedata ??.Naturally,theestimator \u02c6??alsodependsonthechoiceof ??and??.Different choicesforthepenaltyfunctionswereconsideredintheliteratureofpenalizedregression. Ridgeregression TheridgeregressionwasproposedbyHoerlandKennard( 1970)asawaytofighthighlycorrelated regressorsandstabilizethesolutionofthelinearregressionproblem.Theideawastointroducea smallbiasbut,inturn,reducethevarianceoftheestimator.Theridgeregressionisalsoknownas aparticularcaseofTikhonovRegularization(Tikhonov, 1943,1963;Tikhonov&Arsenin, 1977), inwhichthescalematrixisdiagonalwithidenticalentries. Theridgeregressioncorrespondstopenalizingtheregressionbythesquared ??2normofthe parametervector,thatis,thepenaltyin( 3)isgivenby ??(??)=????? ??=1??2 ??=??????2 2. Ridgeregressionhastheadvantageofhavinganeasytocomputeanalyticsolution,wherethe coefficientsassociatedwiththeleastrelevantpredictorsareshrunktowardzero,butneverreach- ing exactly zero. Therefore, it cannot be used for selecting predictors, unless some truncation schemeisemployed. Leastabsoluteshrinkageandselectionoperator TheLASSOwasproposedbyTibshirani( 1996)andChenetal.( 2001)asamethodtoregularize andperformvariableselectionatthesametime.LASSOisoneofthemostpopularregularization methodsanditiswidelyappliedindata-richenvironmentswherenumberoffeatures ??ismuch largerthanthenumberoftheobservations. LASSOcorrespondstopenalizingtheregressionbythe ??1normoftheparametervector,that is,thepenaltyin( 3)isgivenby ??(??)=????? ??=1|????|=??????1.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 81 ThesolutionoftheLASSOisefficientlycalculatedbycoordinatedescentalgorithms(Hastie et al.,2015, Chap. 5). The ??1penalty is the smallest convex ????p e n a l t yn o r mt h a ty i e l d s sparse solutions.Wesaythesolutionis sparseifonlyasubset ??<??coefficientsarenonzero.Inother words,onlyasubsetofvariablesisselectedbythemethod.Hence,LASSOismostusefulwhen thetotalnumberofregressors ??\u00bb??anditisnotfeasibletotestcombinationormodels. Despiteattractiveproperties,therearestilllimitationstotheLASSO.Alargenumberofalterna- tivepenaltieshavebeenproposedtokeepitsdesiredpropertieswhileovercomingitslimitations. AdaptiveLASSO TheadaptiveLASSO(adaLASSO)wasproposedbyZou( 2006)andaimedtoimprovetheLASSO regressionbyintroducingaweightparameter,comingfromafirststepOLSregression.Italsohas sparsesolutionsandefficientestimationalgorithm,butenjoysthe oracleproperty ,meaningthatit hasthesameasymptoticdistributionastheOLSconditionalonknowingthevariablesthatshould enterthemodel.4 TheadaLASSOpenaltyconsistsinusingaweighted ??1penalty: ??(??)=????? ??=1????|????|, wherethenumberoffeatures ????=|??* ??|-1and??* ??isthecoefficientfromthefirst-stepestimation (anyconsistentestimatorof ??0)AdaLASSOcandealwithmanymorevariablesthanobservations. UsingLASSOasthefirst-stepestimatorcanberegardedasthetwo-stepimplementationofthe locallinearapproximationinFanetal.( 2014)withazeroinitialestimate. Elasticnet Theelasticnet(ElNet)wasproposedbyZouandHastie( 2005)asawayofcombiningstrengthsof LASSOandridgeregression.Whilethe ??1partofthemethodperformsvariableselection,the ??2 partstabilizesthesolution.Thisconclusionisevenmoreaccentuatedwhencorrelationsamong predictorsbecomehigh.Asaconsequence,thereisasignificantimprovementinpredictionaccu- racyovertheLASSO(Zou&Zhang, 2009). TheElNetpenaltyisaconvexcombinationof ??1and??2penalties: ??(??)=??[ ????? ??=1??2 ??+(1-??)??? ??=1|????|] =??[?? ????2 2+(1-??) ????1], where???[0,1].TheElNethasboththeLASSOandridgeregressionasspecialcases. JustlikeintheLASSOregression,thesolutiontotheElNetproblemisefficientlycalculatedby coordinatedescentalgorithms.ZouandZhang( 2009)proposetheadaptiveElNet.TheElNetand adaLASSOimprovetheLASSOindistinctdirections:theadaLASSOhastheoraclepropertyand theElNethelpswiththecorrelationamongpredictors.TheadaptiveElNetcombinesthestrengths ofbothmethods.ItisacombinationofridgeandadaLASSO,wherethefirst-stepestimatorcomes fromtheElNet.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 82 MASINIetal. Foldedconcavepenalization LASSOapproachesbecamepopularinsparsehigh-dimensionalestimationproblemslargelydue theircomputationalproperties.Anotherverypopularapproachisthefoldedconcavepenalization of Fan and Li ( 2001). This approach covers a collection of penalty functions satisfying a set of properties.Thepenaltiesaimtopenalizemoreparametersclosetozerothanthosethatarefurther away,improvingperformanceofthemethod.Inthisway,penaltiesareconcavewithrespectto each|????|. OneofthemostpopularformulationsistheSCAD(smoothlyclippedabsolutedeviation).Note thatunlikeLASSO,thepenaltymaydependon ??inanonlinearway.Wesetthepenaltyin( 3)as ??(??)=??? ??=1\u02dc??(????,??,??),where \u02dc??(??,??,??)=? ? ? ? ? ????|??|if|??|=??, 2????|??|-??2-??2 2(??-1)if??=|??|=????, ??2(??+1) 2if|??|>???? for??>2and??>0.TheSCADpenaltyisidenticaltotheLASSOpenaltyforsmallcoefficients, butcontinuouslyrelaxestherateofpenalizationasthecoefficientdepartsfromzero.UnlikeOLS orLASSO,wehavetosolveanonconvexoptimizationproblemthatmayhavemultipleminima andiscomputationallymoreintensivethantheLASSO.Nevertheless,Fanetal.( 2014)show ed howtocalculatetheoracleestimatorusinganiterativeLocalLinearApproximationalgorithm. Otherpenalties Regularizationimposesarestrictiononthesolutionspace,possiblyimposingsparsity.Inadata- richenvironment,itisadesirablepropertyasitislikelythatmanyregressorsarenotrelevantto ourpredictionproblem.Thepresentationaboveconcentratesonthe,possibly,mostusedpenalties intime-seriesforecasting.Nevertheless,therearemanyalternativepenaltiesthatcanbeusedin regularizedlinearmodels. ThegroupLASSO,proposedbyYuanandLin( 2006),penalizestheparametersingroups,com- biningthe??1and??2norms.Itismotivatedbytheproblemofidentifying\u201cfactors,\u201ddenotedby groupsofregressorsas,forinstance,inregressionwithcategoricalvariablesthatcanassumemany values.Let ?={??1,\u2026,????}denoteapartitionof {1,\u2026,??}and??????=[????:???????]thecorrespond- ing regression subvector. The group LASSO assign to ( 3) the penalty??(??)=??? ??=1v |????|????????2, where |????|isthecardinalityofaset ????.Thesolutionisefficientlyestimatedusing,forinstance, thegroup-wisemajorizationdescentalgorithm(Yang&Zou, 2015).Naturally,theadaptivegroup LASSOwasalsoproposedaimingtoimprovesomeofthelimitationspresentonthegroupLASSO algorithm(Wang&Leng, 2008).InthegroupLASSO,thegroupsenterornotintheregression. ThesparsegroupLASSOrecoversparsegroupsbycombiningthegroupLASSOpenaltywiththe ??1penaltyontheparametervector(Simonetal., 2013). ParkandSakaori( 2013)modifytheadaLASSOpenaltytoexplicitlytakeintoaccountlaginfor- mation.KonzenandZiegelmann( 2016)proposeasmallchangeinpenaltyandperformalarge simulationstudytoassesstheperformanceofthispenaltyindistinctsettings.Theyobservethat  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 83 takingintoaccountlaginformationimprovesmodelselectionandforecastingperformancewhen comparedtotheLASSOandadaLASSO.Theyapplytheirmethodtoforecastinginflationandrisk premiumwithsatisfactoryresults. There is a Bayesian interpretation to the regularization methods presented here. The ridge regression can be also seen as a maximum a posteriori estimator of a Gaussian linear regres- sionwithindependent,equivariant,Gaussianpriors.TheLASSOreplacestheGaussianpriorbya Laplaceprior(Hans, 2009;Park&Casella, 2008).ThesemethodsfallwithintheareaofBayesian Shrinkagemethods,whichisaverylargeandactiveresearcharea,anditisbeyondthescopeof thissurvey. 2.1Theoreticalproperties Inthissection,wegiveanoverviewofthetheoreticalpropertiesofpenalizedregressionestimators previously discussed. Most results in high-dimensional time-series estimation focus on model selectionconsistency,oracleproperty,andoraclebounds,forboththefinitedimension( ??fixed, butpossiblylargerthan ??)andhighdimension( ??increaseswith ??,usuallyfaster). Moreprecisely,supposethereisapopulation,parametervector ??0thatminimizesEquation( 2) overrepeatedsamples.Supposethisparameterissparseinasensethatonlycomponentsindexed by??0?{1,\u2026,??} arenonnull.Let \u02c6??0:={??:\u02c6?????0}.Wesayamethodis modelselectionconsistent iftheindexofnonzeroestimatedcomponentsconvergesto ??0inprobability.5 P(\u02c6??0=??0)?1, ???8. Consistencycanalsobestatedintermsofhowclosetheestimatoristotrueparameterforagiven norm.Wesaythattheestimationmethodis ???-consistentifforevery ??>0: P(?\u02c6??0-??0???>??)?0, ???8. Itisimportanttonotethatmodelselectionconsistencydoesnotimply,noritisimpliedby, ???- consistency.Asamatteroffact,oneusuallyhastoimposespecificassumptionstoachieveeach ofthosemodesofconvergence. Model selection performance of a given estimation procedure can be further broke down in terms of how many relevant variables ?????0are included in the model (screening). Or how many irrelevant variables ?????0are excluded from the model. In terms of probability, model screeningconsistencyisdefinedby P(\u02c6??0???0)?1andmodelexclusionconsistencydefinedby P(\u02c6??0???0)?1as???8. Wesayapenalizedestimatorhastheoraclepropertyifitsasymptoticdistributionisthesame astheunpenalizedoneonlyconsideringthe ??0regressors.Finally,oracleriskboundsarefinite sampleboundsontheestimationerrorof \u02c6??thatholdwithhighprobability.Theseboundsrequire relativelystrongconditionsonthecurvatureofobjectivefunction,whichtranslatesintoabound ontheminimumrestrictedeigenvalueofthecovariancematrixamongpredictorsforlinearmod- elsandarateconditionon ??thatinvolvesthenumberofnonzeroparameters, |??0|. The LASSO was originally developed in fixed design with independent and identically dis- tributed(IID)errors,butithasbeenextendedandadaptedtoalargesetofmodelsanddesigns. KnightandFu( 2000)wasprobablythefirstpapertoconsidertheasymptoticsoftheLASSOesti- mator. The authors consider fixed design and fixed ??framework. From their results, it is clear  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 84 MASINIetal. thatthedistributionoftheparametersrelatedtotheirrelevantvariablesisnon-Gaussian.Toour knowledge,thefirst work expanding theresultsto adependentsettingwas Wangetal. ( 2007), wheretheerrortermwasallowedtofollowanautoregressiveprocess.AuthorsshowthatLASSO ismodelselectionconsistent,whereasamodifiedLASSO,similartotheadaLASSO,isbothmodel selectionconsistentandhastheoracleproperty.NardiandRinaldo( 2011)showmodelselection consistencyandpredictionconsistencyforlagselectioninautoregressivemodels.ChanandChen (2011)showoraclepropertiesandmodelselectionconsistencyforlagselectioninARMAmodels. Yoonetal.( 2013)derivemodelselectionconsistencyandasymptoticdistributionoftheLASSO, adaLASSO,andSCAD,forpenalizedregressionswithautoregressiveerrorterms.SangandSun (2015)studylagestimationofautoregressiveprocesseswithlong-memoryinnovationsusinggen- eralpenaltiesandshowmodelselectionconsistencyandasymptoticdistributionfortheLASSO andSCADasparticularcases.Kock( 2016)showsmodelselectionconsistencyandoracleproperty ofadaLASSOforlagselectioninstationaryandintegratedprocesses.Allresultsaboveholdforthe caseoffixednumberofregressorsorrelativelyhighdimension,meaningthat ??/???0. Insparse,high-dimensional,stationaryunivariatetime-seriessettings,where ???8atsome ratefasterthan ??,MedeirosandMendes( 2016,2017)showmodelselectionconsistencyandoracle property of a large set of linear time-series models with difference martingale, strong mixing, andnon-Gaussianinnovations.Itincludes,predictiveregressions,autoregressivemodels ????(??), autoregressive models with exogenous variables ??????(??), autoregressive models with dynamic lags??????(??,??), with possibly conditionally heteroskedastic errors. Xie et al. ( 2017) show oracle boundsforfixeddesignregressionwith ??-mixingerrors.WuandWu( 2016)deriveoraclebounds for the LASSO on regression with fixed design and weak dependent innovations, in a sense of Wu(2005),whereasHanandTsay( 2020)showmodelselectionconsistencyforlinearregression withrandomdesignandweaksparsity6underseriallydependenterrorsandcovariates,withinthe sameweakdependenceframework.XueandTaniguchi( 2020)showmodelselectionconsistency andparameterconsistencyforamodifiedversionoftheLASSOintime-seriesregressionswith long-memoryinnovations. FanandLi( 2001)showmodelselectionconsistencyandoraclepropertyforthefoldedconcave penaltyestimatorsinafixeddimensionalsetting.Kimetal.( 2008)showedthattheSCADalso enjoysthesepropertiesinhighdimensions.Intime-seriessettings,UematsuandTanaka( 2019) show oracle properties and model selection consistency in time-series models with dependent regressors.Ledereretal.( 2019)derivedoraclepredictionboundsformanypenalizedregression problems.Theauthorsconcludethatgenerichigh-dimensionalpenalizedestimatorsprovidecon- sistentpredictionwithanydesignmatrix.Althoughtheresultsarenotdirectlyfocusedontime- seriesproblems,theyaregeneralenoughtoholdinsuchsetting. Babiietal.( 2020c)proposedthesparse-groupLASSOasanestimationtechniquewhenhigh- dimensionaltime-seriesdataarepotentiallysampledatdifferentfrequencies.Theauthorsderived oracleinequalitiesforthesparse-groupLASSOestimatorwithinaframeworkwheredistribution ofthedatamayhaveheavytails. Twoframeworksnotdirectlyconsideredinthissurveybutofgreatempiricalrelevancearenon- stationaryenvironmentsandmultivariatemodels.Insparse,high-dimensional,integratedtime- series settings, Lee and Shi ( 2020)a n dK o oe ta l .( 2020) show model selection consistency and derivetheasymptoticdistributionsofLASSOestimatorsandsomevariants.SmeeksandWijler (2021) proposed the Single-equation Penalized Error Correction Selector (SPECS), which is an automated estimation procedure for dynamic single-equation models with a large number of potentiallycointegratedvariables.Insparsemultivariatetimeseries,Hsuetal.( 2008)showmodel selection consistency in vector autoregressive (VAR) models with white-noise shocks. Ren and  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 85 Zhang(2010)useadaLASSOinasimilarsetting,showingbothmodelselectionconsistencyand oracleproperty.Afterward,CallotandKock( 2013)showmodelselectionconsistencyandoracle propertyoftheadaptiveGroupLASSO.Inhigh-dimensionalsettings,wherethedimensionofthe seriesincreasewiththenumberofobservations,KockandCallot( 2015)andBasuandMichailidis (2015)showoracleboundsandmodelselectionconsistencyfortheLASSOinGaussian ??????(??) models,extendingpreviousworks.MelnykandBanerjee( 2016)extendedtheseresultsforalarge collection of penalties. Zhu ( 2020) derives oracle estimation bounds for folded concave penal- tiesforGaussian ??????(??)modelsinhighdimensions.Morerecently,researchershavedeparted fromGaussianityandcorrectmodelspecification.Wongetal.( 2020)derivedfinitesampleguar- anteesfortheLASSOinamisspecifiedVARmodelinvolving ??-mixingprocesswithsub-Weibull marginaldistributions.Masinietal.( 2019)deriveequation-wiseerrorboundsfortheLASSOesti- matorofweaklysparse ??????(??)inmixingaledependencesettings,thatincludemodelswithcon- ditionallyheteroskedasticinnovations. 2.2Inference Althoughseveralpapersderivedtheasymptoticpropertiesofpenalizedestimatorsaswellasthe oracleproperty,theseresultshavebeenderivedundertheassumptionthatthetruenonzerocoef- ficientsarelargeenough.Thisconditionisknownasthe ??-minrestriction.Furthermore,model selection,suchasthechoiceofthepenaltyparameter,hasnotbeentakenintoaccount.Therefore, thetruelimitdistribution,derivedunderuniformasymptoticsandwithoutthe ??-minrestriction can be very different from Gaussian, being even bimodal; see, for instance, Leeb and P\u00f6tscher (2005,2008)andBellonietal.( 2014)foradetaileddiscussion. Inference after model selection is actually a very active area of research and a vast num- ber of papers have recently appeared in the literature. van de Geer et al. ( 2014) proposed the desparsified LASSO in order to construct (asymptotically) a valid confidence interval for each ????,0bymodifyingtheoriginalLASSOestimate \u02c6??.Let??*beanapproximationfortheinverseof ??:=??(??????' ??),thenthedesparsifiedLASSOisdefinedas \u02dc??:=\u02c6??+??*(??-??\u02c6??)/??.Theaddition of this extra term to the LASSO estimator results in an unbiased estimator that no longer esti- matesanycoefficientexactlyaszero.Moreimportantly,asymptoticnormalitycanberecoverin thesensethatv ??(\u02dc????-????,0)convergesindistributiontoaGaussiandistributionunderappropri- ate regularity conditions. Not surprisingly, the most important condition is how well ??-1can be approximated by ??*. In particular, the authors propose to run ??LASSO regressions of ???? onto??-??:=(??1,\u2026,????-1,????+1,\u2026,????),for1=??=??.Theauthorsnamedthisprocessas nodewide regressions,andusethoseestimatestoconstruct ??*(refertoSection2.1.1invandeGeeretal., 2014, fordetails)). Belloni et al. ( 2014) put forward the double-selection method in the context of on a linear model in the form ????=??01??(1) ??+??' 02??(2) ??+????, where the interest lies on the scalar parame- ter??01and??(2) ??is a high-dimensional vector of control variables. The procedure consists in obtaininganestimationoftheactive(relevant)regressorsinthehigh-dimensionauxiliaryregres- sions of????on??(2)and of??(1) ??on??(2) ??,g i v e nb y\u02c6??1and\u02c6??2, respectively.7This can be obtained eitherbyLASSOoranyotherestimationprocedure.Oncetheset \u02c6??:=\u02c6??1?\u02c6??2isidentified,the (a priori) estimated nonzero parameters can be estimated by a low-dimensional regression ???? on??(1) ??and{??(2) ????:???\u02c6??}. The main result (Theorem 1 of Belloni et al., 2014) states conditions underwhichtheestimator \u02c6??01oftheparameterofinterestproperlystudentizedisasymptotically  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 86 MASINIetal. normal.Therefore,uniformlyvalidasymptoticconfidenceintervalsfor ??01canbeconstructedin theusualfashion. SimilartoTayloretal.( 2014)andLockhartetal.( 2014),Leeetal.( 2016)putforwardgeneral approachtovalidinferenceaftermodelselection.Theideaistocharacterizethedistributionof apostselectionestimatorconditionedontheselectionevent.Morespecifically,theauthorsargue thatthepostselectionconfidenceintervalsforregressioncoefficientsshouldhavethecorrectcov- erageconditionalontheselectedmodel.ThespecificcaseoftheLASSOestimatorisdiscussedin details.ThemaindifferencebetweenLeeetal.( 2016)andTayloretal.( 2014)andLockhartetal. (2014)isthatintheformer,confidenceintervalscanbeformedatanyvalueoftheLASSOpenalty parameterandanycoefficientinthemodel.Finally,itisimportanttostressthatLeeetal.( 2016) inferenceiscarriedonthecoefficientsoftheselectedmodel,whilevandeGeeretal.( 2014)and Bellonietal.( 2014)considerinferenceonthecoefficientsofthetruemodel. Theabovepapersdonotconsideratime-seriesenvironment.Hecqetal.( 2019)isoneofthefirst paperswhichattempttoconsiderpost-selectioninferenceinatime-seriesenvironment.However, theirresultsarederivedunderafixednumberofvariables.Babiietal.( 2020a)andAd\u00e1meketal. (2020)extendtheseminalworkofvandeGeeretal.( 2014)totime-seriesframework. More specifically, Babii et al. ( 2020a) consider inference in time-series regression models underheteroskedastic and autocorrelated errors. The authors consider heteroskedaticity- and autocorrelation-consistent (HAC) estimation with sparse group-LASSO. They propose a debi- ased central limit theorem for low dimensional groups of regression coefficients and study the HACestimatorofthelong-runvariancebasedonthesparse-groupLASSOresiduals.Ad\u00e1meket al.(2020)extendthedesparsifiedLASSOtoatime-seriessettingundernear-epochdependence assumptions,allowingfornon-Gaussian,seriallycorrelatedandheteroskedasticprocesses.Fur- thermore,thenumberofregressorscanpossiblygrowfasterthanthesamplesize. 3NONLINEARMODELS Thefunction??happearingin( 1)isunknownandinseveralapplicationsthelinearityassumption istoorestrictiveandmoreflexibleformsmustbeconsidered.Assumingaquadraticlossfunction, theestimationproblemturnstobetheminimizationofthefunctional ??(??):=??-h? ??=1[????+h-??(????)]2, (4) where????,agenericfunctionspace.However,theoptimizationproblemstatedin( 4)isinfea- sible when ?is infinite dimensional, as there is no efficient technique to search over all ?.O f course,onesolutionistorestrictthefunctionspace,asforinstance,imposinglinearityorspecific formsofparametricnonlinearmodelsasin,forexample,Ter\u00e4svirta( 1994),Suarez-Fari\u00f1asetal. (2004), or McAleer and Medeiros ( 2008); see also Ter\u00e4svirta et al. ( 2010) for a recent review of suchmodels. Alternatively,wecanreplace ?bysimplerandfinite-dimensional ???.Theideaistoconsidera sequenceoffinite-dimensionalspaces,the sievespaces, ???,??=1,2,3,\u2026 ,thatconvergesto ?in  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 87 somenorm.Theapproximatingfunction ????(????)iswrittenas ????(????)=??? ??=1????????(????), where????(\u00b7)isthe??thbasisfunctionfor ???andcanbeeitherfullyknownorindexedbyavector ofparameters,suchthat: ????(????):=??(????;????).Thenumberofbasisfunctions ??:=????willdepend on the sample size ??.??is the dimension of the space and it also depends on the sample size: ??:=????.Therefore,theoptimizationproblemisthenmodifiedto \u02c6????(????)=arg min ????(????)??????-h? ??=1[????+h-????(????)]2. (5) Thesequenceofapproximatingspaces ???ischosenbyusingthestructureoftheoriginalunder- lying space ?and the fundamental concept of dense sets. If we have two sets ??and????,? beingametricspace, ??isdensein??ifforany??>0,?R and?????,thereisa?????suchthat ???-????<??.Thisiscalledthemethodof\u201csieves.\u201dForacomprehensivereviewofthemethod fortime-seriesdata,seeChen( 2007). For example, from the theory of approximating functions we know that the proper subset ???of polynomials is dense in ?, the space of continuous functions. The set of polynomi- als is smaller and simpler than the set of all continuous functions. In this case, it is natural to definethesequenceofapproximatingspaces ???,??=1,2,3,\u2026 bymaking ???thesetofpolyno- mials of degree smaller or equal to ??-1(including a constant in the parameter space). Note that??????(???)=??<8 .Inthelimitthissequenceoffinite-dimensionalspacesconvergestothe infinite-dimensionalspaceofpolynomials,whichonitsturnisdensein ?. Whenthebasisfunctionsareallknown\u201clinearsieves,\u201dtheproblemislinearintheparameters andmethodslikeOLS(when ??\u00ab??)orpenalizedestimationaspreviouslydescribedcanbeused. Forexample,let ??=1andpickapolynomialbasissuchthat ????(????)=??0+??1????+??2??2 ??+??3??3 ??+?+???????? ??. Inthiscase,thedimension ??of???is??+1,duetothepresenceofaconstantterm. If??\u00ab??,thevectorofparameters ??=(??1,\u2026,????)'canbeestimatedby \u02c6??=(??' ??????)-1??' ????, where????isthe??\u00d7(??+1) designmatrixand ??=(??1,\u2026,????)'. Whenthebasisfunctionsarealsoindexedbyparameters(\u201cnonlinearsieves\u201d),nonlinearleast- squaresmethodsshouldbeused.Inthispaper,wewillfocusonfrequentlyusednonlinearsieves: NNsandregressiontrees.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 88 MASINIetal. Figure 1 Graphicalrepresentationofasinglehiddenlayerneuralnetwork[Colourfigurecanbeviewedat wileyonlinelibrary.com] 3.1Neuralnetworks 3.1.1ShallowNN NN is one of the most traditional nonlinear sieves. NN can be classified into shallow or deep networks.WestartdescribingtheshallowNNs.ThemostcommonshallowNNisthefeedforward NNwheretheapproximatingfunction ????(????)isdefinedas ????(????):=????(????;??)=??0+????? ??=1??????(??' ??????+??0,??), =??0+????? ??=1??????(~??' ??~????).(6) Intheabovemodel, ~????=(1,??' ??)',????(\u00b7)isabasisfunctionandtheparametervectortobeestimated isgivenby??=(??0,\u2026,????,??' 1,\u2026,??' ????,??0,1,\u2026,??0,????)',where~????=(??0,??,??' ??)'. NNmodelsformaverypopularclassofnonlinearsievesandhavebeenusedinmanyappli- cationsofeconomicforecasting.Usually,thebasisfunctions ??(\u00b7)arecalledactivationfunctions and the parameters are called weights. The terms in the sum are called hidden neurons as an unfortunateanalogytothehumanbrain.Specification( 6)isalsoknownasasinglehiddenlayer NNmodelasisusuallyrepresentedinthegraphicalasinFigure 1.Thegreencirclesinthefigure represent the input layer which consists of the covariates of the model ( ????). In the example in thefigure,therearefourinputvariables.Theblueandredcirclesindicatethehiddenandoutput layers, respectively. In the example, there are five elements (neurons) in the hidden layer. The arrowsfromthegreentothebluecirclesrepresentthelinearcombinationofinputs: ??' ??????+??0,??, ??=1,\u2026,5.Finally,thearrowsfromthebluetotheredcirclesrepresentthelinearcombination ofoutputsfromthehiddenlayer: ??0+?5 ??=1??????(??' ??????+??0,??).  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 89 Thereareseveralpossiblechoicesfortheactivationfunctions.Intheearlydays, ??(\u00b7)waschosen amongtheclassofsquashingfunctionsasperthedefinitionbelow. Definition1. Afunction??:R?[??,??] ,??<??,isasquashing(sigmoid)functionifitisnon- decreasing,lim???8??(??)=??andlim???-8??(??)=??. Historically,themostpopularchoicesarethelogisticandhyperbolictangentfunctionssuch that: Logistic:??(??)=1 1+exp(-??) Hyperbolictangent :??(??)=exp(??)-exp(-??) exp(??)+exp(-??). Thepopularityofsuchfunctionswaspartiallyduetotheoreticalresultsonfunctionapproxima- tion.Funahashi( 1989)establishesthatNNmodelsasin( 6)withgenericsquashingfunctionsare capableofapproximatinganycontinuousfunctionsfromonefinitedimensionalspacetoanother toanydesireddegreeofaccuracy,providedthat ????issufficientlylarge.Cybenko( 1989)andHornik etal.(1989)simultaneouslyprovedapproximationcapabilitiesofNNmodelstoanyBorelmea- surablefunctionandHorniketal.( 1989)extendedthepreviousresultsandshowedthattheNN modelsarealsocapabletoapproximatethederivativesoftheunknownfunction.Barron( 1993) relatespreviousresultstothenumberoftermsinthemodel. Stinchcombe and White ( 1989) and Park and Sandberg ( 1991) derived the same results of Cybenko(1989)andHorniketal.( 1989)butwithoutrequiringtheactivationfunctiontobesig- moid.Whiletheformerconsideredaverygeneralclassoffunctions,thelaterfocusedonradial- basisfunctions(RBF)definedas: RadialBasis:??(??)=exp(-??2). Morerecently,Yarotsky( 2017)showedthattherectifiedlinearunits(ReLU)as RectifiedLinearUnit :??(??)=max(0,??), arealsouniversalapproximators. Model(6)canbewritteninmatrixnotation.Let ??=(~??1,\u2026,~????), ??=? ? ? ? ??1??11???1?? 1??21???2?? ??? 1????1???????? ? ? ? ??,and?(????)=? ? ? ? ??1??(~??' 1~??1)???(~??' ??~??1) 1??(~??' 1~??2)???(~??' ??~??2) ???? 1??(~??' 1~????)???(~??' ??~????)? ? ? ? ??. Therefore,bydefining ??=(??0,??1,\u2026,????)',theoutputofafeedforwardNNisgivenby:  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 90 MASINIetal. ????(??,??)=[h ??(??1;??),\u2026,h??(????;??)]' =? ? ? ????0+??? ??=1??????(??' ????1+??0,??) ? ??0+??? ??=1??????(??' ??????+??0,??)? ? ? ?? =?(????)??.(7) Thedimensionoftheparametervector ??=[??????(??)',??']'is??=(??+1)\u00d7?? ??+(????+1)andcan easilygetverylargesuchthattheunrestrictedestimationproblemdefinedas \u02c6??=argmin ???R?????-?(????)?? ?2 2 isunfeasible.Asolutionistouseregularizationasinthecaseoflinearmodelsandconsiderthe minimizationofthefollowingfunction: ??(??)= ???-?(????)?? ?2 2+??(??), (8) whereusually ??(??)=????'??.Traditionally,themostcommonapproachtominimize( 8)istouse BayesianmethodsasinMacKay( 1992a);MacKay( 1992b)andForeseeandHagan( 1997).Amore modernapproachistouseatechniqueknownas Dropout(Srivastavaetal., 2014). Thekeyideaistorandomlydropneurons(alongwiththeirconnections)fromtheNNduring estimation.AnNNwith ????neuronsinthehiddenlayercangenerate 2????possible\u201cthinned\u201dNN byjustremovingsomeneurons.Dropoutsamplesfromthis 2????differentthinnedNNandtrainthe sampledNN.Topredictthetargetvariable,weuseasingleunthinnednetworkthathasweights adjustedbytheprobabilitylawinducedbytherandomdrop.Thisproceduresignificantlyreduces overfittingandgivesmajorimprovementsoverotherregularizationmethods. WemodifyEquation( 6)by ??* ??(????)=??0+????? ??=1??????????(??' ??[???????]+??????0,??), where??,??,and??=(??1,\u2026,????)areindependentBernoullirandomvariableseachwithprobability ??ofbeingequalto1.TheNNmodelisthusestimatedbyusing ??* ??(????)insteadof????(????)where, foreachtrainingexample,thevaluesoftheentriesof ??aredrawnfromtheBernoullidistribution. Thefinalestimatesfor ????,????,and????,??aremultipliedby ??. 3.1.2DeepNNs AdeepNNmodelisastraightforwardgeneralizationofspecification( 6)wheremorehiddenlayers areincludedinthemodelasrepresentedinFigure 2.Inthefigure,werepresentadeepNNwith twohiddenlayerswiththesamenumberofhiddenunitsineach.However,thenumberofhidden neuronscanvaryacrosslayers.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 91 Figure 2 Deepneuralnetworkarchitecture[Colourfigurecanbeviewedatwileyonlinelibrary.com] AspointedoutinMhaskaetal.( 2017),whiletheuniversalapproximationpropertyholdsfor shallowNNs,deepnetworkscanapproximatetheclassofcompositionalfunctionsaswellasshal- lownetworksbutwithexponentiallylowernumberoftrainingparametersandsamplecomplexity. Set????as the number of hidden units in layer ???{1,\u2026,??} . For each hidden layer ??, define ????=(~??1??,\u2026,~????????).Then,theoutput ???oflayer??isgivenrecursivelyby ???(???-1(\u00b7)????) ??\u00d7(????+1)=? ? ? ? ??1??(~??' 1???1??-1(\u00b7))???(~??' ???????1??-1(\u00b7)) 1??(~??' 1???2??-1(\u00b7))???(~??' ???????2??-1(\u00b7)) ???? 1??(~??' 1???????-1(\u00b7))???(~??' ???????????-1(\u00b7))? ? ? ? ??, where???:=??.Therefore,theoutputofthedeepNNisthecompositionof ????(??)=???(??3(?2(?1(????1)??2)??3)?)??????. Theestimationoftheparametersisusuallycarriedoutbystochasticgradientdescendmethods withdropouttocontrolthecomplexityofthemodel. 3.1.3Recurrentneuralnetworks Broadlyspeaking,RNNsareNNsthatallowforfeedbackamongthehiddenlayers.RNNscanuse theirinternalstate(memory)toprocesssequencesofinputs.Intheframeworkconsideredinthis paper,agenericRNNcouldbewrittenas ????=??(????-1,????), \u02c6????+h|??=??(????),  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 92 MASINIetal. Figure 3 Architectureofthelong-short-termmemorycell(LSTM)[Colourfigurecanbeviewedat wileyonlinelibrary.com] where\u02c6????+h|??isthepredictionof ????+hgivenobservationsonlyuptotime ??,??and??arefunctions tobedefined,and ????iswhatwecallthe(hidden)state.Fromatime-seriesperspective,RNNscan beseenasakindofnonlinearstate-spacemodel. RNNscanremembertheorderthattheinputsappearthroughitshiddenstate(memory)and theycanalsomodelsequencesofdatasothateachsamplecanbeassumedtobedependenton previousones,asintime-seriesmodels.However,RNNsarehardtobeestimatedastheysuffer fromthevanishing/explodinggradientproblem.Setthecostfunctiontobe ???(??)=??-h? ??=1(????+h-\u02c6????+h|??)2, where??isthevectorofparameterstobeestimated.Itiseasytoshowthatthegradient?????(??) ????can beverysmallordiverge.Fortunately,thereisasolutiontotheproblemproposedbyHochreiter andSchmidhuber( 1997).AvariantofRNNwhichiscalledlong-short-termmemory(LSTM)net- work.Figure 3showsthearchitectureofatypicalLSTMlayer.AnLSTMnetworkcanbecomposed of several layers. In the figure, red circles indicate logistic activation functions, while blue cir- clesrepresenthyperbolictangentactivation.Thesymbols\u201c ??\u201dand\u201c+\u201drepresent,respectively,the  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 93 Algorithm 1 Mathematically,RNNscanbedefinedbythefollowingalgorithm 1. Initiatewith ??0=0and??0=0. 2. Giventheinput ????,for???{1,\u2026,??} ,do: ????= Logistic(????????+????????-1+????) ????= Logistic(????????+????????-1+????) ????= Logistic(????????+????????-1+????) ????=T a n h ( ????????+????????-1+????) ????=( ?????????-1)+(?????????) ????=?????Tanh(????) \u02c6????+h|??=????????+???? where????,????,????,????,????,????,????,????,????,????,????,????,and????areparameterstobeestimated. Figure 4 Informationflowinan LTSMcell[Colourfigurecanbeviewed atwileyonlinelibrary.com] element-wisemultiplicationandsumoperations.TheRNNlayeriscomposedofseveralblocks: the cell state and the forget, input, and ouput gates. The cell state introduces a bit of memory to the LSTM so it can \u201cremember\u201d the past. LSTM learns to keep only relevant information to makepredictions,andforgetnonrelevantdata.Theforgetgatetellswhichinformationtothrow awayfromthecellstate.TheoutputgateprovidestheactivationtothefinaloutputoftheLSTM blockattime??.Usually,thedimensionofthehiddenstate( ????)isassociatedwiththenumberof hiddenneurons. Algorithm 1describesanalyticallyhowtheLSTMcellworks. ????representstheoutputofthe forgetgate.Notethatitisacombinationoftheprevioushiddenstate( ????-1)withthenewinfor- mation(????).Notethat?????[0,1]anditwillattenuatethesignalcomingcom ????-1.Theinputand outputgateshavethesamestructure.Theirfunctionistofilterthe\u201crelevant\u201dinformationfrom theprevioustimeperiodaswellasfromthenewinput. ????scalesthecombinationofinputsand previous information. This signal will be then combined with the output of the input gate ( ????). Thenewhiddenstatewillbeanattenuationofthesignalcomingfromtheoutputgate.Finally, thepredictionisalinearcombinationofhiddenstates.Figure 4illustrateshowtheinformation flowsinanLSTMcell.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 94 MASINIetal. Figure 5 Exampleofasimpletree[Colourfigurecanbeviewedatwileyonlinelibrary.com] 3.2Regressiontrees Aregressiontreeisanonparametricmodelthatapproximatesanunknownnonlinearfunction ??h(????)in (1) with local predictions using recursive partitioning of the space of the covariates. A tree may be represented by a graph as in the left side of Figure 5, which is equivalent as the partitioningintherightsideofthefigureforthisbidimensionalcase.Forexample,supposethat we want to predict the scores of basketball players based on their height and weight. The first nodeofthetreeintheexamplesplitstheplayerstallerthan1.85mfromtheshorterplayers.The secondnodeinthelefttakestheshortplayersgroupsandsplitthembyweightsandthesecond nodeintherightdoesthesamewiththetallerplayers.Thepredictionforeachgroupisdisplayed intheterminalnodesandtheyarecalculatedastheaveragescoreineachgroup.Togrowatree, wemustfindtheoptimalsplittingpointineachnode,whichconsistsofanoptimalvariableand anoptimalobservation.Inthesameexample,theoptimalvariableinthefirstnodeisheightand theobservationis1.85m. Theideaofregressiontreesistoapproximate ??h(????)by h??(????)=????? ??=1????????(????),where????(????)={ 1if????????, 0otherwise. From the above expression, it becomes clear that the approximation of ??h(\u00b7)is equivalent to a linearregressionon ????dummyvariables,where ????(????)isaproductofindicatorfunctions. Let??:=????and??:=????be,respectively,thenumberofterminalnodes(regions, leaves)and parentnodes.Differentregionsaredenotedas ?1,\u2026,???.Therootnodeatposition0.Theparent nodeatposition ??hastwosplit(child)nodesatpositions 2??+1and2??+2.Eachparentnodehas athreshold(split)variableassociated, ????????,where???????={1,2,\u2026,??} .Define??and??asthesets ofparentandterminalnodes,respectively.Figure 6givesanexample.Intheexample,theparent  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 95 Figure 6 Exampleoftreewithlabels nodesare??={0,2,5} andtheterminalnodesare ??={1,6,11,12} . Therefore,wecanwritetheapproximatingmodelas h??(????)=? ???????????????(????;????), (9) where ??????(????;????)=? ???????(??????,??;????)????,??(1+????,??) 2\u00d7[1-??(??????,??;????)](1-????,??)(1+????,??), (10) ??(??????,??;????)={ 1if??????,??=???? 0otherwise, ????,??=? ? ? ??-1ifthepathtoleaf ??doesnotincludeparentnode ??; 0ifthepathtoleaf ??includethe??????????-???????? childofparentnode ??; 1ifthepathtoleaf ??includethe????????-???????? childofparentnode ??. ????: indexes of parent nodes included in the path to leaf ??.????={????}such that???????,?????and? ???????????(????;????)=1. 3.2.1Randomforests RF is a collection of regression trees, each specified in a bootstrap sample of the original data. ThemethodwasoriginallyproposedbyBreiman( 2001).Sincewearedealingwithtimeseries,we useablockbootstrap.Supposethereare ??bootstrapsamples.Foreachsample ??,??=1,\u2026,?? ,a treewith????regionsisestimatedforarandomlyselectedsubsetoftheoriginalregressors. ????is determinedinordertoleaveaminimumnumberofobservationsineachregion.Thefinalforecast  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 96 MASINIetal. Algorithm 2 Theboostingalgorithmisdefinedasthefollowingsteps 1. Initialize ????0=\u00af??:=1 ????? ??=1????; 2.For??=1,\u2026,?? : (a)Make??????=????-??????-1 (b)Growa(small)Treemodeltofit ??????,\u02c6??????=? ???????\u02c6??????????????(????;\u02c6??????) (c)Make????=argmin ????? ??=1[??????-??\u02c6??????]2 (d)Update??????=??????-1+??????\u02c6?????? istheaverageoftheforecastsofeachtreeappliedtotheoriginaldata: \u02c6????+h|??=1 ????? ??=1[????? ??=1\u02c6????,????????,??(????;\u02c6????,??)] . ThetheoryforRFmodelshasbeendevelopedonlytoindependentandidenticallydistributed randomvariables.Forinstance,Scornetetal.( 2015)provesconsistencyoftheRFapproximation totheunknownfunction ??h(????).Morerecently,WagerandAthey( 2018)provedconsistencyand asymptoticnormalityoftheRFestimator. 3.2.2Boostingregressiontrees Boosting is another greedy method to approximate nonlinear functions that uses base learners forasequentialapproximation.Themodelweconsiderhere,calledGradientBoosting,wasintro- ducedbyFriedman( 2001)andcanbeseenasaGradientDescendentmethodinfunctionalspace. ThestudyofstatisticalpropertiesoftheGradientBoostingiswelldevelopedforindependent data.Forexample,forregressionproblems,DuffyandHelmbold( 2002)derivedboundsonthe convergenceofboostingalgorithmsusingassumptionsontheperformanceofthebaselearner. ZhangandYu( 2005)proveconvergence,consistency,andresultsonthespeedofconvergencewith mildassumptionsonthebaselearners.B\u00fchlmann( 2002)showssimilarresultsforconsistencyin thecaseof??2lossfunctionsandthreebasemodels.Sinceboostingindefinitelyleadstooverfitting problems, some authors have demonstrated the consistency of boosting with different types of stopping rules, which are usually related to small step sizes, as suggested by Friedman ( 2001). Someoftheseworksincludeboostinginclassificationproblemsandgradientboostingforboth classificationandregressionproblems.See,forinstance,Jiang( 2004),LugosiandVayatis( 2004), BartlettandTraskin( 2007),ZhangandYu( 2005),B\u00fchlmann( 2006),andB\u00fchlmann( 2002). Boostingisaniterativealgorithm.Theideaofboostedtreesisto,ateachiteration,sequentially refitthegradientofthelossfunctionbysmalltrees.Inthecaseofquadraticlossasconsideredin thispaper,thealgorithmsimplyrefitstheresidualsfromthepreviousiteration. Algorithm 2presentsthesimplifiedboostingprocedureforaquadraticloss.Itisrecommended touseashrinkageparameter ???(0,1]tocontrolthelearningrateofthealgorithm.If ??isclose to 1, we have a faster convergence rate and a better in-sample fit. However, we are more likely tohaveoverfittingandproducepoorout-of-sampleresults.Inaddition,thederivativeishighly affectedbyoverfitting,evenifwelookatin-sampleestimates.Alearningratebetween0.1and0.2 isrecommendedtomaintainareasonableconvergenceratioandtolimitoverfittingproblems.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 97 Thefinalfittedvaluemaybewrittenas \u02c6????+h=\u00af??+??? ??=1??????\u02c6?????? =\u00af??+??? ??=1??\u02c6????? ???????\u02c6??????????????(????;\u02c6??????).(11) 3.3Inference ConductinginferenceinnonlinearMLmethodsistricky.OnepossiblewayistofollowMedeiros etal.(2006),MedeirosandVeiga( 2005),andSuarez-Fari\u00f1asetal.( 2004)andinterpretparticu- larnonlinearMLspecificationsasparametricmodels,asforexample,generalformsofsmooth transition regressions. However, this approach restricts the application of ML methods to very specificsettings.Analternative,istoconsidermodelsthatcanbecastinthesievesframework asdescribedearlier.Thisisthecaseofsplinesandfeed-forwardNNs,forexample.Inthissetup, ChenandShen( 1998)andChen( 2007)derived,underregularityconditions,theconsistencyand asymptoticallynormalityoftheestimatesofasemiparametricsieveapproximations.Theirsetup isdefinedasfollows: ????+h=??' 0????+??(????)+????+h, where??(????)isanonlinearfunctionthatisnonparametricallymodeledbysieveapproximations. ChenandShen( 1998)andChen( 2007)considerboththeestimationofthelinearandnonlinear componentsofthemodel.However,theirresultsarederivedunderthecasewherethedimension of????isfixed. Recently,Chernozhukovetal.( 2017,2018)considerthecasewherethenumberofcovariates divergeasthesamplesizeincreasesinaverygeneralsetup.Inthiscase,theasymptoticresults inChenandShen( 1998)andChen( 2007)arenotvalidandtheauthorsputforwardtheso-called doubleMLmethodsasanicegeneralizationtotheresultsofBellonietal.( 2014).Nevertheless, theresultsdonotincludethecaseoftime-seriesmodels. MorespecificallytothecaseofRandomForests,asymptoticandinferentialresultsarederived inScornetetal.( 2015)andW ageretal.( 2018)forthecaseofIIDdata.Morerecently,Davisand Nielsen(2020)proveauniformconcentrationinequalityforregressiontreesbuiltonnonlinear autoregressive stochastic processes and prove consistency for a large class of random forests. Finally, it is worth mentioning the interesting work of Borup et al. ( 2020). In their paper, the authorsshowthatproperpredictortargetingcontrolstheprobabilityofplacingsplitsalongstrong predictorsandimprovesprediction.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 98 MASINIetal. Algorithm 3 BaggingforTime-SeriesModels TheBaggingalgorithmisdefinedasfollows. 1.Arrangethesetoftuples (????+h,??' ??),??=h+1,\u2026,?? ,intheformofamatrix ??ofdimension(??-h)\u00d7?? . 2. Construct(block)bootstrapsamplesoftheform {(??* (??)2,??'* (??)2),\u2026,(??* (??)??,??'* (??)??)},??=1,\u2026,??,bydrawing blocksof??rowsof??withreplacement. 3.Computethe??thbootstrapforecastas \u02c6??* (??)??+h |??={ 0if|??* ??|<?????, \u02c6??* (??)\u02dc??* (??)??otherwise,(11) where\u02dc??* (??)??:=??* (??)????* (??)??and????isadiagonalselectionmatrixwith ??thdiagonalelementgivenby ??{|????|>??}={ 1if|????|>??, 0otherwise, ??isaprespecifiedcriticalvalueofthetest. \u02c6??* (??)istheOLSestimatorateachbootstraprepetition. 4.Computetheaverageforecastsoverthebootstrapsamples: ~????+h|??=1 ????? ??=1\u02c6??* (??)??|??-1. Algorithm 4 BaggingforTime-SeriesModelsandManyRegressors TheBaggingalgorithmisdefinedasfollows. 0.Run??univariateregressionsof ????+honeachcovariatein ????.Compute??-statisticsandkeeponlytheones thatturnouttobesignificantatagivenprespecifiedlevel.Callthisnewsetofregressorsas ????? 1\u20134. Sameasbeforebutwith ????replacedby?????. 4OTHERMETHODS 4.1Bagging ThetermbaggingmeansBootstrapAggregating andwasproposedbyBreiman( 1996)toreducethe varianceofunstablepredictors.8Itwaspopularizedinthetime-seriesliteraturebyInoueandKil- ian(2008),whotoconstructforecastsfrommultipleregressionmodelswithlocal-to-zeroregres- sionparametersanderrorssubjecttopossibleserialcorrelationorconditionalheteroskedasticity. Baggingisdesignedforsituationsinwhichthenumberofpredictorsismoderatelylargerelative tothesamplesize. Thebaggingalgorithmintime-seriessettingshavetotakeintoaccountthetimedependence dimensionwhenconstructingthebootstrapsamples. InAlgorithm 3,onerequiresthatitispossibletoestimateandconductinferenceinthelinear model.Thisiscertainlyinfeasibleifthenumberofpredictorsislargerthanthesamplesize( ??> ??), which requires the algorithm to be modified. Garcia et al. ( 2017) and Medeiros et al. ( 2021) adoptthechangesasdescribedinAlgorithm 4.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 99 4.2Completesubsetregression CSRisamethodforcombiningforecastsdevelopedbyElliottetal.( 2013,2015).Themotivation was that selecting the optimal subset of ????to predict????+hby testing all possible combinations ofregressorsiscomputationallyverydemandingand,inmostcases,unfeasible.Foragivenset ofpotentialpredictorvariables,theideaistocombineforecastsbyaveraging9allpossiblelinear regressionmodelswithfixednumberofpredictors.Forexample,with ??possiblepredictors,there are??uniqueunivariatemodelsand ????,??=??! (??-??)!??! different??-variatemodelsfor ??=??.Thesetofmodelsforafixedvalueof ??asisknownasthe completesubset. When the set of regressors is large the number of models to be estimated increases rapidly. Moreover,itislikelythatmanypotentialpredictorsareirrelevant.Inthesecases,itwassuggested that one should include only a small, ??, fixed set of predictors, such as 5 or 10. Nevertheless, the number of models still very large, for example, with ??=30and??=8, there are 5,852,925 regression.AnalternativesolutionistofollowGarciaetal.( 2017)andMedeirosetal.( 2021)and adoptasimilarstrategyasinthecaseofBagginghigh-dimensionalmodels.Theideaistostart fitting a regression of ????+hon each of the candidate variables and save the ??-statistics of each variable.The??-statisticsarerankedbyabsolutevalue,andweselectthe ~??variablesthataremore relevantintheranking.TheCSRforecastiscalculatedonthesevariablesfordifferentvaluesof ??.ThisapproachisbasedontheSureIndependenceScreeningofFanandLv( 2008),extended todependentbyYousuf( 2018),thataimstoselectasupersetofrelevantpredictorsamongavery largeset. 4.3Hybridmethods Recently,MedeirosandMendes( 2013)proposedthecombinationofLASSO-basedestimationand NNmodels.Theideaistoconstructafeedforwardsingle-hiddenlayerNNwheretheparametersof thenonlinearterms(neurons)arerandomlygeneratedandthelinearparametersareestimatedby LASSO(oroneofitsgeneralizations).SimilarideaswerealsoconsideredbyKockandTer\u00e4svirta (2014,2015). Traplettietal.( 2000)andMedeirosetal.( 2006)proposedtoaugmentafeedforwardshallow NN by a linear term. The motivation is that the nonlinear component should capture only the nonlinear dependence, making the model more interpretable. This is in the same spirit of the semi-parametricmodelsconsideredinChen( 2007). Inspired by the above ideas, Medeiros et al. ( 2021) proposed combining random forests with adaLASSOandOLS.Theauthorsconsideredtwospecifications.Inthefirstone,calledRF/OLS, the idea is to use the variables selected by a Random Forest in a OLS regression. The second approach, named adaLASSO/RF, works in the opposite direction. First select the variables by adaLASSOandthanusetheminaRandomForestmodel.Thegoalistodisentangletherelative importanceofvariableselectionandnonlinearitytoforecastinflation. Recently,DieboldandShin( 2019)proposethe\u201cpartially-egalitarian\u201dLASSOtocombinesur- veyforecasts.Morespecifically,theproceduresetssomecombiningweightstozeroandshrinks  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 100 MASINIetal. thesurvivorstowardequality.Therefore,thefinalforecastwillbecloserelatedtothesimpleaver- age combination of the survived forecasts. Although the paper considers survey forecasts, the methodisquitegeneralandcanbeappliedtoanysetofforecasts.Aspointedoutbytheauthors, optimally-regularizedregression-basedcombinationsandsubset-averagecombinationsarevery closelyconnected.Dieboldetal.( 2021)extendedtheideasinDieboldetal.( 2019)inordertocon- structregularizedmixturesofdensityforecasts.Bothpapersshedlightonhowmachinelearning methodscanbeusedtooptimallycombinealargesetofforecasts. 5FORECASTCOMPARISON WiththeadvancesintheMLliterature,thenumberofavailableforecastingmodelsandmethods havebeenincreasingatafastpace.Consequently,itisveryimportanttoapplystatisticaltoolsto comparedifferentmodels.Theforecastingliteratureprovidesanumberoftestssincetheseminal paperbyDieboldandMariano( 1995)thatcanbeappliedaswelltotheMLmodelsdescribedin thissurvey. IntheDieboldandMariano\u2019s( 1995)test,twocompetingmethodshavethesameunconditional expectedlossunderthenullhypothesis,andthetestcanbecarriedoutusingasimple ??-test.A smallsampleadjustmentwasdevelopedbyHarveyetal.( 1997).Seealsotherecentdiscussionin Diebold(2015).OnedrawbackoftheDieboldandMariano\u2019s( 1995)testisthatitsstatisticdiverges undernullwhenthecompetingmodelsarenested.However,GiacominiandWhite( 2006)show thatthetestisvalidiftheforecastsarederivedfrommodelsestimatedinarollingwindowframe- work.Recently,McCracken( 2020)showsthatiftheestimationwindowisfixed,theDieboldand Mariano\u2019s( 1995)statisticmaydivergeunderthenull.Therefore,itisveryimportantthatthefore- castsarecomputedinarollingwindowscheme. Inordertoaccommodatecaseswheretherearemorethantwocompetingmodels,anuncondi- tionalsuperiorpredictiveability(USPA)testwasproposedbyWhite( 2000).Thenullhypothesis statesthatabenchmarkmethodoutperformsasetofcompetingalternatives.However,Hansen (2005)showedthatWhite\u2019s( 2000)testcanbeveryconservativewhentherearecompetingmeth- odsthatareinferiortothebenchmark.Anotherimportantcontributiontotheforecastingliter- ature is the model confidence set (MCS) proposed by Hansen et al. ( 2011). An MCS is a set of competingmodelsthatisbuiltinawaytocontainthebestmodelwithrespecttoacertainloss functionandwithagivenlevelofconfidence.TheMCSacknowledgesthepotentiallimitations ofthedataset,suchthatuninformativedatayieldanMCSwithalargenumbermodels,whereas informativedatayieldanMCSwithonlyafewmodels.Importantly,theMCSproceduredoesnot assumethataparticularmodelisthetrueone. AnotherextensionoftheDieboldandMariano\u2019s( 1995)testistheconditionalequalpredictive ability(CEPA)testproposedbyGiacominiandWhite( 2006).Inpracticalapplications,itisimpor- tanttoknownotonlyifagivenmodelissuperiorbutalsowhenitisbetterthanthealternatives. Recently, Li et al. ( 2020) proposed a very general framework to conduct conditional predictive abilitytests. Insummary,itisveryimportanttocomparetheforecastsfromdifferentMLmethodsandthe literatureprovidesanumberofteststhatcanbeused.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 101 6APPLICATIONSOFMLMETHODSTOECONOMICAND FINANCIALFORECASTING 6.1Linearmethods Penalizedregressionsarenowanimportantoptioninthetoolkitofappliedeconomists.Thereis avastliteratureconsideringtheuseofsuchtechniquestoeconomicsandfinancialforecasting. Macroeconomic forecasting is certainly one of the most successful applications of penalized regressions.MedeirosandMendes( 2016)appliedtheadaLASSOtoforecastingU.S.inflationand showedthatthemethodoutperformsthelinearautoregressiveandfactormodels.Medeirosand Vasconcelos( 2016)showthathigh-dimensionallinearmodelsproduce,onaverage,smallerfore- casting errors for macroeconomic variables when a large set of predictors is considered. Their resultsalsoindicatethatagoodselectionoftheadaLASSOhyperparametersreducesforecasting errors. Garcia et al. ( 2017) show that high-dimensional econometric models, such as shrinkage and CSR, perform very well in real-time forecasting of Brazilian inflation in data-rich environ- ments.Theauthorscombineforecastsofdifferentalternativesandshowthatmodelcombination canachievesuperiorpredictiveperformance.SmeeksandWijler( 2018)consideranapplication toalargemacroeconomicU.S.datasetanddemonstratethatpenalizedregressionsareverycom- petitive.Medeirosetal.( 2021)conductavastcomparisonofmodelstoforecastU.S.inflationand showedthepenalizedregressionswerefarsuperiortoseveralbenchmarks,includingfactormod- els. Ardia et al. ( 2019) introduce a general text sentiment framework that optimizes the design for forecasting purposes and apply it to forecasting economic growth in the United States. The methodincludestheuseoftheElnetforsparsedata-drivenselectionandtheweightingofthou- sandsofsentimentvalues.Tarassow( 2019)considerpenalizedVARstoforecastsixdifferenteco- nomicuncertaintyvariablesforthegrowthoftherealM2andrealM4Divisiamoneyseriesfor the United States using monthly data. Uematsu and Tanaka ( 2019) consider high-dimensional forecastingandvariableselectionviafolded-concavepenalizedregressions.Theauthorsforecast quarterly U.S. gross domestic product data using a high-dimensional monthly data set and the mixeddatasampling(MIDAS)frameworkwithpenalization.SeealsoBabiietal.( 2020b,2020c). Thereisalsoavastlistofapplicationsinempiricalfinance.Elliottetal.( 2013)findthatcom- binationsofsubsetregressionscanproducemoreaccurateforecastsoftheequitypremiumthan conventionalapproachesbasedonequal-weightedforecastsandotherregularizationtechniques. AudrinoandKnaus( 2016)usedLASSO-basedmethodstoestimateforecastingmodelsforrealized volatilities.Callotetal.( 2017)considermodelingandforecastinglargerealizedcovariancematri- cesofthe30DowJonesstocksbypenalizedVARmodels.TheauthorsfindthatpenalizedVARs outperformthebenchmarksbyawidemarginandimprovetheportfolioconstructionofamean\u2013 varianceinvestor.Chincoetal.( 2019)usetheLASSOtomake1-minute-aheadreturnforecastsfor avastsetofstockstradedattheNewYorkStockExchange.Theauthorsprovideevidencethat penalizedregressionestimatedbytheLASSOboostout-of-samplepredictivepowerbychoosing predictorsthattraceouttheconsequencesofunexpectednewsannouncements. 6.2Nonlinearmethods TherearemanypapersontheapplicationofnonlinearMLmethodstoeconomicandfinancial forecasting.MostofthepapersfocusonNNmethods,speciallytheonesfromtheearlyliterature.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 102 MASINIetal. With respect to the early papers, most of the models considered were nonlinear versions of autoregressivemodels.Atbest,asmallnumberofextracovariateswereincluded.See,forexam- ple, Ter\u00e4svirta et al. ( 2005) and the references therein. In the majority of the papers, including Ter\u00e4svirtaetal.( 2005),therewasnostrongevidenceofthesuperiorityofnonlinearmodelsasthe differencesinperformanceweremarginal.OtherexamplesfromtheearlyliteratureareSwanson andWhite( 1995,1997a,1997b),BalkinandOrd( 2000),Tkacz(2001),Medeirosetal.( 2001),and Heravietal.( 2004). Morerecently,withtheavailabilityoflargedatasets,nonlinearmodelsarebacktothescene. For example, Medeiros et al. ( 2021) show that, despite the skepticism of the previous literature on inflation forecasting, ML models with a large number of covariates are systematically more accurate than the benchmarks for several forecasting horizons and show that Random Forests dominated all other models. The good performance of the Random Forest is due not only to its specific method of variable selection but also the potential nonlinearities between past key macroeconomicvariablesandinflation.OthersuccessfulexampleisGuetal.( 2020).Theauthors showlargeeconomicgainstoinvestorsusingMLforecastsoffuturestockreturnsbasedonavery largesetofpredictors.Thebestperformingmodelsaretree-basedandneuralnetworks.Coulombe etal.(2020)showsignificantgainswhennonlinearMLmethodsareusedtoforecastmacroeco- nomic time series. Borup et al. ( 2020) consider penalized regressions, ensemble methods, and random forest to forecast employment growth in the United States over the period 2004\u20132019 usingGooglesearchactivity.TheirresultsstronglyindicatethatGooglesearchdatahavepredic- tivepower.Borupetal.( 2020)computenow-andbackcastsofweeklyunemploymentinsurance initialclaimsintheUSbasedonarichsetofdailyGoogleTrendssearch-volumedataandmachine learningmethods. 6.3Empiricalillustration Inthissection,weillustratetheuseofsomeofthemethodsreviewedinthispapertoforecastdaily realizedvarianceoftheBrazilianStockMarketindex(BOVESPA).Weuseasregressorsinforma- tionfromothermajorindexes,namely,theS&P500(US),theFTSE100(UnitedKingdom),DAX (Germany),HangSeng(HongKong),andNikkei(Japan).Ourmeasureofrealizedvolatilityiscon- structedbyaggregatingintradayreturnssampleatthe5-minfrequency.Thedatawereobtained fromtheOxford-ManRealizedLibraryatOxfordUniversity.10 Foreachstockindex,wedefinetherealizedvarianceas ??????=??? ??=1??2 ????, where??????isthelogreturnsampledatthe5-min.frequency. ??isthenumberofavailablereturns atday??. The benchmark model is the heterogeneous autoregressive (HAR) model proposed by Corsi (2009): log??????+1=??0+??1log??????+??5log????5,??+??22log????22,??+????+1, (13)  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 103 Figure 7 Realizedvarianceofdifferentstockindexes[Colourfigurecanbeviewedat wileyonlinelibrary.com] where??????isdailyrealizedvarianceoftheBOVESPAindex, ????5,??=1 54? ??=0??????-??,and ????22,??=1 2221? ??=0??????-??. Asalternatives,weconsideranextendedHARmodelwithadditionalregressorsestimatedby adaLASSO.Weincludeasextraregressorsthedailypastvolatilityoftheotherfiveindexescon- sideredhere.Themodelhasatotalofeightcandidatepredictors.Furthermore,weconsidertwo nonlinearalternativesusingallpredictors:arandomforestandshallowanddeepNNs. TherealizedvariancesofthedifferentindexesareillustratedinFigure 7.ThedatastartinFebru- ary2,2000andendsinMay21,2020,atotalof4200observations.Thesampleincludestwoperi- odsofveryhighvolatility,namely,thefinancialcrisisof2007\u20132008andtheCovid-19pandemics of2020.Weconsiderarollingwindowexercise,wereweset1500observationsineachwindow. Themodelsarereestimatedeveryday. SeveralotherauthorshaveestimatednonlinearandMLmodelstoforecastrealizedvariances. McAleer and Medeiros ( 2008) considered a smooth transition version of the HAR while Hille- brandandMedeiros( 2016)consideredthecombinationofsmoothtransitions,longmemory,and NN models. Hillebrand and Medeiros ( 2010) and McAleer and Medeiros ( 2011) combined NN  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 104 MASINIetal. Table 1 Forecastingresults Fullsample 2007\u20132008 2020 Model MSE QLIKE MSE QLIKE MSE QLIKE HARX-LASSO 0.96**0.98 0.98*0.96 0.90***0.90 Randomforest 1.00 1.02 0.95***0.98 1.13**1.03* Neuralnetwork(1) 0.99**0.99 0.97**0.98 0.99 0.99 Neuralnetwork(3) 0.99**0.99 0.98*0.99 0.99 0.99 Neuralnetwork(5) 0.90**0.99 0.98*0.99 0.99 0.99 The table reports for each model, the mean squared error (MSE) and the QLIKE statistics as a ratio to the HAR benchmark. ValuessmallerthanoneindicatesthatthemodeloutperformstheHAR.TheasterisksindicatetheresultsoftheDiebold-Mariano testofequalforecastingperformance.*,**,and***,indicaterejectionofthenullofequalforecastingabilityatthe10%,5%,and 1%,respectively. modelswithbaggingandScharthandMedeiros( 2009)consideredsmoothtransitionregression trees. The use of LASSO and its generalizations to estimate extensions of the HAR model was proposedbyAudrinoandKnaus( 2016). Althoughthemodelsareestimatedinlogarithms,wereporttheresultsinlevels,whichinthe endisthequantityofinterest.WecomparethemodelsaccordingtotheMSEandtheQLIKEmet- ric. TheresultsareshowninTable 1.Thetablereportsforeachmodel,theMSEandtheQLIKE statisticsasaratiototheHARbenchmark.Valuessmallerthanoneindicatesthatthemodelout- performstheHAR.TheasterisksindicatetheresultsoftheDiebold-Marianotestofequalfore- castingperformance.*,**,and***,indicaterejectionofthenullofequalforecastingabilityatthe 10%, 5%, and 1%, respectively. We report results for the full out-of-sample period, the financial crisis years (2007\u20132008), and then for 2020 as a way to capture the effects of the Covid-19 pan- demicsontheforecastingperformanceofdifferentmodels. Aswecanseefromthetables,theMLmethodsconsideredhereoutperformtheHARbench- mark.ThewinnermodelisdefinitelytheHARmodelwithadditionalregressorsandestimated withadaLASSO.Theperformanceimprovesduringthehighvolatilityperiodsandthegainsreach 10%duringtheCovid-19pandemics.RFsdonotperformwell.Ontheotherhand,NNmodelswith differentnumberofhiddenlayersoutperformthebenchmark. 7CONCLUSIONSANDTHEROADAHEAD Inthispaper,wepresentanonexhaustivereviewofthemostoftherecentdevelopmentsinML andhigh-dimensionalstatisticstotime-seriesmodelingandforecasting.Wepresentedbothlinear andnonlinearalternatives.Furthermore,weconsiderensembleandhybridmodels.Finally,we brieflydiscusstestsforsuperiorpredictiveability. Among linear specification, we pay special attention to penalized regression (Ridge, LASSO anditsgeneralizations,forexample)andensemblemethods(BaggingandCSR).Although,there havebeenmajortheoreticaladvancesintheliteratureonpenalizedlinearregressionmodelsfor dependentdata,thesameisnottrueforensemblemethods.ThetheoreticalresultsforBagging aresofarbasedonindependentdataandtheresultsforCSRarequitelimited. WithrespecttononlinearMLmethods,wefocusedonNNsandtree-basedmethods.Theoret- icalresultsforRFsandboostedtreeshavebeendevelopedonlytoIIDdataandinthecaseofa  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 105 low-dimensionalsetofregressors.ForshallowNNs,Chenetal.( 2007)andChen( 2007)provide some theoretical results for dependent data in the low-dimensional case. The behavior of such modelsinhighdimensionsisstillunderstudy.ThesameistruefordeepNNs. Nevertheless,therecentempiricalevidenceshowsthatnonlinearMLmodelscombinedwith largedatasetscanbeextremelyusefulforeconomicforecasting. Asadirectionforfurtherdevelopmentswelistthefollowingpoints: 1. DevelopresultsforBaggingandBoostingfordependentdata. 2. Show consistency and asymptotic normality of the RF estimator of the unknown function ??h(????)whenthedataaredependent. 3. DeriveabetterunderstandingofthevariableselectionmechanismofnonlinearMLmethods. 4. DevelopinferentialmethodstoaccessvariableimportanceinnonlinearMLmethods. 5. Developmodelsbasedonunstructureddata,suchastextdata,toeconomicforecasting. 6. EvaluateMLmodelsfornowcasting. 7. EvaluateMLinveryunstableenvironmentswithmanystructuralbreaks. Finally,wewouldliketopointthatweleftanumberofotherinterestingMLmethodsoutof this survey, such as, for example, Support Vector Regressions, autoenconders, nonlinear factor models,andmanymore.However,wehopethatthematerialpresentedherecanbeofvalueto anyoneinterestedofapplyingMLtechniquestoeconomicand/orfinancialforecasting. ACKNOWLEDGMENTS Weareverygratefulfortheinsightfulcommentsmadebytwoanonymousreferees.Thesecond authorgratefullyacknowledgesthepartialfinancialsupportfromCNPq.Wearealsogratefulto FrancisX.Diebold,DanielBorup,andAndriiBabiiforhelpfulcomments. ORCID MarceloC.Medeiros https://orcid.org/0000-0001-8471-4323 ENDNOTES 1Morerecently,MLforcausalinferencehavestartedtoreceivealotofattention.However,thissurveywillnot covercausalinferencewithMLmethods. 2The original sentence is \u201cProgramming computers to learn from experience should eventually eliminate the needformuchofthisdetailedprogrammingeffort.\u201dSeeSamuel( 1959). 3Thezeromeanconditioncanbealwaysensuredbyincludinganinterceptinthemodel.Alsothevarianceof ??(????)tobefinitesufficesforthefinitevariance. 4Theoracleproperty wasfirstdescribedinFanandLi( 2001)inthecontextofnonconcavepenalizedestimation. 5Amoreprecisetreatmentwouldseparate signconsistency frommodelselectionconsistency .Signconsistency first appearedinZhaoandYu( 2006)andalsoverifywhetherthesignofestimatedregressionweightsconvergeto thepopulationones. 6Weaksparsity generalizessparsitybysupposingthatcoefficientsare(very)smallinsteadofexactlyzero. 7Therelevantregressorsaretheonesassociatedwithnonzeroparameterestimates. 8Anunstablepredictor haslargevariance.Intuitively,smallchangesinthedatayieldlargechangesinthepredic- tivemodel. 9Itispossibletocombineforecastsusinganyweightingscheme.However,itisdifficulttobeatuniformweighting (Genreetal., 2013). 10https://realized.oxford-man.ox.ac.uk/data/assets  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 106 MASINIetal. References Ad\u00e1mek,R.,Smeekes,S.,&Wilms,I.(2020). LASSOinferenceforhigh-dimensionaltimeseries (TechnicalReport). arxiv:2007.10952. Ardia,D.,Bluteau,K.,&Boudt,K.(2019).Questioningthenewsabouteconomicgrowth:Sparseforecastingusing thousandsofnews-basedsentimentvalues. InternationalJournalofForecasting ,35,1370\u20131386. Audrino,F.,&Knaus,S.D.(2016).LassoingtheHARmodel:Amodelselectionperspectiveonrealizedvolatility dynamics.EconometricReviews ,35,1485\u20131521. Babii,A.,Ghysels,E.,&Striaukas,J.(2020a). Inferenceforhigh-dimensionalregressionswithheteroskedasticityand autocorrelation (TechnicalReport).arxiv:1912.06307. Babii,A.,Ghysels,E.,&Striaukas,J.(2020b). Machinelearningpaneldataregressionswithanapplicationtonow- castingpriceearningsratios (TechnicalReport).arxiv:2008.03600. Babii,A.,Ghysels,E.,&Striaukas,J.(2020c). Machinelearningtimeseriesregressionswithanapplicationtonow- casting(TechnicalReport).arxiv:2005.14057. Balkin, S. D., & Ord, J. K. (2000). Automatic neural network modeling for univariate time series. International JournalofForecasting ,16,509\u2013515. Barron,A.(1993).Universalapproximationboundsforsuperpositionsofasigmoidalfunction. IEEETransactions onInformationTheory ,39,930\u2013945. Bartlett,P.,&Traskin,M.M.(2007).AdaBoostisconsistent. JournalofMachineLearningResearch ,8,2347\u20132368. Basu,S.,&Michailidis,G.(2015).Regularizedestimationinsparsehigh-dimensionaltimeseriesmodels. Annals ofStatistics ,43,1535\u20131567. Belloni,A.,Chernozhukov,V.,&Hansen,C.(2014).Inferenceontreatmenteffectsafterselectionamongsthigh- dimensionalcontrols. ReviewofEconomicStudies ,81,608\u2013650. Borup,D.,Christensen,B.,M\u00fchlbach,N.,&Nielsen,M.(2020).Targetingpredictorsinrandomforestregression. TechnicalReport ,2004.01411,arxiv. Borup,D.,Rapach,D.,&Sch\u00fctte,E.(2020).Now-andbackcastinginitialclaimswithhigh-dimensionaldailyinter- netsearch-volumedata. TechnicalReport ,3690832,SSRN. Breiman,L.(1996).Baggingpredictors. MachineLearning ,24,123\u2013140. Breiman,L.(2001).Randomforests. MachineLearning ,45,5\u201332. B\u00fchlmann, P. L. (2002). Consistency for L2boosting and matching pursuit with trees and tree-type basis func- tions.InResearchreport/Seminarf\u00fcrStatistik,Eidgen\u00f6ssischeTechnischeHochschule(ETH) ,Vol.109.Seminar f\u00fcrStatistik,Eidgen\u00f6ssischeTechnischeHochschule(ETH). B\u00fchlmann,P.(2006).Boostingforhigh-dimensionallinearmodels. AnnalsofStatistics ,34,559\u2013583. Callot, L. A. F., & Kock, A. B. (2013). Oracle efficient estimation and forecasting with the adaptive LASSO and theadaptivegroupLASSOinvectorautoregressions.InN.Haldrup,M.Meitz,&P.Saikkonen(Eds.), Essaysin nonlineartimeserieseconometrics .OxfordUniversityPress. Callot,L.,Kock,A.,&Medeiros,M.(2017).Modelingandforecastinglargerealizedcovariancematricesandport- foliochoice. JournalofAppliedEconometrics ,32,140\u2013158. Chan,K-.S.,&Chen,K.(2011).SubsetARMAselectionviatheadaptiveLASSO. StatisticsandItsInterface ,4,197\u2013 205. Chen,X.(2007).Largesamplesieveestimationofsemi-nonparametricmodels.InJ.Heckman&E.Leamer(Eds.), Handbookofeconometrics (pp.5549\u20135632).Elsevier. Chen,S.,Donoho,D.,&Saunders,M.(2001).Atomicdecompositionbybasispursuit. SIAMReview ,43,129\u2013159. Chen,X.,Racine,J.,&Swanson,N.(2007).SemiparametricARXneural-networkmodelswithanapplicationto forecastinginflation. IEEETransactionsonNeuralNetworks ,12,67 4\u2013683. Chen,X.,&Shen,S.(1998).Sieveextremumestimatesforweaklydependentdata. Econometrica ,66,289\u2013314. Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., & Newey, W. (2017). Dou- ble/debiased/Neymanmachinelearningoftreatmenteffects. AmericanEconomicReview ,107,261\u2013265. Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., & Robins, J. (2018). Dou- ble/debiasedmachinelearningfortreatmentandstructuralparameters. EconometricsJournal ,21,C1\u2013C68. Chinco,A.,Clark-Joseph,A.,&Ye,M.(2019).Sparsesignalsinthecross-sectionofreturns. JournalofFinance ,74, 449\u2013492. Corsi,F.(2009).Asimplelongmemorymodelofrealizedvolatility. JournalofFinancialEconometrics ,7,17 4\u2013196.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 107 Coulombe,P.,Leroux,M.,Stevanovic,D.,&Surprenant,S.(2020). Howismachinelearningusefulformacroeco- nomicforecasting? (Technicalreport).UniversityofPennsylvania. Cybenko,G.(1989).Approximationbysuperpositionofsigmoidalfunctions. MathematicsofControl,Signals,and Systems,2,303\u2013314. Davis,R.,&Nielsen,M.(2020).Modelingoftimeseriesusingrandomforests:Theoreticaldevelopments. Electronic JournalofStatistics14 ,3644\u20133671. Diebold,F.(2015).Comparingpredictiveaccuracy,twentyyearslater:Apersonalperspectiveontheuseandabuse ofDiebold-Marianotests. JournalofBusinessandEconomicStatistics ,33,1\u20139. Diebold,F.X.,&Mariano,R.S.(1995).Comparingpredictiveaccuracy. JournalofBusinessandEconomicStatistics , 13,253\u2013263. Diebold,F.&Shin,M.(2019).Machinelearningforregularizedsurveyforecastcombination:Partially-egalitarian LASSOanditsderivatives. InternationalJournalofForecasting ,35,1679\u20131691. Diebold,F.,Shin,M.,&Zhang,B.(2021).Ontheaggregationofprobabilityassessments:Regularizedmixturesof predictivedensitiesforEurozoneinflationandrealinterestrates. TechnicalReport ,2012.11649,arxiv. Duffy,N.,&Helmbold,D.(2002).Boostingmethodsforregression. MachineLearning ,47,153\u2013200. Elliott,G.,Gargano,A.,&Timmermann,A.(2013).Completesubsetregressions. JournalofEconometrics ,177(2), 357\u2013373. Elliott, G., Gargano, A., & Timmermann, A. (2015). Complete subset regressions with large-dimensional sets of predictors. JournalofEconomicDynamicsandControl ,54,86\u2013110. Elliott,G.,&Timmermann,A.(2008).Economicforecasting. JournalofEconomicLiterature ,46,3\u201356. Elliott,G.,&Timmermann,A.(2016).Forecastingineconomicsandfinance. AnnualReviewofEconomics ,8,81\u2013110. Fan,J.,&Li,R.(2001).Variableselectionvianonconcavepenalizedlikelihoodanditsoracleproperties. Journalof theAmericanStatisticalAssociation ,96,1348\u20131360. Fan,J.,&Lv,J.(2008).Sureindependencescreeningforultrahighdimensionalfeaturespace. JournaloftheRoyal StatisticalSociety,SeriesB ,70,849\u2013911. Fan,J.,Xue,L.,&Zou,H.(2014).Strongoracleoptimalityoffoldedconcavepenalizedestimation. AnnalsofStatis- tics,42,819\u2013849. Foresee,F.D.,&Hagan,M.T.(1997).Gauss-NewtonapproximationtoBayesianregularization. IEEEInternational ConferenceonNeuralNetworks (Vol.3,pp.1930\u20131935).NewYork:IEEE. Friedman,J.(2001).Greedyfunctionapproximation:Agradientboostingmachine. AnnalsofStatistics ,29,1189\u2013 1232. Funahashi, K. (1989). On the approximate realization of continuous mappings by neural networks. Neural Net- works,2,183\u2013192. Garcia,M.,Medeiros,M.,&Vasconcelos,G.(2017).Real-timeinflationforecastingwithhigh-dimensionalmodels: ThecaseofBrazil. InternationalJournalofForecasting ,33(3),679\u2013693. Genre,V.,Kenny,G.,Meyler,A.,&Timmermann,A.(2013).Combiningexpertforecasts:Cananythingbeatthe simpleaverage? InternationalJournalofForecasting ,29,108\u2013121. Giacomini,R.,&White,H.(2006).Testsofconditionalpredictiveability. Econometrica ,74,1545\u20131578. Granger,C.,&Machina,M.(2006).Forecastinganddecisiontheory.In Handbookofeconomicforecasting (Vol.1, pp.81\u201398).Elsevier. Grenander,U.(1981). Abstractinference .NewYork:Wiley. Gu,S.,Kelly,B.,&Xiu,D.(2020).Empiricalassetpricingviamachinelearning. ReviewofFinancialStudies ,33, 2223\u20132273. Hamilton,J.(1994). Timeseriesanalysis .PrincetonUniversityPress. Han,Y.,&Tsay,R.(2020).High-dimensionallinearregressionfordependentdatawithapplicationstonowcasting. StatisticaSinica ,30,1797\u20131827. Hans,C.(2009).BayesianLASSOregression. Biometrika ,96,835\u2013845. Hansen,P.(2005).Atestforsuperiorpredictiveability. JournalofBusinessandEconomicStatistics ,23,365\u2013380. Hansen,P.,Lunde,A.,&Nason,J.(2011).Themodelconfidenceset. Econometrica ,79,453\u2013497. Harvey,D.,Leybourne,S.,&Newbold,P.(1997).Testingtheequalityofpredictionmeansquarederrors. Interna- tionalJournalofForecasting ,13,281\u2013291. Hastie, T., Tibshirani, R., & Friedman, J. (2009). Theelementsofstatisticallearning:Datamining,inference,and prediction.Springer.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 108 MASINIetal. Hastie,T.,Tibshirani,R.,&Wainwright,M.(2015). Statisticallearningwithsparsity:TheLASSOandgeneralizations . CRCPress. Hecq,A.,Margaritella,L.,&Smeekes,S.(2019). Grangercausalitytestinginhigh-dimensionalVARs:Apost-double- selectionprocedure (TechnicalReport).arxiv:1902.10991. Heravi,S.,Osborne,D.,&Birchenhall,C.(2004).LinearversusneuralnetworkforecastsforEuropeanindustrial productionseries. InternationalJournalofForecasting ,20,435\u2013446. Hillebrand,E.,&Medeiros,M.(2010).Thebenefitsofbaggingforforecastmodelsofrealizedvolatility. Econometric Reviews,29,571\u2013593. Hillebrand,E.,&Medeiros,M.C.(2016).Asymmetries,breaks,andlong-rangedependence. JournalofBusiness andEconomicStatistics ,34,23\u201341. Hochreiter,S.,&Schmidhuber,J.(1997).Longshort-termmemory. NeuralComputation ,9,1735\u20131780. Hoerl,A.,&Kennard,R.(1970).Ridgeregression:Biasedestimationfornonorthogonalproblems. Technometrics , 12,55\u201367. Hornik,K.,Stinchombe,M.,&White,H.(1989).Multi-layerFeedforwardnetworksareuniversalapproximators. NeuralNetworks ,2,359\u2013366. Hsu,N.-J.,Hung,H.-L.,&Chang,Y.-M.(2008).SubsetselectionforvectorautoregressiveprocessesusingLASSO. ComputationalStatistics&DataAnalysis ,52,3645\u20133657. Inoue, A., & Kilian, L. (2008). How useful is bagging in forecasting economic time series? A case study of U.S. consumerpriceinflation. JournaloftheAmericanStatisticalAssociation ,103,511\u2013522. James,W.,&Stein,C.(1961).Estimationwithquadraticloss. ProceedingsoftheThirdBerkeleySymposiumonMath- ematicalStatisticsandProbability (Vol.1,pp.361\u2013379). Jiang,W.(2004).ProcessconsistencyforAdaBoost. AnnalsofStatistics ,32,13\u201329. Kim, Y., Choi, H., & Oh, H.-S. (2008). Smoothly clipped absolute deviation on high dimensions. Journal of the AmericanStatisticalAssociation ,103,1665\u20131673. Knight,K.,&Fu,W.(2000).AsymptoticsforLASSO-typeestimators. AnnalsofStatistics ,28,1356\u20131378. Kock,A.(2016).ConsistentandconservativemodelselectionwiththeadaptiveLassoinstationaryandnonstation- aryautoregressions. EconometricTheory ,32,243\u2013259. Kock,A.,&Callot,L.(2015).Oracleinequalitiesforhighdimensionalvectorautoregressions. JournalofEconomet- rics,186,325\u2013344. Kock, A., & Ter\u00e4svirta, T. (2014). Forecasting performance of three automated modelling techniques during the economiccrisis2007-2009. InternationalJournalofForecasting ,30,616\u2013631. Kock, A., & Ter\u00e4svirta, T. (2015). Forecasting macroeconomic variables using neural network models and three automatedmodelselectiontechniques. EconometricReviews ,35,1753\u20131779. Konzen,E.,&Ziegelmann,F.(2016).LASSO-typepenaltiesforcovariateselectionandforecastingintimeseries. JournalofForecasting ,35,592\u2013612. Koo,B.,Anderson,H.,Seo,M.,&Yao,W.(2020).High-dimensionalpredictiveregressioninthepresenceofcoin- tegration.JournalofEconometrics ,219,456\u2013477. Lederer,J.,Yu,L.,&Gaynanova,I.(2019).Oracleinequalitiesforhigh-dimensionalprediction. Bernoulli,25,1225\u2013 1255. Lee,J.,Sun,D.,Sun,Y.,&Taylor,J.(2016).Exactpost-selectioninferencewithapplicationtotheLASSO. Annals ofStatistics ,44,907\u2013927. Lee,J.,&Shi,Z.G.Z.(2020). OnLASSOforpredictiveregression (TechnicalReport).arxiv:1810.03140. Leeb,H.,&P\u00f6tscher,B.(2005).Modelselectionandinference:Factsandfiction. EconometricTheory ,21,21\u201359. Leeb, H., & P\u00f6tscher, B. (2008). Sparse estimators and the oracle property, or the return of Hodges\u2019 estimator. JournalofEconometrics ,142,201\u2013211. Li,J.,Liao,Z.,&Quaedvlieg,R.(2020). Conditionalsuperiorpredictiveability (TechnicalReport).ErasmusSchool ofEconomics. Lockhart,R.,Taylor,J.,Tibshirani,R.,&Tibshirani,R.(2014).Asignificancetestforthelasso. AnnalsofStatistics , 42,413\u2013468. Lugosi,G.,&Vayatis,N.(2004).OntheBayes-riskconsistencyofregularizedboostingmethods. AnnalsofStatistics , 32,30\u201355. MacKay,D.J.C.(1992a).Bayesianinterpolation. NeuralComputation ,4,415\u2013447.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 109 MacKay,D.J.C.(1992b).ApracticalBayesianframeworkforbackpropagationnetworks. NeuralComputation ,4, 448\u2013472. Masini,R.,Medeiros,M.,&Mendes,E.(2019). Regularizedestimationofhigh-dimensionalvectorautoregressions withweaklydependentinnovations (TechnicalReport).arxiv:1912.09002. McAleer,M.,&Medeiros,M.(2011).Forecastingrealizedvolatilitywithlinearandnonlinearmodels. Journalof EconomicSurveys ,25,6\u201318. McAleer,M.,&Medeiros,M.C.(2008).Amultipleregimesmoothtransitionheterogeneousautoregressivemodel forlongmemoryandasymmetries. JournalofEconometrics ,147,104\u2013119. McCracken,M.(2020).Divergingtestsofequalpredictiveability. Econometrica ,88,1753\u20131754. Medeiros, M., & Mendes, E. (2013). Penalized estimation of semi-parametric additive time-series models. In N. Haldrup,M.Meitz,&P.Saikkonen(Eds.), Essaysinnonlineartimeserieseconometrics .OxfordUniversityPress. Medeiros,M.,&Mendes,E.(2016). ??1-Regularizationofhigh-dimensionaltime-seriesmodelswithnon-Gaussian andheteroskedasticerrors. JournalofEconometrics ,191,255\u2013271. Medeiros, M., & Mendes, E. (2017). Adaptive LASSO estimation for ARDL models with GARCH innovations. EconometricReviews ,36,622\u2013637. Medeiros, M., & Vasconcelos, G. (2016). Forecasting macroeconomic variables in data-rich environments. Eco- nomicsLetters ,138,50\u201352. Medeiros, M. C., Ter\u00e4svirta, T., & Rech, G. (2006). Building neural network models for time series: A statistical approach.JournalofForecasting ,25,49\u201375. Medeiros,M.C.,Vasconcelos,G.,Veiga,A.,&Zilberman,E.(2021).Forecastinginflationinadata-richenviron- ment:Thebenefitsofmachinelearningmethods. JournalofBusinessandEconomicStatistics ,39,98\u2013119. Medeiros,M.C.,&Veiga,A.(2005).Aflexiblecoefficientsmoothtransitiontimeseriesmodel. IEEETransactions onNeuralNetworks ,16,97\u2013113. Medeiros,M.C.,Veiga,A.,&Pedreira,C.(2001).Modellingexchangerates:Smoothtransitions,neuralnetworks, andlinearmodels. IEEETransactionsonNeuralNetworks ,12,755\u2013764. Melnyk,I.,&Banerjee,A.(2016).Estimatingstructuredvectorautoregressivemodels. InternationalConferenceon MachineLearning (pp.830\u2013839). Mhaska,H.,Liao,Q.,&Poggio,T.(2017).Whenandwhyaredeepnetworksbetterthanshallowones? Proceedings oftheThirty-FirstAAAIConferenceonArtificialIntelligence(AAAI-17) (pp.2343\u20132349). Nardi,Y.,&Rinaldo,A.(2011).AutoregressiveprocessmodelingviatheLASSOprocedure. JournalofMultivariate Analysis,102,528\u2013549. Park,H.,&Sakaori,F.(2013).LagweightedLASSOfortimeseriesmodel. ComputationalStatistics ,28,493\u2013504. Park,J.,&Sandberg,I.(1991).Universalapproximationusingradial-basis-functionnetworks. NeuralComputation , 3,246\u2013257. Park,T.,&Casella,G.(2008).TheBayesianLASSO. JournaloftheAmericanStatisticalAssociation ,103,681\u2013686. Ren,Y.,&Zhang,X.(2010).SubsetselectionforvectorautoregressiveprocessesviaadaptiveLASSO. Statistics& ProbabilityLetters ,80,1705\u20131712. Samuel, A. (1959). Some studies in machine learning using the game of checkers. IBM Journal of Research and Development ,3(3),210\u2013229. Sang,H.,&Sun,Y.(2015).Simultaneoussparsemodelselectionandcoefficientestimationforheavy-tailedautore- gressiveprocesses. Statistics,49,187\u2013208. Scharth,M.,&Medeiros,M.(2009).AsymmetriceffectsandlongmemoryinthevolatilityofDowJonesstocks. InternationalJournalofForecasting ,25,304\u2013325. Scornet,E.,Biau,G.,&Vert,J.-P.(2015).Consistencyofrandomforests. AnnalsofStatistics ,43,1716\u20131741. Simon,N.,Friedman,J.,Hastie,T.,&Tibshirani,R.(2013).Asparse-groupLASSO. JournalofComputationaland GraphicalStatistics ,22,231\u2013245. Smeeks,S.,&Wijler,E.(2018).Macroeconomicforecastingusingpenalizedregressionmethods. InternationalJour- nalofForecasting ,34,408\u2013430. Smeeks,S.,&Wijler,E.(2021).Anautomatedapproachtowardssparsesingle-equationcointegrationmodelling. JournalofEconometrics ,221(1),247\u2013276. Srivastava,N.,Hinton,G.,Krizhevsky,A.,Sutskever,I.,&Salakhutdinov,R.(2014).Simplewaytopreventneural networksfromoverfitting. JournalofMachineLearningResearch ,15,1929\u20131958.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 110 MASINIetal. Stein,C.(1956).Inadmissibilityoftheusualestimatorforthemeanofamultivariatedistribution. Proceedingsof theThirdBerkeleySymposiumonMathematicalStatisticsandProbability (Vol.1,pp.197\u2013206). Stinchcombe, M., & White, S. (1989). Universal approximation using feedforward neural networks with non- sigmoidhiddenlayeractivationfunctions. ProceedingsoftheInternationalJointConferenceonNeuralNetworks , Washington (pp.613\u2013617).NewYork,NY:IEEEPress. Suarez-Fari\u00f1as,Pedreira,C.,&Medeiros,M.C.(2004).Local-globalneuralnetworks:Anewapproachfornonlin- eartimeseriesmodelling. JournaloftheAmericanStatisticalAssociation ,99,1092\u20131107. Swanson,N.R.,&White,H.(1995).Amodelselectionapproachtoassessingtheinformationinthetermstructure usinglinearmodelsandartificialneuralnetworks. JournalofBusinessandEconomicStatistics ,13,265\u2013275. Swanson,N.R.,&White,H.(1997a).Forecastingeconomictimeseriesusingflexibleversusfixedspecificationand linearversusnonlineareconometricmodels. InternationalJournalofForecasting ,13,439\u2013461. Swanson,N.R.,&White,H.(1997b).Amodelselectionapproachtoreal-timemacroeconomicforecastingusing linearmodelsandartificialneuralnetworks. ReviewofEconomicandStatistics ,79,540\u2013550. Tarassow,A.(2019).ForecastingU.S.moneygrowthusingeconomicuncertaintymeasuresandregularisationtech- niques.InternationalJournalofForecasting ,35,443\u2013457. Taylor,J.,Lockhart,R.,Tibshirani,R.,&Tibshirani,R.(2014). Post-selectionadaptiveinferenceforleastangleregres- sionandtheLASSO (TechnicalReport).arxiv:1401.3889. Ter\u00e4svirta,T.(1994).Specification,estimation,andevaluationofsmoothtransitionautoregressivemodels. Journal oftheAmericanStatisticalAssociation ,89,208\u2013218. Ter\u00e4svirta,T.,Tj\u00f6stheim,D.,&Granger,C.(2010). Modellingnonlineareconomictimeseries .Oxford,UK:Oxford UniversityPress. Ter\u00e4svirta,T.,vanDijk,D.,&Medeiros,M.(2005).Linearmodels,smoothtransitionautoregressionsandneural networksforforecastingmacroeconomictimeseries:Areexamination(withdiscussion). InternationalJournal ofForecasting ,21,755\u201377 4. Tibshirani, R. (1996). Regression shrinkage and selection via the LASSO. J o ur na lo ft heR o ya lS t a t is t ic a lS o ciet y , SeriesB,58,267\u2013288. Tikhonov,A.(1943).Onthestabilityofinverseproblems. DokladyAkademiiNaukSSSR ,39,195\u2013198(inRussian). Tikhonov,A.(1963).Onthesolutionofill-posedproblemsandthemethodofregularization. DokladyAkademii Nauk,151,501\u2013504. Tikhonov,A.,&Arsenin,V.(1977). Solutionsofill-posedproblems .V.HWinstonandSons. Tkacz, G. (2001). Neural network forecasting of Canadian GDP growth. InternationalJournalofForecasting ,17, 57\u201369. Trapletti,A.,Leisch,F.,&Hornik,K.(2000).Stationaryandintegratedautoregressiveneuralnetworkprocesses. NeuralComputation ,12,2427\u20132450. Uematsu,Y.,&Tanaka,S.(2019).High-dimensionalmacroeconomicforecastingandvariableselectionviapenal- izedregression. EconometricsJournal ,22,34\u201356. vandeGeer,S.,B\u00fchlmann,P.,Ritov,Y.,&Dezeure,R.(2014).Onasymptoticallyoptimalconfidenceregionsand testsforhigh-dimensionalmodels. AnnalsofStatistics ,42,1166\u20131202. Wager,S.,&Athey,S.(2018).Estimationandinferenceofheterogeneoustreatmenteffectsusingrandomforests. JournaloftheAmericanStatisticalAssociation ,113,1228\u20131242. Wang,H.,&Leng,C.(2008).AnoteonadaptivegroupLASSO. ComputationalStatistics&DataAnalysis ,52,5277\u2013 5286. Wang,H.,Li,G.,&Tsai,C.-L.(2007).Regressioncoefficientandautoregressiveordershrinkageandselectionvia theLASSO. JournaloftheRoyalStatisticalSociety,SeriesB ,69,63\u201378. White,H.(2000).Arealitycheckfordatasnooping. Econometrica ,68,1097\u20131126. Wong,K.,Li,Z.,&Tewari,A.(2020).LASSOguaranteesfor ??-mixingheavytailedtimeseries. AnnalsofStatistics , 48,1124\u20131142. Wu, W. (2005). Nonlinear system theory: Another look at dependence. Proceedings of the National Academy of Sciences,102,14150\u201314154. Wu, W., & Wu, Y. (2016). Performance bounds for parameter estimates of high-dimensional linear models with correlatederrors. ElectronicJournalofStatistics ,10,352\u2013379. Xie,F.,Xu,L.,&Yang,Y.(2017).LASSOforsparselinearregressionwithexponentially ??-mixingerrors. Statistics &ProbabilityLetters ,125,64\u201370.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 111 Xue, Y., & Taniguchi, M. (2020). Modified LASSO estimators for time series regression models with dependent disturbances. StatisticalMethods&Applications ,29,845\u2013869. Yang,Y.,&Zou,H.H.(2015).Afastunifiedalgorithmforsolvinggroup-LASSOpenalizelearningproblems. Statis- ticsandComputing ,25,1129\u20131141. Yarotsky,D.(2017).ErrorboundsforapproximationswithdeepReLUnetworks. NeuralNetworks ,94,103\u2013114. Yoon,Y.,Park,C.,&Lee,T.(2013).Penalizedregressionmodelswithautoregressiveerrorterms. JournalofStatis- ticalComputationandSimulation ,83,1756\u20131772. Yousuf,K.(2018).Variablescreeningforhighdimensionaltimeseries. ElectronicJournalofStatistics ,12,667\u2013702. Yuan, M., & Lin, Y. (2006). Model selection and estimation in regression with grouped variables. Journal of the RoyalStatisticalSociety,SeriesB ,68,49\u201367. Zhang, T., & Yu, B. (2005). Boosting with early stopping: Convergence and consistency. Annals of Statistics ,33, 1538\u20131579. Zhao, P., & Yu, B. (2006). On model selection consistency of LASSO. Journal of Machine Learning Research ,7, 2541\u20132563. Zhu,X.(2020).Nonconcavepenalizedestimationinsparsevectorautoregressionmodel. ElectronicJournalofStatis- tics,14,1413\u20131448. Zou,H.(2006).TheadaptiveLASSOanditsoracleproperties. JournaloftheAmericanStatisticalAssociation ,101, 1418\u20131429. Zou,H.,&Hastie,T.(2005).Regularizationandvariableselectionviatheelasticnet. JournaloftheRoyalStatistical Society,SeriesB ,67,301\u2013320. Zou,H.,&Zhang,H.(2009).Ontheadaptiveelastic-netwithadivergingnumberofparameters. AnnalsofStatistics , 37,1733\u20131751. Howtocitethisarticle: Masini,R.P.,Medeiros,M.C.,&Mendes,E.F.(2023).Machine learningadvancesfortimeseriesforecasting. JEconSurv ,37,76\u2013111. https://doi.org/10.1111/joes.12429  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License ", "14": "SPECIAL ISSUE Machinelearningadvancesfortimeseries forecasting RicardoP.Masini1,2MarceloC.Medeiros3EduardoF.Mendes4 1CenterforStatisticsandMachine Learning,PrincetonUniversity,USA 2S\u00e3oPauloSchoolofEconomics,Getulio VargasFoundation,Brazil 3DepartmentofEconomics,Pontifical CatholicUniversityofRiodeJaneiro, Brazil 4SchoolofAppliedMathematics,Getulio VargasFoundation,Brazil Correspondence MarceloC.Medeiros,PontificalCatholic UniversityofRiodeJaneiro,RuaMarqu\u00eas deS\u00e3oVicente,225,G\u00e1vea,RiodeJaneiro, RJ,Brazil. Email:mcm@econ.puc-rio.br Fundinginformation CNPqandCAPES;ConselhoNacionalde DesenvolvimentoCient\u00edficoeTecnol\u00f3gicoAbstract In this paper, we survey the most recent advances in supervised machine learning (ML) and high- dimensional models for time-series forecasting. We considerbothlinearandnonlinearalternatives.Among the linear methods, we pay special attention to penal- izedregressionsandensembleofmodels.Thenonlinear methods considered in the paper include shallow and deep neural networks, in their feedforward and recurrent versions, and tree-based methods, such as random forests and boosted trees. We also consider ensembleandhybridmodelsbycombiningingredients fromdifferentalternatives.Testsforsuperiorpredictive ability are briefly reviewed. Finally, we discuss appli- cationofMLineconomicsandfinanceandprovidean illustrationwithhigh-frequencyfinancialdata. KEYWORDS bagging, boosting, deep learning, forecasting, machine learning, neural networks, nonlinear models, penalized regressions, ran- domforests,regressiontrees,regularization,sieveapproximation, statisticallearningtheory JEL CLASSIFICATION: C22 1INTRODUCTION Thispapersurveystherecentdevelopmentsinmachinelearning(ML)methodstoeconomicand financialtime-seriesforecasting.MLmethodshavebecomeanimportantestimation,modelselec- tion,andforecastingtoolforappliedresearchersinEconomicsandFinance.Withtheavailability 76\u00a92021JohnWiley&SonsLtd. JEconSurv. 2023;37:76\u2013111. wileyonlinelibrary.com/journal/joes MASINIetal. 77 ofvastdatasetsintheeraof BigData,producingreliableandrobustforecastsisofgreatimpor- tance.1 However,whatisML?Itiscertainlyabuzzwordwhichhasgainedalotofpopularityduring the last few years. There are a myriad of definitions in the literature and one of the most well establishedisfromtheartificialintelligencepioneerArthurL.SamuelwhodefinesMLas\u201cthe fieldofstudythatgivescomputerstheabilitytolearnwithoutbeingexplicitlyprogrammed.\u201d2We preferalessvaguedefinitionwhereMListhecombinationofautomatedcomputeralgorithms with powerful statistical methods to learn (discover) hidden patterns in rich data sets. In that sense,Statistical Learning Theory gives the statistical foundation of ML. Therefore, this paper is about Statistical Learning developments and not ML in general as we are going to focus on statisticalmodels.MLmethodscanbedividedintothreemajorgroups:supervised,unsupervised, andreinforcementlearning.Thissurveyisaboutsupervisedlearning,wherethetaskistolearn afunctionthatmapsaninput(explanatoryvariables)toanoutput(dependentvariable)basedon dataorganizedasinput\u2013outputpairs.Regressionmodels,forexample,belongtothisclass.Onthe otherhand,unsupervisedlearningisaclassofMLmethodsthatuncoverundetectedpatternsina datasetwithnopreexistinglabelsas,forexample,clusteranalysisordatacompressionalgorithms. Finally,inreinforcementlearning,anagentlearnstoperformcertainactionsinanenvironment whichleadittomaximumreward.Itdoessobyexplorationandexploitationofknowledgeitlearns byrepeatedtrialsofmaximizingthereward.Thisisthecoreofseveralartificialintelligencegame players(AlfaGo,forinstance)aswellasinsequentialtreatments,likeBanditproblems. The supervised ML methods presented here can be roughly divided in two groups. The first oneincludeslinearmodelsandisdiscussedinSection 2.Wefocusmainlyonspecificationsesti- matedbyregularization,alsoknownasshrinkage.SuchmethodsdatebackatleasttoTikhonov (1943).InStatisticsandEconometrics,regularizedestimatorsgainedattentionaftertheseminal papers by Willard James and Charles Stein who popularized the bias-variance trade-off in sta- tistical estimation (James & Stein, 1961;S t e i n ,1956). We start by considering the Ridge Regres- sionestimatorputforwardbyHoerlandKennard( 1970).Afterthat,wepresenttheleastabsolute shrinkageandselection(LASSO)estimatorofTibshirani( 1996)anditsmanyextensions.Wealso includeadiscussionofotherpenalties.Theoreticalderivationsandinferencefordependentdata arealsoreviewed. ThesecondgroupofMLtechniquesfocusesonnonlinearmodels.WecoverthistopicinSec- tion3andstartbypresentingaunifiedframeworkbasedonsievesemiparametricapproximation as in Grenander ( 1981). We continue by analyzing specific models as special cases of our gen- eralsetup.Morespecifically,wecoverfeedforwardneuralnetworks(NNs),bothintheirshallow anddeepversionsandrecurrentneuralnetworks(RNNs),andtree-basedmodelssuchasrandom forests(RFs)andboostedtrees.NNsareprobablyoneofthemostpopularMLmethods.Thesuc- cessispartlyduetothe,inouropinion,misguidedanalogytothefunctioningofthehumanbrain. Contrary to what has been boasted in the early literature, the empirical success of NN models comesfromamathematicalfactthatalinearcombinationofsufficientlymanysimplebasisfunc- tionsisabletoapproximateverycomplicatedfunctionsarbitrarilywellinsomespecificchoiceof metric.Regressiontreesonlyachievedpopularityafterthedevelopmentofalgorithmstoatten- uatetheinstabilityoftheestimatedmodels.AlgorithmslikeRandomForestsandBoostedTrees arenowinthetoolboxofappliedeconomists. Inadditiontothemodelsmentionedabove,wealsoincludeasurveyonensemble-basedmeth- odssuchasBaggingBreiman( 1996)andthecompletesubsetregression(CRS,Elliottetal., 2013, 2015).Furthermore,wegiveabriefintroductiontowhatwenamed\u201chybridmethods,\u201dwhereideas frombothlinearandnonlinearmodelsarecombinedtogeneratenewMLforecastingmethods.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 78 MASINIetal. Beforepresentinganempiricalillustrationofthemethods,wediscusstestsofsuperiorpredic- tiveabilityinthecontextofMLmethods. 1.1Generalframework Aquickwordonnotation:anuppercaseletterasin ??denotesarandomquantityasopposedtoa lowercaseletter ??whichdenotesadeterministic(nonrandom)quantity.Boldlettersasin ??and ??arereservedformultivariateobjectssuchasvectorandmatrices.Thesymbol ?\u00b7???for??=1 denotesthe????normofavector.Foraset ??,weuse |??|todenoteitscardinality. Givenasamplewith ??realizationsoftherandomvector (????,??' ??)',thegoalistopredict ????+h forhorizonsh=1,\u2026,?? .Throughoutthepaper,weconsiderthefollowingassumption: Assumption 1 (Data Generating Process (DGP)). Let {(????,??' ??)'}8 ??=1be a covariance-stationary stochasticprocesstakingvalueson R??+1. Therefore, we are excluding important nonstationary processes that usually appear in time- seriesapplications.Inparticular,unitrootandsometypesonlong-memoryprocessareexcluded byAssumption 1. For(usuallypredetermined)integers ??=1and??=0,definethe??-dimensionalvectorofpre- dictors????:=(????-1,\u2026,????-??,??' ??,\u2026,??' ??-??)'where??=??+??(??+1) and consider the following directforecastingmodel: ????+h=??h(????)+????+h, h=1,\u2026,??, ??=1,\u2026,??, (1) where??h:R???Ris an unknown (measurable) function and ????+h:=????+h-??h(????)is assumedtobezeromeanandfinitevariance.3 Themodel??hcouldbetheconditionalexpectationfunction, ??h(??)=??(????+h|????=?? ),orsim- plythebestlinearprojectionof ????+hontothespacespannedby ????.Regardlessofthemodelchoice, ourtargetbecomes ??h,forh=1,\u2026,?? .As??hisunknown,itshouldbeestimatedfromdata.The targetfunction ??hcanbeasinglemodeloranensembleofdifferentspecificationsanditcanalso changesubstantiallyforeachforecastinghorizon. Given an estimate \u02c6??hfor??h, the next step is to evaluate the forecasting method by estimat- ingitspredictionaccuracy.Mostmeasuresofpredictionaccuracyderivefromtherandomquan- tity?h(????):=|\u02c6??h(????)-??h(????)|.Forinstance,theterm predictionconsistency referstoestimators suchthat?h(????)???0as???8wheretheprobabilityistakentobeunconditional;asopposed toitsconditional counterpartwhichisgivenby ?h(????)???0,wheretheprobabilitylawiscondi- tionalon????=????.Clearly,ifthelatterholdsfor(almost)every ????thentheformerholdsbythelaw ofiteratedexpectation. Othermeasuresofpredictionaccuracycanbederivedfromthe ???norminducedbyeitherthe unconditionalprobabilitylaw ??|?h(????)|??ortheconditionalone ??(|?h(????)|??|????=????)for??=1. Byfar,themostusedarethe (conditional)meanabsolutelypredictionerror (????????)when??=1and (conditional)meansquaredpredictionerror (????????) when??=2, or the(conditional)rootmean squaredpredictionerror (??????????), which is simply thesquare root of ????????. Those measuresof predictionaccuracybasedonthe ???normsarestrongerthanpredictionconsistencyinthesense  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 79 thattheirconvergencetozeroassamplesizeincreasesimpliespredictionconsistencybyMarkov\u2019s inequality. Thisapproachstemsfromcastingeconomicforecastingasadecisionproblem.Underthechoice ofalossfunction,thegoalistoselect ??hfromafamilyofcandidatemodelsthatminimizesthe expectedpredictivelossorrisk.Givenanestimate \u02c6??hfor??h,thenextstepistoevaluatethefore- castingmethodbyestimatingitsrisk.Themostcommonlyusedlossesaretheabsoluteerrorand squarederror,correspondingto ?1and?2riskfunctions,respectively.SeeGrangerandMachina (2006)forreferencesofadetailedexpositionofthistopic,ElliottandTimmermann( 2008)fora discussionoftheroleofthelossfunctioninforecasting,andElliottandTimmermann( 2016)for amorerecentreview. 1.2Summaryofthepaper Apartfromthisbriefintroduction,thepaperisorganizedasfollows.Section 2reviewspenalized linearregressionmodels.NonlinearMLmodelsarediscussedinSection 3.Ensembleandhybrid methodsarepresentedinSection 4.Section5brieflydiscussestestsforsuperiorpredictiveabil- ity. An empirical application is presented in Section 6. Finally, we conclude and discuss some directionsforfutureresearchinSection 7. 2PENALIZEDLINEARMODELS Weconsiderthefamilyoflinearmodelswhere ??(??)=??' 0??in(1)foravectorofunknownparam- eters??0?R??. Notice that we drop the subscript hfor clarity. However, the model as well as theparameter ??0havetobeunderstoodforparticularvalueoftheforecastinghorizon h.These modelscontemplateaseriesofwell-knownspecificationsintime-seriesanalysis,suchaspredic- tiveregressions,autoregressivemodelsoforder ??,????(??),autoregressivemodelswithexogenous variables,??????(??),andautoregressivemodelswithdynamiclags ??????(??,??),amongmanyothers (Hamilton, 1994).Inparticular,( 1)becomes ????+h=??' 0????+????+h, h=1,\u2026,??, ??=1,\u2026,??, (2) whereundersquaredloss, ??0isidentifiedbythebestlinearprojectionof ????+honto????whichis welldefinedwhenever ??:=??(??????' ??)isnonsingular.Inthatcase, ????+hisorthogonalto ????bycon- structionandthispropertyisexploitedtoderiveestimationproceduressuchastheordinaryleast squares(OLS).However,when ??>??(andsometimes ??\u00bb??)theOLSestimatorisnotuniqueas thesamplecounterpartof ??isrankdeficient.Infact,wecancompletelyoverfitwhenever ??=??. Penalizedlinearregressionarisesinthesettingwheretheregressionparameterisnotuniquely defined. It is usually the case when ??is large, possibly larger than the number of observations ??,and/orwhencovariatesarehighlycorrelated.Thegeneralideaistorestrictthesolutionofthe OLS problem to a ball around the origin. It can be shown that, although biased, the restricted solutionhassmallermeansquarederror(MSE),whencomparedtotheunrestrictedOLS(Hastie etal.,2009,Chap.3andChap.6).  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 80 MASINIetal. Inpenalizedregressions,theestimator \u02c6??fortheunknownparametervector ??0minimizesthe Lagrangianform ??(??)=??-h? ??=1( ????+h-??'????)2+??(??), =???-???? ?2 2+??(??),(3) where??:=(??h+1,\u2026????)',??:=(??1,\u2026????-h)',and??(??):=??(??;??,??,??) =0isapenaltyfunc- tion that depends on a tuning parameter ??=0, that controls the trade-off between the good- nessoffitandtheregularizationterm.If ??=0,wehaveaclassicalunrestrictedregression,since ??(??;0,??,??)=0 .Thepenaltyfunctionmayalsodependonasetofextrahyperparameters ??,as wellasonthedata ??.Naturally,theestimator \u02c6??alsodependsonthechoiceof ??and??.Different choicesforthepenaltyfunctionswereconsideredintheliteratureofpenalizedregression. Ridgeregression TheridgeregressionwasproposedbyHoerlandKennard( 1970)asawaytofighthighlycorrelated regressorsandstabilizethesolutionofthelinearregressionproblem.Theideawastointroducea smallbiasbut,inturn,reducethevarianceoftheestimator.Theridgeregressionisalsoknownas aparticularcaseofTikhonovRegularization(Tikhonov, 1943,1963;Tikhonov&Arsenin, 1977), inwhichthescalematrixisdiagonalwithidenticalentries. Theridgeregressioncorrespondstopenalizingtheregressionbythesquared ??2normofthe parametervector,thatis,thepenaltyin( 3)isgivenby ??(??)=????? ??=1??2 ??=??????2 2. Ridgeregressionhastheadvantageofhavinganeasytocomputeanalyticsolution,wherethe coefficientsassociatedwiththeleastrelevantpredictorsareshrunktowardzero,butneverreach- ing exactly zero. Therefore, it cannot be used for selecting predictors, unless some truncation schemeisemployed. Leastabsoluteshrinkageandselectionoperator TheLASSOwasproposedbyTibshirani( 1996)andChenetal.( 2001)asamethodtoregularize andperformvariableselectionatthesametime.LASSOisoneofthemostpopularregularization methodsanditiswidelyappliedindata-richenvironmentswherenumberoffeatures ??ismuch largerthanthenumberoftheobservations. LASSOcorrespondstopenalizingtheregressionbythe ??1normoftheparametervector,that is,thepenaltyin( 3)isgivenby ??(??)=????? ??=1|????|=??????1.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 81 ThesolutionoftheLASSOisefficientlycalculatedbycoordinatedescentalgorithms(Hastie et al.,2015, Chap. 5). The ??1penalty is the smallest convex ????p e n a l t yn o r mt h a ty i e l d s sparse solutions.Wesaythesolutionis sparseifonlyasubset ??<??coefficientsarenonzero.Inother words,onlyasubsetofvariablesisselectedbythemethod.Hence,LASSOismostusefulwhen thetotalnumberofregressors ??\u00bb??anditisnotfeasibletotestcombinationormodels. Despiteattractiveproperties,therearestilllimitationstotheLASSO.Alargenumberofalterna- tivepenaltieshavebeenproposedtokeepitsdesiredpropertieswhileovercomingitslimitations. AdaptiveLASSO TheadaptiveLASSO(adaLASSO)wasproposedbyZou( 2006)andaimedtoimprovetheLASSO regressionbyintroducingaweightparameter,comingfromafirststepOLSregression.Italsohas sparsesolutionsandefficientestimationalgorithm,butenjoysthe oracleproperty ,meaningthatit hasthesameasymptoticdistributionastheOLSconditionalonknowingthevariablesthatshould enterthemodel.4 TheadaLASSOpenaltyconsistsinusingaweighted ??1penalty: ??(??)=????? ??=1????|????|, wherethenumberoffeatures ????=|??* ??|-1and??* ??isthecoefficientfromthefirst-stepestimation (anyconsistentestimatorof ??0)AdaLASSOcandealwithmanymorevariablesthanobservations. UsingLASSOasthefirst-stepestimatorcanberegardedasthetwo-stepimplementationofthe locallinearapproximationinFanetal.( 2014)withazeroinitialestimate. Elasticnet Theelasticnet(ElNet)wasproposedbyZouandHastie( 2005)asawayofcombiningstrengthsof LASSOandridgeregression.Whilethe ??1partofthemethodperformsvariableselection,the ??2 partstabilizesthesolution.Thisconclusionisevenmoreaccentuatedwhencorrelationsamong predictorsbecomehigh.Asaconsequence,thereisasignificantimprovementinpredictionaccu- racyovertheLASSO(Zou&Zhang, 2009). TheElNetpenaltyisaconvexcombinationof ??1and??2penalties: ??(??)=??[ ????? ??=1??2 ??+(1-??)??? ??=1|????|] =??[?? ????2 2+(1-??) ????1], where???[0,1].TheElNethasboththeLASSOandridgeregressionasspecialcases. JustlikeintheLASSOregression,thesolutiontotheElNetproblemisefficientlycalculatedby coordinatedescentalgorithms.ZouandZhang( 2009)proposetheadaptiveElNet.TheElNetand adaLASSOimprovetheLASSOindistinctdirections:theadaLASSOhastheoraclepropertyand theElNethelpswiththecorrelationamongpredictors.TheadaptiveElNetcombinesthestrengths ofbothmethods.ItisacombinationofridgeandadaLASSO,wherethefirst-stepestimatorcomes fromtheElNet.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 82 MASINIetal. Foldedconcavepenalization LASSOapproachesbecamepopularinsparsehigh-dimensionalestimationproblemslargelydue theircomputationalproperties.Anotherverypopularapproachisthefoldedconcavepenalization of Fan and Li ( 2001). This approach covers a collection of penalty functions satisfying a set of properties.Thepenaltiesaimtopenalizemoreparametersclosetozerothanthosethatarefurther away,improvingperformanceofthemethod.Inthisway,penaltiesareconcavewithrespectto each|????|. OneofthemostpopularformulationsistheSCAD(smoothlyclippedabsolutedeviation).Note thatunlikeLASSO,thepenaltymaydependon ??inanonlinearway.Wesetthepenaltyin( 3)as ??(??)=??? ??=1\u02dc??(????,??,??),where \u02dc??(??,??,??)=? ? ? ? ? ????|??|if|??|=??, 2????|??|-??2-??2 2(??-1)if??=|??|=????, ??2(??+1) 2if|??|>???? for??>2and??>0.TheSCADpenaltyisidenticaltotheLASSOpenaltyforsmallcoefficients, butcontinuouslyrelaxestherateofpenalizationasthecoefficientdepartsfromzero.UnlikeOLS orLASSO,wehavetosolveanonconvexoptimizationproblemthatmayhavemultipleminima andiscomputationallymoreintensivethantheLASSO.Nevertheless,Fanetal.( 2014)show ed howtocalculatetheoracleestimatorusinganiterativeLocalLinearApproximationalgorithm. Otherpenalties Regularizationimposesarestrictiononthesolutionspace,possiblyimposingsparsity.Inadata- richenvironment,itisadesirablepropertyasitislikelythatmanyregressorsarenotrelevantto ourpredictionproblem.Thepresentationaboveconcentratesonthe,possibly,mostusedpenalties intime-seriesforecasting.Nevertheless,therearemanyalternativepenaltiesthatcanbeusedin regularizedlinearmodels. ThegroupLASSO,proposedbyYuanandLin( 2006),penalizestheparametersingroups,com- biningthe??1and??2norms.Itismotivatedbytheproblemofidentifying\u201cfactors,\u201ddenotedby groupsofregressorsas,forinstance,inregressionwithcategoricalvariablesthatcanassumemany values.Let ?={??1,\u2026,????}denoteapartitionof {1,\u2026,??}and??????=[????:???????]thecorrespond- ing regression subvector. The group LASSO assign to ( 3) the penalty??(??)=??? ??=1v |????|????????2, where |????|isthecardinalityofaset ????.Thesolutionisefficientlyestimatedusing,forinstance, thegroup-wisemajorizationdescentalgorithm(Yang&Zou, 2015).Naturally,theadaptivegroup LASSOwasalsoproposedaimingtoimprovesomeofthelimitationspresentonthegroupLASSO algorithm(Wang&Leng, 2008).InthegroupLASSO,thegroupsenterornotintheregression. ThesparsegroupLASSOrecoversparsegroupsbycombiningthegroupLASSOpenaltywiththe ??1penaltyontheparametervector(Simonetal., 2013). ParkandSakaori( 2013)modifytheadaLASSOpenaltytoexplicitlytakeintoaccountlaginfor- mation.KonzenandZiegelmann( 2016)proposeasmallchangeinpenaltyandperformalarge simulationstudytoassesstheperformanceofthispenaltyindistinctsettings.Theyobservethat  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 83 takingintoaccountlaginformationimprovesmodelselectionandforecastingperformancewhen comparedtotheLASSOandadaLASSO.Theyapplytheirmethodtoforecastinginflationandrisk premiumwithsatisfactoryresults. There is a Bayesian interpretation to the regularization methods presented here. The ridge regression can be also seen as a maximum a posteriori estimator of a Gaussian linear regres- sionwithindependent,equivariant,Gaussianpriors.TheLASSOreplacestheGaussianpriorbya Laplaceprior(Hans, 2009;Park&Casella, 2008).ThesemethodsfallwithintheareaofBayesian Shrinkagemethods,whichisaverylargeandactiveresearcharea,anditisbeyondthescopeof thissurvey. 2.1Theoreticalproperties Inthissection,wegiveanoverviewofthetheoreticalpropertiesofpenalizedregressionestimators previously discussed. Most results in high-dimensional time-series estimation focus on model selectionconsistency,oracleproperty,andoraclebounds,forboththefinitedimension( ??fixed, butpossiblylargerthan ??)andhighdimension( ??increaseswith ??,usuallyfaster). Moreprecisely,supposethereisapopulation,parametervector ??0thatminimizesEquation( 2) overrepeatedsamples.Supposethisparameterissparseinasensethatonlycomponentsindexed by??0?{1,\u2026,??} arenonnull.Let \u02c6??0:={??:\u02c6?????0}.Wesayamethodis modelselectionconsistent iftheindexofnonzeroestimatedcomponentsconvergesto ??0inprobability.5 P(\u02c6??0=??0)?1, ???8. Consistencycanalsobestatedintermsofhowclosetheestimatoristotrueparameterforagiven norm.Wesaythattheestimationmethodis ???-consistentifforevery ??>0: P(?\u02c6??0-??0???>??)?0, ???8. Itisimportanttonotethatmodelselectionconsistencydoesnotimply,noritisimpliedby, ???- consistency.Asamatteroffact,oneusuallyhastoimposespecificassumptionstoachieveeach ofthosemodesofconvergence. Model selection performance of a given estimation procedure can be further broke down in terms of how many relevant variables ?????0are included in the model (screening). Or how many irrelevant variables ?????0are excluded from the model. In terms of probability, model screeningconsistencyisdefinedby P(\u02c6??0???0)?1andmodelexclusionconsistencydefinedby P(\u02c6??0???0)?1as???8. Wesayapenalizedestimatorhastheoraclepropertyifitsasymptoticdistributionisthesame astheunpenalizedoneonlyconsideringthe ??0regressors.Finally,oracleriskboundsarefinite sampleboundsontheestimationerrorof \u02c6??thatholdwithhighprobability.Theseboundsrequire relativelystrongconditionsonthecurvatureofobjectivefunction,whichtranslatesintoabound ontheminimumrestrictedeigenvalueofthecovariancematrixamongpredictorsforlinearmod- elsandarateconditionon ??thatinvolvesthenumberofnonzeroparameters, |??0|. The LASSO was originally developed in fixed design with independent and identically dis- tributed(IID)errors,butithasbeenextendedandadaptedtoalargesetofmodelsanddesigns. KnightandFu( 2000)wasprobablythefirstpapertoconsidertheasymptoticsoftheLASSOesti- mator. The authors consider fixed design and fixed ??framework. From their results, it is clear  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 84 MASINIetal. thatthedistributionoftheparametersrelatedtotheirrelevantvariablesisnon-Gaussian.Toour knowledge,thefirst work expanding theresultsto adependentsettingwas Wangetal. ( 2007), wheretheerrortermwasallowedtofollowanautoregressiveprocess.AuthorsshowthatLASSO ismodelselectionconsistent,whereasamodifiedLASSO,similartotheadaLASSO,isbothmodel selectionconsistentandhastheoracleproperty.NardiandRinaldo( 2011)showmodelselection consistencyandpredictionconsistencyforlagselectioninautoregressivemodels.ChanandChen (2011)showoraclepropertiesandmodelselectionconsistencyforlagselectioninARMAmodels. Yoonetal.( 2013)derivemodelselectionconsistencyandasymptoticdistributionoftheLASSO, adaLASSO,andSCAD,forpenalizedregressionswithautoregressiveerrorterms.SangandSun (2015)studylagestimationofautoregressiveprocesseswithlong-memoryinnovationsusinggen- eralpenaltiesandshowmodelselectionconsistencyandasymptoticdistributionfortheLASSO andSCADasparticularcases.Kock( 2016)showsmodelselectionconsistencyandoracleproperty ofadaLASSOforlagselectioninstationaryandintegratedprocesses.Allresultsaboveholdforthe caseoffixednumberofregressorsorrelativelyhighdimension,meaningthat ??/???0. Insparse,high-dimensional,stationaryunivariatetime-seriessettings,where ???8atsome ratefasterthan ??,MedeirosandMendes( 2016,2017)showmodelselectionconsistencyandoracle property of a large set of linear time-series models with difference martingale, strong mixing, andnon-Gaussianinnovations.Itincludes,predictiveregressions,autoregressivemodels ????(??), autoregressive models with exogenous variables ??????(??), autoregressive models with dynamic lags??????(??,??), with possibly conditionally heteroskedastic errors. Xie et al. ( 2017) show oracle boundsforfixeddesignregressionwith ??-mixingerrors.WuandWu( 2016)deriveoraclebounds for the LASSO on regression with fixed design and weak dependent innovations, in a sense of Wu(2005),whereasHanandTsay( 2020)showmodelselectionconsistencyforlinearregression withrandomdesignandweaksparsity6underseriallydependenterrorsandcovariates,withinthe sameweakdependenceframework.XueandTaniguchi( 2020)showmodelselectionconsistency andparameterconsistencyforamodifiedversionoftheLASSOintime-seriesregressionswith long-memoryinnovations. FanandLi( 2001)showmodelselectionconsistencyandoraclepropertyforthefoldedconcave penaltyestimatorsinafixeddimensionalsetting.Kimetal.( 2008)showedthattheSCADalso enjoysthesepropertiesinhighdimensions.Intime-seriessettings,UematsuandTanaka( 2019) show oracle properties and model selection consistency in time-series models with dependent regressors.Ledereretal.( 2019)derivedoraclepredictionboundsformanypenalizedregression problems.Theauthorsconcludethatgenerichigh-dimensionalpenalizedestimatorsprovidecon- sistentpredictionwithanydesignmatrix.Althoughtheresultsarenotdirectlyfocusedontime- seriesproblems,theyaregeneralenoughtoholdinsuchsetting. Babiietal.( 2020c)proposedthesparse-groupLASSOasanestimationtechniquewhenhigh- dimensionaltime-seriesdataarepotentiallysampledatdifferentfrequencies.Theauthorsderived oracleinequalitiesforthesparse-groupLASSOestimatorwithinaframeworkwheredistribution ofthedatamayhaveheavytails. Twoframeworksnotdirectlyconsideredinthissurveybutofgreatempiricalrelevancearenon- stationaryenvironmentsandmultivariatemodels.Insparse,high-dimensional,integratedtime- series settings, Lee and Shi ( 2020)a n dK o oe ta l .( 2020) show model selection consistency and derivetheasymptoticdistributionsofLASSOestimatorsandsomevariants.SmeeksandWijler (2021) proposed the Single-equation Penalized Error Correction Selector (SPECS), which is an automated estimation procedure for dynamic single-equation models with a large number of potentiallycointegratedvariables.Insparsemultivariatetimeseries,Hsuetal.( 2008)showmodel selection consistency in vector autoregressive (VAR) models with white-noise shocks. Ren and  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 85 Zhang(2010)useadaLASSOinasimilarsetting,showingbothmodelselectionconsistencyand oracleproperty.Afterward,CallotandKock( 2013)showmodelselectionconsistencyandoracle propertyoftheadaptiveGroupLASSO.Inhigh-dimensionalsettings,wherethedimensionofthe seriesincreasewiththenumberofobservations,KockandCallot( 2015)andBasuandMichailidis (2015)showoracleboundsandmodelselectionconsistencyfortheLASSOinGaussian ??????(??) models,extendingpreviousworks.MelnykandBanerjee( 2016)extendedtheseresultsforalarge collection of penalties. Zhu ( 2020) derives oracle estimation bounds for folded concave penal- tiesforGaussian ??????(??)modelsinhighdimensions.Morerecently,researchershavedeparted fromGaussianityandcorrectmodelspecification.Wongetal.( 2020)derivedfinitesampleguar- anteesfortheLASSOinamisspecifiedVARmodelinvolving ??-mixingprocesswithsub-Weibull marginaldistributions.Masinietal.( 2019)deriveequation-wiseerrorboundsfortheLASSOesti- matorofweaklysparse ??????(??)inmixingaledependencesettings,thatincludemodelswithcon- ditionallyheteroskedasticinnovations. 2.2Inference Althoughseveralpapersderivedtheasymptoticpropertiesofpenalizedestimatorsaswellasthe oracleproperty,theseresultshavebeenderivedundertheassumptionthatthetruenonzerocoef- ficientsarelargeenough.Thisconditionisknownasthe ??-minrestriction.Furthermore,model selection,suchasthechoiceofthepenaltyparameter,hasnotbeentakenintoaccount.Therefore, thetruelimitdistribution,derivedunderuniformasymptoticsandwithoutthe ??-minrestriction can be very different from Gaussian, being even bimodal; see, for instance, Leeb and P\u00f6tscher (2005,2008)andBellonietal.( 2014)foradetaileddiscussion. Inference after model selection is actually a very active area of research and a vast num- ber of papers have recently appeared in the literature. van de Geer et al. ( 2014) proposed the desparsified LASSO in order to construct (asymptotically) a valid confidence interval for each ????,0bymodifyingtheoriginalLASSOestimate \u02c6??.Let??*beanapproximationfortheinverseof ??:=??(??????' ??),thenthedesparsifiedLASSOisdefinedas \u02dc??:=\u02c6??+??*(??-??\u02c6??)/??.Theaddition of this extra term to the LASSO estimator results in an unbiased estimator that no longer esti- matesanycoefficientexactlyaszero.Moreimportantly,asymptoticnormalitycanberecoverin thesensethatv ??(\u02dc????-????,0)convergesindistributiontoaGaussiandistributionunderappropri- ate regularity conditions. Not surprisingly, the most important condition is how well ??-1can be approximated by ??*. In particular, the authors propose to run ??LASSO regressions of ???? onto??-??:=(??1,\u2026,????-1,????+1,\u2026,????),for1=??=??.Theauthorsnamedthisprocessas nodewide regressions,andusethoseestimatestoconstruct ??*(refertoSection2.1.1invandeGeeretal., 2014, fordetails)). Belloni et al. ( 2014) put forward the double-selection method in the context of on a linear model in the form ????=??01??(1) ??+??' 02??(2) ??+????, where the interest lies on the scalar parame- ter??01and??(2) ??is a high-dimensional vector of control variables. The procedure consists in obtaininganestimationoftheactive(relevant)regressorsinthehigh-dimensionauxiliaryregres- sions of????on??(2)and of??(1) ??on??(2) ??,g i v e nb y\u02c6??1and\u02c6??2, respectively.7This can be obtained eitherbyLASSOoranyotherestimationprocedure.Oncetheset \u02c6??:=\u02c6??1?\u02c6??2isidentified,the (a priori) estimated nonzero parameters can be estimated by a low-dimensional regression ???? on??(1) ??and{??(2) ????:???\u02c6??}. The main result (Theorem 1 of Belloni et al., 2014) states conditions underwhichtheestimator \u02c6??01oftheparameterofinterestproperlystudentizedisasymptotically  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 86 MASINIetal. normal.Therefore,uniformlyvalidasymptoticconfidenceintervalsfor ??01canbeconstructedin theusualfashion. SimilartoTayloretal.( 2014)andLockhartetal.( 2014),Leeetal.( 2016)putforwardgeneral approachtovalidinferenceaftermodelselection.Theideaistocharacterizethedistributionof apostselectionestimatorconditionedontheselectionevent.Morespecifically,theauthorsargue thatthepostselectionconfidenceintervalsforregressioncoefficientsshouldhavethecorrectcov- erageconditionalontheselectedmodel.ThespecificcaseoftheLASSOestimatorisdiscussedin details.ThemaindifferencebetweenLeeetal.( 2016)andTayloretal.( 2014)andLockhartetal. (2014)isthatintheformer,confidenceintervalscanbeformedatanyvalueoftheLASSOpenalty parameterandanycoefficientinthemodel.Finally,itisimportanttostressthatLeeetal.( 2016) inferenceiscarriedonthecoefficientsoftheselectedmodel,whilevandeGeeretal.( 2014)and Bellonietal.( 2014)considerinferenceonthecoefficientsofthetruemodel. Theabovepapersdonotconsideratime-seriesenvironment.Hecqetal.( 2019)isoneofthefirst paperswhichattempttoconsiderpost-selectioninferenceinatime-seriesenvironment.However, theirresultsarederivedunderafixednumberofvariables.Babiietal.( 2020a)andAd\u00e1meketal. (2020)extendtheseminalworkofvandeGeeretal.( 2014)totime-seriesframework. More specifically, Babii et al. ( 2020a) consider inference in time-series regression models underheteroskedastic and autocorrelated errors. The authors consider heteroskedaticity- and autocorrelation-consistent (HAC) estimation with sparse group-LASSO. They propose a debi- ased central limit theorem for low dimensional groups of regression coefficients and study the HACestimatorofthelong-runvariancebasedonthesparse-groupLASSOresiduals.Ad\u00e1meket al.(2020)extendthedesparsifiedLASSOtoatime-seriessettingundernear-epochdependence assumptions,allowingfornon-Gaussian,seriallycorrelatedandheteroskedasticprocesses.Fur- thermore,thenumberofregressorscanpossiblygrowfasterthanthesamplesize. 3NONLINEARMODELS Thefunction??happearingin( 1)isunknownandinseveralapplicationsthelinearityassumption istoorestrictiveandmoreflexibleformsmustbeconsidered.Assumingaquadraticlossfunction, theestimationproblemturnstobetheminimizationofthefunctional ??(??):=??-h? ??=1[????+h-??(????)]2, (4) where????,agenericfunctionspace.However,theoptimizationproblemstatedin( 4)isinfea- sible when ?is infinite dimensional, as there is no efficient technique to search over all ?.O f course,onesolutionistorestrictthefunctionspace,asforinstance,imposinglinearityorspecific formsofparametricnonlinearmodelsasin,forexample,Ter\u00e4svirta( 1994),Suarez-Fari\u00f1asetal. (2004), or McAleer and Medeiros ( 2008); see also Ter\u00e4svirta et al. ( 2010) for a recent review of suchmodels. Alternatively,wecanreplace ?bysimplerandfinite-dimensional ???.Theideaistoconsidera sequenceoffinite-dimensionalspaces,the sievespaces, ???,??=1,2,3,\u2026 ,thatconvergesto ?in  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 87 somenorm.Theapproximatingfunction ????(????)iswrittenas ????(????)=??? ??=1????????(????), where????(\u00b7)isthe??thbasisfunctionfor ???andcanbeeitherfullyknownorindexedbyavector ofparameters,suchthat: ????(????):=??(????;????).Thenumberofbasisfunctions ??:=????willdepend on the sample size ??.??is the dimension of the space and it also depends on the sample size: ??:=????.Therefore,theoptimizationproblemisthenmodifiedto \u02c6????(????)=arg min ????(????)??????-h? ??=1[????+h-????(????)]2. (5) Thesequenceofapproximatingspaces ???ischosenbyusingthestructureoftheoriginalunder- lying space ?and the fundamental concept of dense sets. If we have two sets ??and????,? beingametricspace, ??isdensein??ifforany??>0,?R and?????,thereisa?????suchthat ???-????<??.Thisiscalledthemethodof\u201csieves.\u201dForacomprehensivereviewofthemethod fortime-seriesdata,seeChen( 2007). For example, from the theory of approximating functions we know that the proper subset ???of polynomials is dense in ?, the space of continuous functions. The set of polynomi- als is smaller and simpler than the set of all continuous functions. In this case, it is natural to definethesequenceofapproximatingspaces ???,??=1,2,3,\u2026 bymaking ???thesetofpolyno- mials of degree smaller or equal to ??-1(including a constant in the parameter space). Note that??????(???)=??<8 .Inthelimitthissequenceoffinite-dimensionalspacesconvergestothe infinite-dimensionalspaceofpolynomials,whichonitsturnisdensein ?. Whenthebasisfunctionsareallknown\u201clinearsieves,\u201dtheproblemislinearintheparameters andmethodslikeOLS(when ??\u00ab??)orpenalizedestimationaspreviouslydescribedcanbeused. Forexample,let ??=1andpickapolynomialbasissuchthat ????(????)=??0+??1????+??2??2 ??+??3??3 ??+?+???????? ??. Inthiscase,thedimension ??of???is??+1,duetothepresenceofaconstantterm. If??\u00ab??,thevectorofparameters ??=(??1,\u2026,????)'canbeestimatedby \u02c6??=(??' ??????)-1??' ????, where????isthe??\u00d7(??+1) designmatrixand ??=(??1,\u2026,????)'. Whenthebasisfunctionsarealsoindexedbyparameters(\u201cnonlinearsieves\u201d),nonlinearleast- squaresmethodsshouldbeused.Inthispaper,wewillfocusonfrequentlyusednonlinearsieves: NNsandregressiontrees.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 88 MASINIetal. Figure 1 Graphicalrepresentationofasinglehiddenlayerneuralnetwork[Colourfigurecanbeviewedat wileyonlinelibrary.com] 3.1Neuralnetworks 3.1.1ShallowNN NN is one of the most traditional nonlinear sieves. NN can be classified into shallow or deep networks.WestartdescribingtheshallowNNs.ThemostcommonshallowNNisthefeedforward NNwheretheapproximatingfunction ????(????)isdefinedas ????(????):=????(????;??)=??0+????? ??=1??????(??' ??????+??0,??), =??0+????? ??=1??????(~??' ??~????).(6) Intheabovemodel, ~????=(1,??' ??)',????(\u00b7)isabasisfunctionandtheparametervectortobeestimated isgivenby??=(??0,\u2026,????,??' 1,\u2026,??' ????,??0,1,\u2026,??0,????)',where~????=(??0,??,??' ??)'. NNmodelsformaverypopularclassofnonlinearsievesandhavebeenusedinmanyappli- cationsofeconomicforecasting.Usually,thebasisfunctions ??(\u00b7)arecalledactivationfunctions and the parameters are called weights. The terms in the sum are called hidden neurons as an unfortunateanalogytothehumanbrain.Specification( 6)isalsoknownasasinglehiddenlayer NNmodelasisusuallyrepresentedinthegraphicalasinFigure 1.Thegreencirclesinthefigure represent the input layer which consists of the covariates of the model ( ????). In the example in thefigure,therearefourinputvariables.Theblueandredcirclesindicatethehiddenandoutput layers, respectively. In the example, there are five elements (neurons) in the hidden layer. The arrowsfromthegreentothebluecirclesrepresentthelinearcombinationofinputs: ??' ??????+??0,??, ??=1,\u2026,5.Finally,thearrowsfromthebluetotheredcirclesrepresentthelinearcombination ofoutputsfromthehiddenlayer: ??0+?5 ??=1??????(??' ??????+??0,??).  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 89 Thereareseveralpossiblechoicesfortheactivationfunctions.Intheearlydays, ??(\u00b7)waschosen amongtheclassofsquashingfunctionsasperthedefinitionbelow. Definition1. Afunction??:R?[??,??] ,??<??,isasquashing(sigmoid)functionifitisnon- decreasing,lim???8??(??)=??andlim???-8??(??)=??. Historically,themostpopularchoicesarethelogisticandhyperbolictangentfunctionssuch that: Logistic:??(??)=1 1+exp(-??) Hyperbolictangent :??(??)=exp(??)-exp(-??) exp(??)+exp(-??). Thepopularityofsuchfunctionswaspartiallyduetotheoreticalresultsonfunctionapproxima- tion.Funahashi( 1989)establishesthatNNmodelsasin( 6)withgenericsquashingfunctionsare capableofapproximatinganycontinuousfunctionsfromonefinitedimensionalspacetoanother toanydesireddegreeofaccuracy,providedthat ????issufficientlylarge.Cybenko( 1989)andHornik etal.(1989)simultaneouslyprovedapproximationcapabilitiesofNNmodelstoanyBorelmea- surablefunctionandHorniketal.( 1989)extendedthepreviousresultsandshowedthattheNN modelsarealsocapabletoapproximatethederivativesoftheunknownfunction.Barron( 1993) relatespreviousresultstothenumberoftermsinthemodel. Stinchcombe and White ( 1989) and Park and Sandberg ( 1991) derived the same results of Cybenko(1989)andHorniketal.( 1989)butwithoutrequiringtheactivationfunctiontobesig- moid.Whiletheformerconsideredaverygeneralclassoffunctions,thelaterfocusedonradial- basisfunctions(RBF)definedas: RadialBasis:??(??)=exp(-??2). Morerecently,Yarotsky( 2017)showedthattherectifiedlinearunits(ReLU)as RectifiedLinearUnit :??(??)=max(0,??), arealsouniversalapproximators. Model(6)canbewritteninmatrixnotation.Let ??=(~??1,\u2026,~????), ??=? ? ? ? ??1??11???1?? 1??21???2?? ??? 1????1???????? ? ? ? ??,and?(????)=? ? ? ? ??1??(~??' 1~??1)???(~??' ??~??1) 1??(~??' 1~??2)???(~??' ??~??2) ???? 1??(~??' 1~????)???(~??' ??~????)? ? ? ? ??. Therefore,bydefining ??=(??0,??1,\u2026,????)',theoutputofafeedforwardNNisgivenby:  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 90 MASINIetal. ????(??,??)=[h ??(??1;??),\u2026,h??(????;??)]' =? ? ? ????0+??? ??=1??????(??' ????1+??0,??) ? ??0+??? ??=1??????(??' ??????+??0,??)? ? ? ?? =?(????)??.(7) Thedimensionoftheparametervector ??=[??????(??)',??']'is??=(??+1)\u00d7?? ??+(????+1)andcan easilygetverylargesuchthattheunrestrictedestimationproblemdefinedas \u02c6??=argmin ???R?????-?(????)?? ?2 2 isunfeasible.Asolutionistouseregularizationasinthecaseoflinearmodelsandconsiderthe minimizationofthefollowingfunction: ??(??)= ???-?(????)?? ?2 2+??(??), (8) whereusually ??(??)=????'??.Traditionally,themostcommonapproachtominimize( 8)istouse BayesianmethodsasinMacKay( 1992a);MacKay( 1992b)andForeseeandHagan( 1997).Amore modernapproachistouseatechniqueknownas Dropout(Srivastavaetal., 2014). Thekeyideaistorandomlydropneurons(alongwiththeirconnections)fromtheNNduring estimation.AnNNwith ????neuronsinthehiddenlayercangenerate 2????possible\u201cthinned\u201dNN byjustremovingsomeneurons.Dropoutsamplesfromthis 2????differentthinnedNNandtrainthe sampledNN.Topredictthetargetvariable,weuseasingleunthinnednetworkthathasweights adjustedbytheprobabilitylawinducedbytherandomdrop.Thisproceduresignificantlyreduces overfittingandgivesmajorimprovementsoverotherregularizationmethods. WemodifyEquation( 6)by ??* ??(????)=??0+????? ??=1??????????(??' ??[???????]+??????0,??), where??,??,and??=(??1,\u2026,????)areindependentBernoullirandomvariableseachwithprobability ??ofbeingequalto1.TheNNmodelisthusestimatedbyusing ??* ??(????)insteadof????(????)where, foreachtrainingexample,thevaluesoftheentriesof ??aredrawnfromtheBernoullidistribution. Thefinalestimatesfor ????,????,and????,??aremultipliedby ??. 3.1.2DeepNNs AdeepNNmodelisastraightforwardgeneralizationofspecification( 6)wheremorehiddenlayers areincludedinthemodelasrepresentedinFigure 2.Inthefigure,werepresentadeepNNwith twohiddenlayerswiththesamenumberofhiddenunitsineach.However,thenumberofhidden neuronscanvaryacrosslayers.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 91 Figure 2 Deepneuralnetworkarchitecture[Colourfigurecanbeviewedatwileyonlinelibrary.com] AspointedoutinMhaskaetal.( 2017),whiletheuniversalapproximationpropertyholdsfor shallowNNs,deepnetworkscanapproximatetheclassofcompositionalfunctionsaswellasshal- lownetworksbutwithexponentiallylowernumberoftrainingparametersandsamplecomplexity. Set????as the number of hidden units in layer ???{1,\u2026,??} . For each hidden layer ??, define ????=(~??1??,\u2026,~????????).Then,theoutput ???oflayer??isgivenrecursivelyby ???(???-1(\u00b7)????) ??\u00d7(????+1)=? ? ? ? ??1??(~??' 1???1??-1(\u00b7))???(~??' ???????1??-1(\u00b7)) 1??(~??' 1???2??-1(\u00b7))???(~??' ???????2??-1(\u00b7)) ???? 1??(~??' 1???????-1(\u00b7))???(~??' ???????????-1(\u00b7))? ? ? ? ??, where???:=??.Therefore,theoutputofthedeepNNisthecompositionof ????(??)=???(??3(?2(?1(????1)??2)??3)?)??????. Theestimationoftheparametersisusuallycarriedoutbystochasticgradientdescendmethods withdropouttocontrolthecomplexityofthemodel. 3.1.3Recurrentneuralnetworks Broadlyspeaking,RNNsareNNsthatallowforfeedbackamongthehiddenlayers.RNNscanuse theirinternalstate(memory)toprocesssequencesofinputs.Intheframeworkconsideredinthis paper,agenericRNNcouldbewrittenas ????=??(????-1,????), \u02c6????+h|??=??(????),  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 92 MASINIetal. Figure 3 Architectureofthelong-short-termmemorycell(LSTM)[Colourfigurecanbeviewedat wileyonlinelibrary.com] where\u02c6????+h|??isthepredictionof ????+hgivenobservationsonlyuptotime ??,??and??arefunctions tobedefined,and ????iswhatwecallthe(hidden)state.Fromatime-seriesperspective,RNNscan beseenasakindofnonlinearstate-spacemodel. RNNscanremembertheorderthattheinputsappearthroughitshiddenstate(memory)and theycanalsomodelsequencesofdatasothateachsamplecanbeassumedtobedependenton previousones,asintime-seriesmodels.However,RNNsarehardtobeestimatedastheysuffer fromthevanishing/explodinggradientproblem.Setthecostfunctiontobe ???(??)=??-h? ??=1(????+h-\u02c6????+h|??)2, where??isthevectorofparameterstobeestimated.Itiseasytoshowthatthegradient?????(??) ????can beverysmallordiverge.Fortunately,thereisasolutiontotheproblemproposedbyHochreiter andSchmidhuber( 1997).AvariantofRNNwhichiscalledlong-short-termmemory(LSTM)net- work.Figure 3showsthearchitectureofatypicalLSTMlayer.AnLSTMnetworkcanbecomposed of several layers. In the figure, red circles indicate logistic activation functions, while blue cir- clesrepresenthyperbolictangentactivation.Thesymbols\u201c ??\u201dand\u201c+\u201drepresent,respectively,the  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 93 Algorithm 1 Mathematically,RNNscanbedefinedbythefollowingalgorithm 1. Initiatewith ??0=0and??0=0. 2. Giventheinput ????,for???{1,\u2026,??} ,do: ????= Logistic(????????+????????-1+????) ????= Logistic(????????+????????-1+????) ????= Logistic(????????+????????-1+????) ????=T a n h ( ????????+????????-1+????) ????=( ?????????-1)+(?????????) ????=?????Tanh(????) \u02c6????+h|??=????????+???? where????,????,????,????,????,????,????,????,????,????,????,????,and????areparameterstobeestimated. Figure 4 Informationflowinan LTSMcell[Colourfigurecanbeviewed atwileyonlinelibrary.com] element-wisemultiplicationandsumoperations.TheRNNlayeriscomposedofseveralblocks: the cell state and the forget, input, and ouput gates. The cell state introduces a bit of memory to the LSTM so it can \u201cremember\u201d the past. LSTM learns to keep only relevant information to makepredictions,andforgetnonrelevantdata.Theforgetgatetellswhichinformationtothrow awayfromthecellstate.TheoutputgateprovidestheactivationtothefinaloutputoftheLSTM blockattime??.Usually,thedimensionofthehiddenstate( ????)isassociatedwiththenumberof hiddenneurons. Algorithm 1describesanalyticallyhowtheLSTMcellworks. ????representstheoutputofthe forgetgate.Notethatitisacombinationoftheprevioushiddenstate( ????-1)withthenewinfor- mation(????).Notethat?????[0,1]anditwillattenuatethesignalcomingcom ????-1.Theinputand outputgateshavethesamestructure.Theirfunctionistofilterthe\u201crelevant\u201dinformationfrom theprevioustimeperiodaswellasfromthenewinput. ????scalesthecombinationofinputsand previous information. This signal will be then combined with the output of the input gate ( ????). Thenewhiddenstatewillbeanattenuationofthesignalcomingfromtheoutputgate.Finally, thepredictionisalinearcombinationofhiddenstates.Figure 4illustrateshowtheinformation flowsinanLSTMcell.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 94 MASINIetal. Figure 5 Exampleofasimpletree[Colourfigurecanbeviewedatwileyonlinelibrary.com] 3.2Regressiontrees Aregressiontreeisanonparametricmodelthatapproximatesanunknownnonlinearfunction ??h(????)in (1) with local predictions using recursive partitioning of the space of the covariates. A tree may be represented by a graph as in the left side of Figure 5, which is equivalent as the partitioningintherightsideofthefigureforthisbidimensionalcase.Forexample,supposethat we want to predict the scores of basketball players based on their height and weight. The first nodeofthetreeintheexamplesplitstheplayerstallerthan1.85mfromtheshorterplayers.The secondnodeinthelefttakestheshortplayersgroupsandsplitthembyweightsandthesecond nodeintherightdoesthesamewiththetallerplayers.Thepredictionforeachgroupisdisplayed intheterminalnodesandtheyarecalculatedastheaveragescoreineachgroup.Togrowatree, wemustfindtheoptimalsplittingpointineachnode,whichconsistsofanoptimalvariableand anoptimalobservation.Inthesameexample,theoptimalvariableinthefirstnodeisheightand theobservationis1.85m. Theideaofregressiontreesistoapproximate ??h(????)by h??(????)=????? ??=1????????(????),where????(????)={ 1if????????, 0otherwise. From the above expression, it becomes clear that the approximation of ??h(\u00b7)is equivalent to a linearregressionon ????dummyvariables,where ????(????)isaproductofindicatorfunctions. Let??:=????and??:=????be,respectively,thenumberofterminalnodes(regions, leaves)and parentnodes.Differentregionsaredenotedas ?1,\u2026,???.Therootnodeatposition0.Theparent nodeatposition ??hastwosplit(child)nodesatpositions 2??+1and2??+2.Eachparentnodehas athreshold(split)variableassociated, ????????,where???????={1,2,\u2026,??} .Define??and??asthesets ofparentandterminalnodes,respectively.Figure 6givesanexample.Intheexample,theparent  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 95 Figure 6 Exampleoftreewithlabels nodesare??={0,2,5} andtheterminalnodesare ??={1,6,11,12} . Therefore,wecanwritetheapproximatingmodelas h??(????)=? ???????????????(????;????), (9) where ??????(????;????)=? ???????(??????,??;????)????,??(1+????,??) 2\u00d7[1-??(??????,??;????)](1-????,??)(1+????,??), (10) ??(??????,??;????)={ 1if??????,??=???? 0otherwise, ????,??=? ? ? ??-1ifthepathtoleaf ??doesnotincludeparentnode ??; 0ifthepathtoleaf ??includethe??????????-???????? childofparentnode ??; 1ifthepathtoleaf ??includethe????????-???????? childofparentnode ??. ????: indexes of parent nodes included in the path to leaf ??.????={????}such that???????,?????and? ???????????(????;????)=1. 3.2.1Randomforests RF is a collection of regression trees, each specified in a bootstrap sample of the original data. ThemethodwasoriginallyproposedbyBreiman( 2001).Sincewearedealingwithtimeseries,we useablockbootstrap.Supposethereare ??bootstrapsamples.Foreachsample ??,??=1,\u2026,?? ,a treewith????regionsisestimatedforarandomlyselectedsubsetoftheoriginalregressors. ????is determinedinordertoleaveaminimumnumberofobservationsineachregion.Thefinalforecast  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 96 MASINIetal. Algorithm 2 Theboostingalgorithmisdefinedasthefollowingsteps 1. Initialize ????0=\u00af??:=1 ????? ??=1????; 2.For??=1,\u2026,?? : (a)Make??????=????-??????-1 (b)Growa(small)Treemodeltofit ??????,\u02c6??????=? ???????\u02c6??????????????(????;\u02c6??????) (c)Make????=argmin ????? ??=1[??????-??\u02c6??????]2 (d)Update??????=??????-1+??????\u02c6?????? istheaverageoftheforecastsofeachtreeappliedtotheoriginaldata: \u02c6????+h|??=1 ????? ??=1[????? ??=1\u02c6????,????????,??(????;\u02c6????,??)] . ThetheoryforRFmodelshasbeendevelopedonlytoindependentandidenticallydistributed randomvariables.Forinstance,Scornetetal.( 2015)provesconsistencyoftheRFapproximation totheunknownfunction ??h(????).Morerecently,WagerandAthey( 2018)provedconsistencyand asymptoticnormalityoftheRFestimator. 3.2.2Boostingregressiontrees Boosting is another greedy method to approximate nonlinear functions that uses base learners forasequentialapproximation.Themodelweconsiderhere,calledGradientBoosting,wasintro- ducedbyFriedman( 2001)andcanbeseenasaGradientDescendentmethodinfunctionalspace. ThestudyofstatisticalpropertiesoftheGradientBoostingiswelldevelopedforindependent data.Forexample,forregressionproblems,DuffyandHelmbold( 2002)derivedboundsonthe convergenceofboostingalgorithmsusingassumptionsontheperformanceofthebaselearner. ZhangandYu( 2005)proveconvergence,consistency,andresultsonthespeedofconvergencewith mildassumptionsonthebaselearners.B\u00fchlmann( 2002)showssimilarresultsforconsistencyin thecaseof??2lossfunctionsandthreebasemodels.Sinceboostingindefinitelyleadstooverfitting problems, some authors have demonstrated the consistency of boosting with different types of stopping rules, which are usually related to small step sizes, as suggested by Friedman ( 2001). Someoftheseworksincludeboostinginclassificationproblemsandgradientboostingforboth classificationandregressionproblems.See,forinstance,Jiang( 2004),LugosiandVayatis( 2004), BartlettandTraskin( 2007),ZhangandYu( 2005),B\u00fchlmann( 2006),andB\u00fchlmann( 2002). Boostingisaniterativealgorithm.Theideaofboostedtreesisto,ateachiteration,sequentially refitthegradientofthelossfunctionbysmalltrees.Inthecaseofquadraticlossasconsideredin thispaper,thealgorithmsimplyrefitstheresidualsfromthepreviousiteration. Algorithm 2presentsthesimplifiedboostingprocedureforaquadraticloss.Itisrecommended touseashrinkageparameter ???(0,1]tocontrolthelearningrateofthealgorithm.If ??isclose to 1, we have a faster convergence rate and a better in-sample fit. However, we are more likely tohaveoverfittingandproducepoorout-of-sampleresults.Inaddition,thederivativeishighly affectedbyoverfitting,evenifwelookatin-sampleestimates.Alearningratebetween0.1and0.2 isrecommendedtomaintainareasonableconvergenceratioandtolimitoverfittingproblems.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 97 Thefinalfittedvaluemaybewrittenas \u02c6????+h=\u00af??+??? ??=1??????\u02c6?????? =\u00af??+??? ??=1??\u02c6????? ???????\u02c6??????????????(????;\u02c6??????).(11) 3.3Inference ConductinginferenceinnonlinearMLmethodsistricky.OnepossiblewayistofollowMedeiros etal.(2006),MedeirosandVeiga( 2005),andSuarez-Fari\u00f1asetal.( 2004)andinterpretparticu- larnonlinearMLspecificationsasparametricmodels,asforexample,generalformsofsmooth transition regressions. However, this approach restricts the application of ML methods to very specificsettings.Analternative,istoconsidermodelsthatcanbecastinthesievesframework asdescribedearlier.Thisisthecaseofsplinesandfeed-forwardNNs,forexample.Inthissetup, ChenandShen( 1998)andChen( 2007)derived,underregularityconditions,theconsistencyand asymptoticallynormalityoftheestimatesofasemiparametricsieveapproximations.Theirsetup isdefinedasfollows: ????+h=??' 0????+??(????)+????+h, where??(????)isanonlinearfunctionthatisnonparametricallymodeledbysieveapproximations. ChenandShen( 1998)andChen( 2007)considerboththeestimationofthelinearandnonlinear componentsofthemodel.However,theirresultsarederivedunderthecasewherethedimension of????isfixed. Recently,Chernozhukovetal.( 2017,2018)considerthecasewherethenumberofcovariates divergeasthesamplesizeincreasesinaverygeneralsetup.Inthiscase,theasymptoticresults inChenandShen( 1998)andChen( 2007)arenotvalidandtheauthorsputforwardtheso-called doubleMLmethodsasanicegeneralizationtotheresultsofBellonietal.( 2014).Nevertheless, theresultsdonotincludethecaseoftime-seriesmodels. MorespecificallytothecaseofRandomForests,asymptoticandinferentialresultsarederived inScornetetal.( 2015)andW ageretal.( 2018)forthecaseofIIDdata.Morerecently,Davisand Nielsen(2020)proveauniformconcentrationinequalityforregressiontreesbuiltonnonlinear autoregressive stochastic processes and prove consistency for a large class of random forests. Finally, it is worth mentioning the interesting work of Borup et al. ( 2020). In their paper, the authorsshowthatproperpredictortargetingcontrolstheprobabilityofplacingsplitsalongstrong predictorsandimprovesprediction.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 98 MASINIetal. Algorithm 3 BaggingforTime-SeriesModels TheBaggingalgorithmisdefinedasfollows. 1.Arrangethesetoftuples (????+h,??' ??),??=h+1,\u2026,?? ,intheformofamatrix ??ofdimension(??-h)\u00d7?? . 2. Construct(block)bootstrapsamplesoftheform {(??* (??)2,??'* (??)2),\u2026,(??* (??)??,??'* (??)??)},??=1,\u2026,??,bydrawing blocksof??rowsof??withreplacement. 3.Computethe??thbootstrapforecastas \u02c6??* (??)??+h |??={ 0if|??* ??|<?????, \u02c6??* (??)\u02dc??* (??)??otherwise,(11) where\u02dc??* (??)??:=??* (??)????* (??)??and????isadiagonalselectionmatrixwith ??thdiagonalelementgivenby ??{|????|>??}={ 1if|????|>??, 0otherwise, ??isaprespecifiedcriticalvalueofthetest. \u02c6??* (??)istheOLSestimatorateachbootstraprepetition. 4.Computetheaverageforecastsoverthebootstrapsamples: ~????+h|??=1 ????? ??=1\u02c6??* (??)??|??-1. Algorithm 4 BaggingforTime-SeriesModelsandManyRegressors TheBaggingalgorithmisdefinedasfollows. 0.Run??univariateregressionsof ????+honeachcovariatein ????.Compute??-statisticsandkeeponlytheones thatturnouttobesignificantatagivenprespecifiedlevel.Callthisnewsetofregressorsas ????? 1\u20134. Sameasbeforebutwith ????replacedby?????. 4OTHERMETHODS 4.1Bagging ThetermbaggingmeansBootstrapAggregating andwasproposedbyBreiman( 1996)toreducethe varianceofunstablepredictors.8Itwaspopularizedinthetime-seriesliteraturebyInoueandKil- ian(2008),whotoconstructforecastsfrommultipleregressionmodelswithlocal-to-zeroregres- sionparametersanderrorssubjecttopossibleserialcorrelationorconditionalheteroskedasticity. Baggingisdesignedforsituationsinwhichthenumberofpredictorsismoderatelylargerelative tothesamplesize. Thebaggingalgorithmintime-seriessettingshavetotakeintoaccountthetimedependence dimensionwhenconstructingthebootstrapsamples. InAlgorithm 3,onerequiresthatitispossibletoestimateandconductinferenceinthelinear model.Thisiscertainlyinfeasibleifthenumberofpredictorsislargerthanthesamplesize( ??> ??), which requires the algorithm to be modified. Garcia et al. ( 2017) and Medeiros et al. ( 2021) adoptthechangesasdescribedinAlgorithm 4.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 99 4.2Completesubsetregression CSRisamethodforcombiningforecastsdevelopedbyElliottetal.( 2013,2015).Themotivation was that selecting the optimal subset of ????to predict????+hby testing all possible combinations ofregressorsiscomputationallyverydemandingand,inmostcases,unfeasible.Foragivenset ofpotentialpredictorvariables,theideaistocombineforecastsbyaveraging9allpossiblelinear regressionmodelswithfixednumberofpredictors.Forexample,with ??possiblepredictors,there are??uniqueunivariatemodelsand ????,??=??! (??-??)!??! different??-variatemodelsfor ??=??.Thesetofmodelsforafixedvalueof ??asisknownasthe completesubset. When the set of regressors is large the number of models to be estimated increases rapidly. Moreover,itislikelythatmanypotentialpredictorsareirrelevant.Inthesecases,itwassuggested that one should include only a small, ??, fixed set of predictors, such as 5 or 10. Nevertheless, the number of models still very large, for example, with ??=30and??=8, there are 5,852,925 regression.AnalternativesolutionistofollowGarciaetal.( 2017)andMedeirosetal.( 2021)and adoptasimilarstrategyasinthecaseofBagginghigh-dimensionalmodels.Theideaistostart fitting a regression of ????+hon each of the candidate variables and save the ??-statistics of each variable.The??-statisticsarerankedbyabsolutevalue,andweselectthe ~??variablesthataremore relevantintheranking.TheCSRforecastiscalculatedonthesevariablesfordifferentvaluesof ??.ThisapproachisbasedontheSureIndependenceScreeningofFanandLv( 2008),extended todependentbyYousuf( 2018),thataimstoselectasupersetofrelevantpredictorsamongavery largeset. 4.3Hybridmethods Recently,MedeirosandMendes( 2013)proposedthecombinationofLASSO-basedestimationand NNmodels.Theideaistoconstructafeedforwardsingle-hiddenlayerNNwheretheparametersof thenonlinearterms(neurons)arerandomlygeneratedandthelinearparametersareestimatedby LASSO(oroneofitsgeneralizations).SimilarideaswerealsoconsideredbyKockandTer\u00e4svirta (2014,2015). Traplettietal.( 2000)andMedeirosetal.( 2006)proposedtoaugmentafeedforwardshallow NN by a linear term. The motivation is that the nonlinear component should capture only the nonlinear dependence, making the model more interpretable. This is in the same spirit of the semi-parametricmodelsconsideredinChen( 2007). Inspired by the above ideas, Medeiros et al. ( 2021) proposed combining random forests with adaLASSOandOLS.Theauthorsconsideredtwospecifications.Inthefirstone,calledRF/OLS, the idea is to use the variables selected by a Random Forest in a OLS regression. The second approach, named adaLASSO/RF, works in the opposite direction. First select the variables by adaLASSOandthanusetheminaRandomForestmodel.Thegoalistodisentangletherelative importanceofvariableselectionandnonlinearitytoforecastinflation. Recently,DieboldandShin( 2019)proposethe\u201cpartially-egalitarian\u201dLASSOtocombinesur- veyforecasts.Morespecifically,theproceduresetssomecombiningweightstozeroandshrinks  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 100 MASINIetal. thesurvivorstowardequality.Therefore,thefinalforecastwillbecloserelatedtothesimpleaver- age combination of the survived forecasts. Although the paper considers survey forecasts, the methodisquitegeneralandcanbeappliedtoanysetofforecasts.Aspointedoutbytheauthors, optimally-regularizedregression-basedcombinationsandsubset-averagecombinationsarevery closelyconnected.Dieboldetal.( 2021)extendedtheideasinDieboldetal.( 2019)inordertocon- structregularizedmixturesofdensityforecasts.Bothpapersshedlightonhowmachinelearning methodscanbeusedtooptimallycombinealargesetofforecasts. 5FORECASTCOMPARISON WiththeadvancesintheMLliterature,thenumberofavailableforecastingmodelsandmethods havebeenincreasingatafastpace.Consequently,itisveryimportanttoapplystatisticaltoolsto comparedifferentmodels.Theforecastingliteratureprovidesanumberoftestssincetheseminal paperbyDieboldandMariano( 1995)thatcanbeappliedaswelltotheMLmodelsdescribedin thissurvey. IntheDieboldandMariano\u2019s( 1995)test,twocompetingmethodshavethesameunconditional expectedlossunderthenullhypothesis,andthetestcanbecarriedoutusingasimple ??-test.A smallsampleadjustmentwasdevelopedbyHarveyetal.( 1997).Seealsotherecentdiscussionin Diebold(2015).OnedrawbackoftheDieboldandMariano\u2019s( 1995)testisthatitsstatisticdiverges undernullwhenthecompetingmodelsarenested.However,GiacominiandWhite( 2006)show thatthetestisvalidiftheforecastsarederivedfrommodelsestimatedinarollingwindowframe- work.Recently,McCracken( 2020)showsthatiftheestimationwindowisfixed,theDieboldand Mariano\u2019s( 1995)statisticmaydivergeunderthenull.Therefore,itisveryimportantthatthefore- castsarecomputedinarollingwindowscheme. Inordertoaccommodatecaseswheretherearemorethantwocompetingmodels,anuncondi- tionalsuperiorpredictiveability(USPA)testwasproposedbyWhite( 2000).Thenullhypothesis statesthatabenchmarkmethodoutperformsasetofcompetingalternatives.However,Hansen (2005)showedthatWhite\u2019s( 2000)testcanbeveryconservativewhentherearecompetingmeth- odsthatareinferiortothebenchmark.Anotherimportantcontributiontotheforecastingliter- ature is the model confidence set (MCS) proposed by Hansen et al. ( 2011). An MCS is a set of competingmodelsthatisbuiltinawaytocontainthebestmodelwithrespecttoacertainloss functionandwithagivenlevelofconfidence.TheMCSacknowledgesthepotentiallimitations ofthedataset,suchthatuninformativedatayieldanMCSwithalargenumbermodels,whereas informativedatayieldanMCSwithonlyafewmodels.Importantly,theMCSproceduredoesnot assumethataparticularmodelisthetrueone. AnotherextensionoftheDieboldandMariano\u2019s( 1995)testistheconditionalequalpredictive ability(CEPA)testproposedbyGiacominiandWhite( 2006).Inpracticalapplications,itisimpor- tanttoknownotonlyifagivenmodelissuperiorbutalsowhenitisbetterthanthealternatives. Recently, Li et al. ( 2020) proposed a very general framework to conduct conditional predictive abilitytests. Insummary,itisveryimportanttocomparetheforecastsfromdifferentMLmethodsandthe literatureprovidesanumberofteststhatcanbeused.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 101 6APPLICATIONSOFMLMETHODSTOECONOMICAND FINANCIALFORECASTING 6.1Linearmethods Penalizedregressionsarenowanimportantoptioninthetoolkitofappliedeconomists.Thereis avastliteratureconsideringtheuseofsuchtechniquestoeconomicsandfinancialforecasting. Macroeconomic forecasting is certainly one of the most successful applications of penalized regressions.MedeirosandMendes( 2016)appliedtheadaLASSOtoforecastingU.S.inflationand showedthatthemethodoutperformsthelinearautoregressiveandfactormodels.Medeirosand Vasconcelos( 2016)showthathigh-dimensionallinearmodelsproduce,onaverage,smallerfore- casting errors for macroeconomic variables when a large set of predictors is considered. Their resultsalsoindicatethatagoodselectionoftheadaLASSOhyperparametersreducesforecasting errors. Garcia et al. ( 2017) show that high-dimensional econometric models, such as shrinkage and CSR, perform very well in real-time forecasting of Brazilian inflation in data-rich environ- ments.Theauthorscombineforecastsofdifferentalternativesandshowthatmodelcombination canachievesuperiorpredictiveperformance.SmeeksandWijler( 2018)consideranapplication toalargemacroeconomicU.S.datasetanddemonstratethatpenalizedregressionsareverycom- petitive.Medeirosetal.( 2021)conductavastcomparisonofmodelstoforecastU.S.inflationand showedthepenalizedregressionswerefarsuperiortoseveralbenchmarks,includingfactormod- els. Ardia et al. ( 2019) introduce a general text sentiment framework that optimizes the design for forecasting purposes and apply it to forecasting economic growth in the United States. The methodincludestheuseoftheElnetforsparsedata-drivenselectionandtheweightingofthou- sandsofsentimentvalues.Tarassow( 2019)considerpenalizedVARstoforecastsixdifferenteco- nomicuncertaintyvariablesforthegrowthoftherealM2andrealM4Divisiamoneyseriesfor the United States using monthly data. Uematsu and Tanaka ( 2019) consider high-dimensional forecastingandvariableselectionviafolded-concavepenalizedregressions.Theauthorsforecast quarterly U.S. gross domestic product data using a high-dimensional monthly data set and the mixeddatasampling(MIDAS)frameworkwithpenalization.SeealsoBabiietal.( 2020b,2020c). Thereisalsoavastlistofapplicationsinempiricalfinance.Elliottetal.( 2013)findthatcom- binationsofsubsetregressionscanproducemoreaccurateforecastsoftheequitypremiumthan conventionalapproachesbasedonequal-weightedforecastsandotherregularizationtechniques. AudrinoandKnaus( 2016)usedLASSO-basedmethodstoestimateforecastingmodelsforrealized volatilities.Callotetal.( 2017)considermodelingandforecastinglargerealizedcovariancematri- cesofthe30DowJonesstocksbypenalizedVARmodels.TheauthorsfindthatpenalizedVARs outperformthebenchmarksbyawidemarginandimprovetheportfolioconstructionofamean\u2013 varianceinvestor.Chincoetal.( 2019)usetheLASSOtomake1-minute-aheadreturnforecastsfor avastsetofstockstradedattheNewYorkStockExchange.Theauthorsprovideevidencethat penalizedregressionestimatedbytheLASSOboostout-of-samplepredictivepowerbychoosing predictorsthattraceouttheconsequencesofunexpectednewsannouncements. 6.2Nonlinearmethods TherearemanypapersontheapplicationofnonlinearMLmethodstoeconomicandfinancial forecasting.MostofthepapersfocusonNNmethods,speciallytheonesfromtheearlyliterature.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 102 MASINIetal. With respect to the early papers, most of the models considered were nonlinear versions of autoregressivemodels.Atbest,asmallnumberofextracovariateswereincluded.See,forexam- ple, Ter\u00e4svirta et al. ( 2005) and the references therein. In the majority of the papers, including Ter\u00e4svirtaetal.( 2005),therewasnostrongevidenceofthesuperiorityofnonlinearmodelsasthe differencesinperformanceweremarginal.OtherexamplesfromtheearlyliteratureareSwanson andWhite( 1995,1997a,1997b),BalkinandOrd( 2000),Tkacz(2001),Medeirosetal.( 2001),and Heravietal.( 2004). Morerecently,withtheavailabilityoflargedatasets,nonlinearmodelsarebacktothescene. For example, Medeiros et al. ( 2021) show that, despite the skepticism of the previous literature on inflation forecasting, ML models with a large number of covariates are systematically more accurate than the benchmarks for several forecasting horizons and show that Random Forests dominated all other models. The good performance of the Random Forest is due not only to its specific method of variable selection but also the potential nonlinearities between past key macroeconomicvariablesandinflation.OthersuccessfulexampleisGuetal.( 2020).Theauthors showlargeeconomicgainstoinvestorsusingMLforecastsoffuturestockreturnsbasedonavery largesetofpredictors.Thebestperformingmodelsaretree-basedandneuralnetworks.Coulombe etal.(2020)showsignificantgainswhennonlinearMLmethodsareusedtoforecastmacroeco- nomic time series. Borup et al. ( 2020) consider penalized regressions, ensemble methods, and random forest to forecast employment growth in the United States over the period 2004\u20132019 usingGooglesearchactivity.TheirresultsstronglyindicatethatGooglesearchdatahavepredic- tivepower.Borupetal.( 2020)computenow-andbackcastsofweeklyunemploymentinsurance initialclaimsintheUSbasedonarichsetofdailyGoogleTrendssearch-volumedataandmachine learningmethods. 6.3Empiricalillustration Inthissection,weillustratetheuseofsomeofthemethodsreviewedinthispapertoforecastdaily realizedvarianceoftheBrazilianStockMarketindex(BOVESPA).Weuseasregressorsinforma- tionfromothermajorindexes,namely,theS&P500(US),theFTSE100(UnitedKingdom),DAX (Germany),HangSeng(HongKong),andNikkei(Japan).Ourmeasureofrealizedvolatilityiscon- structedbyaggregatingintradayreturnssampleatthe5-minfrequency.Thedatawereobtained fromtheOxford-ManRealizedLibraryatOxfordUniversity.10 Foreachstockindex,wedefinetherealizedvarianceas ??????=??? ??=1??2 ????, where??????isthelogreturnsampledatthe5-min.frequency. ??isthenumberofavailablereturns atday??. The benchmark model is the heterogeneous autoregressive (HAR) model proposed by Corsi (2009): log??????+1=??0+??1log??????+??5log????5,??+??22log????22,??+????+1, (13)  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 103 Figure 7 Realizedvarianceofdifferentstockindexes[Colourfigurecanbeviewedat wileyonlinelibrary.com] where??????isdailyrealizedvarianceoftheBOVESPAindex, ????5,??=1 54? ??=0??????-??,and ????22,??=1 2221? ??=0??????-??. Asalternatives,weconsideranextendedHARmodelwithadditionalregressorsestimatedby adaLASSO.Weincludeasextraregressorsthedailypastvolatilityoftheotherfiveindexescon- sideredhere.Themodelhasatotalofeightcandidatepredictors.Furthermore,weconsidertwo nonlinearalternativesusingallpredictors:arandomforestandshallowanddeepNNs. TherealizedvariancesofthedifferentindexesareillustratedinFigure 7.ThedatastartinFebru- ary2,2000andendsinMay21,2020,atotalof4200observations.Thesampleincludestwoperi- odsofveryhighvolatility,namely,thefinancialcrisisof2007\u20132008andtheCovid-19pandemics of2020.Weconsiderarollingwindowexercise,wereweset1500observationsineachwindow. Themodelsarereestimatedeveryday. SeveralotherauthorshaveestimatednonlinearandMLmodelstoforecastrealizedvariances. McAleer and Medeiros ( 2008) considered a smooth transition version of the HAR while Hille- brandandMedeiros( 2016)consideredthecombinationofsmoothtransitions,longmemory,and NN models. Hillebrand and Medeiros ( 2010) and McAleer and Medeiros ( 2011) combined NN  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 104 MASINIetal. Table 1 Forecastingresults Fullsample 2007\u20132008 2020 Model MSE QLIKE MSE QLIKE MSE QLIKE HARX-LASSO 0.96**0.98 0.98*0.96 0.90***0.90 Randomforest 1.00 1.02 0.95***0.98 1.13**1.03* Neuralnetwork(1) 0.99**0.99 0.97**0.98 0.99 0.99 Neuralnetwork(3) 0.99**0.99 0.98*0.99 0.99 0.99 Neuralnetwork(5) 0.90**0.99 0.98*0.99 0.99 0.99 The table reports for each model, the mean squared error (MSE) and the QLIKE statistics as a ratio to the HAR benchmark. ValuessmallerthanoneindicatesthatthemodeloutperformstheHAR.TheasterisksindicatetheresultsoftheDiebold-Mariano testofequalforecastingperformance.*,**,and***,indicaterejectionofthenullofequalforecastingabilityatthe10%,5%,and 1%,respectively. modelswithbaggingandScharthandMedeiros( 2009)consideredsmoothtransitionregression trees. The use of LASSO and its generalizations to estimate extensions of the HAR model was proposedbyAudrinoandKnaus( 2016). Althoughthemodelsareestimatedinlogarithms,wereporttheresultsinlevels,whichinthe endisthequantityofinterest.WecomparethemodelsaccordingtotheMSEandtheQLIKEmet- ric. TheresultsareshowninTable 1.Thetablereportsforeachmodel,theMSEandtheQLIKE statisticsasaratiototheHARbenchmark.Valuessmallerthanoneindicatesthatthemodelout- performstheHAR.TheasterisksindicatetheresultsoftheDiebold-Marianotestofequalfore- castingperformance.*,**,and***,indicaterejectionofthenullofequalforecastingabilityatthe 10%, 5%, and 1%, respectively. We report results for the full out-of-sample period, the financial crisis years (2007\u20132008), and then for 2020 as a way to capture the effects of the Covid-19 pan- demicsontheforecastingperformanceofdifferentmodels. Aswecanseefromthetables,theMLmethodsconsideredhereoutperformtheHARbench- mark.ThewinnermodelisdefinitelytheHARmodelwithadditionalregressorsandestimated withadaLASSO.Theperformanceimprovesduringthehighvolatilityperiodsandthegainsreach 10%duringtheCovid-19pandemics.RFsdonotperformwell.Ontheotherhand,NNmodelswith differentnumberofhiddenlayersoutperformthebenchmark. 7CONCLUSIONSANDTHEROADAHEAD Inthispaper,wepresentanonexhaustivereviewofthemostoftherecentdevelopmentsinML andhigh-dimensionalstatisticstotime-seriesmodelingandforecasting.Wepresentedbothlinear andnonlinearalternatives.Furthermore,weconsiderensembleandhybridmodels.Finally,we brieflydiscusstestsforsuperiorpredictiveability. Among linear specification, we pay special attention to penalized regression (Ridge, LASSO anditsgeneralizations,forexample)andensemblemethods(BaggingandCSR).Although,there havebeenmajortheoreticaladvancesintheliteratureonpenalizedlinearregressionmodelsfor dependentdata,thesameisnottrueforensemblemethods.ThetheoreticalresultsforBagging aresofarbasedonindependentdataandtheresultsforCSRarequitelimited. WithrespecttononlinearMLmethods,wefocusedonNNsandtree-basedmethods.Theoret- icalresultsforRFsandboostedtreeshavebeendevelopedonlytoIIDdataandinthecaseofa  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 105 low-dimensionalsetofregressors.ForshallowNNs,Chenetal.( 2007)andChen( 2007)provide some theoretical results for dependent data in the low-dimensional case. The behavior of such modelsinhighdimensionsisstillunderstudy.ThesameistruefordeepNNs. Nevertheless,therecentempiricalevidenceshowsthatnonlinearMLmodelscombinedwith largedatasetscanbeextremelyusefulforeconomicforecasting. Asadirectionforfurtherdevelopmentswelistthefollowingpoints: 1. DevelopresultsforBaggingandBoostingfordependentdata. 2. Show consistency and asymptotic normality of the RF estimator of the unknown function ??h(????)whenthedataaredependent. 3. DeriveabetterunderstandingofthevariableselectionmechanismofnonlinearMLmethods. 4. DevelopinferentialmethodstoaccessvariableimportanceinnonlinearMLmethods. 5. Developmodelsbasedonunstructureddata,suchastextdata,toeconomicforecasting. 6. EvaluateMLmodelsfornowcasting. 7. EvaluateMLinveryunstableenvironmentswithmanystructuralbreaks. Finally,wewouldliketopointthatweleftanumberofotherinterestingMLmethodsoutof this survey, such as, for example, Support Vector Regressions, autoenconders, nonlinear factor models,andmanymore.However,wehopethatthematerialpresentedherecanbeofvalueto anyoneinterestedofapplyingMLtechniquestoeconomicand/orfinancialforecasting. ACKNOWLEDGMENTS Weareverygratefulfortheinsightfulcommentsmadebytwoanonymousreferees.Thesecond authorgratefullyacknowledgesthepartialfinancialsupportfromCNPq.Wearealsogratefulto FrancisX.Diebold,DanielBorup,andAndriiBabiiforhelpfulcomments. ORCID MarceloC.Medeiros https://orcid.org/0000-0001-8471-4323 ENDNOTES 1Morerecently,MLforcausalinferencehavestartedtoreceivealotofattention.However,thissurveywillnot covercausalinferencewithMLmethods. 2The original sentence is \u201cProgramming computers to learn from experience should eventually eliminate the needformuchofthisdetailedprogrammingeffort.\u201dSeeSamuel( 1959). 3Thezeromeanconditioncanbealwaysensuredbyincludinganinterceptinthemodel.Alsothevarianceof ??(????)tobefinitesufficesforthefinitevariance. 4Theoracleproperty wasfirstdescribedinFanandLi( 2001)inthecontextofnonconcavepenalizedestimation. 5Amoreprecisetreatmentwouldseparate signconsistency frommodelselectionconsistency .Signconsistency first appearedinZhaoandYu( 2006)andalsoverifywhetherthesignofestimatedregressionweightsconvergeto thepopulationones. 6Weaksparsity generalizessparsitybysupposingthatcoefficientsare(very)smallinsteadofexactlyzero. 7Therelevantregressorsaretheonesassociatedwithnonzeroparameterestimates. 8Anunstablepredictor haslargevariance.Intuitively,smallchangesinthedatayieldlargechangesinthepredic- tivemodel. 9Itispossibletocombineforecastsusinganyweightingscheme.However,itisdifficulttobeatuniformweighting (Genreetal., 2013). 10https://realized.oxford-man.ox.ac.uk/data/assets  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 106 MASINIetal. References Ad\u00e1mek,R.,Smeekes,S.,&Wilms,I.(2020). LASSOinferenceforhigh-dimensionaltimeseries (TechnicalReport). arxiv:2007.10952. Ardia,D.,Bluteau,K.,&Boudt,K.(2019).Questioningthenewsabouteconomicgrowth:Sparseforecastingusing thousandsofnews-basedsentimentvalues. InternationalJournalofForecasting ,35,1370\u20131386. Audrino,F.,&Knaus,S.D.(2016).LassoingtheHARmodel:Amodelselectionperspectiveonrealizedvolatility dynamics.EconometricReviews ,35,1485\u20131521. Babii,A.,Ghysels,E.,&Striaukas,J.(2020a). Inferenceforhigh-dimensionalregressionswithheteroskedasticityand autocorrelation (TechnicalReport).arxiv:1912.06307. Babii,A.,Ghysels,E.,&Striaukas,J.(2020b). Machinelearningpaneldataregressionswithanapplicationtonow- castingpriceearningsratios (TechnicalReport).arxiv:2008.03600. Babii,A.,Ghysels,E.,&Striaukas,J.(2020c). Machinelearningtimeseriesregressionswithanapplicationtonow- casting(TechnicalReport).arxiv:2005.14057. Balkin, S. D., & Ord, J. K. (2000). Automatic neural network modeling for univariate time series. International JournalofForecasting ,16,509\u2013515. Barron,A.(1993).Universalapproximationboundsforsuperpositionsofasigmoidalfunction. IEEETransactions onInformationTheory ,39,930\u2013945. Bartlett,P.,&Traskin,M.M.(2007).AdaBoostisconsistent. JournalofMachineLearningResearch ,8,2347\u20132368. Basu,S.,&Michailidis,G.(2015).Regularizedestimationinsparsehigh-dimensionaltimeseriesmodels. Annals ofStatistics ,43,1535\u20131567. Belloni,A.,Chernozhukov,V.,&Hansen,C.(2014).Inferenceontreatmenteffectsafterselectionamongsthigh- dimensionalcontrols. ReviewofEconomicStudies ,81,608\u2013650. Borup,D.,Christensen,B.,M\u00fchlbach,N.,&Nielsen,M.(2020).Targetingpredictorsinrandomforestregression. TechnicalReport ,2004.01411,arxiv. Borup,D.,Rapach,D.,&Sch\u00fctte,E.(2020).Now-andbackcastinginitialclaimswithhigh-dimensionaldailyinter- netsearch-volumedata. TechnicalReport ,3690832,SSRN. Breiman,L.(1996).Baggingpredictors. MachineLearning ,24,123\u2013140. Breiman,L.(2001).Randomforests. MachineLearning ,45,5\u201332. B\u00fchlmann, P. L. (2002). Consistency for L2boosting and matching pursuit with trees and tree-type basis func- tions.InResearchreport/Seminarf\u00fcrStatistik,Eidgen\u00f6ssischeTechnischeHochschule(ETH) ,Vol.109.Seminar f\u00fcrStatistik,Eidgen\u00f6ssischeTechnischeHochschule(ETH). B\u00fchlmann,P.(2006).Boostingforhigh-dimensionallinearmodels. AnnalsofStatistics ,34,559\u2013583. Callot, L. A. F., & Kock, A. B. (2013). Oracle efficient estimation and forecasting with the adaptive LASSO and theadaptivegroupLASSOinvectorautoregressions.InN.Haldrup,M.Meitz,&P.Saikkonen(Eds.), Essaysin nonlineartimeserieseconometrics .OxfordUniversityPress. Callot,L.,Kock,A.,&Medeiros,M.(2017).Modelingandforecastinglargerealizedcovariancematricesandport- foliochoice. JournalofAppliedEconometrics ,32,140\u2013158. Chan,K-.S.,&Chen,K.(2011).SubsetARMAselectionviatheadaptiveLASSO. StatisticsandItsInterface ,4,197\u2013 205. Chen,X.(2007).Largesamplesieveestimationofsemi-nonparametricmodels.InJ.Heckman&E.Leamer(Eds.), Handbookofeconometrics (pp.5549\u20135632).Elsevier. Chen,S.,Donoho,D.,&Saunders,M.(2001).Atomicdecompositionbybasispursuit. SIAMReview ,43,129\u2013159. Chen,X.,Racine,J.,&Swanson,N.(2007).SemiparametricARXneural-networkmodelswithanapplicationto forecastinginflation. IEEETransactionsonNeuralNetworks ,12,67 4\u2013683. Chen,X.,&Shen,S.(1998).Sieveextremumestimatesforweaklydependentdata. Econometrica ,66,289\u2013314. Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., & Newey, W. (2017). Dou- ble/debiased/Neymanmachinelearningoftreatmenteffects. AmericanEconomicReview ,107,261\u2013265. Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., & Robins, J. (2018). Dou- ble/debiasedmachinelearningfortreatmentandstructuralparameters. EconometricsJournal ,21,C1\u2013C68. Chinco,A.,Clark-Joseph,A.,&Ye,M.(2019).Sparsesignalsinthecross-sectionofreturns. JournalofFinance ,74, 449\u2013492. Corsi,F.(2009).Asimplelongmemorymodelofrealizedvolatility. JournalofFinancialEconometrics ,7,17 4\u2013196.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 107 Coulombe,P.,Leroux,M.,Stevanovic,D.,&Surprenant,S.(2020). Howismachinelearningusefulformacroeco- nomicforecasting? (Technicalreport).UniversityofPennsylvania. Cybenko,G.(1989).Approximationbysuperpositionofsigmoidalfunctions. MathematicsofControl,Signals,and Systems,2,303\u2013314. Davis,R.,&Nielsen,M.(2020).Modelingoftimeseriesusingrandomforests:Theoreticaldevelopments. Electronic JournalofStatistics14 ,3644\u20133671. Diebold,F.(2015).Comparingpredictiveaccuracy,twentyyearslater:Apersonalperspectiveontheuseandabuse ofDiebold-Marianotests. JournalofBusinessandEconomicStatistics ,33,1\u20139. Diebold,F.X.,&Mariano,R.S.(1995).Comparingpredictiveaccuracy. JournalofBusinessandEconomicStatistics , 13,253\u2013263. Diebold,F.&Shin,M.(2019).Machinelearningforregularizedsurveyforecastcombination:Partially-egalitarian LASSOanditsderivatives. InternationalJournalofForecasting ,35,1679\u20131691. Diebold,F.,Shin,M.,&Zhang,B.(2021).Ontheaggregationofprobabilityassessments:Regularizedmixturesof predictivedensitiesforEurozoneinflationandrealinterestrates. TechnicalReport ,2012.11649,arxiv. Duffy,N.,&Helmbold,D.(2002).Boostingmethodsforregression. MachineLearning ,47,153\u2013200. Elliott,G.,Gargano,A.,&Timmermann,A.(2013).Completesubsetregressions. JournalofEconometrics ,177(2), 357\u2013373. Elliott, G., Gargano, A., & Timmermann, A. (2015). Complete subset regressions with large-dimensional sets of predictors. JournalofEconomicDynamicsandControl ,54,86\u2013110. Elliott,G.,&Timmermann,A.(2008).Economicforecasting. JournalofEconomicLiterature ,46,3\u201356. Elliott,G.,&Timmermann,A.(2016).Forecastingineconomicsandfinance. AnnualReviewofEconomics ,8,81\u2013110. Fan,J.,&Li,R.(2001).Variableselectionvianonconcavepenalizedlikelihoodanditsoracleproperties. Journalof theAmericanStatisticalAssociation ,96,1348\u20131360. Fan,J.,&Lv,J.(2008).Sureindependencescreeningforultrahighdimensionalfeaturespace. JournaloftheRoyal StatisticalSociety,SeriesB ,70,849\u2013911. Fan,J.,Xue,L.,&Zou,H.(2014).Strongoracleoptimalityoffoldedconcavepenalizedestimation. AnnalsofStatis- tics,42,819\u2013849. Foresee,F.D.,&Hagan,M.T.(1997).Gauss-NewtonapproximationtoBayesianregularization. IEEEInternational ConferenceonNeuralNetworks (Vol.3,pp.1930\u20131935).NewYork:IEEE. Friedman,J.(2001).Greedyfunctionapproximation:Agradientboostingmachine. AnnalsofStatistics ,29,1189\u2013 1232. Funahashi, K. (1989). On the approximate realization of continuous mappings by neural networks. Neural Net- works,2,183\u2013192. Garcia,M.,Medeiros,M.,&Vasconcelos,G.(2017).Real-timeinflationforecastingwithhigh-dimensionalmodels: ThecaseofBrazil. InternationalJournalofForecasting ,33(3),679\u2013693. Genre,V.,Kenny,G.,Meyler,A.,&Timmermann,A.(2013).Combiningexpertforecasts:Cananythingbeatthe simpleaverage? InternationalJournalofForecasting ,29,108\u2013121. Giacomini,R.,&White,H.(2006).Testsofconditionalpredictiveability. Econometrica ,74,1545\u20131578. Granger,C.,&Machina,M.(2006).Forecastinganddecisiontheory.In Handbookofeconomicforecasting (Vol.1, pp.81\u201398).Elsevier. Grenander,U.(1981). Abstractinference .NewYork:Wiley. Gu,S.,Kelly,B.,&Xiu,D.(2020).Empiricalassetpricingviamachinelearning. ReviewofFinancialStudies ,33, 2223\u20132273. Hamilton,J.(1994). Timeseriesanalysis .PrincetonUniversityPress. Han,Y.,&Tsay,R.(2020).High-dimensionallinearregressionfordependentdatawithapplicationstonowcasting. StatisticaSinica ,30,1797\u20131827. Hans,C.(2009).BayesianLASSOregression. Biometrika ,96,835\u2013845. Hansen,P.(2005).Atestforsuperiorpredictiveability. JournalofBusinessandEconomicStatistics ,23,365\u2013380. Hansen,P.,Lunde,A.,&Nason,J.(2011).Themodelconfidenceset. Econometrica ,79,453\u2013497. Harvey,D.,Leybourne,S.,&Newbold,P.(1997).Testingtheequalityofpredictionmeansquarederrors. Interna- tionalJournalofForecasting ,13,281\u2013291. Hastie, T., Tibshirani, R., & Friedman, J. (2009). Theelementsofstatisticallearning:Datamining,inference,and prediction.Springer.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 108 MASINIetal. Hastie,T.,Tibshirani,R.,&Wainwright,M.(2015). Statisticallearningwithsparsity:TheLASSOandgeneralizations . CRCPress. Hecq,A.,Margaritella,L.,&Smeekes,S.(2019). Grangercausalitytestinginhigh-dimensionalVARs:Apost-double- selectionprocedure (TechnicalReport).arxiv:1902.10991. Heravi,S.,Osborne,D.,&Birchenhall,C.(2004).LinearversusneuralnetworkforecastsforEuropeanindustrial productionseries. InternationalJournalofForecasting ,20,435\u2013446. Hillebrand,E.,&Medeiros,M.(2010).Thebenefitsofbaggingforforecastmodelsofrealizedvolatility. Econometric Reviews,29,571\u2013593. Hillebrand,E.,&Medeiros,M.C.(2016).Asymmetries,breaks,andlong-rangedependence. JournalofBusiness andEconomicStatistics ,34,23\u201341. Hochreiter,S.,&Schmidhuber,J.(1997).Longshort-termmemory. NeuralComputation ,9,1735\u20131780. Hoerl,A.,&Kennard,R.(1970).Ridgeregression:Biasedestimationfornonorthogonalproblems. Technometrics , 12,55\u201367. Hornik,K.,Stinchombe,M.,&White,H.(1989).Multi-layerFeedforwardnetworksareuniversalapproximators. NeuralNetworks ,2,359\u2013366. Hsu,N.-J.,Hung,H.-L.,&Chang,Y.-M.(2008).SubsetselectionforvectorautoregressiveprocessesusingLASSO. ComputationalStatistics&DataAnalysis ,52,3645\u20133657. Inoue, A., & Kilian, L. (2008). How useful is bagging in forecasting economic time series? A case study of U.S. consumerpriceinflation. JournaloftheAmericanStatisticalAssociation ,103,511\u2013522. James,W.,&Stein,C.(1961).Estimationwithquadraticloss. ProceedingsoftheThirdBerkeleySymposiumonMath- ematicalStatisticsandProbability (Vol.1,pp.361\u2013379). Jiang,W.(2004).ProcessconsistencyforAdaBoost. AnnalsofStatistics ,32,13\u201329. Kim, Y., Choi, H., & Oh, H.-S. (2008). Smoothly clipped absolute deviation on high dimensions. Journal of the AmericanStatisticalAssociation ,103,1665\u20131673. Knight,K.,&Fu,W.(2000).AsymptoticsforLASSO-typeestimators. AnnalsofStatistics ,28,1356\u20131378. Kock,A.(2016).ConsistentandconservativemodelselectionwiththeadaptiveLassoinstationaryandnonstation- aryautoregressions. EconometricTheory ,32,243\u2013259. Kock,A.,&Callot,L.(2015).Oracleinequalitiesforhighdimensionalvectorautoregressions. JournalofEconomet- rics,186,325\u2013344. Kock, A., & Ter\u00e4svirta, T. (2014). Forecasting performance of three automated modelling techniques during the economiccrisis2007-2009. InternationalJournalofForecasting ,30,616\u2013631. Kock, A., & Ter\u00e4svirta, T. (2015). Forecasting macroeconomic variables using neural network models and three automatedmodelselectiontechniques. EconometricReviews ,35,1753\u20131779. Konzen,E.,&Ziegelmann,F.(2016).LASSO-typepenaltiesforcovariateselectionandforecastingintimeseries. JournalofForecasting ,35,592\u2013612. Koo,B.,Anderson,H.,Seo,M.,&Yao,W.(2020).High-dimensionalpredictiveregressioninthepresenceofcoin- tegration.JournalofEconometrics ,219,456\u2013477. Lederer,J.,Yu,L.,&Gaynanova,I.(2019).Oracleinequalitiesforhigh-dimensionalprediction. Bernoulli,25,1225\u2013 1255. Lee,J.,Sun,D.,Sun,Y.,&Taylor,J.(2016).Exactpost-selectioninferencewithapplicationtotheLASSO. Annals ofStatistics ,44,907\u2013927. Lee,J.,&Shi,Z.G.Z.(2020). OnLASSOforpredictiveregression (TechnicalReport).arxiv:1810.03140. Leeb,H.,&P\u00f6tscher,B.(2005).Modelselectionandinference:Factsandfiction. EconometricTheory ,21,21\u201359. Leeb, H., & P\u00f6tscher, B. (2008). Sparse estimators and the oracle property, or the return of Hodges\u2019 estimator. JournalofEconometrics ,142,201\u2013211. Li,J.,Liao,Z.,&Quaedvlieg,R.(2020). Conditionalsuperiorpredictiveability (TechnicalReport).ErasmusSchool ofEconomics. Lockhart,R.,Taylor,J.,Tibshirani,R.,&Tibshirani,R.(2014).Asignificancetestforthelasso. AnnalsofStatistics , 42,413\u2013468. Lugosi,G.,&Vayatis,N.(2004).OntheBayes-riskconsistencyofregularizedboostingmethods. AnnalsofStatistics , 32,30\u201355. MacKay,D.J.C.(1992a).Bayesianinterpolation. NeuralComputation ,4,415\u2013447.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 109 MacKay,D.J.C.(1992b).ApracticalBayesianframeworkforbackpropagationnetworks. NeuralComputation ,4, 448\u2013472. Masini,R.,Medeiros,M.,&Mendes,E.(2019). Regularizedestimationofhigh-dimensionalvectorautoregressions withweaklydependentinnovations (TechnicalReport).arxiv:1912.09002. McAleer,M.,&Medeiros,M.(2011).Forecastingrealizedvolatilitywithlinearandnonlinearmodels. Journalof EconomicSurveys ,25,6\u201318. McAleer,M.,&Medeiros,M.C.(2008).Amultipleregimesmoothtransitionheterogeneousautoregressivemodel forlongmemoryandasymmetries. JournalofEconometrics ,147,104\u2013119. McCracken,M.(2020).Divergingtestsofequalpredictiveability. Econometrica ,88,1753\u20131754. Medeiros, M., & Mendes, E. (2013). Penalized estimation of semi-parametric additive time-series models. In N. Haldrup,M.Meitz,&P.Saikkonen(Eds.), Essaysinnonlineartimeserieseconometrics .OxfordUniversityPress. Medeiros,M.,&Mendes,E.(2016). ??1-Regularizationofhigh-dimensionaltime-seriesmodelswithnon-Gaussian andheteroskedasticerrors. JournalofEconometrics ,191,255\u2013271. Medeiros, M., & Mendes, E. (2017). Adaptive LASSO estimation for ARDL models with GARCH innovations. EconometricReviews ,36,622\u2013637. Medeiros, M., & Vasconcelos, G. (2016). Forecasting macroeconomic variables in data-rich environments. Eco- nomicsLetters ,138,50\u201352. Medeiros, M. C., Ter\u00e4svirta, T., & Rech, G. (2006). Building neural network models for time series: A statistical approach.JournalofForecasting ,25,49\u201375. Medeiros,M.C.,Vasconcelos,G.,Veiga,A.,&Zilberman,E.(2021).Forecastinginflationinadata-richenviron- ment:Thebenefitsofmachinelearningmethods. JournalofBusinessandEconomicStatistics ,39,98\u2013119. Medeiros,M.C.,&Veiga,A.(2005).Aflexiblecoefficientsmoothtransitiontimeseriesmodel. IEEETransactions onNeuralNetworks ,16,97\u2013113. Medeiros,M.C.,Veiga,A.,&Pedreira,C.(2001).Modellingexchangerates:Smoothtransitions,neuralnetworks, andlinearmodels. IEEETransactionsonNeuralNetworks ,12,755\u2013764. Melnyk,I.,&Banerjee,A.(2016).Estimatingstructuredvectorautoregressivemodels. InternationalConferenceon MachineLearning (pp.830\u2013839). Mhaska,H.,Liao,Q.,&Poggio,T.(2017).Whenandwhyaredeepnetworksbetterthanshallowones? Proceedings oftheThirty-FirstAAAIConferenceonArtificialIntelligence(AAAI-17) (pp.2343\u20132349). Nardi,Y.,&Rinaldo,A.(2011).AutoregressiveprocessmodelingviatheLASSOprocedure. JournalofMultivariate Analysis,102,528\u2013549. Park,H.,&Sakaori,F.(2013).LagweightedLASSOfortimeseriesmodel. ComputationalStatistics ,28,493\u2013504. Park,J.,&Sandberg,I.(1991).Universalapproximationusingradial-basis-functionnetworks. NeuralComputation , 3,246\u2013257. Park,T.,&Casella,G.(2008).TheBayesianLASSO. JournaloftheAmericanStatisticalAssociation ,103,681\u2013686. Ren,Y.,&Zhang,X.(2010).SubsetselectionforvectorautoregressiveprocessesviaadaptiveLASSO. Statistics& ProbabilityLetters ,80,1705\u20131712. Samuel, A. (1959). Some studies in machine learning using the game of checkers. IBM Journal of Research and Development ,3(3),210\u2013229. Sang,H.,&Sun,Y.(2015).Simultaneoussparsemodelselectionandcoefficientestimationforheavy-tailedautore- gressiveprocesses. Statistics,49,187\u2013208. Scharth,M.,&Medeiros,M.(2009).AsymmetriceffectsandlongmemoryinthevolatilityofDowJonesstocks. InternationalJournalofForecasting ,25,304\u2013325. Scornet,E.,Biau,G.,&Vert,J.-P.(2015).Consistencyofrandomforests. AnnalsofStatistics ,43,1716\u20131741. Simon,N.,Friedman,J.,Hastie,T.,&Tibshirani,R.(2013).Asparse-groupLASSO. JournalofComputationaland GraphicalStatistics ,22,231\u2013245. Smeeks,S.,&Wijler,E.(2018).Macroeconomicforecastingusingpenalizedregressionmethods. InternationalJour- nalofForecasting ,34,408\u2013430. Smeeks,S.,&Wijler,E.(2021).Anautomatedapproachtowardssparsesingle-equationcointegrationmodelling. JournalofEconometrics ,221(1),247\u2013276. Srivastava,N.,Hinton,G.,Krizhevsky,A.,Sutskever,I.,&Salakhutdinov,R.(2014).Simplewaytopreventneural networksfromoverfitting. JournalofMachineLearningResearch ,15,1929\u20131958.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 110 MASINIetal. Stein,C.(1956).Inadmissibilityoftheusualestimatorforthemeanofamultivariatedistribution. Proceedingsof theThirdBerkeleySymposiumonMathematicalStatisticsandProbability (Vol.1,pp.197\u2013206). Stinchcombe, M., & White, S. (1989). Universal approximation using feedforward neural networks with non- sigmoidhiddenlayeractivationfunctions. ProceedingsoftheInternationalJointConferenceonNeuralNetworks , Washington (pp.613\u2013617).NewYork,NY:IEEEPress. Suarez-Fari\u00f1as,Pedreira,C.,&Medeiros,M.C.(2004).Local-globalneuralnetworks:Anewapproachfornonlin- eartimeseriesmodelling. JournaloftheAmericanStatisticalAssociation ,99,1092\u20131107. Swanson,N.R.,&White,H.(1995).Amodelselectionapproachtoassessingtheinformationinthetermstructure usinglinearmodelsandartificialneuralnetworks. JournalofBusinessandEconomicStatistics ,13,265\u2013275. Swanson,N.R.,&White,H.(1997a).Forecastingeconomictimeseriesusingflexibleversusfixedspecificationand linearversusnonlineareconometricmodels. InternationalJournalofForecasting ,13,439\u2013461. Swanson,N.R.,&White,H.(1997b).Amodelselectionapproachtoreal-timemacroeconomicforecastingusing linearmodelsandartificialneuralnetworks. ReviewofEconomicandStatistics ,79,540\u2013550. Tarassow,A.(2019).ForecastingU.S.moneygrowthusingeconomicuncertaintymeasuresandregularisationtech- niques.InternationalJournalofForecasting ,35,443\u2013457. Taylor,J.,Lockhart,R.,Tibshirani,R.,&Tibshirani,R.(2014). Post-selectionadaptiveinferenceforleastangleregres- sionandtheLASSO (TechnicalReport).arxiv:1401.3889. Ter\u00e4svirta,T.(1994).Specification,estimation,andevaluationofsmoothtransitionautoregressivemodels. Journal oftheAmericanStatisticalAssociation ,89,208\u2013218. Ter\u00e4svirta,T.,Tj\u00f6stheim,D.,&Granger,C.(2010). Modellingnonlineareconomictimeseries .Oxford,UK:Oxford UniversityPress. Ter\u00e4svirta,T.,vanDijk,D.,&Medeiros,M.(2005).Linearmodels,smoothtransitionautoregressionsandneural networksforforecastingmacroeconomictimeseries:Areexamination(withdiscussion). InternationalJournal ofForecasting ,21,755\u201377 4. Tibshirani, R. (1996). Regression shrinkage and selection via the LASSO. J o ur na lo ft heR o ya lS t a t is t ic a lS o ciet y , SeriesB,58,267\u2013288. Tikhonov,A.(1943).Onthestabilityofinverseproblems. DokladyAkademiiNaukSSSR ,39,195\u2013198(inRussian). Tikhonov,A.(1963).Onthesolutionofill-posedproblemsandthemethodofregularization. DokladyAkademii Nauk,151,501\u2013504. Tikhonov,A.,&Arsenin,V.(1977). Solutionsofill-posedproblems .V.HWinstonandSons. Tkacz, G. (2001). Neural network forecasting of Canadian GDP growth. InternationalJournalofForecasting ,17, 57\u201369. Trapletti,A.,Leisch,F.,&Hornik,K.(2000).Stationaryandintegratedautoregressiveneuralnetworkprocesses. NeuralComputation ,12,2427\u20132450. Uematsu,Y.,&Tanaka,S.(2019).High-dimensionalmacroeconomicforecastingandvariableselectionviapenal- izedregression. EconometricsJournal ,22,34\u201356. vandeGeer,S.,B\u00fchlmann,P.,Ritov,Y.,&Dezeure,R.(2014).Onasymptoticallyoptimalconfidenceregionsand testsforhigh-dimensionalmodels. AnnalsofStatistics ,42,1166\u20131202. Wager,S.,&Athey,S.(2018).Estimationandinferenceofheterogeneoustreatmenteffectsusingrandomforests. JournaloftheAmericanStatisticalAssociation ,113,1228\u20131242. Wang,H.,&Leng,C.(2008).AnoteonadaptivegroupLASSO. ComputationalStatistics&DataAnalysis ,52,5277\u2013 5286. Wang,H.,Li,G.,&Tsai,C.-L.(2007).Regressioncoefficientandautoregressiveordershrinkageandselectionvia theLASSO. JournaloftheRoyalStatisticalSociety,SeriesB ,69,63\u201378. White,H.(2000).Arealitycheckfordatasnooping. Econometrica ,68,1097\u20131126. Wong,K.,Li,Z.,&Tewari,A.(2020).LASSOguaranteesfor ??-mixingheavytailedtimeseries. AnnalsofStatistics , 48,1124\u20131142. Wu, W. (2005). Nonlinear system theory: Another look at dependence. Proceedings of the National Academy of Sciences,102,14150\u201314154. Wu, W., & Wu, Y. (2016). Performance bounds for parameter estimates of high-dimensional linear models with correlatederrors. ElectronicJournalofStatistics ,10,352\u2013379. Xie,F.,Xu,L.,&Yang,Y.(2017).LASSOforsparselinearregressionwithexponentially ??-mixingerrors. Statistics &ProbabilityLetters ,125,64\u201370.  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MASINIetal. 111 Xue, Y., & Taniguchi, M. (2020). Modified LASSO estimators for time series regression models with dependent disturbances. StatisticalMethods&Applications ,29,845\u2013869. Yang,Y.,&Zou,H.H.(2015).Afastunifiedalgorithmforsolvinggroup-LASSOpenalizelearningproblems. Statis- ticsandComputing ,25,1129\u20131141. Yarotsky,D.(2017).ErrorboundsforapproximationswithdeepReLUnetworks. NeuralNetworks ,94,103\u2013114. Yoon,Y.,Park,C.,&Lee,T.(2013).Penalizedregressionmodelswithautoregressiveerrorterms. JournalofStatis- ticalComputationandSimulation ,83,1756\u20131772. Yousuf,K.(2018).Variablescreeningforhighdimensionaltimeseries. ElectronicJournalofStatistics ,12,667\u2013702. Yuan, M., & Lin, Y. (2006). Model selection and estimation in regression with grouped variables. Journal of the RoyalStatisticalSociety,SeriesB ,68,49\u201367. Zhang, T., & Yu, B. (2005). Boosting with early stopping: Convergence and consistency. Annals of Statistics ,33, 1538\u20131579. Zhao, P., & Yu, B. (2006). On model selection consistency of LASSO. Journal of Machine Learning Research ,7, 2541\u20132563. Zhu,X.(2020).Nonconcavepenalizedestimationinsparsevectorautoregressionmodel. ElectronicJournalofStatis- tics,14,1413\u20131448. Zou,H.(2006).TheadaptiveLASSOanditsoracleproperties. JournaloftheAmericanStatisticalAssociation ,101, 1418\u20131429. Zou,H.,&Hastie,T.(2005).Regularizationandvariableselectionviatheelasticnet. JournaloftheRoyalStatistical Society,SeriesB ,67,301\u2013320. Zou,H.,&Zhang,H.(2009).Ontheadaptiveelastic-netwithadivergingnumberofparameters. AnnalsofStatistics , 37,1733\u20131751. Howtocitethisarticle: Masini,R.P.,Medeiros,M.C.,&Mendes,E.F.(2023).Machine learningadvancesfortimeseriesforecasting. JEconSurv ,37,76\u2013111. https://doi.org/10.1111/joes.12429  14676419, 2023, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/joes.12429 by Higher Education Commission,, Wiley Online Library on [14/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License ", "15": "1028 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 23, NO. 7, JULY 2012 Toward Automatic Time-Series Forecasting Using Neural Networks Weizhong Yan, Senior Member, IEEE Abstract \u2014 Over the past few decades, application of arti?cial neural networks (ANN) to time-series forecasting (TSF) has beengrowing rapidly due to several unique features of ANN models.However, to date, a consistent ANN performance over differentstudies has not been achieved. Many factors contribute to theinconsistency in the performance of neural network models.One such factor is that ANN modeling involves determininga large number of design parameters, and the current designpractice is essentially heuristic and ad hoc, this does not exploitthe full potential of neural networks. Systematic ANN modelingprocesses and strategies for TSF are, therefore, greatly needed.Motivated by this need, this paper attempts to develop anautomatic ANN modeling scheme. It is based on the generalizedregression neural network (GRNN), a special type of neuralnetwork. By taking advantage of several GRNN properties (i.e., asingle design parameter and fast learning) and by incorporatingseveral design strategies (e.g., fusing multiple GRNNs), we havebeen able to make the proposed modeling scheme to be effectivefor modeling large-scale business time series. The initial modelwas entered into the NN3 time-series competition. It was awardedthe best prediction on the reduced dataset among approximately60 different models submitted by scholars worldwide. Index Terms \u2014 Arti?cial neural network, generalized regression neural network, model combination, time-series forecasting. I. I NTRODUCTION CONVENTIONALLY, time-seri es forecasting (TSF) has been performed predominan tly using statistical-based methods, for example, the autoregressive integrated moving average (ARIMA). However, over the past few decades, arti?- cial neural networks (ANNs)\u2014which exhibit superior perfor- mance on classi?cation and regression problems in machine- learning domain\u2014have attracted tremendous attention in theTSF community. Compared to statistics-based forecasting techniques, neural network approaches have several unique characteristics, including: 1) being both nonlinear and data driven; 2) having no requirement for an explicit underlying model (nonparametric); and 3) being more ?exible and uni- versal, thus applicable to mo re complicated models [1]. Because of the aforementione d characteristics, ANNs have been regarded by many experts as a promising technology forTSF. Consequently, in the last few decades, more than 2000 articles on neural network forecasting have been published, Manuscript received January 15, 2012; revised April 19, 2012; accepted April 20, 2012. Date of publication June 1, 2012; date of current version June 8, 2012. The author is with the Machine Learni ng Laboratory, GE Global Research Center, Niskayuna, NY 12309 USA (e-mail: yan@ge.com). Color versions of one or more of the ?gures in this paper are available online at http://ieeexplore.ieee.org. Digital Object Identi?er 10.1109/TNNLS.2012.2198074covering a wide range of applications/?elds [2]. A great number of empirical studies have shown superior performance of neural network forecasters over statistical methods, basedon a single or a small set of time series (e.g., [3]\u2013[5]). However, several studies have shown inferior performance of neural network methods over traditional statistical methods.Heravi et al. [6] conducted a study on comparing neural network models against linear autoregressive models based on 24 time series of annual change in monthly industrial production in three European countries. Their results indicated that linear models generally outperform ANN models. A studyby Callen et al. [7], based on 296 quarterly accounting-earning series, also showed the inferiority of neural networks over linear models. Several factors contribute to the inconsistent results of neural network models across different studies. Adya and Collopy [8] attributed the inconsistency to the ineffectiveness in validation and implementation involved in some studies. They found that, out of 48 business-related forecasting studiesthey identi?ed, only 11 (i.e., 22.9%) were correctly imple- mented and validated. On the other hand, Nelson et al. [9] and Zhang and Kline [10] suggested that the inconsistencyof ANN performance from different studies was the result of different preprocessing strategies adopted in those studies. They believe that time-series preprocessing (e.g., detrending and deseasonalizing) contributes signi?cantly to ANN model performance. Others (e.g., [11]) attributed the inferior performance of ANN models to the inherent requirement of a suf?cient number of samples in order for networks to be fully trained.Most real-world applications, especially economic and ?nan- cial series, however, are short ones, which are inadequate for ANNs to learn the underlying pattern and structure, thus resulting in poor out-of-sample p rediction performance. Still, several studies, for example, [1] and [12], attributed the poorperformance of ANNs to the need for determining a large num- ber of network parameters (e.g., network types, architectures, and many other network paramet ers); the current heuristic and largely ad hoc modeling process does not allow for exploiting the full potential of ANN models. Clearly, how effective ANNs are for TSF is still an open question and more research work is needed in this regard. One approach to maximally exploring the potential of ANN models for TSF is through organized TSF competitions. By pooling the development effort and skills from worldwide participants, a large number of empirical studies can beperformed effectively. The M3 Competition [13] and more 2162\u2013237X/$31.00 \u00a9 2012 IEEE Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:03:03 UTC from IEEE Xplore.  Restrictions apply. YAN: TOWARDS AUTOMATIC TIME-SERIES FORECASTING 1029 recently the Neural Network Forecasting Competition [12] are two examples. Another important research effort is on thedevelopment of a systematic modeling approach to replace the current heuristic and ad hoc methods. By doing that, we can alleviate the dif?culty encountered in ANN modeling, andthus allow for a more reliable evaluation of ANN models for a large number of time series. To that end, Balkin and Ord [11] proposed an automatic procedure for neural network modeling. Their work, however, was limited to multilayer perceptron (MLP) networks only and their method showed disappointingperformance in the M3 competition. Our effort in this paper is also toward automatic ANN modeling for TSF. Realizing that MLP networks have severalshortcomings (e.g., a large number of design parameters, long training time, and suffering from local minima) that make model automation more dif?cult, in this paper we attempt to develop an automatic modeling scheme using generalized regression neural networks (GRNNs), a special type of neuralnetworks. GRNN has only a single design parameter and is simple and fast in training, which are the desirable properties for automated modeling. Our effort in this paper focuseson designing a modeling scheme to take full advantage of these GRNN properties. In addition, we pay great attention to the following design strategies to achieve a more effective and ef?cient automation and good forecasting performance as well: 1) using fusion of multiple GRNNs to alleviate the dif?- culty of determining the spread factor of GRNN; 2) using automatic feature identi?cation and treatment strategy for outliers and trends; 3) adopting the direct approach for multiple-step-ahead (MSA) forecasting. Our initial model was entered in the 2007 Neural Network Time-Series Forecasting Competition (www.neural- forecasting-competition.com). Among approximately 60submissions to the competition, our model was the overall winner for the best prediction of the reduced dataset (11 time series) 1based on several different error measures [12]. The rest of this paper is organized as follows. Section II provides an overview of related work on neural networkforecasting. Section III gives a brief introduction to GRNN. The proposed ANN modeling scheme is described in detail in Section IV . Section V gives our experimental results of themodel. Section VI is dedicated to the sensitivity study and discussion. Section VII concludes this paper. II. R ELATED WORK In the literature, there are a large number of publications on using neural networks for TSF. These publications cover a wide range of TSF applications, varying from ?nancial [7] toeconomic [4], to natural physical phenomena\u2014for example, river ?ow [14], earthquakes [15], and weather [16]. Several overview papers, for example, [1], [8], [17], provide a good 1For the complete dataset, our initial model was ranked 11th in the competition and our improved model that is described in this paper is ranked 5th overall (See Table I in Section V).summary of various applications of neural networks for time series forecasting. Many types of networks have been employed for those diverse TSF applications. The earliest and the most popular type of networks is feed-forward MLPs. Early applicationsof this type of networks include the paper by Farway and Chat?eld [18], Hill et al. [3], and Balkin and Ord [11], while studies by Zhang and Kline [10] and Heravi et al. [6] are some examples of more recent work. Recurrent neural networks are another type of networks that are often used for TSF(e.g., [19]\u2013[22]). Other types of neural networks used for TSF include radial basis function (RBF) networks [23], Bayesian neural networks [24], and neuron-fuzzy networks [25], [26].Ahmed et al. [27] conducted a comparison study of different types of machine-learning models, including MLP, Bayesian neural networks, RBFs, GRNNs, k-nearest neighbor regres- sion, regression tree, support vector regression, and Gaussian processes. Recently, extreme learning machine (ELM), a newtype of neural networks introduced by Huang et al. [28], was adopted by Sorjamaa et al. [29] for TSF. More recently, using Clifford support vector machin es [30] and causality analysis [31] for TSF has also been investigated. GRNNs have also been used for TSF. For related work on GRNNs, please see Section III for details. In addition to single models, multiple models have also been used for TSF, which is often referred to as combining forecasts [32]. Combining multiple statistical models for forecasting has a long history [33]. Empirical studies have shown that combin- ing forecasts not only improves forecasting accuracy but alsoalleviates the dif?culty associated with the conventional design strategy of selecting a single model. For example, Zou and Yang [34] convexly combined multiple ARIMA models with different orders using the so-called aggregated forecast through exponential reweighting (AFTER) scheme and showed thatmodel combination could perform better than model selection when uncertainty in model selection is signi?cant. Combining multiple neural network models for forecasting has also been actively explored in recent years. Both theoret- ical and empirical studies have shown that by intelligently combining the outputs from a series of networks, greateraccuracy than the best individual network can be achieved. Inspired by the success of neural network ensembles (NNEs) ?rst introduced by Hansen and Salamon [35] in the domains of machine learning and data mining, several studies used the concept of the NNE for TSF. For example, Maqsood et al. [16] used an ensemble of different types of networks for weather forecasting in southern Saskatchewan, Canada. Lim and Goh [36] proposed a modi?ed version of the AdaBoostalgorithm to integrate the predictions of multiple Elman recur- rent networks. Original AdaBoost works for classi?cation tasks only, modi?ed AdaBoost works for regression prob- lems so that it can be used for TSF. More recently, Assaad et al. [37] also studied boosting multiple recurrent neural networks for single-step-ahead (SSA) and MSA prediction problems. Both boosting studies, however, were limited to benchmarking datasets (e.g., the sunspots and the Mackey\u2013Glass time series) and have not yet been applied to real-world problems. Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:03:03 UTC from IEEE Xplore.  Restrictions apply. 1030 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 23, NO. 7, JULY 2012 Fig. 1. Typical GRNN structure. III. GRNN S GRNN is a variant of RBF networks [38, p. 277]. A typical GRNN has three layers of arti?cial neurons (see Fig. 1): the input layer, the hidden layer, and the output layer. The hidden layer has radial basis neurons, while neurons in the output layer have a linear transfer function. Given a suf?cient number of neurons, GRNN can approximate a continuous function toan arbitrary accuracy (i.e., it is a universal approximator) [39]. In the original GRNN, the number of radial basis neurons in the hidden layer is set to equal the number of training samples.In such design, a large number of training samples will result in a complex network with too many hidden neurons. One way of reducing the number of hidden neurons is to cluster the training samples ?rst and to set the number of hidden neurons equal to the number of clusters [40]. The input toeach of the radial basis neurons is the distance between the input vector and the training sample. The neuron\u2019s output is the RBF of the input scaled by the spread factor. This type ofneuron gives an output character izing the closeness between input vectors and training samples. The commonly used RBF is the multivariate Gaussian function de?ned by G(x,x i)=exp( -1 2s2||x-xi||2) (1) where xiandsare the center and width, respectively, of the Gaussian function. Given minput\u2013output pairs {xi,yj}?Rn\u00d7 R1,i= 1,2,..., m, and as the training samples, assume the original design of GRNN, that is, the number of hidden neurons is equal to the number of training samples. The GRNN output for a test point, x?Rn,i sd e ? n e da s \u02c6y(x)=m? i=1Wiyi (2) where wi=exp( -||x-xi||2 2s2) ?m k=1exp( -||x-xk||2 2s2). (3) GRNN has one tunable parameter , namely, spread factor [in (2) above]. When the spread fact or is small, the RBF is steep, and only a small number of training samples closest to the input contribute to the network output, which results in a roughresponse surface. As the spread factor increases, the RBF becomes wider and many more t raining samples contribute to the network output, which leads to a smoother responsesurface. Therefore, spread fact or dictates GRNNs prediction performance.As discussed in Section II, MLP networks have several shortcomings that make design, particularly automatic design,of MLPs a dif?cult task [1], [8]. GRNNs, on the other hand, have several advantages, including: 1) it has one design parameter (i.e., spread factor); 2) it is easy to train since it is aone-pass algorithm; 3) it can accurately approximate functions from sparse and noisy data; and 4) it can converge to the conditional mean surface by increasing the number of data samples [39]. It is these unique advantages that make us to choose GRNN in our automatic ANN modeling scheme. In spite of having several unique properties that are desirable for TSF, GRNNs have not been as popular as other networks for TSF. A few of recent studies on GRNN for TSF include[27], where a comparison study was performed on using different machine-learning models, including GRNN, for TSF. In their study, Ahmed et al. [27] used the basic form of GRNN and used 10-fold cross-valid ation to select the best spread factor out of a set of spread factors ranging from 0.05 to0.7. They concluded that GRNN is inferior over MLP and GP, but is generally more robust cross-difference series. Some recent applications of GRNNs in clude ?nancial TSF [41], river ?ow forecasting [25], load forecasting [42], [43], and plasma etching prediction [44]. IV . P ROPOSED METHODOLOGY Our primary goal in this paper is to develop an ANN modeling scheme for TSF, which is as automated as possible so that it can be used to effectively and ef?ciently modela large number of time series. More speci?cally, we have devoted our effort toward the following three objectives in designing our modeling scheme: 1) it requires minimal humanintervention; 2) it is computationally ef?cient for a large number of series; and 3) it has good overall forecasting performance. Our proposed automatic ANN modeling scheme consists of two essential components, namely, preprocessing and ANN modeling , which are described in detail in the following two subsections. A. Preprocessing A real-world time series, regardless of its type and its application, often contains various patterns, such as, trend, seasonality, and outlier. It is well recognized that the treat- ment of these patterns, which we call \u201cpreprocessing\u201d in this paper, is a critical part of time-series modeling [45, p.29]. Preprocessing time series typically includes two steps, namely, pattern identi?cation and pattern treatment. Manually identifying time-series patterns via visual analysis has beenpopularly used in TSF, but it is labor intensive and is limited to a small number of series. When the number of series is large, an automatic pattern identi?cation process is necessary, which is often a challenging task. A few studies, for example [1], have already looked at the p attern identi?cation problem. Toward automatic ANN modeling, our preprocessing in this paper focuses on automatic identi?cation and treatment of three time-series patterns, namely, outliers, trend, and season-ality. Normalization required for neural network modeling in general is also included in our preprocessing. Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:03:03 UTC from IEEE Xplore.  Restrictions apply. YAN: TOWARDS AUTOMATIC TIME-SERIES FORECASTING 1031 1) Outlier Identi?cation and Treatment: Outliers are iso- lated observations that are signi ?cantly different in value from the pattern in the rest of the series. Adya et al. [46] used large second difference value as an indication of outliers. Based on our own previous experience, in this paper, we de?ne an outlieras a point whose absolute value is four times greater than the absolute medians of the three consecutive points before and after, respectively, of the point. That is, x iis an outlier if its value satis?es the following condition : |xi|=4\u00d7max{|ma|,|mb|} (4) where ma=median (xi-3,xi-2,xi-1)and mb=median (xi+1,xi+2,xi+3). When an observation is deemed to be an outlier based on (4), its value is simply replaced with the average value of the two points that are immediately before and after the outlier. 2) Trend Identi?cation and Treatment: Whether or not neural networks can effectively model trend in time series is an open question. The recent work by Qi and Zhang [47] was dedicated to answerin g this speci?c question. Their conclusion was that for most nonlinear and/or stochastic timeseries, detrending data by taking the ?rst difference is the best practical approach for bu ilding effective ANN forecasting models. Their study was based on MLP networks. For GRNNs,however, there has been no such study performed exclusively. Since GRNNs perform prediction based on the similarity of the input point to the historical data points in the input space (see Section III for descriptions of GRNNs), GRNNs are inherently ineffective in modeling trend. Thus effective detrending, espe-cially removing global trend, is more important for GRNNs than other ANN models. There are different types of trend associated with time series, including global linear, local linear, nonlinear, and stochastic trend [45, p. 15]. Common approaches for handling trend include curve ?tting, ?ltering, and differencing [45,p. 16]. A big challenge is on determining whether a series has trend and, if it does, what type of trend, that is, linear, nonlinear, or stochastic it is. Even more challenging is to do this in a systematical, not manual, fashion. Aiming at an automatic modeling scheme, in this paper, we proposea generic detrending scheme\u2014subtracting full-season means. Under this detrending scheme, a series is ?rst split into segments. The length of the segments is equal to the length ofseasonality, that is, 12 for monthly series and 4 for quarterly series. The mean of the historical observations within each of these segments is subtracted from every historical observation in the segment. Let {m 1,m2,..., mk}be the means of the k segments of a series and lbe the length of seasonality. The detrended series, dti, is related to the original series, xi,a s follows: dti=xi-mj=cell( i j),i=1,2,..., n (5) where nis the length of the series. Such a detrending scheme is effective for removing global trends (both linear and non- linear). While forecasting models can be effectively built onthe detrended series, global trend (represented in full-season means) needs to be added back to the model outputs to obtainfuture forecasts. While the fu ll-season means for historical observations can be easily calculated as shown above, themeans for future forecasts are unknown. How can we ?nd means for future forecasts? The re are several ways to estimate the season means of future points. For example, we can createa prediction model to estimate future means based on the historical means, if the series is long enough and thus the number of means is large enough. In this paper, we adopt different strategies for short and long series, respectively. For short series ( n<60 points), we take the future means as the same as the last historical means. For long series, the future means are estimated based on the average of the last two historical means. Effectiveness of our detrending scheme willbe discussed in Section VI by comparing to other detrending schemes. 3) Seasonality Identi?cation and Treatment: For addressing seasonality, in literature there are generally two different ANNmodeling strategies, that is, d irect and deseasonalized. Opin- ions regarding these two strategies are mixed. Nelson et al. [9] and more recently Zhang and Kline [10] found that networkstrained on deseasonalized data performed signi?cantly better than those trained on raw data, while Heravi et al. [6] were in favor of modeling neural networks directly on raw data since they had a concern on potential nonlinearity induced by the seasonality adjustment. There are several ways to identify seasonality of a time series. Most of them are manual processes. One example of such manual processes is by interpreting the correlogram\u2014a graph in which the sample autocorrelation coef?cients are plotted against the different lags. Automatically determining the seasonality of a series is not a trivial task. Zhang and Kline [10] used a simple rule of thumb for identifying seasonality. That is, a series is seasonal if t he autocorrelation coef?cient at the ?rst seasonal lag is greater than 2 /v 2, where nis the length of the series. During our preliminary study, this simple rule of thumb was applied to the NN3 competitiondata. It worked reasonably well for the short seasonal series, but misclassi?ed the majority of the long nonseasonal series. In this paper, we adopt the follo wing seasonality identi?cation strategies for short and long series, respectively. A short series ( n=60) is { seasonal , if?(1)> 2 v n non-seasonal ,otherwise .(6) A long series ( n>60) is { seasonal , if both ?(1)&?(2)>2 v n non-seasonal ,otherwise(7) where nis the length of the series, and ?(1) and ?(2) are the autocorrelation coef?cients at one and two seasonal lags, respectively. Using our seasonality criterion on the NN3 com- petition data, we correctly identi?ed 45 out of all 54 seasonalseries and 53 out of all 57 nonseasonal series. For seasonal series, a simple deseasonalization proce- dure [8] is adopted. It performs deseasonalizing by subtractingthe seasonal average. Let lbe the length of seasonality (12 for monthly data and 4 for quarterly data) and a k,k=1,2,..., l Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:03:03 UTC from IEEE Xplore.  Restrictions apply. 1032 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 23, NO. 7, JULY 2012 be the seasonal averages. The deseasonalized series is dsi=xi-aj=mod(i,l)+1,i=1,2,..., n. (8) To perform forecasting, we simply add the seasonal average back to the outputs of the model that is built on the deseason- alized series. The effectiv eness of deseasonality to GRNNs is discussed in Section VI. 4) Normalization: After performing the above-mentioned pattern treatment, data points are then normalized to a rangeof [0, 1] using linear scalin g based on the minimal and maximum values of the series. Other normalization meth- ods can also be used. Sensitivity of our modeling schemeto different normalization methods will be discussed in Section VI. B. ANN Modeling ANN modeling in this paper involves the following three efforts: 1) determining the spread factor of GRNN; 2) deter-mining the inputs of GRNN; and 3) deciding on MSA fore- casting strategies, all of which are described in detail in the subsequent subsections. 1) GRNNs Spread Factor: As discussed in Section III, spread factor of GRNNs is the only design parameter that directly affects prediction p erformance of GRNNs. Unfortu- nately, there is no single spread factor that works well forall GRNN applications. Moreover, there is no good analytical method that allows for accurate ly determining the best spread factor for a given application. Haykin [38, p. 299] provided aguidance on determining spread factor, that is, s=d max/v 2n, where dmaxis the maximum distance between the training points, and nis the number of training points. The problem with this guidance is that the spread factor is dependent on the number of training samples. That is, it tends to yieldbig spread factor for short series and small spread factor for long series. To date, empirically determining the spread factor by trial and error is still the common practice in thedesign of GRNNs. However, an empirical approach is time consuming especially when the number of series is large. One could use an optimizer (e.g., genetic algorithm) as a wrapperto determine the optimal spread factor for each individual time series by minimizing an objective function (e.g., errors on the holdout samples). However, such optimization is also computationally expensive when the number of time series is large. Moreover, such optimization may only work wellwhen the number of observations is large, that is, for long series. For short series, the spread factor that is optimally selected based on a small number of training samples maynot generalize well to out-of-s ample forecasting. Instead of searching for a single spread f actor for each individual series, this paper tackles the spread factor issue by using multiple (e.g., three in this paper) GRNNs, each of which uses one spread factor from a spread factor set. The spread factorset is series dependent and is related to the distribution of the training samples of the series in the input space. As discussed in Section III, GRNN is an instance-based model,that is, it performs prediction based on the similarity of the input point to the training sam ple points in the input space.We hypothesize that the spread factor of the GRNN model should be related to how the training samples are distributedin the input space. Thus in this paper we propose the spread factor set to be {d 50,d75,d95}, the 50th, 75th, and 95th percentiles of the nearest distances of all training samples tothe rest of the points. The three spread factors are calculated speci?cally for each individual series. In Section VI, we will explore how sensitive the number of GRNNs is to our model performance. All three GRNNs take the same input, and the outputs of the three GRNNs are combined to arrive at the ?nal prediction. Our strategy of using multiple GRNNs with different spread factors in our modeling scheme is inspired by the success of model combination in the domain of machine learning. A large body of literature has shown that model combination can improve model performance for both classi?cation and regression tasks [48]. Even for time series, several studies (e.g.,[13], [32], [33]) have shown that combining forecasts can be an effective tool for improving forecasting accuracy. To the best of our knowledge, however, using model combination foralleviating the dif?culty of individually determining the spread factors of GRNNs in modeling a large number of series has not been studied. In the machine learning literature, one can ?nd many model combination methods derived from different underlyingframeworks [49], ranging from Bayesian probability theory [50], to fuzzy sets [51], to Dem pster\u2013Shafer evidence theory [52], to group decision-making theory (e.g., majority voting,weighted majority voting, and Borda count). Kuncheva [53] provided a good overview of model combination methods. In the ?eld of time series for ecasting, simple combination methods (e.g., simple average) have been popularly used, since studies have shown that a simple average often outperformsthe more sophistic combinatio n methods [33]. Recently, Jose and Winkler [54] proposed two new, simple combination methods\u2014the trimmed and the Winsorized means. While onemay choose to empirically select the best combination method for the given problem, for our automatic modeling scheme, we use the simple average as the combination method. The effectof using different combina tion methods to the forecasting performance of our modeling scheme is investigated through sensitivity study in Section VI. 2) GRNN Inputs: Inputs to GRNNs are typically the lagged observations of a time series. Several studies, for exam-ple, [1], have indicated that selecting model inputs is an important, if not the most important, task in TSF modeling. In machine learning, input selection (or feature selection)is a research topic on its own. Dash and Liu [55] have carried out a comprehensive overview of feature selection techniques. Broadly speaking, feature selection methods can be categorized into ?lter and wrapper approaches [56]. The ?lter approach selects features as a result of preprocessing based on the properties of the data itself, independent of the learning algorithm. The wrapper approach, on the other hand, uses the learning algorithm as part of the evaluation.Wrapper approach generally gives a feature set that has better performance, but is also computationally more expensive. Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:03:03 UTC from IEEE Xplore.  Restrictions apply. YAN: TOWARDS AUTOMATIC TIME-SERIES FORECASTING 1033 Algorithm 1 Pseudocode for Performing the Proposed ANN Modeling FOR each time series { //1. Preprocessing 1.1 Perform outlier identi?cation and treatment if applicable 1.2 Perform trend identi?cation and detrending if applicable 1.3 Perform seasonality identi?cation and deseasonalizing if applicable // 2. ANN modeling 2.1 Hold out the last 18 historical observations for validation and keep the remaining samples for training For each of the input lags of [1,2,\u2026,12] { 2.2 Determine spread factor set for GRNNs 2.3 Train each GRNN on the training set2.4 Test each GRNN on the hold out samples 2.5 Fuse outputs of all GRNNs to obtain initial forecasts 2.6 Add seasonality back, if applicable 2.7 Add trend back, if applicable 2.8 Calculate sMAPE2.8 Record the best input lag and corresponding spread factor set } 2.9 Use all historical observations to retrain GRNNs with the best input lag and the spread factor set 2.10 Perform out-of-sample forecasting 2.11 Add seasonality back if applicable 2.12 Add trend back if applicable2.13 Calculate the forecasting sMAPE } END Studies speci?cally on feature s election for TSF are sparse. Huang et al. [57], Tikka et al. [58], and Crone and Nikolopoulos [59] are a few sample studies on this topic.The majority of real-world applications still rely on experi- ments and/or empirical intuition for determining the model inputs. One can simply try different inputs and pick one withthe smallest error (or other performance measure) from the holdout testing set. In this paper, we adopt such an experi- mental approach for determining the inputs to our GRNNs. To minimize the search time, we consider only the contiguous lags as inputs and we further limit the maximum lag to onefull season (12 for monthly data). For short series ( n=60), we simply pick a ?xed lag equal to the season length (12 for monthly data) considering the fact the empirically selected input based on a small number of training samples may not generalize well to out -of-sample forecasting. 3) Multiple-Step-Ahead Forecasting: Depending on the length of forecasting horizon (the number of points into future), time series can be singl e-step-ahead (SSA) or mult- step-ahead (MSA). SSA forecas ting has the shortest forecast- ing horizon and is relatively easy, thus it has been widely discussed in the literature. MSA forecasting, however, has notbeen widely studied despite the fact that it is often of greater value in many real-world applications. MSA forecasting is much more challenging becau se it involves dealing with growing uncertainties caused b y various sources (e.g., error accumulation and lack of information) [60].For MSA forecasting, there are generally two different modeling approaches, that is, di rect and recursive. The direct approach uses multiple prediction models, each of which is explicit for one of the ksteps ahead. The recursive approach performs one-step-ahead predictions recursively\u2014using the prior prediction as an input on the second and subsequent steps\u2014until it reach es the desired prediction hori- zon. The recursive approach is simple and intuitive, but has a major drawback of prediction error accumulation. The direct approach, on the other hand, is computationallymore expensive since it requires training multiple models. The relative performance of the two modeling approaches generally depends on the time series and on the prediction model used.For neural network models, several studies, for example, [60], have shown that the direct approach is more accurate than the recursive approach in MSA forecasting. Atiya et al. [8] even analytically proved the superiority of the direct approach over the recursive approach. Therefore, this paper employsthe direct approach for MSA forecasting. We will discuss the difference between the two MSA approaches in terms of forecasting perform ance in Section VI. A step-by-step procedure for building the ANN models for TSF using the proposed modeling scheme is summarized in Algorithm 1. V. E XPERIMENTAL RESULTS A. NN3 Competition Datasets In this paper, the NN3 time-series competition dataset [12] is used for validating the ANN modeling scheme proposed. The NN3 competition has two datasets. Dataset A is a complete dataset consisting of 111 monthly time series drawnfrom a homogeneous population of empirical business time series. Dataset B, on the other hand, is a small subset of Dataset A, which consists of 11 time series. The completedataset (Dataset A) contains a balanced sample of both long (more than 100 observations per series) and short (less than 50 observations per series) time series, as well as an even split of seasonal and nonseasonal time series. That is, it includes 25 short-seasonal, 25 long-seasonal, 25 short-nonseasonal,25 long-nonseasonal, and the 11 time series of the reduced dataset (Dataset B). In this paper, we use all 111 series (the complete dataset) for our experimental study. Given thehistorical observations of each time series, the objective of the competition is to forecast the future 18 values, that is, to forecast x t+h,w h e r e h=1,2,... , 18, based on the given historical observations of x1,x2,..., xt. B. Performance Measures For evaluating forecast accuracy, several different measures have been proposed in the literature. Some of them are basedon percentage errors and others are based on relative errors. Hyndman and Koehler [61] conducted a comparison study on different measures of forecast accuracy. For model evaluationand determining the winners of the competition, the NN3 competition organizers chose the symmetric mean absolute Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:03:03 UTC from IEEE Xplore.  Restrictions apply. 1034 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 23, NO. 7, JULY 2012 Fig. 2. Typical series segmentation for model training, testing, and future forecasting. S.S. S.N. L.S. L.N.0204060sMAPE(%) Fig. 3. Boxplots of sMAPEs for groupwise series. The four groups are short seasonal (S.S.), short nonseasonal (S.N.), long seasonal (L.S.), and longnonseasonal (L.N.) ( Note: for all boxplots shown in this paper, red line at the notch of the box indicates median, two ends of the box represent 25th and 75th percentiles, respectively, and \u201c +\u201d represents points outside 25th and 75th percentiles). percentage error (sMAPE) de?ned in (9) below sMAPE =1 MM? i=1|Yi|-|\u02c6Yi| (|Yi|+|\u02c6Yi|)/2\u00d7100 (9) where Yiand\u02c6Yiare the true and predicted values, respec- tively, at ith time point, and Mis the number of forecasting points. sMAPE is a relative error measure, which allows for combining errors computed for different series into one number. For each time series, th e sMAPE is computed over the 18 forecasts, that is, M=18 in (9). Such per-series sMAPE is then averaged over all 111 series to obtain the so-calledoverall average sMAPE. C. Modeling Details Using direct approach for multi-step-ahead forecasting of the NN3 competition data, 18 models are used for each series. Each of the 18 models performs i-step-ahead forecasting, where i=1,2,... , 18. It is worth pointing out that each of the 18 models consists of three GRNNs with different spread factors as described in Section IV . To empirically determine the number of GRNN inputs, for each of the 111 series, the last 18 historical observations are reserved as holdout testing samples and the remaining portion of the historical observations are used for training the GRNNs (as shown in Fig. 2). Since all of the 111 series considered aremonthly series, the seasonal length here is 12. For the long series ( n>60), klagged inputs with k=1,2,... , 12 is tried as the GRNN inputs, and the one with the smallest sMAPEon the holdout testing samples is chosen as the ?nal input for the series. After determining the number of lagged inputs,Short Long0204060sMAPE(%) Fig. 4. Boxplots of sMAPEs\u2014short series versus long series. Seasonal Non-Seasonal0204060sMAPE(%) Fig. 5. Boxplot of sMAPEs\u2014seasonal series versus nonseasonal series. the networks are retrained over all historical observations (including the holdout samples), and such trained networks are used for out-of-sample forecasting. For the short series (n=60), on the other hand, a ?xed 12-lagged input is used. It is worth noting that the number of lagged inputs is kept the same for all 18-horizon models. The ANN modeling scheme proposed in this paper is implemented using M ATLAB (R2009b, The Mathworks, Inc., Natick, MA, USA), while GRNNs are implemented using theNeural Network Toolbox of M ATLAB . D. Results To assess the performance of our automatic modeling scheme, we employ a ?xed-origin evaluation of the 18 fore- casts, which is in accordance to the NN3 competition. Apply-ing our modeling scheme to forecast the future 18 points for each individual series, we obtain t he per-series sMAPEs based on the 18 future points. The overall average sMAPE of theforecasts for all 111 series is 15.80%. To assess our model performance over different segments of the time series, we calculate the descriptive statistics of the sMAPEs individually corresponding to the four series segments and show them in boxplots in Fig. 3. We thenspeci?cally compare the boxplots between 50 short series and 50 long series in Fig. 4, and between 50 seasonal and 50 nonseasonal series in Fig. 5. From those boxplots onecan see that our model generally performs better for seasonal series than nonseasonal series, and our model performs slightly better for long series than short series. The less favorable performance of our model on nonseasonal series indicates that nonseasonal series, especially short nonseasonal series, is moredif?cult to model. We also calculate and plot out in Fig. 6 the sMAPEs over six levels of forecasting horizons. It shows that generally theforecasting error increases as th e forecasting horizon increases, which is in accordance with intuition. Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:03:03 UTC from IEEE Xplore.  Restrictions apply. YAN: TOWARDS AUTOMATIC TIME-SERIES FORECASTING 1035 1 - 3 4 - 6 7 - 9 10 - 12 13 - 15 16 - 18020406080 HorizonssMAPE(%) Fig. 6. Boxplots\u2014sMAPE over different forecast horizons. 0 20 40 60 80 100 120 14020003000400050006000 # of ObservationsValueHistorical points Ground truth Forecasts Fig. 7. Historical observation and future forecasts for Series 68 for which our model yields an sMAPE of 2.7% (the best series). 05 0 1 0 0 1 5 001234x 104 # of ObservationsValueHis torical points Ground truth Forecasts Fig. 8. Historical observation and future forecasts for Series 93 for which our model yields an sMAPE of 73% (the worst series). Out of all 111 series, our per-series sMAPEs are generally below 40%, with the best sMAPE being approximately 2.7% (see Fig. 7). However, several of the series have much highersMAPE. In particular, Series 93 has the sMAPE close to 73%. Fig. 8 shows the historical observations, the true future 18 points, and the 18 forecasts predicted by our model, respectively. Clearly this speci?c series is a dif?cult one and our automatic model scheme could not capture the underlyingpattern well. In Table I, the overall average sMAPE of our model is also compared to those of the other top-performed modelssubmitted to the NN3 competition, where the model IDs with letter \u201cC\u201d as pre?x stand for computational intelligence (CI) models and the model IDs with letter \u201cB\u201d stand for statistical benchmark models. Table I was compiled from [12]. From Table I one can see that our automatic modeling schemeproposed in this paper outperforms almost all of the submitted CI models except Model C27\u2014Echo state networks. Our model performance is also co mparable to the top-performed statistical benchmark models. For details of these submitted and benchmark models, refer to [12]. Had we somehowTABLE I PERFORMANCE COMPARISON BETWEEN OURMODEL AND TOP-PERFORMED MODELS SUBMITTED TO THE COMPETITION ID  Method  sMAPE  Rank B09  Stat. Benchmark  14.84%  1 B07  Stat. Benchmark  14.89%  2 C27  Echo state networks  15.18%  3 B03  Stat. Benchmark - ForecastPro  15.44%  4 -  Our proposed model  15.80%  5 B16  DES  15.90%  6 B17  Comb S-H-D  15.93%  7 B05  Stat Benchmark - Autobox  15.95%  8 C03  Linear model + GA  16.31%  9 B14  SES  16.42%  10 B15  HES  16.49%  11 C46  Regression tree ensemble  16.55%  12 C13  kNN  16.57%  13 Note: In our original submission to the NN3 Competition, we used series-independent design, that is, the spread factors used for GRNNs are the same for all 111 series, which ledto a higher sMAPE of 18.58%. Since then we have adopteda series-dependent design that is reported in this paper, which resulted in a much improved forecasting performance. Fixed-Origin Rolling-Origin0204060sMAPE(%) Fig. 9. Boxplots\u2014comparison of sMAPEs between ?xed origin and rolling- origin evaluations. reduced the sMAPE of Series 93 from 73% to 20% (assuming we can achieve that by ?ne-tuni ng the design parameters of our automatic ANN model), our overall sMAPE would have been around 15.30%, which would put our model further close to the best CI model (C27). To desensitize the error measures to special events at any single origin, we also assessed our model performance based on the rolling-origin evaluation [62]. We did six origins, that is, T,T+1,..., T+5, where Tis the last historical observation. The sMAPEs of these six origins are then averaged for each series. The overall average sMAPE of the 111 series is 17.94% (as opposed to 15.80% for ?xed-origin). The boxplots for both ?xed-origin and rolling-origin evaluations are compared in Fig. 9. VI. D ISCUSSION As discussed in detail in Section IV , our modeling scheme involves adopting several important design strategies, includ-ing subtracting full-season means for detrending, seasonal average subtraction for deseasonalizing, and fusion of multiple GRNNs with different spread factors for simplifying thedetermination of single spread factor. These design strategies are introduced mainly for automating ANN modeling. By Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:03:03 UTC from IEEE Xplore.  Restrictions apply. 1036 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 23, NO. 7, JULY 2012 applying our modeling scheme to the NN3 competition data, we have demonstrated that those design strategies adopted inour modeling scheme are reasonably effective in TSF. In this section, we would like to have a preliminary investigation on how those individual design strategies affect our forecastingperformance and the sensitivity of some design choices to the model performance. To that end, both contrast analysis and sensitivity analysis are conducted in the following two subsections. Limitations and the potential use of our modeling scheme are also discussed in this section. A. Contrast Analysis For contrast analysis, we perform several comparisons between different designs, attempting to answer the following questions. 1) How effective is our detrending strategy? 2) Is deseasonalization a necessary preprocess step for GRNNs? 3) How effective is using multi-GRNN fusion for tackling the spread factor issue in GRNN modeling? 4) How different is it between the two MSA approaches\u2014 direct and recursive? Speci?cally, the following six comparisons are conducted. To assess the effectiveness of the detrending strategy adopted in our modeling scheme, which is described in detail in SectionIV-A, we compare it against the ?rst-difference detrending that is commonly used in TSF. We designate this ?rst comparison as \u201cauto versus ?rst-difference detrending (D1).\u201d We alsocompare our design against no detrending, which is designated as \u201cauto versus no detrending (D2).\u201d To understand if deseasonalization improves GRNNs\u2019 per- formance, we compare our model that uses seasonal average subtraction for deseasonalizing against the design that does notuse deseasonalization. We call this comparison \u201cauto versus nondeseasonalizing (D3).\u201d To assess the effectiveness of our strategy of addressing the spread factor issue, which involves fusion of three GRNNs with different spread factors, we compare our design against the following two designs. The ?rst design uses a single spreadfactor that is estimated using Haykin\u2019s formula, that is, s= d max/v 2n,w h e r e dmaxis the maximum distance between the training samples, and nis the number of training samples. The second design involves ?nding the best single spread factor for each series by grid searching. The search space for thespread factor issue ranges from 0.1 to 1.2 with an increment of 0.2. We designate these two comparisons as \u201cauto versus single calculated SF (D4)\u201d and \u201cauto versus single optimal SF(D5),\u201d respectively. The last contrast analysis we conducted is on comparing the two MSA design strategies\u2014direct and recursive (see Section IV-B). Since our automatic modeling scheme uses direct approach, we designate this comparison as \u201cauto versus recursive MSA (D6).\u201d In all of these six comparisons, the design con?guration (i.e., the full design paramet ers) used in our modeling scheme is treated as the baseline. For each of these comparisons, the design to be compared against is the result of changingTABLE II WILCOXON SIGNED -RANK TESTRESULTS FOR ALLCOMPARISON PAIRS Comparison  sMAPEs (%)  Z-value  p-value 1 Auto versus ?rst-difference detrending (D1) 18.51  -3.143  0.0017 2 Auto versus no detrending (D2) 16.68  -2.071  0.0383 3 Auto versus nondeseasonalizing (D3) 17.74  -4.836  <0.0001 4 Auto versus single calculated SP (D4) 16.37  -3.013  0.0026 5 Auto versus single optimal SP (D5) 15.83  -0.118  0.9057 6 Auto/direct versus recursive MSA (D6) 16.05  -1.351  0.1769 one subset of design parameters corresponding to the spe- ci?c design, while keeping the re st of the design parameters unchanged. To obtain statistical signi?cance of the differences for all of the pairwise comparisons, we use Wilcoxon signed-rank test (WSRT) [63]. WSRT is a nonparametric hypothesis test for the median difference. Compared to the t-test that requires normal distribution of the samples, WSRT makes fewer and less stringent assumptions on the sample distributions and thus is more powerful in detecting the existence of signi?cantdifferences [64]. In our WSRT setting, the matched pair samples are the per-series sMAPEs of the 111 time series, which are calculated using the 18 future forecasts. Table II summarizes the test results, from which the follow- ing conclusions can be made. 1) The detrending scheme used in our model is statistically signi?cantly different (with a p-value of 0.0017) fromthe popularly used ?rst-difference detrending method. More speci?cally, our approach yields a smaller overall sMAPE than the ?rst-difference detrending does sincethe z-value is negative, our detrending design is also statistically signi?cantly better than no trending design (with a z-value of -2.071 and a p-value of 0.0383). 2) Deseasonalizing makes signi?cant improvement (with a z-value of -4.836 and a p-value less than 0.0001), which indicates that deseasonalization is important for GRNN models. 3) The fourth-comparison results show that our spread factor determination strategy is signi?cantly better than using single spread factor calculated using the Haykin\u2019s formula (with a z-value of -3.013 and a p-value of 0.0026). 4) With a p-value of 0.9057 that is much greater than 0.005 (D5), we are con?dent that our spread factor determination strategy is not statistically signi?cantly different (in other words, they are equally effective) interms of the sMAPE from using search to ?nd the spread factor. Our strategy, however, is computationally advan- tageous since it only involves training and evaluatingthree GRNNs as opposed to many more GRNNs in the search method. Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:03:03 UTC from IEEE Xplore.  Restrictions apply. YAN: TOWARDS AUTOMATIC TIME-SERIES FORECASTING 1037 Auto D1 D2 D3 D4 D5 D6020406080sMAPE(%) Fig. 10. Boxplots\u2014comparison of sMAPEs of our modeling scheme against those from the six designs shown in Table II.s 5) Even though the direct approach we adopted as our MSA strategy shows a slightly better performance than the recursive approach in terms of sMAPE (D6 in Table II), the difference between the two approaches is statistically insigni?cant with a p-value of 0.1769. Fig. 10 summarizes all of the six comparisons in boxplots of sMAPEs, where \u201cauto\u201d refers to our automatic modeling scheme and D1 thru D6 are for the six designs we comparedin Table II. We would like to point out that the six comparisons conducted here do not cover all possible pairwise combi- nations of all designs. Also these comparisons only assess the independent effect, but not the interaction among thedesigns. Therefore, we have to be cautious in drawing general conclusions from this paper. B. Sensitivity Analysis To ?nd out how sensitive the design parameters of our automatic neural network modeling scheme are to the fore-casting accuracy, a design of experiments (DOE) study is per- formed. The three factors or des ign parameters considered are: 1) normalization methods; 2) the number of GRNNs forfusion; and 3) fusion methods. The number of levels for each of the three factors is set as follows: three levels for normalization methods, that is, min\u2013max linear normalization to [0 1], min\u2013max linear normalization to [ -1 1], and mean and variance normalization; two levels for the number ofGRNNs, that is, three and ?ve, where the ?ve spread factors for ?ve GRNNs are 5th, 25th, 50th, 75th, and 95th percentiles, respectively, of the nearest dista nces of all training samples to the rest of samples; and three levels for fusion methods, that is, mean, median, and trimmed mean [54]. A full factorial DOE design results in a total of 18 experiments. Analysis of variance (ANOV A) was performed on the sMAPEs of the 18 experiments. Table III shows the ANOV A results. From Table III one can see that with p-value greater than 0.05, our model is generally not sensitive to the three design factors considered, that is, normalization, the numberof GRNNs, or fusion methods. Once again, we have to be cautious about generalizing our conclusions here until a more comprehensive DOE study is completed. C. Limitations The main limitation of the modeling scheme proposed in this paper is that, since it is designed for automatically model- ing large-scale time series, performance of our model may notTABLE III ANOV A R ESULTS Source  DF Sum of Squares Mean Square F- value p- value Normalization methods 2  3.8\u00d710-6 1.9\u00d710-6 0.44  0.653 Number of GRNNs 1  7.9\u00d710-6 7.9\u00d710-6 1.83  0.201 Fusion methods 2  1.5\u00d710-5 7.7\u00d710-6 1.78  0.210 Note: DF=degree of freedom. always be superior for certain time series over other models that are carefully handcrafted speci?cally for the series. Also,not all of the design parameters in our model are optimally chosen, but rather designed in ad hoc fashion. It would be good to extend our modeling scheme by including an optimizer as a wrapper, so that the major ity of the design parameters can be automatically optimized based on the characteristics of the time series. In particular, we have not exhaustively explored the preprocessing strategies for better handling trend, seasonality, and other nonstationary features. However, ourmodeling scheme is ?exible enough to incorporate those preprocessing strategies. In addition, our modeling scheme has only been validated on the NN3 competition data, which consists of various monthly, business-type time series. Hence the conclusions drawn in this paper may not generalize wellover nonbusiness time series. It would be interesting to ?nd out whether or not our modeling scheme works equally well for nonbusiness-type series. We envision that our automatic ANN modeling scheme proposed here can potentially bene?t the TSF community in the following three aspects: 1) as a tool for large-scale TSF research, where a large number of series are involved; 2) as an initial model for users to gain some general knowledge of the series, when dealing with single ora small number of series; 3) as a default setting in forecasting tools, where users have options of choosing different modeling strategiesor design con?gurations. VII. C ONCLUSION ANNs have been actively used for various TSF applica- tions for decades. However, we are still lacking a systematic ANN modeling process and strategy. This paper attempted todevelop an automatic ANN modeling scheme that is based on a special type of network, GRNN. By introducing sev- eral design strategies, we were able to make our automatic modeling scheme effective for TSF. The reasonably good performance of our model on the NN3 competition data thatconsisted of heterogeneous forecasting problems validated the applicability and the effectiveness of our model for large- scale TSF. The following are the main conclusions drawn inthis paper. 1) GRNN is potentially a good candidate for automatic ANN modeling for TSF, thanks to several of its unique properties (e.g., single design parameter). Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:03:03 UTC from IEEE Xplore.  Restrictions apply. 1038 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 23, NO. 7, JULY 2012 2) Our automatic ANN modeling scheme that has GRNN as its base model is largely robust with respect to mostof the design parameters, wh ich makes it feasible for automatically modeling large-scale time series. 3) Computationally, our modeling scheme is reasonably ef?cient because of the property of fast learning of GRNNs and the design strategies carefully adopted in this paper. Automating ANN modeling is certainly a challenging task and has a long way to go before maturing. As an initial effort toward automatic ANN modeling, we employed relatively sim-ple strategies in both preprocessing and ANN modeling steps. Many improvements can be made to our modeling scheme to make it much more effective and ef?cient. For example, we can extend out input selection to include more comprehensive feature selection methods discussed in Section IV-B for identi-fying more salient inputs (both contiguous and noncontiguous lags). As stated earlier, a more thorough sensitive analysis via DOE to assess the robustness of our modeling scheme todifferent design con?gurations is certainly worth pursuing. Our future work may also include applying the modeling scheme to other large-scale datasets, for example, the M3 competition data. A CKNOWLEDGMENT The author would like to thank the NN3 Competition organizers for allowing use of the data in this paper. The author would also like to thank the anonymous reviewers for their constructive comments. REFERENCES [1] G. P. Zhang, B. E. Patuwo, and M. Y . Hu, \u201cForecasting with arti?cial neural networks: The state of the art,\u201d Int. J. Forecast. , vol. 14, pp. 35\u201362, Mar. 1998. [2] S. Crone and P. Grafeille, \u201cAn eval uation framework for publications on arti?cial neural networks in sales forecasting,\u201d in Proc. Int. Conf. Artif. Intell. , Las Vegas, NV , Jun. 2004, pp. 221\u2013227. [3] T. Hill, M. O\u2019Connor, and W. Remus, \u201cNeural network models for times series forecasting,\u201d Manage. Sci. , vol. 42, no. 7, pp. 1082\u20131092, Jul. 1996. [4] N. R. Swanson and H. White, \u201cForecasting economic time series using ?exible versus ?xed speci?cation and linear versus nonlinear econometric models,\u201d Int. J. Forecast. , vol. 13, no. 4, pp. 439\u2013461, 1997. [5] W. Zhang, Q. Cao, and M. J. Schnied erjans, \u201cNeural network earning per share forecasting models: A comparative analysis of alternative methods,\u201d Decision Sci. , vol. 35, no. 2, pp. 205\u2013237, 2004. [6] S. Heravi, D. R. Osborn, and C. R. Birchenhall, \u201cLinear versus neural network forecasts for European i ndustrial production series,\u201d Int. J. Forecast. , vol. 20, no. 3, pp. 435\u2013446, Jul.\u2013Sep. 2004. [7] L. J. Callen, C. C. Kwan, P. C. Yip, and Y . Yuan, \u201cNeural network forecasting of quarterly accounting earnings,\u201d Int. J. Forecast. , vol. 12, no. 4, pp. 475\u2013482, 1996. [8] M. Adya and F. Collopy, \u201cHow effective are neural networks at fore- casting and prediction? A review and evaluation,\u201d Int. J. Forecast. ,v o l . 17, nos. 5\u20136, pp. 481\u2013495, Nov. 1998. [9] M. Nelson, T. Hill, T. Renas, and M. O\u2019Connor, \u201cTime series forecasting using NNs: Should the data be deseasonalized ?rst?\u201d J. Forecast. ,v o l . 18, no. 5, pp. 359\u2013367, 1999. [10] G. P. Zhang and D. M. Kline, \u201cQuarterly time series forecasting with neural networks,\u201d IEEE Trans. Neural Netw. , vol. 18, no. 6, pp. 1800\u2013 1814, Jun. 2007. [11] S. D. Balkin and J. K. Ord, \u201cAutomatic neural network modeling for univariate time series,\u201d Int. J. Forecast. , vol. 16, no. 4, pp. 509\u2013515, 2000.[12] S. F. Crone, M. Hibon, and K. Nikolopoulos, \u201cAdvances in forecasting with neural networks? Empirical evidence from the NN3 competitionon time series prediction,\u201d Int. J. Forecast. , vol. 27, no. 3, pp. 635\u2013660, 2011. [13] S. Makridakis and M. Hibon, \u201cThe M3-competition: Results, conclu- sions, and implications,\u201d Int. J. Forecast. , vol. 16, no. 4, pp. 451\u2013476, 2000. [14] A. F. Atiya, S. M. El-Shoura, S. I. Shaheen, and M. S. El-Sherif, \u201cA comparison between neural networ k forecasting techniques-case study: River ?ow forecasting,\u201d IEEE Trans. Neural Netw. , vol. 10, no. 2, pp. 402\u2013409, Feb. 1999. [15] D. Vere-Jones, \u201cForecasting earthquakes and earthquake risk,\u201d Int. J. Forecast. , vol. 11, no. 4, pp. 503\u2013538, Dec. 1995. [16] I. Maqsood, M. R. Khan, and A. Abraham, \u201cAn ensemble of neural networks for weather forecasting,\u201d Neural Comput. Appl. , vol. 13, no. 2, pp. 112\u2013122, 2004. [17] H. S. Hippert, C. E. Pedreira, and R. C. Souza, \u201cNeural networks for short-term load forecasting: A review and evaluation,\u201d IEEE Trans. Power Syst. , vol. 16, no. 1, pp. 44\u201355, Feb. 2001. [18] J. Farway and C. Chat?eld, \u201cTime series forecasting with neural net- works: A comparative study using the airline data,\u201d Appl. Stat. , vol. 47, no. 2, pp. 231\u2013250, 1995. [19] J. Connors, D. Martin, and L. Atlas, \u201cRecurrent neural networks and robust time series prediction,\u201d IEEE Trans. Neural Netw. , vol. 5, no. 2, pp. 240\u2013254, Mar. 1994. [20] C. M. Kuan and T. Liu, \u201cForecasting exchange rates using feedforward and recurrent neural networks,\u201d J. Appl. Econ. , vol. 10, no. 4, pp. 347\u2013 364, 1995. [21] C. L. Giles, S. Lawrence, and A. C. Tsoi, \u201cNoisy time series prediction using a recurrent neural network and grammatical inference,\u201d Mach. Learn. , vol. 44, nos. 1\u20132, pp. 161\u2013183, 2001. [22] A. G. Parlos, O. T. Rais, and A. F. Atiya, \u201cMulti-step-ahead prediction using dynamic recurrent neural networks,\u201d Neural Netw. , vol. 13, no. 7, pp. 765\u2013786, Sep. 2000. [23] X. B. Yan, Z. Wang, S. H. Yu, and Y . J. Li, \u201cTime series forecasting with RBF neural network,\u201d in Proc. IEEE Int. Conf. Mach. Learn. Cybern. , vol. 8. Guangzhou, China, Aug. 2005, pp. 4680\u20134683. [24] F. Liang, \u201cBayesian neural networks for nonlinear time series forecast- ing,\u201d Stat. Comput. , vol. 15, no. 1, pp. 13\u201329, Jan. 2005. [25] M. Firat, \u201cComparison of arti?cial intelligence techniques for river ?ow forecasting,\u201d Hydrol. Earth Syst. Sci. , vol. 12, no. 1, pp. 123\u2013139, 2008. [26] Y . Bodyanskiy, I. Pliss, and O. V ynokurova, \u201cAdaptive wavelet-neuro- fuzzy network in the forecasting and emulation tasks,\u201d Int. J. Inf. Theories Appl. , vol. 15, no. 1, pp. 47\u201355, 2008. [27] N. K. Ahmed, A. F. Atiya, N. E. Gayar, and H. El-Shishiny, \u201cAn empiri- cal comparison of machine learning models for time series forecasting,\u201d Econ. Rev. , vol. 29, nos. 5\u20136, pp. 594\u2013621, 2010. [28] G. B. Huang, Q. Y . Zhu, and C. K. Siew, \u201cExtreme learning machine: Theory and applications,\u201d Neurocomputing , vol. 70, nos. 1\u20133, pp. 489\u2013 501, Dec. 2006. [29] A. Sorjamaa, Y . Miche, R. Weiss, and A. Lendasse, \u201cLong-term predic- tion of time-series using NNE-based projection and OP-ELM,\u201d in Proc. IEEE World Congr. Comput. Intell. , Jun. 2008, pp. 2674\u20132680. [30] E. J. Bayro-Corrochano and N. Arana-Daniel, \u201cClifford support vector machines for classi?cation, regression, and recurrence,\u201d IEEE Trans. Neural Netw. , vol. 21, no. 11, pp. 1731\u20131746, Nov. 2010. [31] S. Hu, G. Dai, G. A. Worrell, Q. Dai, and H. Liang, \u201cCausality analysis of neural connectivity: Critical ex amination of existing methods and advances of new methods,\u201d IEEE Trans. Neural Netw. , vol. 22, no. 6, pp. 829\u2013844, Jun. 2011. [32] J. S. Armstrong, \u201cCombining forecasts,\u201d in Principles of Forecasting: A Handbook for Researchers and Practitioners , J. S. Armstrong Ed. Norwell, MA: Kluwer, 2001. [33] R. T. Clemen, \u201cCombining forecasts: A review and annotated bibliog- raphy,\u201d Int. J. Forecast. , vol. 5, no. 4, pp. 559\u2013583, 1989. [34] H. Zou and Y . H. Yang, \u201cCombining time series models for forecasting,\u201d Int. J. Forecast. , vol. 20, no. 1, pp. 69\u201384, 2004. [35] L. K. Hansen and P. Salamon, \u201cNeural network ensembles,\u201d IEEE Trans. Pattern Anal. Mach. Learn. , vol. 12, no. 10, pp. 993\u20131001, Oct. 1990. [36] C. P. Lim and W. Y . Goh, \u201cThe application of an ensemble of boosted Elman networks to time series prediction: A benchmark study,\u201d Int. J. Comput. Intell. , vol. 3, no. 2, pp. 119\u2013126, 2006. [37] M. Assaad, R. Bone, and H. Cardot, \u201cA new boosting algorithm for improved time-series forecasting with recurrent neural networks,\u201d Inf. Fusion , vol. 9, no. 1, pp. 41\u201355, Jan. 2008. Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:03:03 UTC from IEEE Xplore.  Restrictions apply. YAN: TOWARDS AUTOMATIC TIME-SERIES FORECASTING 1039 [38] S. Haykin, Neural Networks: A Comprehensive Foundation , 2nd ed. Englewood Cliffs, NJ: Prentice-Hall, 1990. [39] D. F. Specht, \u201cA general regression neural network,\u201d IEEE Trans. Neural Netw. , vol. 2, no. 6, pp. 568\u2013576, Nov. 1991. [40] H. Husain, M. Khalid, and R. Yusof, \u201cAutomatic clustering of general- ized regression neural network by similarity index based fuzzy C-meansclustering,\u201d in Proc. IEEE Region 10 Conf. (TENCON) ,v o l .2 .N o v . 2004, pp. 302\u2013305. [41] W. M. Li, Y . Luo, Q. Zhu, J. W. Liu, and J. J. Le, \u201cApplications of AR*- GRNN model for ?nancial time series forecasting,\u201d Neural Comput. Appl. , vol. 17, nos. 5\u20136, pp. 441\u2013448, 2008. [42] D. X. Niu, H. Q. Wang, and Z. H. Gu, \u201cShort-term load forecasting using general regression neural network,\u201d in Proc. Int. Conf. Mach. Learn. Cybern. , vol. 7. Guangzhou, China, Aug. 2005, pp. 4076\u20134082. [43] M. M. Tripathi, K. G. Upadhyay, an d S. N. Singh, \u201cShort-term load fore- casting using generalized regression and probabilistic neural networks in the electricity market,\u201d Electr. J. , vol. 21, no. 9, pp. 24\u201334, Nov. 2008. [44] B. Kim, D. W. Lee, K. Y . Parka, S. R. Choi, and S. Choi, \u201cPrediction of plasma etching using a randomi zed generalized regression neural network,\u201d Vacuum , vol. 76, no. 1, pp. 37\u201343, Oct. 2004. [45] C. Chat?eld, The Analysis of Time Series: An Introduction ,6 t he d . Boston, MA: Chapman & Hall, 2004. [46] M. Adya, F. Collopy, J. S. Armstrong, and M. Kennedy, \u201cAutomatic identi?cation of time series features for rule-based forecasting,\u201d Int. J. Forecast. , vol. 17, no. 2, pp. 143\u2013157, 2001. [47] M. Qi and P. G. Zhang, \u201cTrend time-series modeling and forecasting with neural networks,\u201d IEEE Trans. Neural Netw. , vol. 19, no. 5, pp. 808\u2013816, May 2008. [48] B. Gavin, W. Jeremy, H. Rachel, and Y . Xin, \u201cDiversity creation methods: A survey and categorization,\u201d J. Inf. Fusion , vol. 6, pp. 5\u2013 20, Dec. 2005. [49] P. Bonissone, K. Goebel, and W. Yan , \u201cClassi?er fusion using triangular norms,\u201d in Proc. 5th Int. Workshop Multiple Classi?er Syst. , Cagliari, Italy, Jun. 2004, pp. 154\u2013163. [50] L. Xu, A. Krzyzak, and C. Y . Suen, \u201cMethods of combining multiple classi?ers and their applications to handwriting recognition,\u201d IEEE Trans. Syst. Man Cybern. , vol. 22, no. 3, pp. 418\u2013435, May\u2013Jun. 1992. [51] S. Cho and J. Kim, \u201cCombining multiple neural networks by fuzzy integral for robust classi?cation,\u201d IEEE Trans. Syst. Man Cybern. ,v o l . 25, no. 2, pp. 380\u2013384, Feb. 1995. [52] A. Al-Aniand and M. Deriche, \u201cA new technique for combining multiple classi?ers using the Dempster -Shafer theory of evidence,\u201d J. Artif. Intell. Res., vol. 17, no. 1, pp. 333\u2013361, Jul. 2002. [53] L. Kuncheva, Combining Pattern Classi?ers: Methods and Algorithms . New York: Wiley, 2004. [54] V . R. R. Jose and R. L. Winkler, \u201cSimple robust averages of forecasts: Some empirical results,\u201d Int. J. Forecast. , vol. 24, no. 1, pp. 163\u2013169, Jan.\u2013Mar. 2008.[55] M. Dash and H. Liu, \u201cFeature selection for classi?cation,\u201d Intell. Data Anal. , vol. 1, no. 3, pp. 131\u2013156, 1997. [56] R. Kohavi and H. J. George, \u201cWrappers for feature subset selection,\u201d Artif. Intell. , vol. 97, nos. 1\u20132, pp. 273\u2013324, Dec. 1997. [57] W. Huang, Y . Nakamor, and S. W ang, \u201cA general approach based on autocorrelation to determine input vari ables for neural networks for time series forecasting,\u201d J. Syst. Sci. Complex. , vol. 14, no. 3, pp. 297\u2013305, 2004. [58] J. Tikka, A. Lendasse, and J. Hollm en, \u201cInput selection for long-term prediction of time series,\u201d in Proc. 8th Int. Work-Conf. Artif. Neural Netw. , 2005, pp. 1002\u20131009. [59] S. F. Crone and K. Nikolopoulos, \u201cInput variable selection for time series prediction with neural networks-an evaluation of visual, autocorrelationand spectral analysis for varying seasonality,\u201d in Proc. 1st Eur. Symp. Time Series Predict. , Helsinki, Finland, 2007, pp. 1\u201311. [60] A. Sorjamaaa, H. Jin, N. Reyhania, Y . Jia, and A. Lendasse, \u201cMethod- ology for long-term prediction of time series,\u201d Neurocomputing , vol. 70, nos. 16\u201318, pp. 2861\u20132869, Oct. 2007. [61] R. J. Hyndman and A. B. Koehler, \u201cAnother look at measures of forecast accuracy,\u201d Int. J. Forecast. , vol. 22, no. 4, pp. 679\u2013688, 2006. [62] L. J. Tashman, \u201cOut-of-sample tests of forecasting accuracy: An analysis and review,\u201d Int. J. Forecast. , vol. 16, no. 4, pp. 437\u2013450, 2000. [63] F. Wilcoxon, \u201cIndividual com parisons by ranking methods,\u201d Biometrics , vol. 1, no. 6, pp. 80\u201383, Dec. 1945. [64] M. Hollander and D. Wolfe, Nonparametric Statistical Methods .N e w York: Wiley, 1999. Weizhong Yan (M\u201904\u2013SM\u201908) received the Ph.D. degree in mechanical engineering from Rensselaer Polytechnic Institute, Troy, NY , in 2002. He has been with General Electric Company, Fair?eld, CT, since 1998. Currently, he is a SeniorResearcher with the Machine Learning Laboratory, GE Global Research Center, Niskayuna, NY . His specialties include applying advanced data-drivenanalytic techniques to anomaly detection, diagnos-tics, and prognostics & health management of indus- trial assets, such as jet engines, gas turbines, and oil and gas equipment. He has authored ove r 70 publications in referred journals and conference proceedings and has ?led over 25 U.S. patents. His current research interests include large-scale analytics, ensemble learning, and time series forecasting. Dr. Yan is an Editor of the International Journal of Arti?cial Intelligence, and an Editorial Board Member of the International Journal of Prognostics and Health Management . Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:03:03 UTC from IEEE Xplore.  Restrictions apply. ", "16": "REVIEW ARTICLE Deep Learning for Time Series Forecasting: A Survey Jose\u00b4F. Torres,1,{Dalil Hadjout,2,{Abderrazak Sebaa,3,4Francisco Marti \u00b4nez-A \u00b4lvarez,1and Alicia Troncoso1,* Abstract Time series forecasting has become a very intensive ?eld of research, which is even increasing in recent years. Deep neural networks have proved to be powerful and are achieving high accuracy in many application ?elds. For these reasons, they are one of the most widely used methods of machine learning to solve problems dealing with big data nowadays. In this work, the time series forecasting problem is initially formulated along with its mathematical fundamentals. Then, the most common deep learning architectures that are currently being successfully applied to predict time series are described, highlighting their advantages and limitations. Particular attention is given to feed forward networks, recurrent neural networks (including Elman, long-short term memory, gated recurrent units, andbidirectional networks), and convolutional neural networks. Practical aspects, such as the setting of values for hyper- parameters and the choice of the most suitable frameworks, for the successful application of deep learning to time series are also provided and discussed. Several fruitful research ?elds in which the architectures analyzed have obtained a good performance are reviewed. As a result, research gaps have been identi?ed in the literature for several domains of application, thus expecting to inspire new and better forms of knowledge. Keywords: big data; deep learning; time series forecasting Introduction The interest in processing huge amounts of data has ex- perienced a rapid increase during the past decade due to the massive deployment of smart sensors1or the so- cial media platforms,2which generate data on a continu- ous basis.3However, this situation poses new challenges, such as storing these data in disks or making available the required computational resources. Big data analytics emerges, in this context, as an es- sential process focused on ef?ciently collecting, organiz- ing, and analyzing big data with the aim of discovering patterns and extracting valuable information.4In most organizations, this helps to identify new opportunities and making smarter moves, which leads to more ef?- cient operations and higher pro?ts.5 From all the learning paradigms that are cur- rently being used in big da ta, deep learning high- lights because of its outstanding performance as the scale of data increases.6Most of the layer computa-tions in deep learning can be done in parallel by, for instance, powerful graphic processing units (GPUs). That way, scalable distributed models are easier to be built and they provide better accuracy at a much higher speed. Higher depth allows for more complex non-linear functions but, in turn, with higher compu- tational costs.7 Deep learning can be applied to numerous research ?elds. Applications to both supervised and unsuper- vised problems can be abundantly found in the litera- ture.8Pattern recognition and classi?cation were the ?rst and most relevant uses of deep learning, achievinggreat success in speech recognition, text mining, or image analysis. Nevertheless, the application to regres- sion problems is becoming quite popular nowadays mainly due to the development of deep-learning archi- tectures particularly conceived to deal with data indexed over time. Such is the case of time series and, more spe- ci?cally, time series forecasting. 9 1Data Science and Big Data Lab, Pablo de Olavide University, Seville, Spain. 2Department of Commerce, SADEG Company (Sonelgaz Group), Bejaia, Algeria. 3LIMED Laboratory, Faculty of Exact Sciences, University of Bejaia, Bejaia, Algeria. 4Higher School of Sciences and Technologies of Computing and Digital, Bejaia, Algeria. {Equally contributing authors. *Address correspondence to: Alicia Troncoso, Data Science and Big Data Lab, Pablo de Olavide University, Seville ES-41013, Spain, E-mail: atrolor@upo.esBig Data Volume 9, Number 1, 2021\u00aaMary Ann Liebert, Inc. DOI: 10.1089/big.2020.0159 3 Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  A time series is a set of measures collected at even in- tervals of time and ordered chronologically.10Given this de?nition, it is hard to ?nd physical or chemical phenomena without variables that evolve over time. For this reason, the proposal of time series forecasting approaches is fruitful and can be found in almost all scienti?c disciplines. Statistical approaches have been used from the 1970s onward, especially those based on the Box-Jenkins methodology.11With the appearance of machine learn- ing and its powerful regression methods,12many mod- els were proposed as outperforming the former, which have remained as baseline methods in most research works. However, methods based on deep learning are currently achieving superior results and much effort is being put into developing new architecture. For all that has been mentioned earlier, the primary motivation behind this survey is to provide a compre- hensive understanding of deep-learning fundamentals for researchers interested in the ?eld of time series fore- casting. Further, it overviews several applications in which these techniques have been proven successful and, as a result, research gaps have been identi?ed in the literature and are expected to inspire new and bet- ter forms of knowledge. Although other surveys discussing deep-learning properties have been publishe dd u r i n gt h ep a s ty e a r s ,t h e majority of them provided a general overview of both the- ory and applications to time series forecasting. Thus, Zhang et al.13reviewed emerging researches of deep- learning models, including th eir mathematical formula- tion, for big data feature learning. Another remarkable work can be found in Ref.,14in which the authors intro- duced the time series classi?cation problem and provided an open-source framework with implemented algorithms and the University of East Anglia/University of Californiain Riverside repository. 15Recently, Mayer and Jacobsen published a survey about sca l a b l ed e e pl e a r n i n go nd i s - tributed infrastructures, in which the focus was placed on techniques and tools, along with a smart discussion about the existing challenges in this ?eld.16 The rest of the article is structured as follows. The forecasting problem and mathematical formulation for time series can be found in the Problem De?nition sec- tion. Deep-Learning Architectures section introduces the deep-learning architectures typically used in the con- text of time series forecasting. Practical Aspects sectionprovides information about several practical aspects (in- cluding implementation, hyper-parameter tuning, or hardware resources) that must be considered when ap-plying deep learning to forecast time series. Applications section overviews the most relevant papers, sorted by ?elds, in which deep learning has been applied to fore- cast time series. Finally, the lessons learned and the con- clusions drawn are discussed in the Conclusions section. Problem De?nition This section provides the time series de?nition (TimeSeries De?nition section), along with a description ofthe main time series components (Time Series Compo- nents section). The mathema tical formulation for the time series forecasting problem is introduced in the Mathematical Formulation section. Final remarks about the length of the time seri es can be found in Short- and Long-Time Series Forecasting section. Time series de?nition A time series is de?ned as a sequence of values, chrono-logically ordered, and observed over time. Although the time is a variable measured on a continuous basis, thevalues in a time series are sampled at constant intervals (?xed sampling frequency). This de?nition holds true for many applications, but not every time series can be modeled in this way, due to some of the following reasons: 1. Missing data in time series is a very common problem due to the reliability of data collection. To deal with these values, there are a lot of strat- egies but those based on imputing the missing in- formation and on omitting the entire record are the most widely used. 17 2. Outlying data is also an issue that appears very frequently in time series. Methods based on robust statistics must be chosen to remove these values or, simply, to incorporate them into the model.18 3. When data are collected at irregular time periods, they can be called either unevenly spaced time se- ries or, if big enough, data streams.3 Some of these issues can be handled natively by the used model, but if the data are collected irregularly, this should be accounted for in the model. In this survey, the time series preprocessing is out of scope, but please refer to this work for detailed information.19 Time series components Time series are usually characterized by three compo-nents: trend, seasonality, and irregular components, also known as residuals. 20Such components are de- scribed later:4 TORRES ET AL Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  1. Trend. It is the general movement that the time series exhibits during the observation period, without considering seasonality and irregularities. In some texts, this component is also known as long-term variation. Although there are different kinds of trends in time series, the most popular are linear, exponential, or parabolic ones. 2. Seasonality. This component identi?es variations that occur at speci?c regular intervals and may provide useful information when time periods ex- hibit similar patterns. It integrates the effects rea- sonably stable along with the time, magnitude, and direction. Seasonality can be caused by several factors such as climate or economical cycles, or even festivities. 3. Residuals. Once the trend and cyclic oscillations have been calculated and removed, some residual values remain. These va lues can be, sometimes, high enough to mask the trend and the seasonality. In this case, the term outlier is used to refer these residuals, and robust statistics are usually applied to cope with them.20These ?uctuations can be of diverse origin, which makes the prediction almost impossible. However, if by any chance, this origin can be detected or modeled, they can be thought of precursors in trend changes. A time series is an aggregate of these three compo- nents. Real-world time series present a meaningful ir- regular component and are not stationary (mean and variance are not constant over time), turning this com- ponent into the most challenging one to model. For thisreason, to make accurate predictions for them is ex- tremely dif?cult, and many forecasting classical meth- ods try to decompose the target time series into these three components and make predictions for all of them separately. The effectiveness of one technique or another is assessed according to its capability of forecasting this particular component. It is for the analysis of this com- ponent where data mining-based techniques have been shown to be particularly powerful.Time series can be graphically represented. In particu- lar, the x-axis identi?es the time, whereas the y-axis iden- ti?es the values recorded at punctual time stamps ( x t). This representation allows the visual detection of the most highlighting features of a series, such as oscilla- tions amplitude, existing seasons, and cycles or the ex- istence of anomalous data or outliers. Figure 1 depictsan time series, x t, using an additive model with linear seasonality with constant frequency and amplitude over time, represented by the function sin(x); linear trend where changes over time are consistently made by the same amount, represented by the function 0:0213 x; and residuals, represented by random num- bers in the interval [0,0:1]. Mathematical formulation Time series models can be either univariate (one time- dependent variable) or multivariate (more than one time-dependent variables). Although models may dra- matically differ between a univariate and a multivariate system, the majority of the deep-learning models can handle indistinctly with both of them. On the one hand, let y=y(t/C0L),...,y(t/C01), y(t),y(t\u00fe1),...,y(t\u00feh)be a given univariate time series with Lvalues in the historical data, where each y(t/C0i), for i=0,...,L, represents the recorded value of the variable yat time t/C0i. The forecasting process consists of estimating the value of y(t\u00fe1), denoted by^y(t\u00fe1), with the aim of minimizing the error, which is typically represented as a function of y(t\u00fe1)/C0^y(t\u00fe1). This prediction can be made also when the horizon of prediction, h, is greater than one, that is, when the objective is to predict the hnext values after y(t), that is, y(t\u00fei),w i t h i=1,...,h. In this situ- ation, the best prediction is reached when the function +h i=1(y(t\u00fei)/C0^y(t\u00fei))is minimized. On the other hand, multivariate time series can be expressed as follows, in the matrix form: where yi(t/C0m)identi?es the set of time series, with i=f1,2,...,ng, being m=f0,1,...,Lgthe historical data and current sample and m=f/C01,/C02,...,/C0hgy1 y2 ... yn yT0 BBBBB@1 CCCCCA=y 1(t/C0L)... y1(t/C01)y1(t)y1(t\u00fe1)... y1(t\u00feh) y2(t/C0L)... y2(t/C01)y2(t)y2(t\u00fe1)... y2(t\u00feh) ... ... ... ... ... ... ... yn(t/C0L)... yn(t/C01)yn(t)yn(t\u00fe1)... yn(t\u00feh)0 BBBB@1 CCCCA,( 1)DEEP LEARNING FOR TIME SERIES FORECASTING 5 Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  FIG. 1. Illustrative time series, showing seasonality, trend, and residuals. 6 Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  the future hvalues. Usually, there is one target time series (the one to be predicted) and the remaining ones are denoted as independent time series. Short- and long time series forecasting Another key issue is the length of the time series. Depending on the number of samples, long- or short time series can be de?ned. It is well known that the Box-Jenkins\u2019 models do not work well for long time se- ries mainly due to the time-c onsuming process of param- eters optimization and to th ei n c l u s i o no fi n f o r m a t i o n , w h i c hi sn ol o n g e ru s e f u lt om odel the current samples.9 How to deal with these issues is highly related to the purpose of the model. Flexible nonparametric modelscould be used, but this still assumes that the model struc- ture will work over the whole period of the data, which is not always true. A better approach consists of allowing the model to vary over time. This can be done by ei- ther adjusting a parametric model with time-varying parameters or adjusting a nonparametric model with a time-based kernel. But if the goal is only to forecast a few observations, it is simpler to ?t a model with the most recent samples and transforming the long time series into a short one. 21 Although a preliminary approach to use a distrib- uted ARIMA model has been recently published,22 it remains challenging to deal with such time serieswith classical forecasting methods. However, a number of machine-learning algorithms adapted to deal with ultra-long time series, or big data time series, havebeen published in recent years. 23These models make use of clusters of machines or GPUs to overcome the limitations described in the previous paragraphs. Deep-learning models can deal with time series in a scalable way and provide accurate forecasts.24Ensem- ble learning can also be useful to forecast big data time series25or even methods based on well-established methods such as nearest neighbours26,27or pattern se- quence similarity.28 Deep-Learning Architectures This section provides a theoretical tour of deep learn-ing for time series prediction in big data environments. First, a description of the most used architectures in the literature to predict time series is made. Then, a state-of-the-art analysis is carried out, where the deep-learning works and f rameworks to deal with big data are described. Deep feed forward neural network Deep feed forward neural networks (DFFNN), alsocalled multi-layer perceptron, arose due to the inability of single-layer neural networks to learn certain func- tions. The architecture of a DFFNN is composed of an input layer, an output layer, and different hidden layers,as shown in Figure 2. In addition, each hidden layer has a certain number of neurons to be determined. The relationships between the neurons of two con- secutive layers are modeled by weights, which are calcu- lated during the training phase of the network. In FIG. 2. Basic architecture of a DFFNN for time series forecasting. DFFNN, deep feed-forward neural network.DEEP LEARNING FOR TIME SERIES FORECASTING 7 Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  particular, the weights are computed by minimizing a cost function by means of gradient descent optimization methods. Then, the back-propagation algorithm is used to calculate the gradient of the cost function. Once the weights are computed, the values of the output neurons of the network are obtained by using a feed-forward process de?ned by the following equation: al=g(Wl aal/C01\u00febl a), ( 2) where alare the activation values in the l-th layer, that is, a vector composed of the values of the neurons of the l-th layer, Wl aandbl aare the weights and bias corresponding to the l-th layer, and gis the activation function. There- fore, the alvalues are computed by using the activation values of the l/C01l a y e r , al/C01,a si n p u t .I nt i m es e r i e sf o r e - casting, the recti?ed linear unit function is commonly used as activation function for all layers, except for the output layer to obtain the predicted values, which gener- ally uses the hyperbolic tangent function ( tanh). For all network architectures, the values of some hyper-parameters have to be chosen in advance. These hyper-parameters, such as the number of layers and the number of neurons, de?ne the network architecture, and other hyper-parameters, such as the learning rate,the momentum, and number of iterations or mini- batch size, among others, have a great in?uence on the convergence of the gradient descend methods. The optimal choice of these hyper-parameters is impor- tant, as these values greatly in?uence the prediction re- sults obtained by the network. The hyper-parameters will be discussed in more detail in the Hyper-Parameter Optimization section. Recurrent neural network Recurrent neural networks (RNNs) are speci?callydesigned to deal with sequential data such as sequences of words in problems related to machine translation, audio data in speech recognition, or time series in fore- casting problems. All these problems present a common characteristic, whi ch is that the data have a temporal de- pendency between them. Traditional feed-forward neuralnetworks cannot take into account these dependencies, and RNNs arise precisely to address this problem. 29 Therefore, the input data in the architecture of a RNNare both past and current data. There are different types of architectures, depending on the number of data inputs and outputs in the network, such as one to one (one input and one output), one to many (one input and many outputs), many to one (many inputsand one output), and many to many (many inputs and outputs). The most common RNNs are many to one for classi?cation problems or many to many for machine translation or time series forecasting for instance. In ad- dition, for the case of a time series, the length of the inputdata sequence is usually different from the size of the out- put data sequence that usually is the number of samples to be predicted. A basic RNN architecture to address the forecasting of time ser ies is shown in Figure 3. x iand ^xi are the actual and predicted values of the time series at time i,a n d his the number of samples to be predicted, called prediction horizon. The most widely used RNNs for time series forecast- ing are brie?y described later. Elman RNN. The Elman network (ENN) was the ?rst RNN and it incorporated the tstate of a hidden unit to make predictions in data sequences.30The ENN con- sists of a classical one-layer feed-forward network but the hidden layer is connected to a new layer, called con- text layer, using ?xed weights equal to one, as shown in Figure 4. The main function of the neurons of thisFIG. 3. Basic architecture of an RNN for time series forecasting. RNN, recurrent neural network. FIG. 4. Architecture of an ENN for time series forecasting. ENN, Elman network.8 TORRES ET AL Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  context layer is to save a copy of the values of activation of the neurons of the hidden layer. Then, the model is de?ned by: at=g(Waxt\u00feUaat/C01\u00feba), ( 3) where atare the values of the neurons in the tstate in the hidden layer, xtis the current input, at/C01is the in- formation saved in the context hidden units, Wa,Ua, andbaare the weights and the bias, and gis the activa- tion function. Long short-term memory. Standard basic RNNs suf- fer the vanishing gradient problem, which consists of the gradient decreasing as the number of layers in- creases. Indeed, for deep RNNs with a high number of layers, the gradient practically becomes null, prevent- ing the learning of the network. For this reason, these networks have a short-term memory and do not obtain good results when dealing with long sequences that re-quire memorizing all the information contained in the complete sequence. Long short-term memory (LSTM) recurrent networks emerge to solve the vanishing gradi- ent problem. 31For this purpose, LSTM uses three gates to keep longstanding relevant information and discard irrelevant information. These gates are Gfforget gate, Guupdate gate, and Gooutput gate. Gfdecides what in- formation should be thrown away or saved. A value close to 0 means that the past information is forgottenwhereas a value close to 1 means that it remains. G ude- cides what new information ~ctto use to update the ct memory state. Thus, ctis updated by using both Gf andGu. Finally, Godecides which is the output value that will be the input of the next hidden unit. The information of the at/C01previous hidden unit and the information of the xtcurrent input is passed through thersigmoid activation function to compute all the gate values and through the tanh activation function to com- pute the ~ctnew information, which will be used to up- date. The equations de?ning an LSTM unit are: ect=tanh ( Wc[at/C01,xt]\u00febc), ( 4) Gu=r(Wu[at/C01,xt]\u00febu), ( 5) Gf=r(Wf[at/C01,xt]\u00febf), ( 6) Go=r(Wo[at/C01,xt]\u00febo), ( 7)ct=Gu\u00b7~ct\u00feGf\u00b7ct/C01,( 8) at=Go\u00b7tanh ( ct), ( 9) where Wu,Wf, and Wo, and bu,bf, and boare the weights and biases that govern the behavior of theG u,Gf, andGogates, respectively, and Wcandbcare the weights and bias of the ~ctmemory cell candidate. Figure 5 shows a picture of how a hidden unit works in an LSTM recurrent network. The \u00b7and+operators mean an element-wise vectors multiplication and sum. Gated recurrent units. Recurrent networks with gated recurrent units (GRU) are long-term memory net- works such as LSTMs but they emerged in 201432,33 as a simpli?cation of LSTMs due to the high computa- tional cost of the LSTM networks. GRU is one of the most commonly used versions that researchers have converged on and found to be robust and useful for many different problems. The use of gates in RNNs has made it possible to improve capturing of very long-range dependencies, making RNNs much more effective. The LSTM is more powerful and more effec- tive since it has three gates instead of two, but the GRU is a simpler model and it is computationally faster as it only has two gates, Guupdate gate and Grrelevance gate as shown in Figure 6. The Gugate will decide whether the ctmemory state is or is not updated by using the ~ctmemory state candidate. The Grgate deter- mines how relevant ct/C01is to compute the next candi- date for ct, that is, ~ct. A GRU is de?ned by the following equations: Gu=r(Wu[ct/C01,xt]\u00febu,( 10) Gr=r(Wr[ct/C01,xt]\u00febr), ( 11) FIG. 5. Hidden unit in an LSTM. LSTM, long short-term memory.DEEP LEARNING FOR TIME SERIES FORECASTING 9 Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  ~ct=tanh ( Wc[Gr\u00b7ct/C01,xt]\u00febc), ( 12) ct=Gu\u00b7~ct\u00fe(1/C0Gu)\u00b7ct/C01,( 13) at=ct,( 14) where WuandWr, and buandbrare the weights and the bias that govern the behavior of the GuandGr gates, respectively, and Wcandbcare the weights and bias of the ~ctmemory cell candidate. Bidirectional RNN. There are some problems, in the ?eld of natural language processing (NLP) for instance, where to predict a value of a data sequence in a given instant of time, information from the sequence both before and after that instant is needed. Bidirectional re- current neural networks (BRNNs) address this issue to solve this kind of problems. The main disadvantage of the BRNNs is that the entire data sequence is needed before the prediction can be made. Standard networks compute the activation values for hidden units by using a unidirectional feed-forward process. However, in a BRNN, the prediction uses in-formation from the past as well as information from the present and the future as input, using both forward and backward processing. Thus, the prediction at time t,^x t, is obtained by using agactivation function applied to the corresponding weights with both the forward and backward activation at time t. That is: ^xt=g(Wx[af t,ab t]\u00febx), ( 15) where Wxandbxare the weights and bias and af tandab t are the activation values of the hidden units computed by forward and backward processing, respectively, and gis an activation function.Figure 7 presents the basic architecture of a BRNN. A BRNN can be seen as two RNNs together, where the different hidden units have two values, one com- puted by forward and another one by backward. In ad- dition, the BRNN units can be standard RNN units or GRU or LSTM units. In fact, a BRNN with LSTM unitsis commonly used for a lot of NLP problems. Deep recurrent neural network. A deep recurrent neu- ral network (DRNN) can be considered as an RNN with more than one layer, also called stacked RNN. The hid- den units can be standard RNN, GRU or LSTM units, and it can be unidirectional or bidirectional as described in previous sections. Figure 8 illustrates the architecture of a DRNN with three layers. In general, a DRNN works quite well for time series forecasting, but its performance deteriorates when using very long data sequences as input. To addressthis issue, attention mechanisms can be incorporated into the model, being one of the most powerful ideas in deep learning. 34An attention model allows a neuralFIG. 6. Hidden unit in a GRU. GRU, gated recurrent units.FIG. 7. Basic architecture of a BRNN. BRNN, bidirectional recurrent neural network, FIG. 8. Basic architecture of a DRNN. DRNN, deep recurrent neural network.10 TORRES ET AL Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  network to pay attention to only part of an input data sequence while it is generating the output. This atten- tion is modeled by using weights, which are computed by a single-layer feed-forward neural network.35 Convolutional neural networks Convolutional neural networks (CNN) were presentedin Ref. 36by Fukushima and are one of the most com- mon architectures in image processing and computer vision.37The CNNs have three kinds of layers: convolu- tion, pooling, and fully connected. The main task of the convolution layers is the learning of the features from data input. For that, ?lters of a prede?ned size are ap- plied to the data by using the convolution operation be- tween matrices. The convolution is the sum of all element-wise products. The pooling reduces the size of input, speeding up the computing and preventing over?tting. The most popular pooling methods are av- erage and max pooling, which summarize the valuesby using the mean or maximum value, respectively. Once the features have been extracted by the convolu- tional layers, the forecasting is carried out by using fully connected layers, also called dense layers, as in DFFNN. The input data for these last fully connected layers are the ?attened features resulting of the convolu- tional and pooling layers. Figure 9 depicts the overall ar- chitecture of a CNN. Recently, a variant of CNN, called temporal convo- lutional networks (TCNs), 38has emerged for data se- quence, competing directly with DRNNs in terms of execution times and memory requirements. The TCNs have the same architecture as a DFFNN but the values of activations for each layer are com- puted by using earlier values from the previous layer. Dilated convolution is used to select which values of the neurons from the previous layer will contribute tothe values of the neurons in the next layer. Thus, this dilated convolution operation captures both local and temporal information. The dilated convolution, Fd, is a function de?ned as follows: Fd(x)=+K/C01 i=0f(i)/C1xt/C0d/C1i,( 16) where dis the dilation factor parameter, and fis a ?lter of size K. Figure 10 shows the architecture of a TCNN when applying a dilated convolution by using a ?lter of size 3 and dilation factors of 1, 2, and 4 for each layer, respectively. Moreover, it is necessary to use generic residual modules in addition to convolutional layers when deeper and larger TCN are used to achieve further sta- bilization. These generic residual blocks consist of add- ing the input of data to the output before applying theactivation function. Then, the TCN model can be de- ?ned as follows:FIG. 9. Architecture of a CNN. CNN, convolutional neural networks. FIG. 10. Architecture of a TCN using a ?lter of size 3. TCN, temporal convolutional network.DEEP LEARNING FOR TIME SERIES FORECASTING 11 Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  al t=g(Wl aFd(al/C01 t)\u00febl a\u00feal/C01 t), ( 17) where Fd(/C1)is the dilated convolution of dfactor de- ?ned in Equation (16), al tis the value of the neuron of the l-th layer at time t,Wl aandbl aare the weights and bias corresponding to the l-th layer, and gis the ac- tivation function. Practical aspects Implementation The implementation of a multilayer perceptron is rela- tively simple. However, deep-learning models are more complex, and their implementation requires a highlevel of technical expertise and a considerable time in- vestment to implement. For this reason, the pro?le of the deep-learning expert has become one of the most demanded nowadays. To make easier implementations and reduce the time needed to design and train a model, some companies have focused their work on de- veloping frameworks that allow for the implementa- tion, training and use of deep learning models. The main idea of the deep-learning frameworks is to provide an interface that allows for the implementation of models without having to pay too much attention to the mathematical complexity behind them. There are several frameworks available in the literature. The choice of one or another will depend on several impor- tant factors, such as the type of architecture that can be implemented, support for distributed programming environments, or whether it can run on GPUs. In this sense, Table 1 summarizes the most widely used frameworks in the literature, where the term all includes the DFFNN, CNN, TCN, RNN, LSTM,GRU, or BRNN architectures, and CPU is a central processing unit.Table 1 shows that the predominant programming language for developing deep-learning models is Python. In addition, most of the frameworks support distributed execution and the use of GPU\u2019s. Although the described frameworks facilitate the development of the models, some of them require too many lines of code to obtain a complete implementation. Forthis reason, high-level libraries based on the core of the frameworks have been developed, making pro- gramming even easier. Some examples of high-level libraries can be Keras, 50Sonnet,51Swift, or Gluon,52 among others. The main advantage of using a high-level-library is that the syntax can be reused for another base framework, in addition to facilitating its imple- mentation. However, the lack of ?exibility is the main disadvantage. Hyper-parameter optimization The combination of frameworks and high-level-libraries greatly facilitates the implementation of mod- els. However, there is an important study gap: the model optimization. This optimization will determinethe quality of the model, and it must be performed based on the adjustment of its hyper-parameters. In deep learning, there are two types of hyper-parameters: model parameters and optimization parameters. The model parameters must be adjusted in the model de?- nition to obtain optimal performance. The optimiza- tion parameters are adjusted during the training phase of the model by using the dataset. Some of the most relevant hyper-parameters are described and cat- egorized by network architecture in Table 2. The number of hyper-parameters will depend on the network architecture to be used. In addition, the value of each one will be in?uenced by the characteristics of Table 1. Deep-learning frameworks Framework Core language Available interfaces Architecture Distributed CPU jGPU TensorFlow39C++ Python, JavaScript, C ++, Java, Go, C#, Julia All 33 j3 H2O40Java Python, R, Scala, REST DFFNN 33 j3 Dl4j41Java Python, Scala, Clojure, Kotlin, C, C ++ All 33 j3 PyTorch42Lua Python, C, C ++ All 33 j3 Caffe43C++ Python, MATLAB CNN 73 j3 Neon44Python Python All 73 j3 Chainer45Python Python All 33 j3 Theano46Python Python All 73 j3 MXNet47Python Python, Scala, Julia, Clojure, Java, C ++, R, Perl All 33 j3 ONNX48Python Python CNN, DFFNN 73 j7 PaddlePaddle Python Python CNN 33 j3 CNTK49C++ Python, C ++, C# DFFNN, CNN, RNN 33 j3 CNN, convolutional neural networks; CPU, central processing unit; DFFNN, deep feed-forward neural networks; GPU, graphic processing unit; RNN, recurrent neural network.12 TORRES ET AL Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  the problem and the data. This makes the task of opti- mizing a model a challenge for the research community. Moreover, and taking into account the parameters de- scribed in Table 2, an immense number of possible com- binations can be deduced. For this reason, various metaheuristics and optimization strategies are used. According to the literature, there are several strategiesto optimize a set of hyper-parameters for deep-learning models, as shown in Table 3. Thus, the hyper-parameter optimization methods can be classi?ed into four major blocks: 1. Trial-error: This optimization method is based on varying each of the hyper-parameters manually. Therefore, this method implies a high time in- vestment, having a relatively low computational cost and a low search space, because it requires the action of a user to modify the values manually each time a run is ?nished. Since in deep learning there are a large number of hyper-parameters and the values they can set are in?nite, it is not advis- able to use this optimization method. 2. Grid: The grid method explores the different pos- sible combinations for a set of established hyper-parameters. This method covers a high search space, although it has a high computational cost associated with it, which makes this method unvi- able to apply in deep learning, let alone in big data environments. 3. Random: Random search allows to cover a high search space, because in?nite combinations ofhyper-parameters can be generated. Within this group we can differentiate between totally ran- dom or guided search strategies, such as those based on metaheuristics. Examples of this type of searches are the genetic algorithms, 68,69parti- cle swarm optimization,70or neuroevolution of augmenting topologies71algorithms, among oth- ers. The wide search range, added to the medium cost involved in this search strategy, makes it oneof the best methods for optimizing deep-learning models. In addition, new hyper-parameters opti- mization metaheuristics are being published, such as the bioinspired model in the propagation of COVID-19 presented by the authors in Ref. 72 4. Probabilistic: This optimization method tracks each of the evaluations. These evaluations are used to generate a probabilistic model that assigns values to the different hyper-parameters. The most common algorithms to optimize hyper- parameters by using probabilistic methods arethose based on Bayesian approaches. 73 There are many libraries for the optimization of hyper-parameters in an automated way. However, veryTable 2. Relevant hyper-parameters Hyper-parameter Architectures Description Optimizer All Algorithm used to update the weights of each layer after each iteration.53 Learning rate All It determines the size of the step at each iteration of the optimization method.54 Number of epochs All Number of passes made in the whole training set.55 Batch size All Number of sub-samples that the network uses to update the weights.56 Hidden layers All It determines the depth of the neural network.57 Activation function All Introduces nonlinearity in the model, which allows the extraction of more complex knowledge.58 Momentum All It prevents oscillations in the convergence of the method.59 Weight initialization All It prevents the explosion or vanishing of the activation in the layers.60 Dropout All It eliminates certain connections between neurons in each iteration. It is used to prevent over-fitting.61 L1/L2 Regularization All It prevents over-fitting, stopping weights that are too high so that the model does not depend on a single feature.62 Units RNN, DFFNN It determines the level of knowledge that is extracted by each layer. It is highly dependent on the size of the data used.57 Kernel/?lter CNN Matrix that moves over the input data. It allows the extraction of characteristics.63 Stride CNN The number of pixels that move over the input matrix for each filter.64 Padding CNN Number of null samples added to a dataset when it is processed by the kernel.65 Number of channels CNN Depth of the matrices involved in the convolutions.66 Pooling CNN It allows to reduce the number of parameters and calculations in the network.67 nb_stacks TCN Number of stacks of residual blocks.Dilations TCN A deep stack of dilated convolutions to capture long-range temporal patterns. TCN, temporal convolutional network. Table 3. Search strategies Strategy Deep learning Cost Search space Trial-error 7 Low Low Grid 7 High High Random 3 Medium High Probabilistic 3 Medium Medium-drivenDEEP LEARNING FOR TIME SERIES FORECASTING 13 Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  few are designed speci?cally for the optimization of deep-learning model hyper-parameters, being also compatible with the frameworks and high-level libraries described in Table 1. Table 4 summarizes a set of librar- ies for the optimization of hyper-parameters in deep- learning models, classifying them by search strategies,support to distributed computing, programming lan- guage, and compatible framework from Table 1. Note that it is not known whether HPOLib supports distrib- uted computing or in which frameworks it works. Hardware performance One of the most important decisions a researcher must make is to determine the physical resources needed to ensure that deep-learning algorithms will ?nd accurate models. Hence, this section overviews different hard- ware infrastructures typically used for deep-learning contexts, given its increasing demand for better and more sophisticated hardware. Although a CPU can be used to execute deep-learning algorithms, the intensive computational requirements usually make the CPU physical resources insuf?cient(scalar architecture). For this reason, three different hardware architectures are typically used for mining information with deep-learning frameworks: GPU, tensor processing unit (TPU), and intelligence pro- cessing unit (IPU). A GPU is a co-processor allocated in a CPU that is speci?cally designed to handle graphics in computing environments. The GPUs can have hundreds or even thousands of more cores than a CPU, but running atlower speeds. The GPUs achieve high data parallelism with single instructions, multiple data architecture and play an important role in the current arti?cial in- telligence domain, with a wide variety of applications. The ?rst generation of TPUs was introduced in 2016, at the Google I/O Conference and they were speci?cally designed to run already trained neural networks. The TPUs are custom application-speci?c integrated cir-cuits built speci?cally for machine learning. Compared with GPUs (frequently used for the same tasks since 2016), TPUs are implicitly designed for a larger volume of reduced precision calculation (e.g., from 8 bits of precision) and lack of hardware for rasterization/ texture mapping. The term was coined for a speci?cchip designed for Google\u2019s TensorFlow framework. Generally speaking, TPUs have less accuracy compared with the computations performed on a normal CPU or GPU, but it is suf?cient for the calculations they have to perform (an individual TPU can process more than 100 millions of pictures per day). Moreover, TPUs are highly optimized for large batches and CNNs and have the highest training throughput. 79 The IPU is completely diffe rent from today\u2019s CPU and GPU processors. It is a highly ?ex ible, easy-to-use, parallel processor that has been designed from the ground up todeliver state-of-the-art performance on current machine- learning models. But more importantly, the IPU has been designed to allow new and emerging machine intelligence workloads to be realized. The IPU delivers much better arithmetic ef?ciency on small batch sizes for both training and inference, which results in faster model convergence in training, models that generalize better, the ability to parallelize over many more IPU processors to reduce training time for a given batch size, and also deliversmuch higher throughput at lower latencies for inference. Another interesting feature is its lower power consump- tion compared with GPUs or TPUs (up to 20% less). Table 5 summarizes the properties of the processing units explored in this section. Note that the perfor- mance is measured in ?ops and the cost in USD.Table 4. Hyper-parameters optimization libraries Library Search strategy Distributed Language Framework Elephas Random, Probabilistic Yes Python Keras Hyperas Random, Probabilistic Yes Python KerasHyperopt74Random, Probabilistic Yes Python \u2014 Dlopt75Random No Python Keras Talos76Grid, Random Yes Python keras Keras-tuner Random Yes Python KerasH 2O40Grid, Random Yes Python, R H 2O BoTorch77Probabilistic Yes Python PyTorch HPOLib78Probabilistic \u2014 Python \u2014 Table 5. Processing units properties Units Architecture Batch size Performance Cost CPU Scalar Small ~109~102 GPU Vector Large ~1012~103 TPU ASIC Large ~1012\u2014 IPU Graph Small ~1015~10514 TORRES ET AL Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  Note that for TPUs cloud services are available for a price starting at 4.50 USD per hour (retrieved in March 2020). Applications To motivate the relevance of the time series prediction problem, an analysis of the state of the art has been carried out by classifying the deep-learning research works by application domain (such as energy and fuels, image and video, ?nance, environment, indus- try, or health) and the most widespread network archi- tectures used (ENN, LSTM, GRU, BRNN, DFFNN,CNN, or TCN). A summary on the works reviewed can be found in Table 6. An overview of the items for each application do- main is made in the following paragraphs, to highlight the goals reached for each method and ?eld: 1. Energy and fuels: With the increasing use of re- newable energies, accurate estimates are needed to improve power system planning and operat- ing. Many techniques have been used to make predictions, including deep learning. 195Reviewing the literature in the past few years, it can be con- cluded that the vast majority of deep-learning ar- chitectures are suitable to this application area. For example, architectures based on LSTM,90 ENN,85,86GRU,94BRNN,95and TCN100have been used to predict electricity demand consump- tion. LSTM89and CNN99have also been used to forecast photo-voltaic energy load. A GRU has been used to forecast soot emission in diesel en- gines in Ref.93An ensemble of DFFNN was devel- oped by the authors in Ref.98to forecast time series of general purpose. After that, this strategy has been also used to forecast load demand time series.97In Ref.91the authors proposed an applica-tion of LSTM to forecast oil production. Hybrid architectures have been also used in this research ?eld, for example, to forecast the price of car- bon,102the price of energy in electricity mar- kets,101energy consumption,103or solar power generation.105 2. Image and video: Image and video analysis is a very broad area of research, and it works related to any application domain. For example, Hu et al. conducted a wide study of deep learning for image-based cancer detection and diagno- sis.196In Ref.197the authors summarized some techniques and studies used to recognize video se- quence actions from timed images. The authors presented in Ref.107an application of an ENN to forecast and monitor the slopes displacementover photogrammetry performed by unmanned aerial vehicles. In Ref. 117the authors combined GRU, RNN, and CNN to classify satellite image time series. Although all these works offer highly competitive results, the use of convolution-based networks predominates in the literature to solve forecasting problems using image or video time series data. On the one hand, CNNs have been used to forecast the combustion instability,108 temporal dependencies in satellite images,111the speed of large-scale traf?c109or to detect coronary artery stenosis,113among others. On the other hand, TCN are booming when it comes to analyz- ing images and videos. For example, Miao et al. used a TCN to estimate density maps from vid- eos.114The authors in Ref.116also applied a TCN to summarize generic videos. Another interest- ing work in which images were used can be found in Ref.115In this work, they used a TCN model to dynamically detect stress through facialphotographs. Table 6. Summary of the works reviewed and classi?ed into network architecture and application domain RNN DFFNN CNN Hybrid/others ENN LSTM GRU BRNN CNN TCN Energy and fuels80\u201386 87\u201392 93,94 95 96\u201398 99 100 101\u2013106 Image and video107\u2014\u2014 \u2014 \u2014108\u2013113 114\u2013116 117 Financial \u2014118\u2013121 120\u2013122 121 123 120,124\u2013126\u2014120,127\u2013133 Environmental134\u2013142 143\u2013146 145,147\u2013149 150 151 152 153 150,154,155 Industry156,157 158\u2013160 161,162 163,164 164,165 166 167,168 166,169,170 Health \u2014171\u2014172 173 113,174,175\u2014176\u2013181 Misc \u2014 \u2014182 183 184 185\u2013187 188\u2013192 193,194 BRNN, bidirectional recurrent neural network; CNN, convolutional neural networks; ENN, Elman network; LSTM, long-short term memory; GRU, gated recurrent units.DEEP LEARNING FOR TIME SERIES FORECASTING 15 Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  3. Financial: Financial analysis has been a challeng- ing issue for decades. Therefore, there are many research works related to this application area, as described in Ref.198In addition, various archi- tectures such as CNN,124\u2013126DNN,123GRU,122or LSTM118,119have been used. Some authors make a comparison between some of these architec-tures, analyzing which one offers better results. 121 Although these studies are widespread, the com-plexity of the problem requires the search for new methodologies and architectures. 120,128\u2013133 4. Environmental: Environmental data analysis is one of the most popular areas for the scienti?c community. Many of these works are also based on the application of deep-learning techniques to forecast time series. The authors in Ref.150ap- plied CNN and LSTM to forecast wind speed or temperature by using meteorological data from Beijing, China. Other authors focused on a single speci?c variable. For instance, the authors used TCN, GRU, ENN, BRNN, and LSTM architec- tures to forecast information related to wind in.134,136,137,146,147,149,155Water quality and de- mand were also predicted by using TCN and ENN in Refs.140,153An application of LSTM- based neural networks for correlated time series prediction was also proposed by Wan et al.143 Further, carbon dioxide emissions,139?ood,143 orNH 3concentration for swine house199were also predicted by using deep-learning techniques, in particular ENN. 5. Industry: In the industr y sector, deep-learning techniques are also being used to carry out tasks of different kinds.200For instance, TCN and BRNN can be used to traf?c ?ow forecast- ing.163,167The LSTM can be used for multiple purposes, such as process planning,160construc- tion equipment recognition158or to improve the performance of organizations.159,161The au- thors in Ref.164used a DFFNN to forecast bath and metal height features in the electrolysis pro- cess. The ENN and GRU networks have been also used, for example, to forecast the useful life or degradation of the materials.156,157,195 Deep-learning techniques are also widely ap-plied to architecture, as can be seen in the in- depth study conducted by the authors inRef. 201It can be concluded that almost all net- work architectures have been used, given the wide variety of problems existing in this area.6. Health: The use of deep-learning architectures i nt h ea r e ao fh e a l t hi sc o m m o ni nt h ep a s t years.196,202However, time series prediction using deep-learning models is not very widespread as time series are generally short in this ?eld, along with the high computational cost involved in re- current network training. The authors of Ref.173 conducted a comprehensive study of time series prediction models in health care diagnosis and prognosis with a focus on cardiovascular disease. Instead, it is usual to apply convolution-based ar- chitectures or implement hybrid models. For ex- ample, the authors used CNN to accelerate the computation for magnetic resonance ?ngerprint- ing in Ref.175CNN was also used to monitoring t h es l e e ps t a g ei nR e f .176for detecting premature problems as ventricular contractions174or to fore- cast the Sepsis.180In Ref.179the authors used a backpropagation network to forecast the incidence rate of pneumonia. Other network architecture such as LSTM can be used to forecast the status of critical patients according to their vital func- tions.171A recent study conducted by the authors in Ref.181uses some deep-learning architectures to forecast COVID-19 cases. 7. Miscellaneous: In recent years, the TCN has been one of the most widely checked general purpose ar-chitectures for time series forecasting. 182,189,190,192 However, any of the other network architecturescan be applied to time series of miscellaneous appli- cation domains not classi?ed in Table 6. For exam- ple, CNN and RNN can be used to detect human activity 186or hybrid models to detect anomalies.194 Namely, readers interested in cybersecurity can?nd a detailed description in Refs. 184,203 From the previous analysis of Table 6, two main con- clusions can be drawn. First, there exist several meth- ods that have not been applied yet to particular application ?elds. Second, the existence of these gaps encourages the conduction of research in such lines. Conclusions Deep learning has proven to be one of the most power-ful machine-learning techniques for solving complex problems dealing with big data. Most of the data mainly generated through smart devices are time series nowadays, and their prediction is one of the most fre- quent and current problems in almost all research areas. Thus, these two topics have been jointly analyzed16 TORRES ET AL Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  in this survey to provide an overview of deep-learning techniques applied to time series forecasting. First, the most used deep-learning architectures for time series data in the past years have been described, with special emphasis on important practical aspects that can have a great in?uence on the reported results. In particular, it has placed focus on the search for hyper-parameters,the frameworks for deployment of the different archi- tectures, and the existing hardware to lighten the hard training of the proposed network architectures. Second, a study of the deep neural networks used to predict time series in different application domains has been carried out in this survey, with the aim of pro- viding a good comparative framework to be used in fu- ture works and to show which architectures have not been suf?ciently tested in some applications. Author Disclosure Statement No competing ?nancial interests exist. Funding Information This work was supported by the Spanish Ministry of Science, Innovation and Universities under project TIN2017-88209-C2-1-R. Also, this work has been partially supported by the Ge neral Directorate of Sci- enti?c Research and Technological Development(DGRSDT, Algeria), under the PRFU project (ref: C00 L07UN060120200003). References 1. Plageras AP, Psannis KE, Stergiou C, et al. Ef?cient IoT-based sensor big data collection-processing and analysis in smart buildings. FutureGener Comput Syst. 2018;82:349\u2013357. 2. Patil HP, Atique M. CDNB: CAVIAR-dragon?y optimization with naive bayes for the sentiment and affect analysis in social media. Big Data. 2020;8:107\u2013124. 3. Gama J. Knowledge discovery from data streams. UK: Chapman & Hall/CRC, 2010. 4. Al-Jarrah OY, Yoo PD, Muhaidat S, et al. Ef?cient machine learning for big data: A review. Big Data Res. 2015;2:87\u201393. 5. Dhar V, Sun C, Batra P. Transforming ?nance into vision: Concurrent ?nancial time series as convolutional net. Big Data. 2019; 7:276\u2013285. 6. Nguyen G, Dlugolinsky S, Boba \u00b4k M, et al. Machine learning and deep learning frameworks and libraries for large-scale data mining: A sur-vey. Artif Intell Rev. 2019;52:77\u2013124. 7. Maji P, Mullins R. On the reduction of computational complexity of deep convolutional neural networks. Entropy. 2018;20:305. 8. Schmidhuber J. Deep learning in neural networks: An overview. Neural Netw. 2015;61:85\u2013117. 9. Makridakis S, Wheelwright SC, Hyndman RJ. Forecasting methods and applications. USA: John Wiley and Sons, 2008. 10. Chat?eld C. The analysis of time series: An introduction. UK: Chapman & Hall/CRC, 2003. 11. Box GEP, Jenkins GM. Time series analysis: forecasting and control. USA: John Wiley and Sons, 2008. 12. Marti \u00b4nez-A \u00b4lvarez F, Troncoso A, Asencio-Corte \u00b4s G, Riquelme JC. A survey on data mining techniques applied to electricity-related time seriesforecasting. Energies 2015;8:13162\u201313193.13. Zhang Q, Yang LT, Chen Z, et al. A survey on deep learning for big data. Inf Fusion 2018;42:146\u2013157. 14. Fawaz HI, Forestier G, Weber J, et al. Deep learning for time series classi?cation: A review. Data Min Knowl Discov 2019;33:917\u2013963. 15. Bagnall A, Lines J, Vickers W, et al. 2017. The UEA & UCR time series classi?cation repository. Available online at www.timeseriesclassi?cation.com. (last accessed on April 30, 2020). 16. Mayer R, Jacobsen HA. Scalable deep learning on distributed infra- structures: challenges, techniques, and tools. ACM Comput Surv 2020;53:Article 3. 17. Buuren S. Flexible imputation of missing data. UK: Chapman & Hall/CRC, 2012. 18. Maronna RA, Martin RD, Yohai VJ. Robust statistics: theory and methods. USA: Wiley, 2006. 19. Fu TC. A review on time series data mining. Eng Appl Artif Intell. 2011;24: 164\u2013181. 20. Shumway RH, Stoffer DS. Time series analysis and its applications (with R examples). USA: Springer, 2011. 21. Hyndman RJ, Athanasopoulos G. Forecasting: principles and practice. Australia: Otexts, 2018. 22. Wang X, Kang Y, Hyndman RJ, et al. Distributed ARIMA models for ultra- long time series. arXiv e-prints , arXiv:2007.09577, 2020. 23. Rakthanmanon T, Campana B, Mueen A, et al. Addressing big data time series: Mining trillions of time series subsequences under dynamictime warping. ACM Trans Knowl Discov Data 2013;7:10. 24. Torres JF, Galicia A, Troncoso A, et al. A scalable approach based on deep learning for big data time series forecasting. Integr Comput Aided Eng 2018;25:335\u2013348. 25. Galicia A, Talavera-Llames RL, Troncoso A, et al. Multi-step forecasting for big data time series based on ensemble learning. Knowl Based Syst2019;163:830\u2013841. 26. Talavera-Llames R, Pe \u00b4rez-Chaco \u00b4n R, Troncoso A, et al. Big data time se- ries forecasting based on nearest neighbors distributed computing with spark. Knowl Based Syst 2018;161:12\u201325. 27. Talavera-Llames R, Pe \u00b4rez-Chaco \u00b4n R, Troncoso A, Marti \u00b4nez-A \u00b4lvarez F. MV-kWNN: A novel multivariate and multi-output weighted nearestneighbors algorithm for big data time series forecasting. Neurocom-puting 2019;353:56\u201373. 28. Pe \u00b4rez-Chaco \u00b4n R, Asencio-Corte \u00b4s G, Marti \u00b4nez A \u00b4lvarez F, et al. Big data time series forecasting bas ed on pattern sequence similarity and its application to the electricity demand. Inf Sci 2020;540:160\u2013174. 29. Rumelhart D, Hinton G, Williams R. Long short-term memory. Nature 1986;323:533\u2013536. 30. Elman JL. Finding structure in time. Energy Rep 1990;14:179\u2013211.31. Hochreiter S, Schmidhuber J. Long short-term memory. Neural Comput 1997;9:1735\u20131780. 32. Chung J, Gulcehre C, Cho K, et al. Empirical evaluation of gated recurrent neural networks on sequence modeling. In: Proceedings of the Neural Information Processing Systems, Canada, 2014. pp. 1\u201312. 33. Cho K, Merrienboer BV, Bahdanau D, et al. On the properties of neural machine translation: encoder-decoder approaches. In: Proceedings of SSST-8. Qatar, 2014. pp. 103\u2013111. 34. Bahdanau D, Cho K, Bengio Y. Neural machine translation by jointly learning to align and translate. In: Proceedings of the InternationalConference on Learning Representations, 2015, pp. 149\u2013158. 35. Xu K, Ba J, Kiros R, et al. Show, attend and tell: Neural image caption generation with visual attention. In: Proceedings of the InternationalConference on Machine Learning, 2015, pp. 2048\u20132057. 36. Fukushima K. Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position.Biol Cybern 1980;36:193\u2013202. 37. Zhang W, Hasegawa A, Matoba O, et al. Shift-invariant neural network for image processing: Learning and generalization. Appl Artif NeuralNetw III 1992;1709:257\u2013268. 38. Alla S, Adari SK. Beginning anomaly detection using Python-based deep learning. USA: Apress, 2019. 39. Abadi M, Agarwal A, Barham P, et al. 2015. TensorFlow: large-scale machine learning on heterogeneous systems. Available online athttp://tensor?ow.org. (last accessed on April 30, 2020). 40. Candel A, LeDell E, Arora A, et al. 2015. Deep learning with h2o. Available online at http://h2o.ai/resources. (last accessed on April 30, 2020).DEEP LEARNING FOR TIME SERIES FORECASTING 17 Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  41. Eclipse Deeplearning4j development team. 2016. DL4J: deep learning for Java. Available online at https://github.com/eclipse/ deeplearning4j. (last accessed on April 30, 2020). 42. Paszke A, Gross S, Massa F, et al. Pytorch: an imperative style, highper- formance deep learning library. In: Proceedings of the Advances inNeural Information Processing Systems. Vol. 32, 2019. pp. 8026\u20138037. 43. Jia Y, Shelhamer E, Donahue J, et al. Caffe: Convolutional architecture for fast feature embedding. arXiv e-prints, arXiv:1408.5093, 2014. 44. Intel Nervana systems. Neon deep learning framework 2017. Available online at https://github.com/NervanaSystems/neon, 2017. (lastaccessed on April 30, 2020). 45. Tokui S, Okuta R, Akiba T, et al. Chainer: A deep learning framework for accelerating the research cycle. In: Proceedings of International Con-ference on Knowledge Discovery and Data Mining 2019, pp. 2002\u2013 2011. 46. Theano Development Team. Theano: A Python framework for fast computation of mathematical expressions. arXiv e-prints, arXiv:1605.02688, 2016. 47. Tianqi C, Li M, Li Y, et al. Mxnet: A ?exible and ef?cient machine learning library for heterogeneous distributed systems. arXiv e-prints arXiv: 1512.01274, 2015. 48. Bai J, Lu F, Zhang K, et al. 2019. Onnx: Open neural network exchange. Available online at https://github.com/onnx/onnx. (last accessed onJune 15, 2020). 49. Seide F, Agarwal A. CNTK: Microsoft\u2019s open-source deep-learning toolkit. In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. USA, 2016, pp. 2135\u20132135. 50. Chollet F. 2015. Keras. Available online at https://keras.io51. DeepMind revision. Sonnet, 2019.52. Guo J, He H, He T, et al. Gluoncv and gluonnlp: Deep learning in com- puter vision and natural language processing. J Mach Learn Res 2020;21:1\u20137. 53. Choi D, Shallue CJ, Nado Z, et al. On empirical comparisons of optimizers for deep learning. arXiv e-prints, arXiv:1910.05446, 2019. 54. You K, Long M, Wang J, Jordan MI. How does learning rate decay help modern neural networks? In Proceedings of the International Con-ference on Learning Representations, 2019. pp. 1\u201314. 55. Sinha S, Singh TN, Singh V, Verma A. Epoch determination for neural network by self-organized map (SOM). Comput Geosci 2010 14:199\u2013 206. 56. Masters D, Luschi C. Revisiting small batch training for deep neural networks. arXiv e-prints, arXiv:1804.07612, 2018. 57. Sha? I, Ahmad J, Shah SI, et al. Impact of varying neurons and hidden layers in neural network architecture for a time frequency application.In: Proceedings of the IEEE International Multitopic Conference. USA,2006. pp. 188\u2013193. 58. Ding B, Qian H, Zhou J. Activation functions and their characteristics in deep neural networks. In: Proceedings of the Chinese Control andDecision Conference. USA, 2018. pp. 1836\u20131841. 59. Sutskever I, Martens J, Dahl G, et al. On the importance of initialization and momentum in deep learning. In: Proceedings of the InternationalConference on Machine Learning, 2013. pp. 1139\u20131147. 60. Kumar SK. On weight initialization in deep neural networks. arXiv e-prints, arXiv:1704.08863, 2017. 61. Srivastava N, Hinton G, Krizhevsky A, et al. Dropout: A simple way to prevent neural networks from over?tting. J Mach Learn Res 2014;15:1929\u20131958. 62. Ng AY. Feature selection, l1 vs. l2 regularization, and rotational invari- ance. In: Proceedings of the ACM International Conference on Machine Learning. USA, 2004. pp. 78\u201385. 63. Mairal J, Koniusz P, Harchaoui Z, Schmid C. Convolutional kernel net- works. In: Proceedings of the Neural Information Processing Systems.USA, 2014. pp. 1\u20139. 64. Zaniolo L, Marques O. On the use of variable stride in convolutional neural networks. Multimed Tools Appl. 2020;79:13581\u201313598. 65. Dwarampudi M, Reddy NVS. Effects of padding on LSTMs and CNNs. arXiv e-prints, arXiv:1903.07288, 2019. 66. Zhu H, An Z, Yang C, et al. Rethinking the number of channels for the convolutional neural network. arXiv e-prints, arXiv:1909.01861, 2019. 67. Scherer F, Mu \u00a8 ller A, Behnke S. Evaluation of pooling operations in con- volutional architectures for object recognition. In: Proceedings ofArti?cial Neural Networks. USA, 2010. pp. 92\u2013101.68. Ma B, Li X, Xia Y, et al. Autonomous deep learning: A genetic DCNN designer for image classi?cation. Neurocomputing 2020;379:152\u2013161. 69. Itano F, De-Abreu-De-Sousa MA, Del-Moral-Hernandez E. Extending MLP ANN hyper-parameters optimization by using genetic algorithm. In:Proceedings of the IEEE International Joint Conference on NeuralNetworks. USA, 2018. pp. 1\u20138. 70. Kennedy K, Eberhart R. Particle swarm optimization. In: Proceedings of International Conference on Neural Networks. Vol. 4, USA, 1995. pp. 1942\u20131948. 71. Stanley KO, Miikkulainen R. Evolving neural networks through aug- menting topologies. Evol Comput. 2002;10:99\u2013127. 72. Marti \u00b4nez-A \u00b4lvarez F, Asencio-Corte \u00b4s G, Torres JF, et al. Coronavirus opti- mization algorithm: A bioinspired metaheuristic based on the COVID-19 Propagation Model. Big Data 2020;8:308\u2013322. 73. Ranjit MP, Ganapathy G, Sridhar K, et al. Ef?cient deep learning hyper- parameter tuning using cloud infrastructure: intelligent distributedhyperparameter tuning with bayesian optimization in the cloud. In:Proceedings of International Conference on Cloud Computing. USA,2019. pp. 520\u2013522. 74. Bergstra J, Yamins D, Cox DD. Making a science of model search: hyperparameter optimization in hundreds of dimensions for vision architectures. In: Proceedings of the International Conference onInternational Conference on Machine Learning, 2013. pp. 115\u2013123. 75. Camero A, Toutouh J, Alba E. Dlopt: Deep learning optimization library. arXiv e-prints, arXiv:1807.03523, 2018. 76. Autonomio. Talos. Available online at http://github.com/autonomio/ talos, 2019. 77. Balandat M, Karrer B, Jiang DR, et al. BoTorch: Programmable Bayesian Optimization in PyTorch. arXiv e-prints, arXiv:1910.06403, 2019. 78. Eggensperger K, Feurer M, Hutter F, et al. Towards an empirical foun- dation for assessing bayesian optimization of hyperparameters. In:Proceedings of the Neural Information Processing Systems. USA, 2013.pp. 1\u20135. 79. Wang YE, Wei GY, Brooks D. Benchmarking TPU, GPU, and CPU platforms for deep learning. arXiv e-prints, arXiv:1907.10701, 2019. 80. Yu D, Wang Y, Liu H, et al. System identi?cation of PEM fuel cells using an improved Elman neural network and a new hybrid optimization al-gorithm. Energy Rep. 2019;5:1365\u20131374. 81. Zheng Y, Yao Z, Zhou H, et al. Power generation forecast of top gas recovery turbine unit based on Elman model. In: Proceedings of the IEEE Chinese Control Conference. USA, 2018. pp. 7498\u20137501. 82. Ruiz LGB, Rueda R, Cue \u00b4llar MP, et al. Energy consumption forecasting based on Elman neural networks with evolutive optimization. ExpertSyst Appl. 2018;92:380\u2013389. 83. Wang J, Lv Z, Liang Y, et al. Fouling resistance prediction based on GA\u2013 Elman neural network for circulating cooling water with electromag- netic anti-fouling treatment. J Energy Inst. 2019;92:1519\u20131526. 84. Li W, Jiao Z, Du L, et al. An indirect RUL prognosis for lithium-ion battery under vibration stress using Elman neural network. Int J HydrogEnergy. 2019;44:12270\u201312276. 85. Yu Y, Wang X, Bru \u00a8 ndlinger R. Improved Elman neural network short-term residents load forecasting considering human comfort index. J Electr Eng Technol. 2019;14:2315\u20132322. 86. Li D, Wang H, Zhang Y, et al. Power grid load state information per- ception forecasting technology for battery energy storage systembased on Elman neural network. In: Proceedings of informationTechnology, Networking, Electronic and Automation Control Confer-ence. USA, 2019. pp. 914\u2013917. 87. Abdel-Nasser M, Mahmoud K. Accurate photovoltaic power forecasting models using deep LSTM-RNN. Neural Comput Appl. 2019;31:2727\u2013 2740. 88. Khodabakhsh A, Ari I, Bakir M, et al. Forecasting multivariate time-series data using LSTM and mini-batches. In: Proceedings of Data Engi-neering and Communications Technologies, 2020. pp. 121\u2013129. 89. Gao M, Li J, Hong F, et al. Day-ahead power forecasting in a large-scale photovoltaic plant based on weather classi?cation using LSTM. Energy. 2019;187:115838. 90. Muzaffar S, Afshari A. Short-term load forecasts using LSTM networks. Proc Energy Proc. 2019;158:2922\u20132927. 91. Song X, Liu Y, Xue L, et al. Time-series well performance prediction based on long short-term memory (LSTM) neural network model. J PetSci Eng. 2020;186:106682.18 TORRES ET AL Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  92. Wang JQ, Du Y, Wang J. LSTM based long-term energy consumption prediction with periodicity. Energy. 2020;197:117197. 93. Gokhan A, Yilmaz E, Unel M, et al. Estimating soot emission in diesel engines using gated recurrent unit networks. IFAC Papers Online.2019;52:544\u2013549. 94. Wu W, Liao W, Miao J, et al. Using gated recurrent unit network to forecast short-term load considering impact of electricity price. Proc Energy Proc. 2019;158:3369\u20133374. 95. Tang X, Dai Y, Wang T, et al. Short-term power load forecasting based on multi-layer bidirectional recurrent neural network. IET Gener TransmDistrib. 2019;13:3847\u20133854. 96. Shao Z, Zheng Q, Yang S, et al. Modeling and forecasting the electricity clearing price: A novel BELM based pattern classi?cation frameworkand a comparative analytic study on multi-layer BELM and LSTM. Energy Econ. 2020;86:104648. 97. Qiu X, Ren Y, Suganthan PN, et al. Empirical mode decomposition based ensemble deep learning for load demand time series forecasting. ApplSoft Comput J. 2017;54:246\u2013255. 98. Qiu X, Zhang L, Ren Y, et al. Ensemble deep learning for regression and time series forecasting. In: Proceedings of the IEEE Symposium Series on Computational Intelligence in Ensemble Learning. USA, 2014. pp. 1\u20136. 99. Manohar M, Koley E, Ghosh S, et al. Spatio-temporal information based protection scheme for PV integrated microgrid under solar irradianceintermittency using deep convolutional neural network. Int J ElectrPower Energy Syst. 2020;116:105576. 100. Mishra K, Basu S, Maulik U. DaNSe: A dilated causal convolutional net- work based model for load forecasting. Lect Notes Comput Sci. 2019;11941:234\u2013241. 101. Qiao W, Yang Z. Forecast the electricity price of U.S. using a wavelet transform-based hybrid model. Energy 2020;193:116704. 102. Ji L, Zou Y, He K, et al. Carbon futures price forecasting based with ARIMA-CNN-LSTM model. Proc Comput Sci. 2019;162:33\u201338. 103. Kim TY, Cho SB. Predicting residential energy consumption using CNN- LSTM neural networks. Energy. 2019;182:72\u201381. 104. Shen M, Xu Q, Wang K, et al. Short-term bus load forecasting method based on cnn-gru neural network. Lect Notes Electr Eng 2020;585:711\u2013722. 105. AlKandari M, Ahmad I. Solar power generation forecasting using en- semble approach based on deep learning and statistical methods. Appl Comput Inf. 2020;6:1\u201320. 106. Kong Z, Tang B, Deng L, et al. Condition monitoring of wind turbines based on spatio-temporal fusion of SCADA data by convolutionalneural networks and gated recurrent units. Renew Energy 2020;146:760\u2013768. 107. Wang S, Zhang Z, Ren Y, et al. UAV photogrammetry and AFSA-Elman neural network in slopes displacement monitoring and forecasting. KSCE J Civil Eng. 2020;24:19\u201329. 108. Sarkar S, Lore KG, Sarkar S, et al. Early detection of combustion instability from hi-speed ?ame images via deep learning and symbolic time se-ries analysis. In: Proceedings of the Annual Conference of the Prog-nostics and Health Management Society. USA, 2015. pp. 353\u2013362. 109. Ma X, Dai Z, He Z, et al. Learning traf?c as images: A deep convolutional neural network for large-scale transportation network speed predic-tion. Sensors 2017;17:818. 110. Chen W, Shi K. A deep learning framework for time series classi?cation using relative position matrix and convolutional neural network.Neurocomputing 2019;359:384\u2013394. 111. Ienco D, Interdonato R, Gaetano R, et al. Combining Sentinel-1 and Sentinel-2 satellite image time series for land cover mapping via a multi-source deep learning architecture. J Photogrammetry RemoteSens. 2019;158:11\u201322. 112. Marti \u00b4nez-Arellano G, Terrazas G, Ratchev S. Tool wear classi?cation using time series imaging and deep learning. Int J Adv Manuf Technol. 2019;104:3647\u20133662. 113. Wu W, Zhang J, Xie H, et al. Automatic detection of coronary artery stenosis by convolutional neural network with temporal constraint.Comput Biol Med 2020;118:103657. 114. Miao Y, Han J, Gao Y, Zhang B. ST-CNN: Spatial-Temporal Convolutional Neural Network for crowd counting in videos. Pattern Recogn Lett.2019;125:113\u2013118.115. Feng S. Dynamic facial stress recognition in temporal convolutional network. In: Proceedings of the Communications in Computer and Information Science. USA, 2019. pp. 698\u2013706. 116. Zhang Y, Kampffmeyer M, Liang X, et al. Dilated temporal relational adversarial network for generic video summarization. Multimed ToolsAppl. 2019;78:35237\u201335261. 117. Interdonato R, Ienco D, Gaetano R, et al. DuPLO: A DUal view Point deep Learning architecture for time series classi?catiOn. ISPRS J Photo- gramm Remote Sens. 2019;149:91\u2013104. 118. Yan H, Ouyang H. Financial time series prediction based on deep learning. Wireless Pers Commun. 2018;102:683\u2013700. 119. Sismanoglu G, Onde M, Kocer F, et al. Deep learning based forecasting in stock market with big data analytics. In: Proceedings of the IEEE Sci-enti?c Meeting on Electrical-Electronics and Biomedical Engineering and Computer Science. USA, 2019. pp. 10057\u201310059. 120. Jayanth BA, Harish RDS, Nair BB. Applicability of deep learning models for stock price forecasting an empirical study on bankex data. ProcComput Sci. 2018;143:947\u2013953. 121. Jiang M, Liu J, Zhang L, et al. An improved stacking framework for stock index prediction by leveraging tree-based ensemble models and deep learning algorithms. Physica A 2020;541:122272. 122. Wu W, Wang Y, Fu J, et al. Preliminary study on interpreting stock price forecasting based on tree regularization of GRU. In: Proceedings ofCommunications in Computer and Information Science. Vol. 1059,USA, 2019. pp. 476\u2013487. 123. Orimoloye LO, Sung MC, Ma T, et al. Comparing the effectiveness of deep feedforward neural networks and shallow architectures for predicting stock price indices. Expert Syst Appl. 2020;139:112828. 124. Makarenko AV. Deep learning algorithms for estimating Lyapunov ex- ponents from observed time series in discrete dynamic systems. In:Proceedings of International Conference Stability and Oscillations ofNonlinear Control Systems. USA, 2018. pp. 1\u20134. 125. Dingli A, Fournier KS. Financial time series forecasting\u2014a deep learning approach. Int J Mach Learn Comput. 2017;7:118\u2013122. 126. Kelotra A, Pandey P. Stock market prediction using Optimized Deep- ConvLSTM Model. Big Data 2020;8:5\u201324. 127. Ni L, Li Y, Wang X, et al. Forecasting of Forex time series data based on deep learning. Proc Comput Sci. 2019;147:647\u2013652. 128. Bao W, Yue J, Rao Y. A deep learning framework for ?nancial time series using stacked autoencoders and long-short term memory. PLos One. 2017;12:e0180944. 129. Munkhdalai L, Li M, Theera-Umpon N, et al. VAR-GRU: A hybrid model for multivariate ?nancial time series prediction. Lect Notes Artif Intell.2020;12034:322\u2013332. 130. Chen CT, Chiang LK, Huang YC, et al. Forecasting interaction of ex- change rates between ?at currencies and cryptocurrencies based on deep relation networks. In: Proceedings of the IEEE International Conference on Agents. USA, 2019. pp. 69\u201372. 131. Berradi Z, Lazaar M. Integration of principal component analysis and recurrent neural network to forecast the stock price of Casablancastock exchange. Proc Comput Sci 2019;148:55\u201361. 132. Wang Q, Xu W, Huang X, et al. Enhancing intraday stock price manip- ulation detection by leveraging recurrent neural networks with en- semble learning. Neurocomputing 2019;347:46\u201358. 133. Long W, Lu Z, Cui L. Deep learning-based feature engineering for stock price movement prediction. Knowl Based Syst. 2019;164:163\u2013173. 134. Liu H, Tian HQ, Liang XF, et al. Wind speed forecasting approach using secondary decomposition algorithm and Elman neural networks. ApplEnergy. 2015;157:183\u2013194. 135. Yu C, Li Y, Xiang H, et al. Data mining-assisted short-term wind speed forecasting by wavelet packet decomposition and Elman neural net-work. J Wind Eng Indus Aerodyn. 2018;175:136\u2013143. 136. Liu H, Wei MX, Fei LY. Wind speed forecasting method based on deep learning strategy using empirical wavelet transform, long short termmemory neural network and Elman neural network. Energy Conv Manage. 2018;156:498\u2013514. 137. Zhang Y, Pan G. A hybrid prediction model for forecasting wind energy resources. Environ Sci Pollut Res. 2020;27:19428\u201319446. 138. Zhang L, Xie Y, Chen A, et al. A forecasting model based on enhanced Elman neural network for air quality prediction. Lect Notes Electr Eng.2019;518:65\u201374.DEEP LEARNING FOR TIME SERIES FORECASTING 19 Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  139. Huang Y, Shen L. Elman neural network optimized by ?re?y algorithm for forecasting China\u2019s carbon dioxide emissions. Commun Comput Inf Sci. 2018;951:36\u201347. 140. Xiao D, Hou S, Li WZ, et al. Hourly campus water demand forecasting using a hybrid EEMD-Elman neural network model. In: SustainableDevelopment of Water Resources and Hydraulic Engineering in China.Environmental Earth Sciences. USA, 2019. pp. 71\u201380. 141. Shen W, Fu X, Wang R, et al. A prediction model of NH3 concentration for swine house in cold region based on empirical mode decompo-sition and Elman neural network. Inf Proc Agric. 2019;6:297\u2013305. 142. Wan X, Yang Q, Jiang P, et al. A hybrid model for real-time probabilistic ?ood forecasting using Elman neural network with heterogeneity oferror distributions. Water Resour Manage. 2019;33:4027\u20134050. 143. Wan H, Guo S, Yin K, et al. CTS-LSTM: LSTM-based neural networks for correlatedtime series prediction. Knowl Based Syst. 2019;191:105239. 144. Freeman BS, Taylor G, Gharabaghi B, et al. Forecasting air quality time series using deep learning. J Air Waste Manage Assoc. 2018;68:866\u2013886. 145. De-Melo GA, Sugimoto DN, Tasinaffo PM, et al. A new approach to river ?ow forecasting: LSTM and GRU multivariate models. IEEE Latin Am Trans. 2019;17:1978\u20131986. 146. Chen J, Zeng GQ, Zhou W, et al. Wind speed forecasting using nonlinear- learning ensemble of deep learning time series prediction andextremal optimization. Energy Conv Manage. 2018;165:681\u2013695. 147. Niu Z, Yu Z, Tang W, et al. Wind power forecasting using attention-based gated recurrent unit network. Energy. 2020;196:117081. 148. Li W, Wu H, Zhu N, et al. Prediction of dissolved oxygen in a ?shery pond based on gated recurrent unit (GRU). Inf Process Agric. 2020, In press. 149. Peng Z, Peng S, Fu L, et al. A novel deep learning ensemble model with data denoising for short-term wind speed forecasting. Energy ConversManage. 2020;207:112524. 150. Jin X, Yu X, Wang X, et al. Prediction for time series with CNN and LSTM. Lect Notes Electr Eng 2020;582:631\u2013641. 151. Maqsood H, Mehmood I, Maqsood M, et al. A local and global event sentiment based ef?cient stock exchange forecasting using deeplearning. Int J Inf Manage. 2020;50:432\u2013451. 152. O\u2019Shea TJ, Roy T, Clancy TC. Over-the-air deep learning based radio signal classi?cation. IEEE J Select Topics Signal Process. 2018;12:168\u2013179. 153. Zhang Y, Thorburn PJ, Fitch P. Multi-task temporal convolutional net- work for predicting water quality sensor data. In: Proceedings ofNeural Information Processing Communications in Computer andInformation Science. USA, 2019. pp. 122\u2013130. 154. Sun Y, Zhao Z, Ma X, et al. Short-timescale gravitational microlensing events prediction with ARIMA-LSTM and ARIMA-GRU hybrid model.Lect Notes Comput Sci. 2019;11473:224\u2013238. 155. Liu H, Mi X, Li Y, et al. Smart wind speed deep learning based multi-step forecasting model using singular spectrum analysis, convolutionalgated recurrent unit network and support vector regression. RenewEnergy. 2019;143:842\u2013854. 156. Li X, Zhang L, Wang Z, et al. Remaining useful life prediction for lithium- ion batteries based on a hybrid model combining the long short-term memory and Elman neural networks. J Energy Storage. 2019;21:510\u2013 518. 157. Yang L, Wang F, Zhang J, et al. Remaining useful life prediction of ul- trasonic motor based on Elman neural network with improved particleswarm optimization. Measurement. 2019;143:27\u201338. 158. Rashid KM, Louis J. Times-series data augmentation and deep learning for construction equipment activity recognition. Adv Eng Inform. 2019;42:100944. 159. Huang X, Zanni-Merk C, Cre \u00b4milleux B. Enhancing deep learning with semantics: An application to manufacturing time series analysis. ProcComput Sci. 2019;159:437\u2013446. 160. Mehdiyev N, Lahann J, Emrich A, et al. Time series classi?cation using deep learning for process planning: A case from the process industry. Proc Comput Sci 2017;114:242\u2013249. 161. Wang S, Chen J, Wang H, et al. Degradation evaluation of slewing bearing using HMM and improved GRU. Measurement. 2019;146:385\u2013395. 162. Wang J, Yan J, Li C, et al. Deep heterogeneous GRU model for predictive analytics in smart manufacturing: Application to tool wear prediction.Comput Indus. 2019;111:1\u201314.163. Bohan H, Yun B. Traf?c ?ow prediction based on BRNN. In: Proceedings of the IEEE International Conference on Electronics Information and Emergency Communication. USA, 2019. pp. 320\u2013323. 164. Pasias A, Vafeiadis T, Ioannidis D, et al. Forecasting bath and metal height features in electrolysis process. In: Proceedings of the Inter-national Conference on Distributed Computing in Sensor Systems.2019. pp. 312\u2013317. 165. Jiang P, Chen C, Liu X. Time series prediction for evolutions of complex systems: A deep learning approach. In: Proceedings of rhe IEEEInternational Conference on Control and Robotics Engineering, 2016.pp. 1\u20136. 166. Canizo M, Triguero I, A Conde, et al. Multi-head CNN\u2013RNN for multi-time series anomaly detection: An industrial case study. Neurocomputing.2019;363:246\u2013260. 167. Kuang L, Hua C, Wu J, et al. Traf?c volume prediction based on multi- sources GPS trajectory data by temporal convolutional network.Mobile Netw Appl. 2020;25:1\u201313. 168. Wu P, Sun J, Chang X, et al. Data-driven reduced order model with temporal convolutional neural network. Comput Methods Appl MechEng. 2020;360:112766. 169. Varona B, Monteserin A, Teyseyre A. A deep learning approach to au- tomatic road surface monitoring and pothole detection. Pers Ubiqui-tous Comput. 2020;24:519\u2013534. 170. Cai M, Pipattanasomporn M, Rahman S. Day-ahead building-level load forecasts using deep learning vs. traditional time-series techniques.Appl Energy. 2019;236:1078\u20131088. 171. da Silva DB, Schmidt D, da Costa CA, da Rosa Righi R, Esko?er B. Deep- signs: A predictive model based on deep learning for the early de-tection of patient health deterioration. Expert Syst Appl. 2021;165:113905. 172. Yu W, Kim Y, Mechefske C. Remaining useful life estimation using a bi- directional recurrent neural network based autoencoder scheme.Mech Syst Signal Process 2019;129:764\u2013780. 173. Bui C, Pham N, Vo A, Tran A, Nguyen A, Le T. Time series forecasting for healthcare diagnosis and prognostics with the focus on cardiovasculardiseases. In: Proceedings of the International Conference on theDevelopment of Biomedical Engineering in Vietnam. USA, 2018.pp. 809\u2013818. 174. Liu Y, Huang Y, Wang J, et al. Detecting premature ventricular contrac- tion in children with deep learning. J Shanghai Jiaotong Univ. 2018;23: 66\u201373. 175. Hoppe E, Ko \u00a8rzdo\u00a8rfer G, Wu \u00a8 r? T, et al. Deep learning for magnetic reso- nance ?ngerprinting: A new approach for predicting quantitativeparameter values from time series. In: Studies in Health Technologyand Informatics, Vol. 243. Netherlands: IOS Press, 2017. pp. 202\u2013206. 176. Chambon S, Galtier MN, Arnal PJ, et al. A deep learning architecture for temporal sleep stage classi?cation using multivariate and multi- modal time series. IEEE Trans Neural Syst and Rehabil Eng. 2018;26:758\u2013769. 177. Lauritsen SM, Kal\u00f8r ME, Kongsgaard EL, et al. Early detection of sepsis utilizing deep learning on electronic health record event sequences.Artif Intell Med. 2020;104:101820. 178. Chen X, He J, Wu X, et al. Sleep staging by bidirectional long short-term memory convolution neural network. Fut Gen Comput Syst. 2020;109:188\u2013196. 179. Liang liang M, Fu peng T. Pneumonia incidence rate predictive model of nonlinear time series based on dynamic learning rate BP neural net-work. In: Proceedings of the Fuzzy Information and Engineering. USA,2010. pp. 739\u2013749. 180. Sarafrazi S, Choudhari RS, Mehta C, et al. Cracking the \u2018\u2018sepsis\u2019\u2019 code: Assessing time series nature of ehr data, and using deep learning forearly sepsis prediction. In: Proceedings of the Computing in Cardiol-ogy. UK, 2019. pp. 1\u20134. 181. Zeroual A, Harrou F, Dairi A, Sun Y. Deep learning methods for fore- casting covid-19 time-series data: A comparative study. Chaos Solit Fract. 2020;140:110121. 182. Zhang X, Shen F, Zhao J, et al. Time series forecasting using GRU neural network with multi-lag after decomposition. Lect Notes Comput Sci.2017;10638:523\u2013532. 183. Zhao X, Xia L, Zhang J, et al. Arti?cial neural network based modeling on unidirectional and bidirectional pedestrian ?ow at straight corridors.Physica A. 2020;547:123825.20 TORRES ET AL Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  184. Imamverdiyev Y, Abdullayeva F. Deep learning method for denial of service attack detection based on restricted boltzmann machine. Big Data. 2018;6:159\u2013169. 185. Munir M, Siddiqui SA, Dengel A, et al. DeepAnT: A deep learning ap- proach for unsupervised anomaly detection in time series. IEEE Access.2019;7:1991\u20132005. 186. Zebin T, Scully PJ, Ozanyan KB. Human activity recognition with inertial sensors using a deep learning approach. In: Proceedings of IEEE Sensors. USA, 2017. pp. 1\u20133. 187. Bendong Z, Huanzhang L, Shangfeng C, et al. Convolutional neural networks for time series classi?cation. J Syst Eng Electr. 2017;28:162\u2013169. 188. Jiang W, Wang Y, Tang Y. A sequence-to-sequence transformer pre- mised temporal convolutional network for chinese word segmenta- tion. In: Proceedings of Parallel Architectures, Algorithms and Programming. USA, 2020. pp. 541\u2013552. 189. Shao J, Shen H, Cao Q, et al. Temporal convolutional networks for popularity prediction of messages on social medias. Lect NotesComput Sci. 2019;:135\u2013147. 190. Chen Y, Kan Y, Chen Y, et al. Probabilistic forecasting with temporal convolutional neural network. Neurocomputing. 2020;399:491\u2013501. 191. Xi R, Hou M, Fu M, et al. Deep dilated convolution on multimodality time series for human activity recognition. In: Proceedings of the IEEEInternational Joint Conference on Neural Networks. USA, 2018.pp. 53381\u201353396. 192. Wang R, Peng C, Gao J, et al. A dilated convolution network-based LSTM model for multi-step prediction of chaotic time series. Comput Appl Math. 2020;39:1\u201322. 193. Rodrigues F, Markou I, Pereira FC. Combining time-series and textual data for taxi demand prediction in event areas: A deep learning ap-proach. Inf Fusion. 2019;49:120\u2013129. 194. Kalinin MO, Lavrova DS, Yarmak AV. Detection of threats in cyberphys- ical systems based on deep learning methods using multidimensional time series. Autom Control Comput Sci. 2018;52:912\u2013917. 195. Wang H, Lei Z, Zhang X, et al. A review of deep learning for renewable energy forecasting. Energy Conv Manage. 2019;198:111799. 196. Hu Z, Tang J, Wang Z, et al. Deep learning for image-based cancer de- tection and diagnosis\u2014A survey. Pattern Recogn. 2018;83:134\u2013149. 197. Atto AM, Benoit A, Lambert P. Timed-image based deep learning for action recognition in video sequences. Pattern Recogn. 2020;104: 107353.198. Sezer OB, Gudelek M, Ozbayoglu AM. Financial time series forecasting with deep learning: A systematic literature review: 2005\u20132019. Appl Soft Comput. 2020;90:106181. 199. Shen Z, Zhang Y, Lu J, et al. A novel time series forecasting model with deep learning. Neurocomputing. 2020;396:302\u2013313. 200. Wang Y, Zhang D, Liu Y, et al. Enhancing transportation systems via deep learning: A survey. Transp Res Part C Emerg Technol. 2019;99: 144\u2013163. 201. Kamilaris A, Prenafeta-Boldu \u00b4FX. Deep learning in agriculture: A survey. Comput Electr Agric. 2018;147:70\u201390. 202. Rui Z, Ruqiang Y, Zhenghua C, et al. Deep learning and its applications to machine health monitoring. Mech Syst Signal Process. 2019;115:213\u2013237. 203. Mahdavifar S, Ghorbani AA. Application of deep learning to cyberse- curity: A survey. Neurocomputing 2019;347:149\u2013176. Cite this article as: Torres JF, Hadjout D, Sebaa A, Marti \u00b4nez-A \u00b4lvarez F, Troncoso A (2021) Deep learning for time series forecasting: a survey.Big Data 9:1, 3\u201321, DOI: 10.1089/big.2020.0159. Abbreviations Used BRNN \u00bcbidirectional recurrent neural network CNN \u00bcconvolutional neural networks CPU \u00bccentral processing unit DFFNN \u00bcdeep feed forward neural networks DRNN \u00bcdeep recurrent neural network ENN \u00bcElman network GPU \u00bcgraphic processing unit GRU \u00bcgated recurrent units IPU\u00bcintelligence processing unit LSTM \u00bclong-short term memory NLP\u00bcnatural language processing RNN \u00bcrecurrent neural network TCN\u00bctemporal convolutional network TPU\u00bctensor processing unitDEEP LEARNING FOR TIME SERIES FORECASTING 21 Downloaded by National University of Computer and Emerging Sciences, Islamabad, Pakistan from www.liebertpub.com at 02/14/24. For personal use only.  ", "17": "Training Tips for the Transformer Model Martin Popel, Ondrej Bojar Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics, Prague, Czechia Abstract This article describes our experiments in neural machine translation using the recent Ten- sor2TensorframeworkandtheTransformersequence-to-sequencemodel(Vaswanietal.,2017). We examine some of the critical parameters that a?ect the ?nal translation quality, memory usage, training stability and training time, concluding each experiment with a set of recom- mendations for fellow researchers. In addition to con?rming the general mantra \u201cmore data and larger models\u201d, we address scaling to multiple GPUs and provide practical tips for im- proved training regarding batch size, learning rate, warmup steps, maximum sentence length andcheckpointaveraging. Wehopethatourobservationswillallowotherstogetbetterresults given their particular hardware and data constraints. 1. Introduction It has been already clearly established that neural machine translation (NMT) is the new state of the art in machine translation, see e.g. the most recent evaluation campaigns(Bojaretal.,2017a;Cettoloetal.,2017). Manyfundamentalchangesofthe underlying neural network architecture are nevertheless still frequent and it is very di?cult to predict which of the architectures has the best combination of properties towininthelongterm,consideringallrelevantcriterialiketranslationquality,model size, stability and speed of training, interpretability but also practical availability of goodimplementations. Aconsiderablepartofamodel\u2019ssuccessintranslationquality consists in the training data, the model\u2019s sensitivity to noise in the data but also on a wide range of hyper-parameters that a?ect the training. Having the right setting of them turns out to be often a critical component for the success. 1arXiv:1804.00247v2  [cs.CL]  2 May 2018Inthisarticle,weexperimentwitharelativelynewNMTmodel,calledTransformer (Vaswanietal.,2017)asimplementedintheTensor2Tensor /one.superior(abbreviatedT2T)toolkit, version1.2.9. Themodelandthetoolkithavebeenreleasedshortlyaftertheevaluation campaignatWMT2017 /two.superioranditsbehavioronlarge-datanewstranslationisnotyetfully explored. We want to empirically explore some of the important hyper-parameters. Hopefully, our observations will be useful also for other researchers considering this model and framework. Whileinvestigationsintothee?ectofhyper-parameterslikelearningrateandbatch sizeareavailableinthedeep-learningcommunity(e.g.Bottouetal.,2016;Smithand Le, 2017; Jastrzebski et al., 2017), these are either mostly theoretic or experimentally supported from domains like image recognition rather than machine translation. In this article, we ?ll the gap by focusing exclusively on MT and on the Transformer model only, providing hopefully the best practices for this particular setting. Some of our observations con?rm the general wisdom (e.g. larger training data aregenerallybetter)andquantifythebehavioronEnglish-to-Czechtranslationexper- iments. Some of our observations are somewhat surprising, e.g. that two GPUs are more than three times faster than a single GPU, or our ?ndings about the interaction between maximum sentence length, learning rate and batch size. Thearticleisstructuredasfollows. InSection2,wediscussourevaluationmethod- ologyandmaincriteria: translationqualityandspeedoftraining. Section3describes our dataset and its preparations. Section 4 is the main contribution of the article: a set of commented experiments, each with a set of recommendations. Finally, Sec- tion5comparesourbestTransformerrunwithsystemsparticipatinginWMT17. We conclude in Section 6. 2. Evaluation Methodology Machine translation can be evaluated in many ways and some forms of human judgment should be always used for the ultimate resolution in any ?nal application. ThecommonpracticeinMTresearchistoevaluatethemodelperformanceonatestset against one or more human reference translations. The most widespread automatic metricisundoubtedlytheBLEUscore(Papinenietal.,2002),despiteitsacknowledged problems and better-performing alternatives (Bojar et al., 2017b). For simplicity, we stick to BLEU, too (we evaluated all our results also with /c.sc/h.sc/r.scF(Popovic, 2015), but foundnosubstantialdi?erencesfromBLEU).Inparticular,weusethecase-insensitive sacr\u00e9BLEU /three.superiorwhich uses a ?xed tokenization (identical to mteval-v14.pl --interna- /one.superiorhttps://github.com/tensorflow/tensor2tensor /two.superiorhttp://www.statmt.org/wmt17 /three.superiorhttps://github.com/awslabs/sockeye/tree/master/contrib/sacrebleu The signature of the BLEU scores reported in this paper is BLEU+case.lc+lang.en-cs+numrefs.1+smooth. exp+test.wmt13+tok.intl+version.1.2.3 . 2tional-tokenization ) and automatically downloads the reference translation for a given WMT testset. 2.1. Considerations on Stopping Criterion The situation in NMT is further complicated by the fact that the training of NMT systemsisusuallynon-deterministic, 4and(esp. withthemostrecentmodels)hardly everconvergesorstartsover?tting 5onreasonablybigdatasets. Thisleadstolearning curvesthatneverfully?attenletalonestartdecreasing(seeSection4.2). Thecommon practice of machine learning to evaluate the model on a ?nal test set when it started over?tting (or a bit sooner) is thus not applicable in practice. Many papers in neural machine translation do not specify any stopping criteria whatsoever. Sometimes,theymentiononlyanapproximatenumberofdaysthemodel was trained for, e.g. Bahdanau et al. (2015), sometimes the exact number of training steps is given but no indication on \u201chow much converged\u201d the model was at that point,e.g. Vaswanietal.(2017). Mostprobably,thetrainingwasrununtilnofurther improvementswereclearlyapparentonthedevelopmenttestset,andthemodelwas evaluated at that point. Such an approximate stopping criterion is rather risky: it is conceivablethatdi?erentsetupswerestoppedatdi?erentstagesoftrainingandtheir comparison is not fair. A somewhat more reliable method is to keep training for a speci?ed number of iterations or a certain number of epochs. This is however not a perfect solution either, if the models are not quite converged at that time and the di?erence in their performance is not su?ciently large. It is quite possible that e.g. a more complex model would need a few more epochs and eventually arrived at a higher score than its competitor. Also, the duration of one training step (or one epoch) di?ers between models(seeSection4.1)andfromthepracticalpointofview,wearemostlyinterested in the wall-clock time. When we tried the standard technique of early stopping, when Nsubsequent evaluationsonthedevelopmenttestsetdonotgiveimprovementslargerthanagiven delta,wesawabigvarianceinthetrainingtimeand?nalBLEU,evenforexperiments with the same hyper-parameters and just a di?erent random seed. Moreover to get the best results, we would have had to use a very large Nand a very small delta. 4Evenifwe?xtherandomseed(whichwasnotdoneproperlyinT2Tv1.2.9),achangeofsomehyper- parameters may a?ect the results not because of the change itself, but because it in?uenced the random initialization. 5By over?tting we mean here that the translation quality (test-set BLEU) begins to worsen, while the training loss keeps improving. 32.2. Our Final Choice: Full Learning Curves Basedonthediscussionabove,wedecidedtoreportalwaysthefulllearningcurves and not just single scores. This solution does not fully prevent the risk of premature judgments,butthereaderscanatleastjudgeforthemselvesiftheywouldexpectany sudden twist in the results or not. In all cases, we plot the case-insensitive BLEU score against the wall-clock time in hours. This solution obviously depends on the hardware chosen, so we always usedthesameequipment: oneuptoeightGeForceGTX1080TiGPUswithNVIDIA driver 375.66. Some variation in the measurements is unfortunately unavoidable because we could not fully isolate the computation from di?erent processes on the same machine and from general network tra?c, but based on our experiments with replicated experiments such variation is negligible. 2.3. Terminology For clarity, we de?ne the following terms and adhere to them for the rest of the paper: Translation quality is an automatic estimate of how well the translation carried out by a particular ?xed model expresses the meaning of the source. We estimate translation quality solely by BLEU score against one reference translation. Training Steps denote the number of iterations, i.e. the number of times the opti- mizer update was run. This number also equals the number of (mini)batches that were processed. Batch Size isthenumberoftrainingexamplesusedbyoneGPUinonetrainingstep. In sequence-to-sequence models, batch size is usually speci?ed as the number ofsentencepairs . However,theparameter batch_size inT2Ttranslationspeci?es the approximate number of tokens(subwords) in one batch. 6This allows to use a higher number of short sentences in one batch or a smaller number of long sentences. E?ective Batch Size is the number of training examples consumed in one training step. WhentrainingonmultipleGPUs,theparameter batch_size isinterpreted perGPU.Thatis,with batch_size=1500 and8GPUs,thesystemactuallydigests 12k subwords of each language in one step. Training Epoch corresponds to one complete pass over the training data. Unfortu- nately, it is not easy to measure the number of training epochs in T2T. 7T2T 6For this purpose, the number of tokens in a sentence is de?ned as the maximum of source and target subwords. T2Talsodoesreorderingandbucketingofthesentencesbytheirlengthtominimizetheuseof padding symbols. However, some padding is still needed, thus batch_size only approximates the actual number of (non-padding) subwords in a batch. 7https://github.com/tensorflow/tensor2tensor/issues/415 4reports only the number of training steps. In order to convert training steps to epochs, we need to multiply the steps by the e?ective batch size and divide by thenumberofsubwordsinthetrainingdata(seeSection3.1). Thesegmentation ofthetrainingdataintosubwordsisusuallyhiddentotheuserandthenumber of subwords must be thus computed by a special script. Computation Speed issimplytheobservednumberoftrainingstepsperhour. Com- putation speed obviously depends on the hardware (GPU speed, GPU-CPU communication) and software (driver version, CUDA library version, imple- mentation). The main parameters a?ecting computation speed are the model size,optimizerandothersettingsthatdirectlymodifytheformulaoftheneural network. Training Throughput is the amount of training data digested by the training. We report training throughput in subwords per hour. Training Throughput equals to the Computation Speed multiplied by the e?ective batch size. Convergence Speed orBLEUConvergence istheincreaseinBLEUdividedbytime. Convergence speed changes heavily during training, starting very high and decreasing as the training progresses. A converged model should have conver- gence speed of zero. Time Till Score is the training time needed to achieve a certain level of translation quality, in our case BLEU. We use this as an informal measure because it is not clear how to de?ne the moment of \u201cachieving\u201d a given BLEU score. We de?ne it as time after which the BLEU never falls below the given level. 8 Examples Till Score is the number of training examples (in subwords) needed to achieve a certain level of BLEU. It equals to the Time Till Score multiplied by Training Throughput. 2.4. Tools for Evaluation within Tensor2Tensor T2T, being implemented in TensorFlow, provides nice TensorBoard visualizations of the training progress. The original implementation was optimized towards speed of evaluation rather than towards following the standards of the ?eld. T2T thus reports\u201capprox-bleu\u201dbydefault,whichiscomputedontheinternalsubwords(never exposed to the user, actually) instead of words (according to BLEU tokenization). As a result, \u201capprox-bleu\u201d is usually about 1.2\u20131.8 times higher than the real BLEU. Due to its dependence on the training data (for the subword vocabulary), it is not easily reproducible in varying experiments and thus not suitable for reporting in publications. 8Such de?nition of Time Till Score leads to a high variance of its values because of the relatively high BLEU variance between subsequent checkpoints (visible as a \u201c?ickering\u201d of the learning curves in the ?gures). To decrease the variation one can use a bigger development test set. 5sentences EN words CS words CzEng 1.7 57 M 618 M 543 M europarl-v7 647 k 15 M 13 M news-commentary-v11 190 k 4.1 M 3.7 M commoncrawl 161 k 3.3 M 2.9 M Total 58 M 640 M 563 M Table 1: Training data resources Weimplementedahelperscript t2t-bleu whichcomputesthe\u201creal\u201dBLEU(giving the same result as sacr\u00e9BLEU with --tokenization intl ). Our script can be used in two ways: \u2022To evaluate one translated ?le: t2t-bleu --translation=my-wmt13.de --reference=wmt13_deen.de \u2022To evaluate all translations in a given directory (created e.g. by t2t-translate- all) and store the results in a TensorBoard events ?le. All the ?gures in this article were created this way. Wealsoimplemented t2t-translate-all and t2t-avg-all scripts,whichtranslate all checkpoints in a given directory and average a window of N subsequent check- points, respectively. ?For details on averaging see Section 4.10. 3. Data Selection and Preprocessing We focused on the English-to-Czech translation direction. Most of our training data comes from the CzEng parallel treebank, version 1.7 (57M sentence pairs), /one.superior\u00b0 and the rest (1M sentence pairs) comes from three smaller sources (Europarl, News Commentary, Common Crawl) as detailed in Table 1. We use this dataset of 58M sentence pairs for most our experiments. In some experiments (in Sections 4.2 and 4.6), we substitute CzEng 1.7 with an older and considerably smaller CzEng 1.0 (Bojar et al., 2012) containing 15M sentence pairs (233M/206M of en/cs words). To plot the performance throughout the training, we use WMT newstest2013 as a development set (not overlapping with the training data). In Section 5, we apply our best model (judged from the performance on the development set) to the WMT newstest2017, for comparison with the state-of-the-art systems. ?All three scripts are now mergedin the T2T master. All three scripts can be used while the trainingis still in progress, i.e. they wait a given number of minutes for new checkpoints to appear. /one.superior\u00b0http://ufal.mff.cuni.cz/czeng/czeng17 , which is a subset of CzEng 1.6 (Bojar et al., 2016). 63.1. Training Data Preprocessing Data preprocessing such as tokenization and truecasing has always been a very importantpartofthesetupofstatisticalmachinetranslationsystems. Ahugeleapin scaling NMT to realistic data size has been achieved by the introduction of subword units(Sennrichetal.,2016),butthelong-termvisionofthedeep-learningcommunity is to leave all these \u201ctechnicalities\u201d up to the trained neural network and feed it with as original input as possible (see e.g. Lee et al., 2016). T2T adopts this vision and while it supports the use of external subword units, it comes with its own built-in method similar to the word-piece algorithm by Wu et al. (2016)anddoesnotexpecttheinputtobeeventokenized. Basedonasmallsampleof thetrainingdata,T2Twilltrainasubwordvocabularyandapplyittoallthetraining and later evaluation data. We follow the T2T default and provide raw plain text training sentences. We use the default parameters: shared source and target (English and Czech) subword vocabulary of size 32k. /one.superior/one.superiorAfter this preprocessing, the total number of subwords in our main training data is 992 millions (taking the maximum of English and Czech lengths for each sentence pair, as needed for computing the number of epochs, see Section 2.3). The smaller dataset CzEng 1.0 has 327 million subwords. In both cases the average number of subwords per (space-delimited) word is about 1.5. Evenwhenfollowingthedefaults,therearesomeimportantdetailsthatshouldbe considered. We thus provide our ?rst set of technical tips here: Tips on Training Data Preprocessing \u2022Makesurethatthesubwordvocabularyistrainedonasu?cientlylargesample of the training data. /one.superior/two.superior \u2022AsdiscussedinSection4.5,ahigherbatchsizemaybebene?cialforthetraining and the batch size can be higher when excluding training sentences longer than a given threshold. This can be controlled with parameter max_length (see Section4.4),butitmaybeagoodideatoexcludetoolongsentencesevenbefore preparingthetrainingdatausing t2t-datagen . ThiswaytheTFRecordstraining ?les will be smaller and their processing a bit faster. /one.superior/three.superior /one.superior/one.superiorMoredetailsonT2TwithBPEsubwordunitsbySennrichetal.(2016)vs. theinternalimplementation canbefoundinthetechnicalreport\u201cMorphologicalandLanguage-AgnosticWordSegmentationforNMT\u201d attached to the Deliverable 2.3 of the project QT21: http://www.qt21.eu/resources/ . /one.superior/two.superiorThis is controlled by a file_byte_budget constant, which must be changed directly in the source code inT2Tv1.2.9. Asignoftoosmalltrainingdataforthesubwordvocabularyisthatthe min_count asreported in the logs is too low, so the vocabulary is estimated from words seen only once or twice. /one.superior/three.superiorWe did no such pre-?ltering in our experiments. 74. Experiments In this section, we present several experiments, always summarizing the obser- vations and giving some generally applicable tips that we learned. All experiments were done with T2T v1.2.9 unless stated otherwise. We experiment with two sets of hyper-parameters pre-de?ned in T2T: trans- former_big_single_gpu (BIG) and transformer_base_single_gpu (BASE), which di?er mainly in the size of the model. Note that transformer_big_single_gpu and trans- former_base_single_gpu are just names of a set of hyper-parameters, which can be applied even when training on multiple GPUs, as we do in our experiments, see Section 4.7. /one.superior4 Our baselinesetting uses theBIG model withits default hyper-parametersexcept for: \u2022batch_size=1500 (see the discussion of di?erent sizes in Section 4.5), \u2022--train_steps=6000000 ,i.e. highenough,sowecanstopeachexperimentman- ually as needed, \u2022--save_checkpoints_secs=3600 which forces checkpoint saving each hour (see Section 4.10), \u2022--schedule=train which disables the internal evaluation with approx_bleu and thus makes training a bit faster (see Section 2). /one.superior5 4.1. Computation Speed and Training Throughput We are primarily interested in the translation quality (BLEU learning curves and TimeTillScore)andwediscussitinthefollowingsections4.2\u20134.10. Inthissection,we focushoweveronlyonthe computationspeed andtrainingthroughput . Botharea?ected by three important factors: batch size, number of used GPUs and model size. The speed is usually almost constant for a given experiment. /one.superior6 Table 2 shows the computation speed and training throughput for a single GPU and various batch sizes and model sizes (BASE and BIG). The BASE model allows for using a higher batch size than the BIG model. The cells where the BIG model resulted in out-of-memory errors are marked with \u201cOOM\u201d. /one.superior7We can see that the /one.superior4According to our experiments (not reported here), transformer_big_single_gpu is better than trans- former_big even when training on 8 GPUs, although the naming suggests that the T2T authors had an opposite experience. /one.superior5Alsotherearesomeproblemswiththealternativeschedules train_and_evaluate (itneedsmoremem- ory) and continuous_train_and_eval (see https://github.com/tensorflow/tensor2tensor/issues/556 ). /one.superior6TensorBoard shows global_step/sec statistics, i.e. the computation speed curve. These curves in our experimentsarealmostconstantforthewholetrainingwithvariationwithin2%,exceptformomentswhen a checkpoint is being saved (and the computation speed is thus much slower). /one.superior7For these experiments, we used max_length=50 in order to be able to test bigger batch sizes. However, in additional experiments we checked that max_length does not a?ect the training throughput itself. 8model batch_size BASE BIG 50043.4k 23.6k 100030.2k 13.5k 150022.3k 9.8k 200016.8k 7.5k 250014.4k 6.5k 300012.3k OOM 4500 8.2k OOM 6000 6.6k OOM (a) Computation speed (steps/hour)model batch_size BASE BIG 50021.7M 11.9M 100030.2M 13.5M 150033.4M 14.7M 200033.7M 15.0M 250036.0M 16.2M 300037.0M OOM 450036.7M OOM 600039.4M OOM (b) Training throughput (subwords/hour) Table 2: Computation speed and training throughput for a single GPU. computation speed decreases with increasing batch size because not all operations in GPU are fully batch-parallelizable. The training throughput grows sub-linearly with increasing batch size, so based on these experiments only, there is just a small advantage when setting the batch size to the maximum value. We will return to this question in Section 4.5, while taking into account the translation quality. We can also see the BASE model has approximately two times bigger throughput as well as computation speed relative to the BIG model. GPUs steps/hour subwords/hour 1 9.8k 14.7M 2 7.4k 22.2M 6 5.4k 48.6M 8 5.6k 67.2M Table 3: Computation speed and training throughput for various numbers of GPUs, with the BIG model and batch_size=1500 . Table 3 uses the BIG model and batch_size=1500 , while varying the number of GPUs. The overhead in GPU synchronization is apparent from the decreasing com- putation speed. Nevertheless, the training throughput still grows with more GPUs, so e.g. with 6 GPUs we process 3.2 times more training data per hour relative to a single GPU (while without any overhead we would hypothetically expect 6 times more data). 924252627 0 50 100 150 200 2501234567891011BLEU Training time (hours)Training time (days) 58M training sentences 16M training sentences Figure 1: Training data size e?ect. BLEU learning curves for our main training dataset with 58 million sentence pairs and an alternative training dataset with 16 million sentence pairs. Both trained with 8 GPUs, BIG model and batch_size=1500 . The overhead when scaling to multiple GPUs is smaller than the overhead when scaling to a higher batch size. Scaling from a single GPU to 6 GPUs increases the throughput 3.2 times, but scaling from batch size 1000 to 6000 on a single GPU increases the throughput 1.3 times. 4.2. Training Data Size Forthisexperiment,wesubstitutedCzEng1.7withCzEng1.0inthetrainingdata, sothetotaltrainingsizeis16millionsentencepairs(255M/226MofEnglish/Czech words). Figure1comparestheBLEUlearningcurvesoftwoexperimentswhichdi?er only in the training data: the baseline CzEng 1.7 versus the smaller CzEng 1.0. Both are trained on the same hardware with the same hyper-parameters (8 GPUs, BIG, batch_size=1500 ). Training on the smaller dataset (2.5 times smaller in the number of words) converges to BLEU of about 25.5 after two days of training and does not improve over the next week of training. Training on the bigger dataset gives slightly worse results in the ?rst eight hours of training (not shown in the graph) but clearly better results after two days of training, reaching over 26.5 BLEU after eight days. /one.superior8 With batch_size=1500 and8GPUs,trainingoneepochofthesmallerdataset(with CzEng1.0)takes27ksteps(5hoursoftraining),comparedto83ksteps(15hours)for the bigger dataset (with CzEng 1.7). This means about 10 epochs in the smaller dataset were needed for reaching the convergence and this is also the moment when the bigger /one.superior8We compared the two datasets also in another experiment with two GPUs, where CzEng 1.7 gave slightly worse results than CzEng 1.0 during the ?rst two days of training but clearly better results after eight days. We hypothesize CzEng 1.0 is somewhat cleaner than CzEng 1.7. 10datasetstartsbeingclearlybetter. However, even18epochsinthebiggerdatasetwerenot enough to reach the convergence .enough to reach the convergence Tips on Training Data Size \u2022For comparing di?erent datasets (e.g. smaller and cleaner vs. bigger and noisier), we need to train long enough because results after ?rst hours (or days if training on a single GPU) may be misleading . \u2022For large training data (as CzEng 1.7 which has over half a gigaword), BLEU improves even after one week of training on eight GPUs (or after 20 days of training on two GPUs in another experiment). \u2022We cannot easily interpolate one dataset results to another dataset. While the smaller training data (with CzEng 1.0) converged after 2 days, the main training data (with CzEng 1.7), which is 2.5 times bigger, continues improving even after 2.5\u00d72 days. /one.superior? 4.3. Model Size Choosing the right model size is important for practical reasons: larger models maynot?tanymoreonyourGPUortheymayrequiretouseaverysmallbatchsize. We experiment with two models, /two.superior\u00b0as pre-de?ned in Tensor2Tensor \u2013 transfor- mer_big_single_gpu (BIG) and transformer_base_single_gpu (BASE), which di?er in four hyper-parameters summarized in Table 4. model hidden_size ?lter_size num_heads adam_beta2 BASE 512 2048 8 0.980 BIG 1024 4096 16 0.998 Table4: transformer_big_single_gpu (BIG)and transformer_base_single_gpu (BASE) hyper-parameter di?erences. Figure2showsthatonasingleGPU,theBIGmodelbecomesclearlybetterthanthe BASEmodelafter4hoursoftrainingifwekeepthebatchsizethesame\u20132000(andwe have con?rmed it with 1500 in other experiments). However, the BASE model takes lessmemory,sowecana?ordahigherbatchsize,inourcase4500(withno max_length restriction,seethenextsection),whichimprovestheBLEU(seeSection4.5). Buteven /one.superior?Althoughsuchanexpectationmayseemna\u00efve,wecan?nditinliterature. Forexample,Bottou(2012) inSection4.2writes: \u201c Expectthevalidationperformancetoplateauafteranumberofepochsroughlycomparableto the number of epochs needed to reach this point on the small training set. \u201d /two.superior\u00b0We tried also a model three times as large as BASE (1.5 times as large as BIG), but it did not reach better results than BIG, so we don\u2019t report it here. 111618202224 0 10 20 30 40 50 60 70BLEU Training time (hours)BIG model, batch size 2000, 1 GPU BASE model, batch size 4500, 1 GPU BASE model, batch size 2000, 1 GPU Figure 2: E?ect of model size and batch size on a single GPU. 2223242526 0 10 20 30 40 50BLEU Training time (hours)BIG model, batch size 1500, 8 GPUs BASE model, batch size 4500, 8 GPUs Figure 3: E?ect of model size and batch size on 8 GPUs. so, after less than one day of training, BIG with batch size 2000 becomes better than BASE with batch size 4500 (or even 6000 with max_length =70 in another experiment) and the di?erence grows up to 1.8 BLEU after three days of training. Figure3con?rmsthiswith8GPUs\u2013hereBIGwithbatchsize1500becomesclearly better than BASE with batch size 4500 after 18 hours of training. Tips on Model Size \u2022Prefer the BIG over the BASE model if you plan to train longer than one day and have 11 GB (or more) memory available on GPU. \u2022With less memory you should benchmark BIG and BASE with the maximum possible batch size. 12maximum batch size longer sentences max_length BIG+Adam BIG+Adafactor BASE+Adam train test none 2040 2550 4950 0.0% 0.0% 150 2230 2970 5430 0.2% 0.0% 100 2390 3280 5990 0.7% 0.3% 702630 3590 6290 2.1% 2.2% 502750 3770 6430 5.0% 9.1% Table5: Maximumbatchsizewhich?tsinto11GBmemoryforvariouscombinations ofmax_length (maximum sentence length in subwords), model size (base or big) and optimizer (Adam or Adafactor). The last two columns show the percentage of sentences in the train (CzEng 1.7) and test (wmt13) data that are longer than a given threshold. \u2022Forfastdebugging(ofmodel-size-unrelatedaspects)useamodelcalled trans- former_tiny . 4.4. Maximum Training Sentence Length Theparameter max_length speci?esthemaximumlengthofasentenceinsubwords. Longersentences(eitherinsourceortargetlanguage)areexcludedfromthetraining completely. If no max_length is speci?ed (which is the default), batch_size is used instead. Loweringthe max_length allowstouseahigherbatchsizeorabiggermodel. Since the Transformer implementation in T2T can suddenly run out of memory even after several hours of training, it is good to know how large batch size ?ts in your GPU. Table 5 presents what we empirically measured for the BASE and BIG models with Adam and Adafactor /two.superior/one.superioroptimizers and various max_length values. Setting max_length toolowwouldresultinexcludingtoomanytrainingsentences and biasing the translation towards shorter sentences, which would hurt the trans- lation quality. The last two columns in Table 5 show that setting max_length to 70 (resp. 100) results in excluding only 2.1% (resp. 0.7%) of sentences in the training data, and only 2.2% (resp. 0.3%) sentences in the development test data are longer, so the detrimental e?ect of smaller training data and length bias should be minimal in this setting. However, our experiments with batch_size =1500 in Figure 4 show a strange drop in BLEU after one hour of training for all experiments with max_length 70 or lower. Even with max_length 150 or 200 the BLEU learning curve is worse than with max_length =400,which?nallygivesthesameresultasnotusingany max_length /two.superior/one.superiorTheAdafactoroptimizer(ShazeerandStern,2018)isavailableonlyinT2T1.4.2ornewerandhasthree times smaller models than Adam because it does not store ?rst and second moments for all weights. We leave further experiments with Adafactor for future work. 13051015 0123456789BLEU Training time (hours)max length 400 max length 200 max length 150 max length 70 max length 50 max length 25 Figure 4: E?ect of restricting the training data to various max_length values. All trained on a single GPU with the BIG model and batch_size =1500. An experiment without any max_length is not shown, but it has the same curve as max_length =400. restriction. Thetraininglossof max_length =25(and50and70)hashighvarianceand stops improving after the ?rst hour of training but shows no sudden increase (as in the case of diverged training discussed in Section 4.6 when the learning rate is too high). We have no explanation for this phenomenon. /two.superior/two.superior We did another set of experiments with varying max_length , but this time with batch_size =2000 instead of 1500. In this case, max_length 25 and 50 still results in slowergrowingBLEUcurves,but70andhigherhasthesamecurveasno max_length restriction. So in our case, if the batch size is high enough, the max_length has almost no e?ect on BLEU , but this should be checked for each new dataset. We trained several models with various max_length for three days and observed thattheyarenotabletoproducelongertranslationsthanwhatwasthemaximumlengthused in training , even if we change the decoding parameter alpha. Tips on max_length \u2022Set (a reasonably low) max_length . This allows to use a higher batch size and prevents out-of-memory errors after several hours of training. Also, with a higher percentage of training sentences that are almost max_length long, there isahigherchancethatthetrainingwillfaileitherimmediately(ifthebatchsize is too high) or never (otherwise)., \u2022Setareasonablyhigh max_length . Considerthepercentageofsentencesexcluded fromtrainingandfromthetargeteddevelopmenttestsetandalsowatchforun- expecteddrops(orstagnations)oftheBLEUcurveinthe?rsthoursoftraining. /two.superior/two.superiorhttps://github.com/tensorflow/tensor2tensor/issues/582 1410121416182022 0 10 20 30 40 50 60 70BLEU Training time (hours)BASE, batch size 6000 BASE, batch size 4500 BASE, batch size 3000 BASE, batch size 1500 BASE, batch size 1000 Figure 5: E?ect of the batch size with the BASE model. All trained on a single GPU. 4.5. Batch Size Thedefault batch_size valueinrecentT2Tversionsis4096subwordsforallmodels except for transformer_base_single_gpu , where the default is 2048. However, we recommend to always set the batch size explicitly /two.superior/three.superioror at least make a note what was the default in a given T2T version when reporting experimental results. Figure5showslearningcurvesfor?vedi?erentbatchsizes(1000,1500,3000,4500 and 6000) for experiments with a single GPU and the BASE model. /two.superior4A higher batch sizeup to 4500 is clearly better in terms of BLEU as measured by Time Till Score and ExamplesTillScoremetricsde?nedinSection4.1. Forexample,togetoverBLEUof18 with batch_size =3000,weneed7hours(260Mexamples),andwith batch_size =1500, we need about 3 days (2260M examples) i.e. 10 times longer (9 time more examples). FromTable2aweknowthatbiggerbatcheshaveslowercomputationspeed,sowhen re-plotting Figure 5 with steps instead of time on the x-axis, the di?erence between the curves would be even bigger. From Table 2b we know that bigger batches have slightly higher training throughput, so when re-plotting with number of examples processed on the x-axis, the di?erence will be smaller, but still visible. The only exceptionisthedi?erencebetweenbatchsize4500and6000,whichisverysmalland /two.superior/three.superiore.g. --hparams=\"batch_size=1500,learning_rate=0.20,learning_rate_warmup_steps=16000\" As the batch size is speci?ed in subwords, we see no advantage in using power-of-two values. /two.superior4All the experiments in Figure 5 use max_length =70, but we have got the same curves when re-running without any max_length restrictions, except for batch_size =6000 which failed with OOM. 1505101520 0 5 10 15 20 25 30 35BLEU Training time (hours)BIG, batch size 2000 BIG, batch size 1500 BIG, batch size 1450 BIG, batch size 1400 BIG, batch size 1300 BIG, batch size 1000 Figure 6: E?ect of the batch size with the BIG model. All trained on a single GPU. canbefullyexplainedbythefactthatbatchsize6000has7%higherthroughputthan batch size 4500. Sofor the BASE model, a higher batch size gives better results , although with dimin- ishing returns. This observation goes against the common knowledge in other NMT frameworks and deep learning in general (Keskar et al., 2017) that smaller batches proceedslower(trainingexamplesperhour)butresultinbettergeneralization(higher test-set BLEU) in the end. In our experiments with the BASE model in T2T, bigger batches are not only faster in training throughput (as could be expected), but also faster in convergence speed, Time Till Score and Examples Till Score. Interestingly, when replicating these experiments with the BIG model, we see quite di?erentresults ,asshowninFigure6. TheBIGmodelneedsacertainminimalbatchsize tostartconvergingatall,butforhigherbatchsizesthereisalmostnodi?erenceinthe BLEUcurves(butstill,biggerbatchnevermakestheBLEUworseinourexperiments). In our case, the sharp di?erence is between batch size 1450, which trains well, and 1400, which drops o? after two hours of training, recovering only slowly. According to Smith and Le (2017) and Smith et al. (2017), the gradient noise scale , i.e. scaleofrandom?uctuationsintheSGD(orAdametc.) dynamics,isproportional to learning rate divided by the batch size (cf. Section 4.8). Thus when lowering the batchsize,weincreasethenoisescaleandthetrainingmay diverge. Thismaybeeither permanent, as in the case of batch size 1000 in Figure 6, or temporary, as in the case of batch size 1300 and 1400, where the BLEU continues to grow after the temporary drop, but much more slowly than the non-diverged curves. We are not sure what causes the di?erence between the BASE and BIG models with regards to the sensitivity to batch size. One hypothesis is that the BIG model is 1605101520 051015202530354045BLEU Training time (hours)learning rate 0.25 learning rate 0.20 learning rate 0.10 learning rate 0.05 learning rate 0.01 Figure 7: E?ect of the learning rate on a single GPU. All trained on CzEng 1.0 with the default batch size (1500) and warmup steps (16k). more di?cult to initialize and thus more sensitive to divergence in the early training phase. Also while for BASE, increasing the batch size was highly helpful until 4500, for BIG this limit may be below 1450, i.e. below the minimal batch size needed for preventing diverged training. Tip on Batch Size \u2022Batch size should be set as high as possible while keeping a reserve for not hitting the out-of-memory errors. It is advisable to establish the largest possible batch size before starting the main and long training. 4.6. Learning Rate and Warmup Steps on a Single GPU The default learning rate in T2T translation models is 0.20. Figure 7 shows that varying the value within range 0.05\u20130.25 makes almost no di?erence. Setting the learningratetoolow(0.01)resultsinnotablyslowerconvergence. Settingthelearning rate too high (0.30, not shown in the ?gure) results in divergedtraining, which means inthiscasethatthelearningcurvestartsgrowingasusual,butatonemomentdrops down almost to zero and stays there forever. A common solution to prevent diverged training is to decrease the learning_rate parameter or increase learning_rate_warmup_steps or introduce gradient clipping. The learning_rate_warmup_steps parameter con?gures a linear_warmup_rsqrt_decay schedule /two.superior5and it is set to 16 000 by default (for the BIG model), meaning that within /two.superior5The schedule was called noamin T2T versions older than 1.4.4. 1705101520 051015202530354045BLEU Training time (hours)warmup steps 12k warmup steps 14k warmup steps 16k warmup steps 32k warmup steps 48k Figure 8: E?ect of the warmup steps on a single GPU. All trained on CzEng 1.0 with the default batch size (1500) and learning rate (0.20). the?rst16kstepsthelearningrategrowslinearlyandthenfollowsaninversesquare root decay ( t-0.5, cf. Section 4.8.3). At 16k steps, the actual learning rate is thus the highest. If a divergence is to happen, it usually happens within the ?rst few hours of training, when the actual learning rate becomes the highest. Once we increased the warmup steps from 16k to 32k, we were able to train with the learning rate of 0.30 and even 0.50 without any divergence. The learning curves looked similarly to the baselineone(withdefaultvaluesof16kwarmupstepsandlearningrate0.20). When tryinglearningrate1.0,wehadtoincreasewarmupstepsto60k(with40kthetraining divergedafteronehour)\u2013thisresultedinaslowerconvergenceat?rst(about3BLEU lowerthanthebaselineafter8hoursoftraining),butafter3\u20134daysoftraininghaving the same curve as the baseline. Figure8showsthee?ectofdi?erentwarmupstepswitha?xedlearningrate(the default0.20). Settingwarmupstepstoolow(12k)resultsindivergedtraining. Setting them too high (48k, green curve) results in a slightly slower convergence at ?rst, but matching the baseline after a few hours of training. We can conclude that for a single GPU and the BIG model, there is a relatively largerangeoflearningrateandwarmupstepsvaluesthatachievetheoptimalresults. The default values learning_rate =0.20 and learning_rate_warmup_steps =16000 are within this range. Tips on Learning Rate and Warmup Steps \u2022In case of diverged training, try gradient clipping and/or more warmup steps. 18\u2022Ifthatdoesnothelp(orifthewarmupstepsaretoohighrelativetotheexpected total training steps), try decreasing the learning rate. \u2022Note that when you decrease warmup steps (and keep learning rate), you also increase the maximum actual learning rate because of the way how the lin- ear_warmup_rsqrt_decay (aka noam) schedule is implemented. /two.superior6 4.7. Number of GPUs T2T allows to train with multiple GPUs on the same machine simply using the parameter --worker_gpus ./two.superior7As explained in Section 2.3, the parameter batch_size is interpreted per GPU, so with 8 GPUs, the e?ective batch size is 8 times bigger. Asingle-GPUexperimentwithbatchsize4000,shouldgiveexactlythesameresults as two GPUs and batch size 2000 and as four GPUs and batch size 1000 because the e?ective batch size is 4000 in all three cases. We have con?rmed this empirically. By the \u201csame results\u201d we mean BLEU (or train loss) versus training steps on the x-axis. Whenconsideringtime,thefour-GPUexperimentwillbethefastestone,asexplained in Section 4.1. Figure 9 shows BLEU curves for di?erent numbers of GPUs and the BIG model with batch size, learning rate and warmup steps ?xed on their default values (1500, 0.20and16k,respectively). Ascouldbeexpected,trainingwithmoreGPUsconverges faster. WhatisinterestingistheTimeTillScore. Table6liststheapproximatetraining timeandnumberoftrainingexamples(inmillionsofsubwords)neededto\u201csurpass\u201d (i.e. achieve and never again fall below) BLEU of 25.6. # GPUs hours subwords (M) 1>600 >9000 2 203 2322\u00b72 = 4644 6 56 451\u00b76 = 2706 8 40 341\u00b78 = 2728 Table 6: Time and training data consumed to reach BLEU of 25.6, i.e. Time Till Score andExamplesTillScore. Notethattheexperimenton1GPUwasendedafter25days of training without clearly surpassing the threshold (already outside of Figure 9). /two.superior6This holds at least in T2T versions 1.2.9\u20131.5.2, but as it is somewhat unexpected/unintuitive for some users, it may be ?xed in future, see https://github.com/tensorflow/tensor2tensor/issues/517 . /two.superior7and making sure environment variable CUDA_VISIBLE_DEVICES is set so enough cards are visible. T2T allows also distributed training (on multiple machines), but we have not experimented with it. Both single-machine multi-gpu and distributed training use synchronous Adam updates by default. 1923.52424.52525.52626.527 0 50 100 150 200 250 300 3501234567891011121314BLEU Training time (hours)Training time (days) 8GPU 6GPU 2GPU 1GPU 25.6 Figure 9: E?ect of the number of GPUs. BLEU=25.6 is marked with a black line. We can see that two GPUs are more than three times faster than a single GPU when measuring the Time Till Score and need much less training examples (i.e. they have lowerExamplesTillScore). Similarly, eightGPUsaremorethan?vetimesfasterthantwo GPUsand 1.7 times less training data is needed. Recall that in Figure 6 we have shown that increasing the batch size from 1450 to 2000hasalmostnoe?ectontheBLEUcurve. However,whenincreasingthee?ective batch size by using more GPUs, the improvement is higher than could be expected from the higher throughput. /two.superior8We ?nd this quite surprising, especially considering the fact that we have not tuned the learning rate and warmup steps (see the next section). Tips on the Number of GPUs \u2022For the fastest BLEU convergence use as many GPUs as available (in our experi- ments up to 8). \u2022This holds even when there are more experiments to be done. For example, it is better to run one 8-GPUs experiment after another, rather than running two 4-GPUs experiments in parallel or eight single-GPU experiments in parallel. /two.superior8It would be interesting to try simulating multi-GPU training on a single GPU, simply by doing the updateonceafterNbatches(andsummingthegradients). Thisissimilartothe ghostbatches ofHo?eretal. (2017), but using ghost batch size higher than the actual batch size. We leave this for future work. 204.8. Learning Rate and Warmup Steps on Multiple GPUs 4.8.1. Related Work Thereisagrowingnumberofpapersonscalingdeeplearningtomultiplemachines withsynchronousSGD(oritsvariants)byincreasingthee?ectivebatchsize. Wewill focus mostly on the question how to adapt the learning rate schedule, when scaling from one GPU (or any device, in general) to kGPUs. Krizhevsky (2014) says \u201c Theory suggests that when multiplying the batch size by k, one should multiply the learning rate byv kto keep the variance in the gradient expectation constant\u201d, without actually explaining which theory suggests so. However, in the experimentalparthereportsthatwhatworkedthebest,wasa linearscalingheuristics , i.e. multiplying the learning rate by k, again without any explanation nor details on the di?erence betweenv kscaling and kscaling. The linear scaling heuristics become popular, leading to good scaling results in practice(Goyaletal.,2017;Smithetal.,2017)andalsotheoreticalexplanations(Bottou etal.,2016;SmithandLe,2017;Jastrzebskietal.,2017). SmithandLe(2017)interpret SGD(anditsvariants)asastochasticdi?erentialequationandshowthatthe gradient noise scale g/equalx?(N B-1) , where?is the learning rate, Nis the training set size, and Bis the e?ective batch size. This noise \u201c drives SGD away from sharp minima, and therefore there is an optimal batch size which maximizes the test set accuracy \u201d. In other words for keeping the optimal level of gradient noise (which leads to \u201c?at minima\u201d that generalize well), we need to scale the learning rate linearly when increasing the e?ective batch size. However,Ho?eretal.(2017)suggesttousev kscalinginsteadofthelinearscaling and provide both theoretical and empirical support for this claim. They show that cov(?w,?w)??2 NB,thusifwewanttokeepthethecovariancematrixoftheparameters update step ?win the same range for any e?ective batch size B, we need to scale the learningrateproportionallytothesquarerootof B. Theyfoundthatv kscalingworks better than linear scaling on CIFAR10. /two.superior?You et al. (2017) con?rm linear scaling does not perform well on ImageNet and suggest to use Layer-wise Adaptive Rate Scaling. Wecanseethatlarge-batchtrainingisstillanopenresearchquestion. Mostofthe paperscitedabovehaveexperimentalsupportonlyfromtheimagerecognitiontasks (usuallyImageNet)andconvolutionalnetworks(e.g. ResNet),soitisnotclearwhether their suggestions can be applied also on sequence-to-sequence tasks (NMT) with self-attentional networks (Transformer). There are several other di?erences as well: Modernconvolutionalnetworksareusuallytrainedwith batchnormalization (Io?eand Szegedy, 2015), which seems to be important for the scaling, while Transformer uses /two.superior?Toclosethegapbetweensmall-batchtrainingandlarge-batchtraining,Ho?eretal.(2017)introduce(in additiontov kscaling)so-called ghostbatchnormalization andadaptedtrainingregime ,whichmeansdecaying the learning rate after a given number of steps instead of epochs. 21layer normalization (Lei Ba et al., 2016). /three.superior\u00b0Also, Transformer uses Adam together with an inverse-square-root learning-rate decay, while most ImageNet papers use SGD with momentum and piecewise-constant learning-rate decay. 4.8.2. Our Experiments We decided to ?nd out empirically the optimal learning rate for training on 8 GPUs. Increasing the learning rate from 0.20 to 0.30 resulted in diverged training (BLEU dropped to almost 0 after two hours of training). Similarly to our single-GPU experiments (Section 4.6), we were able prevent the divergence by increasing the warmupstepsorbyintroducinggradientclipping(e.g. with clip_grad_norm=1.0 ,we were able to use learning rate 0.40, but increasing it further to 0.60 led to divergence anyway). However, none of these experiments led to any improvements over the default learning rate \u2013 all had about the same BLEU curve after few hours of training. Jastrzebski et al. (2017) shows that \u201c the invariance under simultaneous rescaling of learning rate and batch size breaks down if the learning rate gets too large or the batch size gets too small \u201d. A similar observation was reported e.g. by Bottou et al. (2016). Thus our initial hypothesis was that 0.20 (or 0.25) is the maximal learning rate suitable for stable training in our experiments even when we scale from a single GPUto 8 GPUs. Consideringthisinitialhypothesis,weweresurprisedthatwewereabletoachieveso goodTimeTillScorewith8GPUs(morethan8timessmallerrelativetoasingleGPU, as reported in Table 6). To answer this riddle we need to understand how learning rate schedules are implemented in T2T. 4.8.3. Parametrization of Learning Rate Schedules in T2T In most works on learning rate schedules /three.superior/one.superiorthe \u201ctime\u201d parameter is actually inter- preted as the number of epochs or training examples. For example a popular setup forpiecewise-constantdecayinImageNettraining(e.g.Goyaletal.,2017)istodivide the learning rate by a factor of 10 at the 30-th, 60-th, and 80-th epoch. However,inT2T,itisthe global_step variablethatisusedasthe\u201ctime\u201dparameter. So when increasing the e?ective batch size 8 times, e.g. by using 8 GPUs instead of a singleGPU,theactuallearningrate /three.superior/two.superiorachievesagivenvalueafterthesamenumberof steps,butthismeansafter8timeslesstrainingexamples. Fortheinverse-square-root /three.superior\u00b0Applying batch normalization on RNN is di?cult. Transformer does not use RNN, but still we were not successful in switching to batch normalization (and possibly ghost batch normalization) due to NaN loss errors. /three.superior/one.superiorExamplesoflearningrateschedulesareinverse-square-rootdecay,inverse-timedecay,exponentialde- cay, piecewise-constant decay, see https://www.tensorflow.org/api_guides/python/train#Decaying_the_ learning_rate for TF implementations. /three.superior/two.superiorByactuallearningratewemeanthelearningrateafterapplyingthedecayschedule. The learning_rate parameter stays the same in this case. 22decay, we have actual_lr(steps)/equalxc\u00b7steps-0.5/equalx1v 8\u00b7actual_lr(steps\u00b78), where cis a constant containing also the learning_rate parameter. So with 8 GPUs, if we divide thelearning_rate parameter byv 8, we achieve the same actual learning rate after a given number of training examples as in the original single-GPU setting. This explains the riddle from the previous section. By keeping the learning_rate parameter the same when scaling to ktimes bigger e?ective batch, we actually increase the actuallearningratev ktimes,inaccordancewiththesuggestionofHo?eretal.(2017). /three.superior/three.superior This holds only for the linear_warmup_rsqrt_decay (aka noam) schedule and ignoring the warmup steps. If we want to keep the same learning rate also in the warmup phase, we would need to divide the warmup steps by k. However, this means that the maximum actual learning rate will bev ktimes higher, relative to the single-GPU maximal actual learning rate and this leads to divergence in our experiments. In deed, many researchers (e.g. Goyal et al., 2017) suggest to use a warmup when scaling to more GPUs in order to prevent divergence. Transformer uses learning rate warmup by default even for single-GPU training (cf. Section 4.6), but it makes sense to use more warmup training examples in multi-GPU setting. In our experiments with 8 GPUs and the default learning rate 0.20, using 8k warmup steps instead of the default 16k had no e?ect on the BLEU curve (it was a bit higher in the ?rst few hours, but the same afterwards). Further decreasing the warmup steps resulted in a retarded BLEU curve (for 6k) or a complete divergence (for 2k). Tips on Learning Rate and Warmup Steps on Multiple GPUs \u2022Keep the learning_rate parameter at its optimal value found in single-GPU experiments. \u2022Youcantrydecreasingthewarmupsteps,butlessthanlinearlyandyoushould not expect to improve the ?nal BLEU this way. 4.9. Resumed Training T2Tallowstoresumetrainingfromacheckpoint,simplybypointingthe output_dir parametertoadirectorywithanexistingcheckpoint(speci?edinthe checkpoint ?le). Thismaybeusefulwhenthetrainingfails(e.g. becauseofhardwareerror),whenwe need to continue training on a di?erent machine or during hyper-parameter search, when we want to continue with the most promising setups. T2T saves also Adam /three.superior/three.superiorIn addition to suggesting thev klearning-rate scaling, Ho?er et al. (2017) show that to fully close the \u201cgeneralization gap\u201d, we need to train longer because the absolute number of steps (updates) matters. So from this point of view, using steps instead of epochs as the time parameter for learning rate schedules may not be a completely wrong idea. 232626.226.426.626.8 110 120 130 140 150 160 170 180BLEU Training time (hours)averaging 16 checkpoints averaging 8 checkpoints no averaging Figure 10: E?ect of checkpoint averaging. All trained on 6 GPUs. momentumintothecheckpoint,sothetrainingcontinuesalmostasifithadnotbeen stopped. However,itdoesnotstorethepositioninthetrainingdata\u2013itstartsfroma randomposition. Alsotherelativetime(andwall-clocktime)inTensorBoardgraphs will be in?uenced by the stopping. Resumed training can also be exploited for changing some hyper-parameters, which cannot be meta-parametrized by the number of steps. For example, Smith etal.(2017)suggesttoincreasethee?ectivebatchsize(andnumberofGPUs)during training, instead of decaying the learning rate. Yet another usage is to do domain adaptation by switching from (large) general- domain training data to (small) target-domain training data for the few last epochs. Inthiscase,considereditingalsothelearningrateorlearningrateschedule(orfaking theglobal_step stored in the checkpoint) to make sure the learning rate is not too small. 4.10. Checkpoint Averaging Vaswanietal.(2017)suggesttoaveragethelast20checkpointssavedin10-minute intervals (using utils/avg_checkpoints.py ). According to our experiments slightly betterresultsareachievedwithaveragingcheckpointssavedin1-hourintervals. This has also the advantage that less time is spent with checkpoint saving, so the training is faster. Figure 10 shows the e?ect of averaging is twofold: the averaged curve has lower variance (?ickering) from checkpoint to checkpoint and it is almost always better than the baseline without averaging (usually by about 0.2 BLEU). In some setups, we have seen improvements due to averaging over 1 BLEU. In the early phases of training, while the (baseline) learning curve grows fast, it is better to use fewer 24Manual Automatic Scores # Ave % Ave z BLEU TER CharacTER BEER System \u2013 \u2013 \u2013 23.8 0.662 0.582 0.543 T2T 8 GPUs 8 days 162.0 0.308 22.8 0.667 0.588 0.540 uedin-nmt 259.7 0.240 20.1 0.703 0.612 0.519 online-B 3 55.9 0.111 20.2 0.696 0.607 0.524 limsi-factored 55.2 0.102 20.0 0.699 - - LIUM-FNMT 55.2 0.090 20.2 0.701 0.605 0.522 LIUM-NMT 54.1 0.050 20.5 0.696 0.624 0.523 CU-Chimera 53.3 0.029 16.6 0.743 0.637 0.503 online-A 8 41.9 -0.327 16.2 0.757 0.697 0.485 PJATK Table7: WMT17systemsforEnglish-to-CzechandourbestT2Ttrainingrun. Manual scores are from the o?cial WMT17 ranking. Automatic metrics were provided by http://matrix.statmt.org/ . For *TER metrics, lower is better. Best results in bold, second-best in italics. checkpoints for averaging. In later phases (as shown in Figure 10, after 4.5\u20137.5 days of training), it seems that 16 checkpoints (covering last 16 hours) give slightly better results on average than 8 checkpoints, but we have not done any proper evaluation for signi?cance (using paired bootstrap testing for each hour and then summarizing the results). The fact that resumed training starts from a random position in the training data (cf. Section 4.9) can be actually exploited for \u201cforking\u201d a training to get two (or more) copies of the model, which are trained for the same number of steps, but independentlyinthelaterstagesandthusendingwithdi?erentweightssavedinthe ?nal checkpoint. These semi-independent models can be averaged in the same way ascheckpointsfromthesamerun,asdescribedabove. Ourpreliminaryresultsshow this helps a bit (on top of checkpoint averaging). Tips on Checkpoint Averaging \u2022Use it. Averaging 8 checkpoints takes about 5 minutes, so it is a \u201cBLEU boost for free\u201d (compared with the time needed for the whole training). \u2022See the tools for automatic checkpoint averaging and evaluation described in Section 2.4. 5. Comparison with WMT17 Systems Table 7 provides the results of WMT17 English-to-Czech news translation task, with our best Transformer model (BIG trained on 8 GPUs for 8 days, averaging 8 checkpoints) evaluated using the exact same implementation of automatic metrics. While the automatic evaluation is not fully reliable (see e.g. the high BLEU score 25for CU-Chimera despite its lower manual rank), we see that the Transformer model outperforms the best system in BLEU, TER, CharacTER and BEER, despite it does not use any back-translated data, reranking with other models (e.g. right-to-left reranking)norensembling(asisthecaseofuedin-nmtandothersystems). Notethat our Transformer uses a subset of the constrained training data for WMT17, so the results are comparable. 6. Conclusion We presented a broad range of basic experiments with the Transformer model (Vaswani et al., 2017) for English-to-Czech neural machine translation. While we limit our exploration to the more or less basic parameter settings, we believe this report can be useful for other researchers. In sum, experiments done for this article took about 4 years of GPU time. Among other practical observations, we\u2019ve seen that for the Transformer model, larger batch sizes lead not only to faster training but more importantly better trans- lation quality. Given at least a day and a 11GB GPU for training, the larger setup (BIG)shouldbealwayspreferred. TheTransformermodelanditsimplementationin Tensor2Tensor is also best ?t for \u201cintense training\u201d: using as many GPUs as possible andrunningexperimentsoneafteranothershouldbepreferredoverrunningseveral single-GPU experiments concurrently. Thebestperformingmodelweobtainedon8GPUstrainedfor8dayshasoutper- formed the WMT17 winner in a number of automatic metrics. Acknowledgements This research was supported by the grants 18-24210S of the Czech Science Foun- dation,H2020-ICT-2014-1-645452(QT21)oftheEU,SVV260453,andusinglanguage resources distributed by the LINDAT/CLARIN project of the Ministry of Education, Youth and Sports of the Czech Republic (LM2015071). Bibliography Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. Neural Machine Translation by Jointly Learning to Align and Translate. In Proceedings of ICLR , 2015. Bojar, Ondrej, Zdenek \u017dabokrtsk\u00fd, Ondrej Du\u0161ek, Petra Galu\u0161c\u00e1kov\u00e1, Martin Majli\u0161, David Marecek, Jir\u00ed Mar\u0161\u00edk, Michal Nov\u00e1k, Martin Popel, and Ale\u0161 Tamchyna. The Joy of Par- allelism with CzEng 1.0. In Proceedings of the Eighth International Language Resources and EvaluationConference(LREC\u201912) ,pages3921\u20133928,Istanbul,Turkey,May2012.ELRA,Euro- pean Language Resources Association. ISBN 978-2-9517408-7-7. Bojar, Ondrej, Ondrej Du\u0161ek, Tom Kocmi, Jindrich Libovick\u00fd, Michal Nov\u00e1k, Martin Popel, Roman Sudarikov, and Du\u0161an Vari\u0161. CzEng 1.6: Enlarged Czech-English Parallel Corpus 26with Processing Tools Dockered. In Sojka, Petr, Ale\u0161 Hor\u00e1k, Ivan Kopecek, and Karel Pala, editors,Text, Speech, and Dialogue: 19th International Conference, TSD 2016 , number 9924 in Lecture Notes in Arti?cial Intelligence, pages 231\u2013238. Masaryk University, Springer International Publishing, 2016. ISBN 978-3-319-45509-9. Bojar,Ondrej,RajenChatterjee,ChristianFedermann,YvetteGraham,BarryHaddow,Matthias Huck,PhilippKoehn,VarvaraLogacheva,ChristofMonz,MatteoNegri,MattPost,Raphael Rubino,LuciaSpecia,andMarcoTurchi. Findingsofthe2017ConferenceonMachineTrans- lation(WMT17). In ProceedingsoftheSecondConferenceonMachineTranslation ,Copenhagen, Denmark, September 2017a. ACL. Bojar, Ondrej, Yvette Graham, and Amir Kamran. Results of the WMT17 Metrics Shared Task. In Proceedings of the Second Conference on Machine Translation , Copenhagen, Denmark, September 2017b. ACL. Bottou, L\u00e9on. Stochastic Gradient Descent Tricks , pages 421\u2013436. Springer Berlin Heidelberg, Berlin, Heidelberg, 2012. ISBN 978-3-642-35289-8. doi: 10.1007/978-3-642-35289-8_25. URL https://doi.org/10.1007/978-3-642-35289-8_25 . Bottou, L., F. E. Curtis, and J. Nocedal. Optimization Methods for Large-Scale Machine Learn- ing.ArXiv e-prints , June 2016. URL https://arxiv.org/abs/1606.04838 . Cettolo, Mauro, Marcello Federico, Luisa Bentivogli, Jan Niehues, Sebastian St\u00fcker, Katsuhito Sudoh, Koichiro Yoshino, and Christian Federmann. Overview of the IWSLT 2017 Evalua- tionCampaign. In Proceedingsofthe14thInternationalWorkshoponSpokenLanguageTranslation (IWSLT), pages 2\u201314, Tokyo, Japan, 2017. Goyal,Priya,PiotrDoll\u00e1r,RossB.Girshick,PieterNoordhuis,LukaszWesolowski,AapoKyrola, AndrewTulloch,YangqingJia,andKaimingHe. Accurate,LargeMinibatchSGD:Training ImageNet in 1 Hour. CoRR, 2017. URL http://arxiv.org/abs/1706.02677 . Ho?er, Elad, Itay Hubara, and Daniel Soudry. Train longer, generalize better: closing the generalization gap in large batch training of neural networks. In Guyon, I., U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Ad- vances in Neural Information Processing Systems 30 , pages 1731\u20131741. Curran Associates, Inc., 2017. URL http://papers.nips.cc/paper/6770-train-longer-generalize-better-closing- the-generalization-gap-in-large-batch-training-of-neural-networks.pdf. Io?e,SergeyandChristianSzegedy. BatchNormalization: AcceleratingDeepNetworkTraining byReducingInternalCovariateShift. CoRR,abs/1502.03167,2015. URL http://arxiv.org/ abs/1502.03167 . Jastrzebski, Stanislaw, Zachary Kenton, Devansh Arpit, Nicolas Ballas, Asja Fischer, Yoshua Bengio, and Amos J. Storkey. Three Factors In?uencing Minima in SGD. CoRR, abs/1711.04623, 2017. URL http://arxiv.org/abs/1711.04623 . Keskar, Nitish Shirish, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Peter Tang. On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima. In Proceedings of ICLR , 2017. URL http://arxiv.org/abs/1609.04836 . Krizhevsky, Alex. One weird trick for parallelizing convolutional neural networks. CoRR, abs/1404.5997, 2014. URL http://arxiv.org/abs/1404.5997 . 27Lee, Jason, Kyunghyun Cho, and Thomas Hofmann. Fully Character-Level Neural Machine Translation without Explicit Segmentation. CoRR, 2016. URL http://arxiv.org/abs/1610. 03017. Lei Ba, J., J. R. Kiros, and G. E. Hinton. Layer Normalization. ArXiv e-prints , July 2016. Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu. BLEU: a Method for Au- tomatic Evaluation of Machine Translation. In Proceedings of ACL 2002 , pages 311\u2013318, Philadelphia, Pennsylvania, 2002. Popovic,Maja. chrF:charactern-gramF-scoreforautomaticMTevaluation. In Proceedingsofthe TenthWorkshoponStatisticalMachineTranslation ,pages392\u2013395,Lisbon,Portugal,September 2015. ACL. URL http://aclweb.org/anthology/W15-3049 . Sennrich, Rico, Barry Haddow, and Alexandra Birch. Neural Machine Translation of Rare Words with Subword Units. In Proceedings of ACL 2016 , pages 1715\u20131725, Berlin, Germany, August 2016. ACL. URL http://www.aclweb.org/anthology/P16-1162 . Shazeer, N. and M. Stern. Adafactor: Adaptive Learning Rates with Sublinear Memory Cost. ArXiv e-prints , Apr. 2018. URL https://arxiv.org/abs/1804.04235 . Smith, Samuel L. and Quoc V. Le. A Bayesian Perspective on Generalization and Stochastic Gradient Descent. In Proceedings of Second workshop on Bayesian Deep Learning (NIPS 2017) , Long Beach, CA, USA, 2017. URL http://arxiv.org/abs/1710.06451 . Smith, Samuel L., Pieter-Jan Kindermans, and Quoc V. Le. Don\u2019t Decay the Learning Rate, Increase the Batch Size. CoRR, 2017. URL http://arxiv.org/abs/1711.00489 . Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, LukaszKaiser,andIlliaPolosukhin. AttentionisAllyouNeed. InGuyon,I.,U.V.Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30 , pages 6000\u20136010. Curran Associates, Inc., 2017. URL http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf . Wu, Yonghui, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey,MaximKrikun,YuanCao,QinGao,KlausMacherey,Je?Klingner,ApurvaShah, MelvinJohnson,XiaobingLiu,LukaszKaiser,StephanGouws,YoshikiyoKato,TakuKudo, HidetoKazawa,KeithStevens,GeorgeKurian,NishantPatil,WeiWang,Cli?Young,Jason Smith,JasonRiesa,AlexRudnick,OriolVinyals,GregCorrado,Macdu?Hughes,andJe?rey Dean. Google\u2019sNeuralMachineTranslationSystem: BridgingtheGapbetweenHumanand MachineTranslation. CoRR,abs/1609.08144,2016. URL http://arxiv.org/abs/1609.08144 . You, Yang, Igor Gitman, and Boris Ginsburg. Scaling SGD Batch Size to 32K for ImageNet Training. CoRR, abs/1708.03888, 2017. URL http://arxiv.org/abs/1708.03888 . Address for correspondence: Martin Popel popel@ufal.mff.cuni.cz Institute of Formal and Applied Linguistics Faculty of Mathematics and Physics, Charles University Malostransk\u00e9 n\u00e1mest\u00ed 25, 118 00 Praha 1 Czech Republic 28", "18": "Proceedings of the 2020 EMNLP (Systems Demonstrations) , pages 38\u201345 November 16-20, 2020. c?2020 Association for Computational Linguistics38 Transformers: State-of-the-Art Natural Language Processing Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R \u00b4emi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, Alexander M. Rush Hugging Face, Brooklyn, USA / {first-name}@huggingface.co Abstract Recent progress in natural language process- ing has been driven by advances in both model architecture and model pretraining. Trans- former architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this ca- pacity for a wide variety of tasks. Trans- formers is an open-source library with the goal of opening up these advances to the wider machine learning community. The li- brary consists of carefully engineered state- of-the art Transformer architectures under a uni?ed API. Backing this library is a cu- rated collection of pretrained models made by and available for the community. Trans- formers is designed to be extensible by re- searchers, simple for practitioners, and fast and robust in industrial deployments. The li- brary is available at https://github.com/ huggingface/transformers . 1 Introduction The Transformer (Vaswani et al., 2017) has rapidly become the dominant architecture for natural lan- guage processing, surpassing alternative neural models such as convolutional and recurrent neural networks in performance for tasks in both natural language understanding and natural language gen- eration. The architecture scales with training data and model size, facilitates ef?cient parallel training, and captures long-range sequence features. Model pretraining (McCann et al., 2017; Howard and Ruder, 2018; Peters et al., 2018; Devlin et al., 2018) allows models to be trained on generic cor- pora and subsequently be easily adapted to speci?c tasks with strong performance. The Transformer architecture is particularly conducive to pretrain- ing on large text corpora, leading to major gains in accuracy on downstream tasks including text classi- ?cation (Yang et al., 2019), language understanding(Liu et al., 2019b; Wang et al., 2018, 2019), ma- chine translation (Lample and Conneau, 2019a), coreference resolution (Joshi et al., 2019), com- monsense inference (Bosselut et al., 2019), and summarization (Lewis et al., 2019) among others. This advance leads to a wide range of practical challenges that must be addressed in order for these models to be widely utilized. The ubiquitous use of the Transformer calls for systems to train, analyze, scale, and augment the model on a variety of plat- forms. The architecture is used as a building block to design increasingly sophisticated extensions and precise experiments. The pervasive adoption of pre- training methods has led to the need to distribute, ?ne-tune, deploy, and compress the core pretrained models used by the community. Transformers is a library dedicated to supporting Transformer-based architectures and facilitating the distribution of pretrained models. At the core of the libary is an implementation of the Transformer which is designed for both research and production. The philosophy is to support industrial-strength im- plementations of popular model variants that are easy to read, extend, and deploy. On this founda- tion, the library supports the distribution and usage of a wide-variety of pretrained models in a cen- tralized model hub. This hub supports users to compare different models with the same minimal API and to experiment with shared models on a variety of different tasks. Transformers is an ongoing effort maintained by the team of engineers and researchers at Hugging Face with support from a vibrant community of over 400 external contributors. The library is re- leased under the Apache 2.0 license and is available on GitHub1. Detailed documentation and tutorials are available on Hugging Face\u2019s website2. 1https://github.com/huggingface/ transformers 2https://huggingface.co/transformers/39 Figure 1: Average daily unique downloads of the most downloaded pretrained models, Oct. 2019 to May 2020. 2 Related Work The NLP and ML communities have a strong cul- ture of building open-source research tools. The structure of Transformers is inspired by the pi- oneering tensor2tensor library (Vaswani et al., 2018) and the original source code for BERT (De- vlin et al., 2018), both from Google Research. The concept of providing easy caching for pre- trained models stemmed from AllenNLP (Gard- ner et al., 2018). The library is also closely re- lated to neural translation and language modeling systems, such as Fairseq (Ott et al., 2019), Open- NMT (Klein et al., 2017), Texar (Hu et al., 2018), Megatron-LM (Shoeybi et al., 2019), and Mar- ian NMT (Junczys-Dowmunt et al., 2018). Build- ing on these elements, Transformers adds extra user-facing features to allow for easy downloading, caching, and ?ne-tuning of the models as well as seamless transition to production. Transformers maintains some compatibility with these libraries, most directly including a tool for performing infer- ence using models from Marian NMT and Google\u2019s BERT. There is a long history of easy-to-use, user- facing libraries for general-purpose NLP. Two core libraries are NLTK (Loper and Bird, 2002) and Stanford CoreNLP (Manning et al., 2014), which collect a variety of different approaches to NLP in a single package. More recently, general-purpose, open-source libraries have focused primarily on machine learning for a variety of NLP tasks, these include Spacy (Honnibal and Montani, 2017), Al- lenNLP (Gardner et al., 2018), ?air (Akbik et al., 2019), and Stanza (Qi et al., 2020). Transform- ersprovides similar functionality as these libraries. Additionally, each of these libraries now uses theTransformers library and model hub as a low-level framework. Since Transformers provides a hub for NLP mod- els, it is also related to popular model hubs includ- ing Torch Hub and TensorFlow Hub which collect framework-speci?c model parameters for easy use. Unlike these hubs, Transformers is domain-speci?c which allows the system to provide automatic sup- port for model analysis, usage, deployment, bench- marking, and easy replicability. 3 Library Design Transformers is designed to mirror the standard NLP machine learning model pipeline: process data, apply a model, and make predictions. Al- though the library includes tools facilitating train- ing and development, in this technical report we focus on the core modeling speci?cations. For complete details about the features of the library refer to the documentation available on https: //huggingface.co/transformers/ . Every model in the library is fully de?ned by three building blocks shown in the diagram in Fig- ure 2: (a) a tokenizer, which converts raw text to sparse index encodings, (b) a transformer, which transforms sparse indices to contextual embed- dings, and (c) a head, which uses contextual em- beddings to make a task-speci?c prediction. Most user needs can be addressed with these three com- ponents. Transformers Central to the library are carefully tested implementations of Transformer architecture variants which are widely used in NLP. The full list of currently implemented architectures is shown in Figure 2 (Left). While each of these architectures40Heads Name Input Output Tasks Ex. Datasets Language Modeling x1:n-1 xn?V Generation WikiText-103 Sequence Classi?cation x1:N y?C Classi?cation, Sentiment AnalysisGLUE, SST, MNLI Question Answering x1:M,xM:Nyspan[1 :N]QA, Reading ComprehensionSQuAD, Natural Questions Token Classi?cation x1:N y1:N?CNNER, Tagging OntoNotes, WNUT Multiple Choice x1:N,X y?X Text Selection SWAG, ARC Masked LM x1:N\\n xn?V Pretraining Wikitext, C4 Conditional Generation x1:N y1:M?VMTranslation, SummarizationWMT, IWSLT, CNN/DM, XSum Transformers Masked [x1:N\\n?xn] BERT (Devlin et al., 2018) RoBERTa (Liu et al., 2019a) Autoregressive [x1:n-1?xn] GPT / GPT-2 (Radford et al., 2019) Trans-XL (Dai et al., 2019) XLNet (Yang et al., 2019) Seq-to-Seq [~x1:N?x1:N] BART (Lewis et al., 2019) T5 (Raffel et al., 2019) MarianMT (J.-Dowmunt et al., 2018) Specialty: Multimodal MMBT (Kiela et al., 2019) Specialty: Long-Distance Reformer (Kitaev et al., 2020) Longformer (Beltagy et al., 2020) Specialty: Ef?cient ALBERT (Lan et al., 2019) Electra (Clark et al., 2020) DistilBERT (Sanh et al., 2019) Specialty: Multilingual XLM/RoBERTa (Lample and Conneau, 2019b) T ransformer  T okenizer Head Head Tokenizers Name Ex. Uses Character-Level BPE NMT, GPT Byte-Level BPE GPT-2 WordPiece BERT SentencePiece XLNet Unigram LM Character Reformer Custom Bio-Chem Figure 2: The Transformers library. (Diagram-Right) Each model is made up of a Tokenizer, Transformer, and Head. The model is pretrained with a ?xed head and can then be further ?ne-tuned with alternate heads for different tasks. (Bottom) Each model uses a speci?c Tokenizer either implemented in Python or in Rust. These often differ in small details, but need to be in sync with pretraining. (Left) Transformer architectures specialized for different tasks, e.g. understanding versus generation, or for speci?c use-cases, e.g. speed, image+text. (Top) heads allow a Transformer to be used for different tasks. Here we assume the input token sequence is x1:Nfrom a vocabulary V, andyrepresents different possible outputs, possibly from a class set C. Example datasets represent a small subset of example code distributed with the library.41shares the same multi-headed attention core, there are signi?cant differences between them including positional representations, masking, padding, and the use of sequence-to-sequence design. Addition- ally, various models are built to target different applications of NLP such as understanding, gener- ation, and conditional generation, plus specialized use cases such as fast inference or multi-lingual applications. Practically, all models follow the same hierarchy of abstraction: a base class implements the model\u2019s computation graph from an encoding (projection on the embedding matrix) through the series of self- attention layers to the ?nal encoder hidden states. The base class is speci?c to each model and closely follows the model\u2019s original implementation which gives users the ?exibility to easily dissect the inner workings of each individual architecture. In most cases, each model is implemented in a single ?le to enable ease of extensibility. Wherever possible, different architectures fol- low the same API allowing users to switch easily between different models. A set of Auto classes provides a uni?ed API that enables very fast switch- ing between models and even between frameworks. These classes automatically instantiate with the con?guration speci?ed by the user-speci?ed pre- trained model. Tokenizers A critical NLP-speci?c aspect of the library is the implementations of the tokenizers nec- essary to use each model. Tokenizer classes (each inheriting from a common base class) can either be instantiated from a corresponding pretrained model or can be con?gured manually. These classes store the vocabulary token-to-index map for their corre- sponding model and handle the encoding and de- coding of input sequences according to a model\u2019s speci?c tokenization process. The tokenizers im- plemented are shown in Figure 2 (Right). Users can easily modify tokenizer with interfaces to add additional token mappings, special tokens (such as classi?cation or separation tokens), or otherwise resize the vocabulary. Tokenizers can also implement additional useful features for the users. These range from token type indices in the case of sequence classi?cation to maximum length sequence truncating taking into account the added model-speci?c special tokens (most pretrained Transformer models have a maxi- mum sequence length). For training on very large datasets, Python-basedtokenization is often undesirably slow. In the most recent release, Transformers switched its im- plementation to use a highly-optimized tokeniza- tion library by default. This low-level library, available at https://github.com/huggingface/ tokenizers , is written in Rust to speed up the tokenization procedure both during training and deployment. Heads Each Transformer can be paired with one out of several ready-implemented heads with outputs amenable to common types of tasks. These heads are implemented as ad- ditional wrapper classes on top of the base class, adding a speci?c output layer, and op- tional loss function, on top of the Transformer\u2019s contextual embeddings. The full set of im- plemented heads are shown in Figure 2 (Top). These classes follow a similar naming pattern: XXXForSequenceClassification where XXX is the name of the model and can be used for adaptation (?ne-tuning) or pretraining. Some heads, such as conditional generation, support extra functionality like sampling and beam search. For pretrained models, we release the heads used to pretrain the model itself. For instance, for BERT we release the language modeling and next sen- tence prediction heads which allows easy for adap- tation using the pretraining objectives. We also make it easy for users to utilize the same core Trans- former parameters with a variety of other heads for ?netuning. While each head can be used generally, the library also includes a collection of examples that show each head on real problems. These ex- amples demonstrate how a pretrained model can be adapted with a given head to achieve state-of-the- art results on a large variety of NLP tasks. 4 Community Model Hub Transformers aims to facilitate easy use and dis- tribution of pretrained models. Inherently this is a community process; a single pretraining run fa- cilitates ?ne-tuning on many speci?c tasks. The Model Hub makes it simple for any end-user to ac- cess a model for use with their own data. This hub now contains 2,097 user models, both pretrained and ?ne-tuned, from across the community. Fig- ure 1 shows the increase and distribution of popular transformers over time. While core models like BERT and GPT-2 continue to be popular, other spe- cialized models including DistilBERT (Sanh et al., 2019), which was developed for the library, are42 Figure 3: Transformers Model Hub. (Left) Example of a model page and model card for SciBERT (Beltagy et al., 2019), a pretrained model targeting extraction from scienti?c literature submitted by a community contrib- utor. (Right) Example of an automatic inference widget for the pretrained BART (Lewis et al., 2019) model for summarization. Users can enter arbitrary text and a full version of the model is deployed on the ?y to produce a summary. now widely downloaded by the community. The user interface of the Model Hub is designed to be simple and open to the community. To upload a model, any user can sign up for an account and use a command-line interface to produce an archive consisting a tokenizer, transformer, and head. This bundle may be a model trained through the library or converted from a checkpoint of other popular training tools. These models are then stored and given a canonical name which a user can use to download, cache, and run the model either for ?ne- tuning or inference in two lines of code. To load FlauBERT (Le et al., 2020), a BERT model pre- trained on a French training corpus, the command is: 1tknzr = AutoTokenizer.from_pretrained( 2 \"flaubert/flaubert_base_uncased\") 3model = AutoModel.from_pretrained( 4 \"flaubert/flaubert_base_uncased\") When a model is uploaded to the Model Hub, it is automatically given a landing page describing its core properties, architecture, and use cases. Addi- tional model-speci?c metadata can be provided via a model card (Mitchell et al., 2018) that describes properties of its training, a citation to the work, datasets used during pretraining, and any caveats about known biases in the model and its predictions. An example model card is shown in Figure 3 (Left). Since the Model Hub is speci?c to transformer- based models, we can target use cases that wouldbe dif?cult for more general model collections. For example, because each uploaded model includes metadata concerning its structure, the model page can include live inference that allows users to ex- periment with output of models on a real data. Fig- ure 3 (Right) shows an example of the model page with live inference. Additionally, model pages in- clude links to other model-speci?c tools like bench- marking and visualizations. For example, model pages can link to exBERT (Hoover et al., 2019), a Transformer visualization library. Community Case Studies The Model Hub high- lights how Transformers is used by a variety of different community stakeholders. We summarize three speci?c observed use-cases in practice. We highlight speci?c systems developed by users with different goals following the architect, trainer, and end-user distinction of Strobelt et al. (2017): Case 1: Model Architects AllenAI, a major NLP research lab, developed a new pretrained model for improved extraction from biomedical texts called SciBERT (Beltagy et al., 2019). They were able to train the model utilizing data from PubMed to produce a masked language model with state-of- the-art results on targeted text. They then used the Model Hub to distribute the model and promote it as part of their CORD - COVID-19 challenge, making it trivial for the community to use. Case 2: Task Trainers Researchers at NYU were43interested in developing a test bed for the per- formance of Transformers on a variety of differ- ent semantic recognition tasks. Their framework Jiant (Pruksachatkun et al., 2020) allows them to experiment with different ways of pretraining mod- els and comparing their outputs. They used the Transformers API as a generic front-end and per- formed ?ne-tuning on a variety of different models, leading to research on the structure of BERT (Ten- ney et al., 2019). Case 3: Application Users Plot.ly, a company fo- cused on user dashboards and analytics, was in- terested in deploying a model for automatic doc- ument summarization. They wanted an approach that scaled well and was simple to deploy, but had no need to train or ?ne-tune the model. They were able to search the Model Hub and ?nd DistilBART , a pretrained and ?ne-tuned summarization model designed for accurate, fast inference. They were able to run and deploy the model directly from the hub with no required research or ML expertise. 5 Deployment An increasingly important goal of Transformers is to make it easy to ef?ciently deploy model to pro- duction. Different users have different production needs, and deployment often requires solving sig- ni?cantly different challenges than training. The library thereforce allows for several different strate- gies for production deployment. One core propery of the libary is that models are available both in PyTorch and TensorFlow, and there is interoperability between both frameworks. A model trained in one of frameworks can be saved through standard serialization and be reloaded from the saved ?les in the other framework seamlessly. This makes it particularly easy to switch from one framework to the other one along the model life- time (training, serving, etc.). Each framework has deployment recommenda- tions. For example, in PyTorch, models are compat- ible with TorchScript, an intermediate representa- tion of a PyTorch model that can then be run either in Python in a more ef?cient way, or in a high- performance environment such as C++. Fine-tuned models can thus be exported to production-friendly environment, and run through TorchServing. Ten- sorFlow includes several serving options within its ecosystem, and these can be used directly. Transformers can also export models to interme- diate neural network formats for further compila- Figure 4: Experiments with Transformers inference in collaboration with ONNX. tion. It supports converting models to the Open Neural Network Exchange format (ONNX) for de- ployment. Not only does this allow the model to be run in a standardized interoperable format, but also leads to signi?cant speed-ups. Figure 4 shows experiments run in collaboration with the ONNX team to optimize BERT, RoBERTa, and GPT-2 from the Transformers library. Using this interme- diate format, ONNX was able to achieve nearly a 4x speedup on this model. The team is also ex- perimenting with other promising intermediate for- mats such as JAX/XLA (Bradbury et al., 2018) and TVM (Chen et al., 2018). Finally, as Transformers become more widely used in all NLP applications, it is increasingly im- portant to deploy to edge devices such as phones or home electronics. Models can use adapters to convert models to CoreML weights that are suit- able to be embedded inside a iOS application, to enable on-the-edge machine learning. Code is also made available3. Similar methods can be used for Android devices. 6 Conclusion As Transformer and pretraining play larger roles in NLP, it is important for these models to be acces- sible to researchers and end-users. Transformers is an open-source library and community designed to facilitate users to access large-scale pretrained models, to build and experiment on top of them, and to deploy them in downstream tasks with state- of-the-art performance. Transformers has gained signi?cant organic traction since its release and is set up to continue to provide core infrastructure while helping to facilitate access to new models. 3https://github.com/huggingface/ swift-coreml-transformers44References a. PyTorch Hub. https://pytorch.org/hub/ . Ac- cessed: 2020-6-29. b. TensorFlow hub. https://www.tensorflow. org/hub . Accessed: 2020-6-29. Alan Akbik, Tanja Bergmann, Duncan Blythe, Kashif Rasul, Stefan Schweter, and Roland V ollgraf. 2019. Flair: An easy-to-use framework for state-of-the-art nlp. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Com- putational Linguistics (Demonstrations) , pages 54\u2013 59. aclweb.org. Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciB- ERT: A pretrained language model for scienti?c text. InProceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Lan- guage Processing (EMNLP-IJCNLP) , pages 3615\u2013 3620. Iz Beltagy, Matthew E Peters, and Arman Cohan. 2020. Longformer: The Long-Document transformer. Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chai- tanya Malaviya, Asli C \u00b8 elikyilmaz, and Yejin Choi. 2019. Comet: Commonsense transformers for auto- matic knowledge graph construction. In ACL. James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dou- gal Maclaurin, and Skye Wanderman-Milne. 2018. JAX: composable transformations of Python+NumPy programs. Tianqi Chen, Thierry Moreau, Ziheng Jiang, Lianmin Zheng, Eddie Yan, Haichen Shen, Meghan Cowan, Leyuan Wang, Yuwei Hu, Luis Ceze, et al. 2018. {TVM}: An automated end-to-end optimizing com- piler for deep learning. In 13th{USENIX}Sympo- sium on Operating Systems Design and Implementa- tion ({OSDI}18), pages 578\u2013594. Kevin Clark, Minh-Thang Luong, Quoc V Le, and Christopher D Manning. 2020. ELECTRA: Pre- training text encoders as discriminators rather than generators. Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Car- bonell, Quoc V Le, and Ruslan Salakhutdinov. 2019. Transformer-XL: Attentive language models beyond a Fixed-Length context. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. BERT: Pre-training of deep bidirectional transformers for language under- standing. Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson Liu, Matthew Pe- ters, Michael Schmitz, and Luke Zettlemoyer. 2018. AllenNLP: A deep semantic natural language pro- cessing platform.Matthew Honnibal and Ines Montani. 2017. spacy 2: Natural language understanding with bloom embed- dings, convolutional neural networks and incremen- tal parsing. To appear , 7(1). Benjamin Hoover, Hendrik Strobelt, and Sebastian Gehrmann. 2019. exBERT: A visual analysis tool to explore learned representations in transformers mod- els. Jeremy Howard and Sebastian Ruder. 2018. Universal language model ?ne-tuning for text classi?cation. In ACL. Zhiting Hu, Haoran Shi, Bowen Tan, Wentao Wang, Zichao Yang, Tiancheng Zhao, Junxian He, Lianhui Qin, Di Wang, Xuezhe Ma, Zhengzhong Liu, Xiao- dan Liang, Wangrong Zhu, Devendra Singh Sachan, and Eric P Xing. 2018. Texar: A modularized, ver- satile, and extensible toolkit for text generation. Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S Weld, Luke Zettlemoyer, and Omer Levy. 2019. Spanbert: Improving pre-training by representing and predict- ing spans. arXiv preprint arXiv:1907.10529 . Marcin Junczys-Dowmunt, Roman Grundkiewicz, Tomasz Dwojak, Hieu Hoang, Kenneth Hea?eld, Tom Neckermann, Frank Seide, Ulrich Germann, Al- ham Fikri Aji, Nikolay Bogoychev, Andr \u00b4e F T Mar- tins, and Alexandra Birch. 2018. Marian: Fast neu- ral machine translation in c++. Douwe Kiela, Suvrat Bhooshan, Hamed Firooz, and Davide Testuggine. 2019. Supervised multimodal bitransformers for classifying images and text. Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya. 2020. Reformer: The ef?cient transformer. Guillaume Klein, Yoon Kim, Yuntian Deng, Jean Senel- lart, and Alexander Rush. 2017. OpenNMT: Open- source toolkit for neural machine translation. In Proceedings of ACL 2017, System Demonstrations , pages 67\u201372, Vancouver, Canada. Association for Computational Linguistics. Guillaume Lample and Alexis Conneau. 2019a. Cross- lingual language model pretraining. In NeurIPS . Guillaume Lample and Alexis Conneau. 2019b. Cross- lingual language model pretraining. Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. 2019. ALBERT: A lite BERT for self-supervised learning of language representations. Hang Le, Lo \u00a8ic Vial, Jibril Frej, Vincent Segonne, Max- imin Coavoux, Benjamin Lecouteux, Alexandre Al- lauzen, Beno \u02c6it Crabb \u00b4e, Laurent Besacier, and Didier Schwab. 2020. Flaubert: Unsupervised language model pre-training for french. In Proceedings of The 12th Language Resources and Evaluation Con- ference , pages 2479\u20132490, Marseille, France. Euro- pean Language Resources Association.45Mike Lewis, Yinhan Liu, Naman Goyal, Mar- jan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019. BART: Denoising Sequence-to-Sequence pre- training for natural language generation, translation, and comprehension. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man- dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019a. RoBERTa: A robustly optimized BERT pretraining approach. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man- dar S. Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke S. Zettlemoyer, and Veselin Stoyanov. 2019b. Roberta: A robustly optimized bert pretraining ap- proach. ArXiv , abs/1907.11692. Edward Loper and Steven Bird. 2002. NLTK: The nat- ural language toolkit. Christopher D Manning, Mihai Surdeanu, John Bauer, Jenny Rose Finkel, Steven Bethard, and David Mc- Closky. 2014. The stanford CoreNLP natural lan- guage processing toolkit. In Proceedings of 52nd annual meeting of the association for computational linguistics: system demonstrations , pages 55\u201360. aclweb.org. Bryan McCann, James Bradbury, Caiming Xiong, and Richard Socher. 2017. Learned in translation: Con- textualized word vectors. In I Guyon, U V Luxburg, S Bengio, H Wallach, R Fergus, S Vishwanathan, and R Garnett, editors, Advances in Neural Informa- tion Processing Systems 30 , pages 6294\u20136305. Cur- ran Associates, Inc. Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and Timnit Gebru. 2018. Model cards for model reporting. Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. 2019. fairseq: A fast, extensible toolkit for sequence modeling. Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word repre- sentations. Yada Pruksachatkun, Phil Yeres, Haokun Liu, Jason Phang, Phu Mon Htut, Alex Wang, Ian Tenney, and Samuel R Bowman. 2020. jiant: A software toolkit for research on general-purpose text understanding models. arXiv preprint arXiv:2003.02249 . Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, and Christopher D Manning. 2020. Stanza: A python natural language processing toolkit for many human languages.Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI Blog , 1(8):9. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2019. Exploring the limits of transfer learning with a uni?ed Text-to-Text trans- former. Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019. DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catan- zaro. 2019. Megatron-lm: Training multi-billion parameter language models using gpu model paral- lelism. arXiv preprint arXiv:1909.08053 . Hendrik Strobelt, Sebastian Gehrmann, Hanspeter P?s- ter, and Alexander M Rush. 2017. Lstmvis: A tool for visual analysis of hidden state dynamics in recur- rent neural networks. IEEE transactions on visual- ization and computer graphics , 24(1):667\u2013676. Ian Tenney, Dipanjan Das, and Ellie Pavlick. 2019. Bert rediscovers the classical nlp pipeline. In ACL. Ashish Vaswani, Samy Bengio, Eugene Brevdo, Fran- cois Chollet, Aidan N. Gomez, Stephan Gouws, Llion Jones, Lukasz Kaiser, Nal Kalchbrenner, Niki Parmar, Ryan Sepassi, Noam Shazeer, and Jakob Uszkoreit. 2018. Tensor2tensor for neural machine translation. CoRR , abs/1803.07416. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, L Ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In I Guyon, U V Luxburg, S Bengio, H Wallach, R Fergus, S Vishwanathan, and R Gar- nett, editors, Advances in Neural Information Pro- cessing Systems 30 , pages 5998\u20136008. Curran Asso- ciates, Inc. Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. 2019. Superglue: A stickier benchmark for general-purpose language un- derstanding systems. ArXiv , abs/1905.00537. Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. 2018. Glue: A multi-task benchmark and analysis platform for natural language understanding. In ICLR . Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Car- bonell, Ruslan Salakhutdinov, and Quoc V . Le. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. ArXiv , abs/1906.08237.", "2": "arXiv:1909.12072v1  [cs.AI]  26 Sep 2019Towards Explainable Arti?cial Intelligence Wojciech Samek1and Klaus-Robert M\u00a8 uller2,3,4 1Fraunhofer Heinrich Hertz Institute, 10587 Berlin, German y wojciech.samek@hhi.fraunhofer.de 2Technische Universit\u00a8 at Berlin, 10587 Berlin, Germany 3Korea University, Anam-dong, Seongbuk-gu, Seoul 02841, Ko rea 4Max Planck Institute for Informatics, Saarbr\u00a8 ucken 66123, Germany klaus-robert.mueller@tu-berlin.de Abstract. In recent years, machine learning (ML) has become a key enabling technology for the sciences and industry. Especia lly through improvements in methodology, the availability of large dat abases and in- creased computational power, today\u2019s ML algorithms are abl e to achieve excellent performance (at times even exceeding the human le vel) on an increasing number of complex tasks. Deep learning models ar e at the forefront of this development. However, due to their nested non-linear structure, these powerful models have been generally consi dered \u201cblack boxes\u201d, not providing any information about what exactly ma kes them arrive at their predictions. Since in many applications, e. g., in the med- ical domain, such lack of transparency may be not acceptable , the de- velopment of methods for visualizing, explaining and inter preting deep learning models has recently attracted increasing attenti on. This intro- ductory paper presents recent developments and applicatio ns in this ?eld and makes a plea for a wider use of explainable learning algorithms in practice. Keywords: Explainable Arti?cial Intelligence \u00b7Model Transparency \u00b7 Deep Learning \u00b7Neural Networks \u00b7Interpretability 1 Introduction Today\u2019s arti?cial intelligence (AI) systems based on machine learning excel in many ?elds. They not only outperform humans in complex visual task s [16,53] or strategic games [ 56,83,61], but also became an indispensable part of our every day lives, e.g., as intelligent cell phone cameras which can recognize an d track faces [71], as online services which can analyze and translate written texts [ 11] or as consumer devices which can understand speech and generat e human-like answers [ 90]. Moreover, machine learning and arti?cial intelligence have become The ?nal authenticated publication is available online at https://doi.org/10.1007/978-3-030-28954-6_1 . In: W. Samek et al. (Eds.) Explainable AI: Interpreting, Explaining and Visualizing Deep Learning. Lecture Notes in Computer Science, vol. 11700, pp. 5-22. Springer, C ham (2019).2 W. Samek and K.-R. M\u00a8 uller indispensable tools in the sciences for tasks such as prediction, simu lation or ex- ploration [ 78,15,89,92]. These immense successes of AI systems mainly became possible through improvements in deep learning methodology [ 48,47], the avail- abilityoflargedatabases[ 17,34]andcomputationalgainsobtainedwithpowerful GPU cards [ 52]. Despite the revolutionary character of this technology, challenge s still exist which slow down or even hinder the prevailance of AI in some application s. Examplar challenges are (1) the large complexity and high energy dem ands of current deep learning models [ 29], which hinder their deployment in resource restricted environments and devices, (2) the lack of robustness to adversarial attacks [55], which pose a severe security risk in application such as autonomous driving5, and (3) the lack of transparency and explainability [ 76,32,18], which reduces the trust in and the veri?ability of the decisions made by an A I system. This paper focuses on the last challenge. It presents recent deve lopments in the ?eld of explainable arti?cial intelligence and aims to foster awareness for the advantages\u2013and at times\u2013also for the necessity of transparent decision making in practice. The historic second Go match between Lee Sedol and Alp haGo [82] nicely demonstrates the power of today\u2019s AI technology, and hints at its enor- mous potential for generating new knowledge from data when being accessible for human interpretation. In this match AlphaGo played a move, whic h was classi?ed as \u201cnot a human move\u201d by a renowned Go expert, but which was the deciding move for AlphaGo to win the game. AlphaGo did not explain the m ove, but the later playunveiled the intention behind its decision. With explain able AI it may be possible to also identify such novel patterns and strategie s in domains like health, drug development or material sciences, moreover, the explanations will ideally let us comprehend the reasoning of the system and unders tand why the system has decided e.g. to classify a patient in a speci?c manner o r asso- ciate certain properties with a new drug or material. This opens up inn umerable possibilities for future research and may lead to new scienti?c insight s. The remainder of the paper is organized as follows. Section 2discusses the need for transparencyand trust in AI. Section 3comments on the di?erent types of explanations and their respective information content and use in practice. Recent techniques of explainable AI are brie?y summarized in Section 4, includ- ing methods which rely on simple surrogate functions, frame explana tion as an optimization problem, access the model\u2019s gradient or make use of the model\u2019s internal structure. The question of how to objectively evaluate t he quality of explanations is addressed in Section 5. The paper concludes in Section 6with a discussion on general challenges in the ?eld of explainable AI. 5The authors of [ 24] showed that deep models can be easily fooled by physical-wo rld attacks. For instance, by putting speci?c stickers on a stop sign one can achieve that the stop sign is not recognized by the system anymore.1. Towards Explainable Arti?cial Intelligence 3 2 Need for Transparency and Trust in AI Black box AI systems have spread to many of today\u2019s applications. F or machine learning models used, e.g., in consumer electronics or online translatio n services, transparency and explainability are not a key requirement as long as the overall performance of these systems is good enough. But even if these s ystems fail, e.g., the cell phone camera does not recognize a person or the tran slation service produces grammatically wrong sentences, the consequences are rather unspec- tacular. Thus, the requirements for transparency and trust ar e rather low for these types of AI systems. In safety critical applications the situ ation is very di?erent. Here, the intransparency of ML techniques may be a limitin g or even disqualifying factor. Especially if single wrong decisions can result in da nger to life and health of humans (e.g., autonomous driving, medical domain) o r signi?- cant monetary losses (e.g., algorithmic trading), relying on a data-d riven system whose reasoning is incomprehensible may not be an option. This intran sparency is one reason why the adoption of machine learning to domains such as health is more cautious than the usage of these models in the consumer, e-c ommerce or entertainment industry. In the following we discuss why the ability to explain the decision making o f an AI system helps to establish trust and is of utmost importance, n ot only in medical or safety critical applications. We refer the reader to [ 91] for a discussion of the challenges of transparency. 2.1 Explanations Help to Find \u201cClever Hans\u201d Predictors Clever Hans was a horse that could supposedly count and that was c onsidered a scienti?c sensation in the yearsaround 1900.As it turned out later , Hans did not master the math but in about 90 percent of the cases, he was able t o derive the correct answer from the questioner\u2019s reaction. Analogous behav iours have been recently observed in state-of-the-art AI systems [ 46]. Also here the algorithms have learned to use some spurious correlates in the training and tes t data and similarly to Hans predict right for the \u2018wrong\u2019 reason. For instance, the authors of [ 44,46] showed that the winning method of the PASCAL VOC competition [ 23] was often not detecting the object of interest, but was utilizing correlations or context in the data to correctly clas sify an im- age. It recognized boats by the presence of water and trains by t he presence of rails in the image, moreover, it recognized horses by the presenc e of a copy- right watermark6. The occurrence of the copyright tags in horse images is a clear artifact in the dataset, which had gone unnoticed to the orga nizers and participants of the challenge for many years. It can be assumed th at nobody has systematically checked the thousands images in the dataset fo r this kind of artifacts (but even if someone did, such artifacts may be easily o verlooked). Many other examples of \u201cClever Hans\u201d predictors have been descr ibed in the 6The PASCAL VOC images have been automatically crawled from ? ickr and espe- cially the horse images were very often copyrighted with a wa termark.4 W. Samek and K.-R. M\u00a8 uller literature. For instance, [ 73] show that current deep neural networks are dis- tinguishing the classes \u201cWolf\u201d and \u201cHusky\u201d mainly by the presence of snow in the image. The authors of [ 46] demonstrate that deep models over?t to padding artifacts when classifying airplanes, whereas [ 63] show that a model which was trained to distinguish between 1000 categories, has not learned du mbbells as an independent concept, but associates a dumbbell with the arm wh ich lifts it. Such \u201cCleverHans\u201d predictors perform well on their respective te st sets, but will certainly fail if deployed to the real-world, where sailing boats may lie o n a boat trailer, both wolves and huskies can be found in non-snow regions an d horses do not have a copyright sign on them. However, if the AI system is a blac k box, it is very di?cult to unmask such predictors. Explainability helps to dete ct these types of biases in the model or the data, moreover, it helps to unde rstand the weaknesses of the AI system (even if it is not a \u201cClever Hans\u201d predic tor). In the extreme case, explanations allow to detect the classi?er\u2019s misbehav iour (e.g., the focus on the copyright tag) from a single test image7. Since understanding the weaknesses of a system is the ?rst step towards improving it, expla nations are likely to become integral part of the training and validation process o f future AI models. 2.2 Explanations Foster Trust and Veri?ability The ability to verify decisions of an AI system is very important to fos ter trust, both in situations where the AI system has a supportive role (e.g., me dical diag- nosis) and in situations whereit practicallytakesthe decisions (e.g., a utonomous driving). In the former case, explanations provide extra informat ion, which, e.g., help the medical expert to gain a comprehensive picture of the patie nt in order to takethe best therapydecision.Similarlyto aradiologist,whowrite sadetailed report explaining his ?ndings, a supportive AI system should in detail explain its decisions rather than only providing the diagnosis to the medical e xpert. In cases where the AI system itself is deciding, it is even more critical to be able to comprehend the reasoning of the system in order to verify that it is not behav- ing like Clever Hans, but solves the problem in a robust and safe manne r. Such veri?cations are required to build the necessary trust in every new technology. There is also a social dimension of explanations. Explaining the rationa le behind one\u2019s decisions is an important part of human interactions [ 30]. Explana- tions help to build trust in a relationship between humans, and should t herefore be also part of human-machine interactions [ 3]. Explanations are not only an in- evitable part of human learning and education (e.g., teacher explains solution to student), but also foster the acceptance of di?cult decisions and are important for informed consent (e.g., doctor explaining therapy to patient). Thus, even if not providing additional information for verifying the decision, e.g., b ecause the patient may have no medical knowledge, receiving explanations usua lly make us feel better as it integrates us into the decision-making process. A n AI system which interacts with humans should therefore be explainable. 7Traditional methods to evaluate classi?er performance req uire large test datasets.1. Towards Explainable Arti?cial Intelligence 5 2.3 Explanations are a Prerequisite for New Insights AI systems have the potential to discover patterns in data, which are not acces- sible to the human expert. In the case of the Go game, these patte rns can be new playing strategies [ 82]. In the case of scienti?c data, they can be unknown associations between genes and diseases [ 51], chemical compounds and material properties [ 68] or brain activations and cognitive states [ 49]. In the sciences, identifying these patterns, i.e., explaining and interpreting what fea tures the AI system uses for predicting, is often more important than the pred iction itself, be- cause it unveils information about the biological, chemical or neural m echanisms and may lead to new scienti?c insights. This necessity to explain and interpret the results has led to a stron g domi- nance of linear models in scienti?c communities in the past (e.g. [ 42,67]). Linear models are intrinsically interpretable and thus easily allow to extract t he learned patterns. Only recently, it became possible to apply more powerful models such as deep neural networks without sacri?cing interpretability. Thes e explainable non-linear models have already attracted attention in domains such as neuro- science [87,89,20], health [ 33,14,40], autonomous driving [ 31], drug design [ 70] and physics [ 78,72] and it can be expected that they will play a pivotal role in future scienti?c research. 2.4 Explanations are Part of the Legislation The in?ltration of AI systems into our daily lives poses a new challenge f or the legislation.Legaland ethical questionsregardingthe responsibility ofAI systems and their level of autonomy have recently received increased atte ntion [21,27]. But also anti-discrimination and fairness aspects have been widely dis cussed in the contextofAI[ 28,19].TheEU\u2019sGeneralDataProtectionRegulation(GDPR) has even added the right to explanation to the policy in Articles 13, 14 and 22, highlighting the importance of human-understandable interpretat ions derived from machine decisions. For instance, if a person is being rejected f or a loan by the AI system of a bank, in principle, he or she has the right to know w hy the system has decided in this way, e.g., in order to make sure that the de cision is compatible with the anti-discrimination law or other regulations. Altho ugh it is not yet clear how these legal requirements will be implemented in prac tice, one can be sure that transparency aspects will gain in importance as AI decisions will more and more a?ect our daily lives. 3 Di?erent Facets of an Explanation Recently proposed explanation techniques provide valuable informa tion about the learned representations and the decision-making of an AI syst em. These explanations may di?er in their information content, their recipient a nd their purpose. In the following we describe the di?erent types of explana tions and comment on their usefulness in practice.6 W. Samek and K.-R. M\u00a8 uller 3.1 Recipient Di?erent recipients may require explanations with di?erent level of d etail and withdi?erentinformationcontent.Forinstance,forusersofAIt echnologyitmay be su?cient to obtain coarse explanations, which are easy to interp ret, whereas AI researchers and developers would certainly prefer explanation s, which give them deeper insights into the functioning of the model. In the case of image classi?cation such simple explanations could coar sely highlight image regions, which are regarded most relevant for the mo del. Several preprocessingsteps, e.g., smoothing, ?ltering or contrastnorma lization,could be applied to further improve the visualization quality. Although discard ing some information, such coarse explanations could help the ordinary user to foster trust in AI technology. On the other hand AI researchers and dev elopers, who aim to improve the model, may require all the available information, inclu ding negative evidence, about the AI\u2019s decision in the highest resolution ( e.g., pixel- wiseexplanations),becauseonlythiscompleteinformationgivesdet ailedinsights into the (mal)functioning of the model. One can easily identify further groups of recipients, which are inter ested in di?erent types of explanations. For instance, when applying AI to t he medical domain these groups could be patients, doctors and institutions. A n AI system which analyzes patient data could provide simple explanations to the p atients, e.g., indicating too high blood sugar, while providing more elaborate exp lana- tions to the medical personal, e.g., unusual relation between di?ere nt blood parameters. Furthermore, institutions such as hospitals or the F DA might be less interested in understanding the AI\u2019s decisions for individual pat ients, but would rather prefer to obtain global or aggregated explanations, i.e., patterns which the AI system has learned after analyzing many patients. 3.2 Information Content Di?erenttypesofexplanationprovideinsightsintodi?erentaspect softhemodel, ranging from information about the learned representations to th e identi?cation of distinct prediction strategies and the assessment of overall mo del behaviour. Depending on the recipient of the explanations and his or her intent, it may be advantageous to focus on one particular type of explanation. In t he following we brie?y describe four di?erent types of explanations. 1.Explaining learned representations : This type of explanation aims to foster the understanding of the learned representations, e.g., n eurons of a deep neural network. Recent work [ 12,38] investigates the role of single neurons or group of neurons in encoding certain concepts. Other methods [84,93,64,65] aim to interpret what the model has learned by building proto- types that are representative of the abstract learned concept . These meth- ods, e.g., explain what the model has learned about the category \u201cc ar\u201d by generating a prototypical image of a car. Building such a prototype can be formulated within the activation maximization framework and has b een1. Towards Explainable Arti?cial Intelligence 7 shown to be an e?ective tool for studying the internal represent ation of a deep neural network. 2.Explaining individual predictions : Other types of explanations provide information about individual predictions, e.g., heatmaps visualizing wh ich pixels have been most relevant for the model to arrive at its decision [60] or heatmaps highlighting the most sensitive parts of an input [ 84]. Such explanations help to verify the predictions and establish trust in the correct functioning on the system. Layer-wise Relevance Propagation (LR P) [9,58] provides a general framework for explaining individual predictions, i.e., it is applicable to various ML models, including neural networks [ 9], LSTMs [ 7], Fisher Vector classi?ers [ 44] and Support Vector Machines [ 35]. Section 4 gives an overview over recently proposed methods for computing in dividual explanations. 3.Explaining model behaviour : This type of explanations go beyond the analysis of individual predictions towards a more general understa nding of model behaviour, e.g., identi?cation of distinct prediction strategie s. The spectral relevance analysis (SpRAy) approach of [ 46] computes such meta explanations by clusteringindividual heatmaps. Eachcluster then r epresents a particular prediction strategy learned by the model. For instance , the au- thors of [ 46] identify four clusters when classifying \u201chorse\u201d images with the Fisher Vector classi?er [ 77] trained on the PASCAL VOC 2007 dataset [ 22], namely (1) detect the horse and rider, 2) detect a copyright tag in portrait oriented images, 3) detect wooden hurdles and other contextual elements of horsebackriding, and 4) detect a copyrighttag in landscape orient ed images. Such explanations are useful for obtaining a global overviewover t he learned strategies and detecting \u201cClever Hans\u201d predictors [ 46]. 4.Explaining with representative examples : Another class of methods interpret classi?ers by identifying representative training example s [41,37]. This type of explanations can be useful for obtaining a better unde rstanding of the training dataset and how it in?uences the model. Furthermor e, these representative examples can potentially help to identify biases in the data and make the model more robust to variations of the training datas et. 3.3 Role Besides the recipient and information content it is alsoimportant to c onsider the purpose of an explanation. Here we can distinguish two aspects, na mely (1) the intent of the explanation method (what speci?c question does the e xplanation answer) and (2) our intent (what do we want to use the explanation for). Explanations are relative and it makes a huge di?erence whether the ir intent is to explain the prediction as is (even if it is incorrect), whether they aim to visualize what the model \u201cthinks\u201d about a speci?c class (e.g., the tru e class) or whether they explain the prediction relative to another alternative (\u201cwhy is this image classi?ed as car and not as truck\u201d). Methods such as LRP allow to answer all these di?erent questions, moreover, they also allow to adjust t he amount of positive and negative evidence in the explanations, i.e., visualize what s peaks8 W. Samek and K.-R. M\u00a8 uller for (positive evidence) and against (negative evidence) the predic tion. Such ?ne- grained explanations foster the understanding of the classi?er an d the problem at hand. Furthermore, there may be di?erent goals for using the explanatio ns beyond visualization and veri?cation of the prediction. For instance, explan ations can be potentially used to improve the model, e.g., by regularization [ 74]. Also since explanations provide information about the (relevant parts of the ) model, they can be potentially used for model compression and pruning. Many ot her uses (certi?cation of the model, legal use) of explanations can be thoug ht of, but the details remain future work. 4 Methods of Explainable AI This section gives an overviewover di?erent approaches to explaina ble AI, start- ing with techniques which are model-agnostic and rely on a simple surro gate function to explain the predictions. Then, we discuss methods which compute explanations by testing the model\u2019s response to local perturbation s (e.g., by uti- lizing gradient information or by optimization). Subsequently, we pre sent very e?cient propagation-based explanation techniques which leverage the model\u2019s internal structure. Finally, we consider methods which go beyond in dividual ex- planations towards a meta-explanation of model behaviour. This section is not meant to be a complete survey of explanation meth ods, but it rather summarizes the most important developments in this ?e ld. Some approaches to explainable AI, e.g., methods which ?nd in?uencial exa mples [37], are not discussed in this section. 4.1 Explaining with Surrogates Simple classi?ers such as linear models or shallow decision trees are intr insically interpretable, so that explaining its predictions becomes a trivial ta sk. Complex classi?ers such as deep neural networks or recurrent models on t he other hand contain several layers of non-linear transformations, which large ly complicates the task of ?nding what exactly makes them arrive at their predictio ns. One approach to explain the predictions of complex models is to locally approximate them with a simple surrogate function, which is interpre table. A populartechniquefallingintothiscategoryisLocalInterpretableM odel-agnostic Explanations (LIME) [ 73]. This method samples in the neighborhood of the input of interest, evaluates the neural network at these points, and tries to ?t the surrogate function such that it approximates the function of interest. If the input domain of the surrogate function is human-interpretable, th en LIME can even explain decisions of a model which uses non-interpretable feat ures. Since LIME ismodel agnostic,it can be applied toanyclassi?er,evenwithou t knowing its internals, e.g., architecture or weights of a neural network clas si?er. One major drawback of LIME is its high computational complexity, e.g., fo r state-of- the-art models such as GoogleNet it requires several minutes for c omputing the explanation of a single prediction [ 45].1. Towards Explainable Arti?cial Intelligence 9 Similar to LIME which builds a model for locally approximating the functio n of interest, the SmoothGrad method [ 85] samples the neighborhood of the input to approximate the gradient. Also SmoothGrad does not leverage t he internals of the model, however, it needs access to the gradients. Thus, it c an also be regarded as a gradient-based explanation method. 4.2 Explaining with Local Perturbations Another class of methods construct explanations by analyzing the model\u2019s re- sponse to local changes. This includes methods which utilize the grad ient infor- mation as well as perturbation- and optimization-based approache s. Explanation methods relying on the gradient of the function of inter est [2] have a long history in machine learning. One example is the so-called Sen sitivity Analysis (SA) [ 62,10,84]. Although being widely used as explanation methods, SA technically explains the change in prediction instead of the predict ion itself. Furthermore, SA has been shown to su?er from fundamental pro blems such as gradient shattering and explanation discontinuities, and is therefo re considered suboptimal for explanation of today\u2019s AI models [ 60]. Variants of Sensitivity Analysis exist which tackle some of these problems by locally averaging the gradients [ 85] or integrating them along a speci?c path [ 88]. Perturbation-basedexplanationmethods[ 94,97,25]explicitlytestthemodel\u2019s response to more general local perturbations. While the occlusion method of [ 94] measures the importance of input dimensions by masking parts of th e input, the Prediction Di?erence Analysis (PDA) approachof[ 97] uses conditional sampling within the pixel neighborhood of an analyzed feature to e?ectively r emove infor- mation. Both methods are model-agnostic, i.e., can be applied to any c lassi?er, but are computationally not very e?cient, because the function of interest (e.g., neural network) needs to be evaluated for all perturbations. The meaningful perturbation method of [ 25,26] is another model-agnostic technique to explaining with local perturbations. It regards explan ation as a meta prediction task and applies optimization to synthesize the maxim ally in- formative explanations. The idea to formulate explanation as an opt imization problem is also used by other methods. For instance, the methods [ 84,93,64] aim to interpret what the model has learned by building prototypes t hat are representative of the learned concept. These prototypes are c omputed within the activation maximization framework by searching for an input pat tern that produces a maximum desired model response. Conceptually, activa tion maxi- mization [ 64] is similar to the meaningful perturbation approach of [ 25]. While the latter ?nds a minimum perturbation of the data that makes f(x) low, activa- tion maximization ?nds a minimum perturbation of the gray image that m akes f(x) high. The costs of optimization can make these methods computat ionally very demanding.10 W. Samek and K.-R. M\u00a8 uller 4.3 Propagation-Based Approaches (Leveraging Structure) Propagation-based approaches to explanation are not oblivious to the model which they explain, but rather integrate the internal structure o f the model into the explanation process. Layer-wise Relevance Propagation (LRP) [ 9,58] is a propagation-based ex- planation framework, which is applicable to general neural network structures, including deep neural networks [ 13], LSTMs [ 7,5], and Fisher Vector classi?ers [44]. LRP explains individual decisions of a model by propagating the pred iction from the output to the input using local redistribution rules. The pr opagation process can be theoretically embedded in the deep Taylor decompos ition frame- work [59]. More recently, LRP was extended to a wider set of machine learning models, e.g., in clustering [ 36] or anomaly detection [ 35], by ?rst transforming the model into a neural network (\u2018neuralization\u2019) and then applying L RP to explain its predictions. The leveraging of the model structure toge ther with the use of appropriate (theoretically-motivated) propagation rules, enables LRP to deliver good explanations at very low computational cost (one forw ard and one backwardpass).Furthermore,thegeneralityoftheLRPframew orkallowsalsoto express other recently proposed explanation techniques, e.g., [ 81,95]. Since LRP does not rely on gradients, it does not su?er from problems such as gradient shattering and explanation discontinuities [ 60]. Other popular explanation methods leveragingthe model\u2019s internal s tructure are Deconvolution [ 94] and Guided Backprogagation [ 86]. In contrast to LRP, these methods do not explain the prediction in the sense \u201chow much d id the input feature contribute to the prediction\u201d, but rather identify p atterns in input space, that relate to the analyzed network output. Many other explanation methods have been proposed in the literatu re which fall into the \u201cleveraging structure\u201d category. Some of these met hods use heuris- tics to guide the redistribution process [ 79], others incorporate an optimization step into the propagation process [ 39]. The iNNvestigate toolbox [ 1] provides an e?cient implementation for many of these propagation-based ex planation methods. 4.4 Meta-Explanations Finally, individual explanations can be aggregated and analyzed to ide ntify gen- eral patterns of classi?er behavior. A recently proposed method , spectral rel- evance analysis (SpRAy) [ 46], computes such meta explanations by clustering individual heatmaps. This approach allows to investigate the predict ions strate- gies of the classi?er on the whole dataset in a (semi-)automated man ner and to systematically ?nd weak points in models or training datasets. Another type ofmeta-explanation aims to better understand the learned rep- resentations and to provide interpretations in terms of human-fr iendly concepts. For instance, the network dissection approach of [ 12,96] evaluates the semantics of hidden units, i.e., quantify what concepts these neurons encode . Other recent work [38] provides explanations in terms of user-de?ned concepts and tes ts to which degree these concepts are important for the prediction.1. Towards Explainable Arti?cial Intelligence 11 5 Evaluating Quality of Explanations The objective assessment of the quality of explanations is an active ?eld of re- search. Many e?orts have been made to de?ne quality measures fo r heatmaps which explain individual predictions of an AI model. This section gives an overview over the proposed approaches. A popular measure for heatmap quality is based on perturbation ana lysis [9,75,6]. The assumption of this evaluation metric is that the perturbation o f relevant (according to the heatmap) input variables should lead to a steeper decline of the prediction score than the perturbation of input dimen sions which are of lesser importance. Thus, the average decline of the predict ion score after several rounds of perturbation (starting from the most relevan t input variables) de?nes an objective measure of heatmap quality. If the explanatio n identi?es the truly relevant input variables, then the decline should be large. The a uthors of [75]recommendtouseuntargetedperturbations(e.g.,uniformnoise )toallowfair comparison of di?erent explanation methods. Although being very p opular, it is clear that perturbation analysis can not be the only criterion to eva luate expla- nation quality, because one could easily design explanations techniqu es which would directly optimize this criterion. Examples are occlusion methods which were used in [ 94,50], however, they have been shown to be inferior (according to other quality criteria) to explanation techniques such as LRP [ 8]. Other studies use the \u2018pointing game\u201d [ 95] to evaluate the quality of a heatmap. The goal of this game is to evaluate the discriminativeness of the explanations for localizing target objects, i.e., it is compared if the mo st rele- vant point of the heatmap lies on the object of designated categor y. Thus, these measures assume that the AI model will focus most attention on th e object of interest when classifying it, therefore this should be re?ected in th e explanation. However, this assumption may not always be true, e.g., \u201cClever Hans \u201d predic- tors [46] may rather focus on context than of the object itself, irrespec tively of the explanation method used. Thus, their explanations would be eva luated as poor quality according to this measure although they truly visualize t he model\u2019s prediction strategy. Task speci?c evaluation schemes have also been proposed in the liter ature. For example, [ 69] use the subject-verb agreement task to evaluate explanations of a NLP model. Here the model predicts a verb\u2019s number and the exp lana- tions verify if the most relevant word is indeed the correct subject or a noun with the predicted number. Other approaches to evaluation rely on human judg- ment [73,66]. Such evaluation schemes relatively quickly become impractical if evaluating a larger number of explanations. A recent study [ 8] proposes to objectively evaluate explanation for sequential data using ground truth information in a toy task. The idea of this ev aluation metric is to add or subtract two numbers within an input sequence an d measure the correlation between the relevances assigned to the elements o f the sequence and the two input numbers. If the model is able to accurately perfo rm the ad- dition and subtraction task, then it must focus on these two numbe rs (other12 W. Samek and K.-R. M\u00a8 uller numbers in the sequence are random) and this must be re?ected in t he explana- tion. An alternative and indirect way to evaluate the quality of explanation s is to use them for solving other tasks. The authors of [ 6] build document-level rep- resentations from word-level explanations. The performance of these document- level representations(e.g., in a classi?cation task) re?ect the qua lity of the word- level explanations. Another work [ 4] uses explanation for reinforcement learning. Many other functionally-grounded evaluations [ 18] could be conceived such as using explanations for compressing or pruning the neural network or training student models in a teacher-student scenario. Lastly, another promising approach to evaluate explanations is bas ed on the ful?llment of a certain axioms [ 80,88,54,60,57]. Axioms are properties of an ex- planation that are considered to be necessary and should therefo re be ful?lled. Proposedaxiomsinclude relevanceconservation[ 60], explanationcontinuity[ 60], sensitivity [ 88] and implementation invariance[ 88]. In contrastto the other qual- ity measures discussed in this section, the ful?llment or non-ful?llmen t of certain axioms can be often shown analytically, i.e., does not require empirical evalua- tions. 6 Challenges and Open Questions Although signi?cant progress has been made in the ?eld of explainable AI in the last years, challenges still exist both on the methods and theory sid e as well as regarding the way explanations are used in practice. Researchers have already started working on some of these challenges, e.g., the objective ev aluation of explanation quality or the use of explanations beyond visualization. O ther open questions, especially those concerning the theory, are more fund amental and more time will be required to give satisfactory answers to them. Explanation methods allow us to gain insights into the functioning of th e AI model. Yet, these methods are still limited in several ways. First, heatmaps computed with today\u2019s explanation methods visualize \u201c?rst-order\u201d information, i.e., they show which input features have been identi?ed as being relev ant for the prediction. However, the relation between these features, e.g., w hether they are important on their own or only whether they occur together, rema ins unclear. Understanding these relations is important in many applications, e.g., in the neurosciences such higher-order explanations could help us to iden tify groups of brain regions which act together when solving a speci?c task (brain n etworks) rather than just identifying important single voxels. Another limitation is the low abstraction level of explanations. Heatm aps show that particular pixels are important without relating these rele vance values to more abstract concepts such as the objects or the scene disp layed in the image. Humans need to interpret the explanations to make sense th em and to understand the model\u2019s behaviour. This interpretation step can be di?cult and erroneous.Meta-explanations which aggregateevidence fro m these low-level heatmaps and explain the model\u2019s behaviour on a more abstract, mor e human1. Towards Explainable Arti?cial Intelligence 13 understandable level, are desirable. Recently, ?rst approaches t o aggregate low- level explanations [ 46] and quantify the semantics of neural representations [ 12] have been proposed. The construction of more advanced meta-e xplanations is a rewarding topic for future research. Since the recipient of explanations is ultimately the human user, the u se of explanations in human-machine interaction is an important future research topic.Someworks(e.g.,[ 43])havealreadystartedtoinvestigatehumanfactorsin explainable AI. Constructing explanations with the right user focus , i.e., asking therightquestionsintherightway,isaprerequisitetosuccessful human-machine interaction. However, the optimization of explanations for optimal human usage is still a challenge which needs further study. A theory of explainable AI, with a formal and universally agreed de?n ition of what explanations are, is lacking. Some works made a ?rst step towa rdsthis goal by developing mathematically well-founded explanation methods. For instance, the authors of [ 59] approach the explanation problem by integrating it into the theoretical framework of Taylor decomposition. The axiomatic approaches [88,54,60] constitute another promising direction towards the goal of deve loping a general theory of explainable AI. Finally, the use of explanations beyond visualization is a wide open challenge. Future work will show how to integrate explanations into a larger optimization process in order to, e.g., improve the model\u2019s performan ce or reduce its complexity. Acknowledgements. This work was supported by the German Ministry for Education and Research as Berlin Big Data Centre (01IS14013A ), Berlin Center for Machine Learning (01IS18037I) and TraMeExCo (01IS 18056A). Partial funding by DFG is acknowledged (EXC 2046/1, project-ID: 390685689). This work was also supported by the Institute for Information & Co mmuni- cations Technology Planning & Evaluation (IITP) grant funded by th e Korea government (No. 2017-0-00451, No. 2017-0-01779). References 1. Alber, M., Lapuschkin, S., Seegerer, P., H\u00a8 agele, M., Sch \u00a8 utt, K.T., Montavon, G., Samek, W., M\u00a8 uller, K.R., D\u00a8 ahne, S., Kindermans, P.J.: iNN vestigate neural net- works!. Journal of Machine Learning Research 20(93), 1\u20138 (2019) 2. Ancona, M., Ceolini, E., \u00a8Oztireli, C., Gross, M.: Gradient-based attribution meth- ods. In: Explainable AI: Interpreting, Explaining and Visu alizing Deep Learning. Lecture Notes in Computer Science 11700, Springer (2019) 3. Antunes, P., Herskovic, V., Ochoa, S.F., Pino, J.A.: Stru cturingdimensions for col- laborative systems evaluation. ACM Computing Surveys (CSU R)44(2), 8 (2012) 4. Arjona-Medina, J.A., Gillhofer, M., Widrich, M., Untert hiner, T., Hochreiter, S.: RUDDER: Return Decomposition for Delayed Rewards. arXi v preprint arXiv:1806.07857 (2018) 5. Arras, L., Arjona-Medina, J., Gillhofer, M., Widrich, M. , Montavon, G., M\u00a8 uller, K.R.,Hochreiter, S., Samek,W.: Explainingandinterpreti ngLSTMs with LRP.In:14 W. Samek and K.-R. M\u00a8 uller Explainable AI: Interpreting, Explaining and Visualizing Deep Learning. Lecture Notes in Computer Science 11700, pp. 211238. Springer (2019) 6. Arras, L., Horn, F., Montavon, G., M\u00a8 uller, K.R., Samek, W .: \u201dWhat is relevant in a text document?\u201d: An interpretable machine learning app roach. PLoS ONE 12(8), e0181142 (2017) 7. Arras, L., Montavon, G., M\u00a8 uller, K.R., Samek, W.: Explai ning recurrent neural network predictions in sentiment analysis. In: EMNLP\u201917 Wo rkshop on Computa- tional Approaches to Subjectivity, Sentiment & Social Medi a Analysis (WASSA). pp. 159\u2013168 (2017) 8. Arras, L., Osman, A., M\u00a8 uller, K.R., Samek, W.: Evaluatin g recurrent neural net- work explanations. In: ACL\u201919 Workshop on BlackboxNLP: Ana lyzing and Inter- preting Neural Networks for NLP, pp. 113-126 (2019) 9. Bach, S., Binder, A., Montavon, G., Klauschen, F., M\u00a8 ulle r, K.R., Samek, W.: On pixel-wise explanations for non-linear classi?er decisio ns by layer-wise relevance propagation. PLoS ONE 10(7), e0130140 (2015) 10. Baehrens, D., Schroeter, T., Harmeling, S., Kawanabe, M ., Hansen, K., M\u00a8 uller, K.R.: How to explain individual classi?cation decisions. J ournal of Machine Learn- ing Research 11, 1803\u20131831 (2010) 11. Bahdanau, D., Cho, K., Bengio, Y.: Neural machine transl ation by jointly learning to align and translate. In: International Conference on Lea rning Representations (ICLR). (2015) 12. Bau, D., Zhou, B., Khosla, A., Oliva, A., Torralba, A.: Ne twork dissection: Quanti- fying interpretability of deep visual representations. In : IEEE Conference on Com- puter Vision and Pattern Recognition (CVPR). pp. 6541\u20136549 (2017) 13. Binder, A., Bach, S., Montavon, G., M\u00a8 uller, K.R., Samek , W.: Layer-wise relevance propagation for deep neural network architectures. In: Inf ormation Science and Applications (ICISA), pp. 913\u2013922 (2016) 14. Binder, A., Bockmayr, M., H\u00a8 agele, M., Wienert, S., Heim , D., Hellweg, K., Sten- zinger, A., Parlow, L., Budczies, J., Goeppert, B., et al.: T owards computational ?uorescence microscopy: Machine learning-based integrat ed prediction of morpho- logical and molecular tumor pro?les. arXiv preprint arXiv: 1805.11178 (2018) 15. Chmiela, S.,Sauceda, H.E.,M\u00a8 uller, K.R.,Tkatchenko, A.:Towards exactmolecular dynamics simulations with machine-learned force ?elds. Na ture Communications 9(1), 3887 (2018) 16. Cire\u00b8 san, D., Meier, U., Masci, J., Schmidhuber, J.: A co mmittee of neural networks for tra?c sign classi?cation. In: International Joint Conf erence on Neural Networks (IJCNN). pp. 1918\u20131921 (2011) 17. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large- scale hierarchical image database. In: IEEE Conference on C omputer Vision and Pattern Recognition (CVPR). pp. 248\u2013255 (2009) 18. Doshi-Velez,F., Kim,B.: Towardsarigorous scienceofi nterpretablemachinelearn- ing. arXiv preprint arXiv:1702.08608 (2017) 19. Doshi-Velez, F., Kortz, M., Budish, R., Bavitz, C., Gers hman, S., O\u2019Brien, D., Schieber, S., Waldo, J., Weinberger, D., Wood, A.: Accounta bility of AI under the law: The role of explanation. arXiv preprint arXiv:1711.01 134 (2017) 20. Eitel, F., Soehler,E., Bellmann-Strobl,J., Brandt,A. U.,Ruprecht,K.,Giess, R.M., Kuchling, J., Asseyer, S., Weygandt, M., Haynes, J.D., et al .: Uncovering convo- lutional neural network decisions for diagnosing multiple sclerosis on conventional mri usinglayer-wise relevance propagation. arXivpreprin tarXiv:1904.08771 (2019) 21. European Commission\u2019s High-Level Expert Group: Draft e thics guidelines for trustworthy AI. European Commission (2019)1. Towards Explainable Arti?cial Intelligence 15 22. Everingham, M., Eslami, S.A., Van Gool, L., Williams, C. K., Winn, J., Zisserman, A.: The PASCAL Visual Object Classes Challenge: A Retrospec tive. International Journal of Computer Vision 111(1), 98\u2013136 (2015) 23. Everingham,M.,VanGool, L.,Williams, C.K., Winn,J., Z isserman,A.:ThePascal visual object classes (VOC) challenge. International Jour nal of Computer Vision 88(2), 303\u2013338 (2010) 24. Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati , A., Xiao, C., Prakash, A., Kohno, T., Song, D.: Robust physical-world attacks on de ep learning models. arXiv preprint arXiv:1707.08945 (2017) 25. Fong, R.C., Vedaldi, A.: Interpretable explanations of black boxes by meaningful perturbation. In: IEEE International Conference on Comput er Vision (CVPR). pp. 3429\u20133437 (2017) 26. Fong, R., Vedaldi, A.: Explanations for attributing dee p neural network predic- tions. In: Explainable AI: Interpreting, Explaining and Vi sualizing Deep Learning. Lecture Notes in Computer Science 11700, pp. 149167. Springer (2019) 27. Goodman, B., Flaxman, S.: European union regulations on algorithmic decision- making and a \u201cright to explanation\u201d. AI Magazine 38(3), 50\u201357 (2017) 28. Hajian, S.,Bonchi,F.,Castillo, C.: Algorithmicbias: Fromdiscriminationdiscovery to fairness-aware data mining. In: 22nd ACM SIGKDD Internat ional Conference on Knowledge Discovery and Data Mining. pp. 2125\u20132126 (2016 ) 29. Han, S., Pool, J., Tran, J., Dally, W.: Learning both weig hts and connections for e?cient neural network. In: Advances in Neural Information Processing Systems (NIPS). pp. 1135\u20131143 (2015) 30. Heath, R.L., Bryant, J.: Human communication theory and research: Concepts, contexts, and challenges. Routledge (2013) 31. Hofmarcher, M., Unterthiner, T., Arjona-Medina, J., Kl ambauer, G., Hochreiter, S., Nessler, B.: Visual scene understanding for autonomous driving using semantic segmentation. In: Explainable AI: Interpreting, Explaini ng and Visualizing Deep Learning. Lecture Notes in Computer Science 11700, pp. 285296. Springer (2019) 32. Holzinger, A., Langs, G., Denk, H., Zatloukal, K., M\u00a8 ull er, H.: Causability and explainabilty of arti?cial intelligence in medicine. Wile y Interdisciplinary Reviews: Data Mining and Knowledge Discovery p. e1312 (2019) 33. Horst, F., Lapuschkin, S., Samek, W., M\u00a8 uller, K.R., Sch \u00a8 ollhorn, W.I.: Explaining the unique nature of individual gait patterns with deep lear ning. Scienti?c Reports 9, 2391 (2019) 34. Karpathy,A.,Toderici, G.,Shetty,S.,Leung,T., Sukth ankar,R.,Fei-Fei,L.: Large- scale video classi?cation with convolutional neural netwo rks. In: IEEE conference on Computer Vision and Pattern Recognition (CVPR). pp. 1725 \u20131732 (2014) 35. Kau?mann, J., M\u00a8 uller, K.R., Montavon, G.: Towards expl aining anomalies: A deep Taylor decomposition of one-class models. arXiv preprint a rXiv:1805.06230 (2018) 36. Kau?mann, J., Esders, M., Montavon, G., Samek, W., M\u00a8 ull er, K.R.: From cluster- ing to cluster explanations via neural networks. arXiv prep rint arXiv:1906.07633 (2019) 37. Khanna, R., Kim, B., Ghosh, J., Koyejo, O.: Interpreting black box predictions using ?sher kernels. arXiv preprint arXiv:1810.10118 (201 8) 38. Kim, B., Wattenberg, M., Gilmer, J., Cai, C., Wexler, J., Viegas, F., Sayres, R.: Interpretability beyond feature attribution: Quantitati ve testing with concept acti- vationvectors (TCAV). In:International Conference onMac hine Learning(ICML). pp. 2673\u20132682, (2018)16 W. Samek and K.-R. M\u00a8 uller 39. Kindermans, P.J., Sch\u00a8 utt, K.T., Alber, M., M\u00a8 uller, K. R., Erhan, D., Kim, B., D\u00a8 ahne, S.: Learning how to explain neural networks: Patter nnet and patternattri- bution. In: International Conference on Learning Represen tations (ICLR). (2018) 40. Klauschen, F., M\u00a8 uller, K.R., Binder, A., Bockmayr, M., H\u00a8 agele, M., Seegerer, P., Wienert,S.,Pruneri,G., deMaria, S.,Badve,S.,etal.: Sco ringoftumor-in?ltrating lymphocytes: From visual estimation to machine learning. S eminars in Cancer Biology52(2), 151\u2013157 (2018) 41. Koh, P.W., Liang, P.: Understanding black-box predicti ons via in?uence functions. In: International Conference on Machine Learning (ICML). p p. 1885\u20131894 (2017) 42. Kriegeskorte, N., Goebel, R., Bandettini, P.: Informat ion-based functional brain mapping. Proceedings of the National Academy of Sciences 103(10), 3863\u20133868 (2006) 43. Lage, I., Chen, E., He, J., Narayanan, M., Kim, B., Gershm an, S., Doshi-Velez, F.: An evaluation of the human-interpretability of explana tion. arXiv preprint arXiv:1902.00006 (2019) 44. Lapuschkin, S., Binder, A., Montavon, G., M\u00a8 uller, K.R. , Samek, W.: Analyzing classi?ers: Fisher vectors and deep neural networks. In: IE EE Conference on Com- puter Vision and Pattern Recognition (CVPR). pp. 2912\u20132920 (2016) 45. Lapuschkin, S.: Opening the Machine Learning Black Box w ith Layer-wise Rele- vance Propagation. Ph.D. thesis, Technische Universit\u00a8 at Berlin (2019) 46. Lapuschkin, S., W\u00a8 aldchen, S., Binder, A., Montavon, G. , Samek, W., M\u00a8 uller, K.R.: Unmaskingclever hans predictors and assessing what machin es really learn. Nature Communications 10, 1096 (2019) 47. LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. Nature 521(7553), 436\u2013444 (2015) 48. LeCun, Y.A., Bottou, L., Orr, G.B., M\u00a8 uller, K.R.: E?cie nt backprop. In: Neural networks: Tricks of the trade, pp. 9\u201348. Springer (2012) 49. Lemm, S., Blankertz, B., Dickhaus, T., M\u00a8 uller, K.R.: In troduction to machine learning for brain imaging. Neuroimage 56(2), 387\u2013399 (2011) 50. Li, J., Monroe, W., Jurafsky, D.: Understanding Neural N etworks through Repre- sentation Erasure. arXiv preprint arXiv:1612.08220 (2016 ) 51. Libbrecht, M.W., Noble, W.S.: Machine learning applica tions in genetics and ge- nomics. Nature Reviews Genetics 16(6), 321 (2015) 52. Lindholm, E., Nickolls, J., Oberman, S., Montrym, J.: Nv idia tesla: A uni?ed graphics and computing architecture. IEEE Micro 28(2), 39\u201355 (2008) 53. Lu, C., Tang, X.: Surpassing human-level face veri?cati on performance on LFW with GaussianFace. In: 29th AAAI Conference on Arti?cial In telligence. pp. 3811\u2013 3819 (2015) 54. Lundberg, S.M., Lee, S.I.: A uni?ed approach to interpre ting model predictions. In: Advances in Neural Information Processing Systems (NIP S). pp. 4765\u20134774 (2017) 55. Madry,A., Makelov, A.,Schmidt,L., Tsipras, D.,Vladu, A.:Towards deeplearning models resistant to adversarial attacks. In: Internationa l Conference on Learning Representations (ICLR). (2018) 56. Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Venes s, J., Bellemare, M.G., Graves, A., Riedmiller, M., Fidjeland, A.K., Ostrovski, G. , et al.: Human-level control through deep reinforcement learning. Nature 518(7540), 529\u2013533 (2015) 57. Montavon, G.: Gradient-based vs. propagation-based ex planations: An axiomatic comparison. In: Explainable AI: Interpreting, Explaining and Visualizing Deep Learning. Lecture Notes in Computer Science 11700, pp. 253265. Springer (2019)1. Towards Explainable Arti?cial Intelligence 17 58. Montavon, G., Binder, A., Lapuschkin, S., Samek, W., M\u00a8 u ller, K.R.: Layer-wise relevance propagation: An overview. In: Explainable AI: In terpreting, Explaining and Visualizing Deep Learning. Lecture Notes in Computer Sc ience11700, pp. 193-209. Springer (2019) 59. Montavon, G., Lapuschkin, S., Binder, A., Samek, W., M\u00a8 u ller, K.R.: Explaining nonlinear classi?cation decisions with deep Taylor decomp osition. Pattern Recog- nition65, 211\u2013222 (2017) 60. Montavon, G., Samek, W., M\u00a8 uller, K.R.: Methods for inte rpretingand understand- ing deep neural networks. Digital Signal Processing 73, 1\u201315 (2018) 61. Morav? c\u00b4 ik, M., Schmid, M., Burch, N., Lis\u00b4 y, V., Morril l, D., Bard, N., et al.: Deepstack: Expert-level arti?cial intelligence in heads- up no-limit poker. Science 356(6337), 508\u2013513 (2017) 62. Morch, N., Kjems, U., Hansen, L.K., Svarer, C., Law, I., L autrup, B., Strother, S., Rehm, K.: Visualization of neural networks using saliency m aps. In: International Conference on Neural Networks (ICNN). vol. 4, pp. 2085\u20132090 (1995) 63. Mordvintsev, A., Olah, C., Tyka, M.: Inceptionism: Goin g deeper into neural net- works (2015) 64. Nguyen, A., Dosovitskiy, A., Yosinski, J., Brox, T., Clu ne, J.: Synthesizing the preferred inputs for neurons in neural networks via deep gen erator networks. In: Advances in Neural Information Processing Systems (NIPS). pp. 3387\u20133395 (2016) 65. Nguyen, A., Yosinski, J., Clune, J.: Understanding neur al networks via feature visualization: A survey. In: Explainable AI: Interpreting , Explaining and Visualiz- ing Deep Learning. Lecture Notes in Computer Science 11700, pp. 5576. Springer (2019) 66. Nguyen, D.: Comparing Automatic and Human Evaluation of Local Explanations for Text Classi?cation. In: Conference of the North America n Chapter of the As- sociation for Computational Linguistics: Human Language T echnologies (NAACL- HLT). pp. 1069\u20131078 (2018) 67. Phinyomark, A., Petri, G., Ib\u00b4 a\u02dc nez-Marcelo, E., Osis, S.T., Ferber, R.: Analysis of big data in gait biomechanics: Current trends and future dir ections. Journal of Medical and Biological Engineering 38(2), 244\u2013260 (2018) 68. Pilania, G., Wang, C., Jiang, X., Rajasekaran, S., Rampr asad, R.: Accelerating materials property predictions using machine learning. Sc ienti?c Reports 3, 2810 (2013) 69. Poerner, N.,Roth,B., Sch\u00a8 utze,H.: Evaluatingneural n etworkexplanationmethods using hybrid documents and morphosyntactic agreement. In: 56th Annual Meeting of the Association for Computational Linguistics (ACL). pp . 340\u2013350 (2018) 70. Preuer, K., Klambauer, G., Rippmann, F., Hochreiter, S. , Unterthiner, T.: Inter- pretable deep learning in drug discovery. In: Explainable A I: Interpreting, Explain- ing and Visualizing Deep Learning. Lecture Notes in Compute r Science 11700, Springer (2019) 71. Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You o nly look once: Uni?ed, real-time object detection. In: IEEE Conference on Compute r Vision and Pattern Recognition (CVPR). pp. 779\u2013788 (2016) 72. Reyes, E., Est\u00b4 evez, P.A., Reyes, I., Cabrera-Vives, G. , Huijse, P., Carrasco, R., Forster, F.: Enhanced rotational invariant convolutional neural network for super- novae detection. In: International Joint Conference on Neu ral Networks (IJCNN). pp. 1\u20138 (2018) 73. Ribeiro, M.T., Singh, S., Guestrin, C.: Why should i trus t you?: Explaining the predictions ofanyclassi?er. In:ACMSIGKDDInternational Conference onKnowl- edge Discovery and Data Mining. pp. 1135\u20131144 (2016)18 W. Samek and K.-R. M\u00a8 uller 74. Ross, A.S., Hughes, M.C., Doshi-Velez, F.: Right for the right reasons: Training di?erentiable models by constraining their explanations. In: 26th International Joint Conferences on Arti?cial Intelligence (IJCAI). pp. 2 662\u20132670 (2017) 75. Samek, W., Binder, A., Montavon, G., Lapuschkin, S., M\u00a8 u ller, K.R.: Evaluating the visualization of what a deep neural network has learned. IEEE Transactions on Neural Networks and Learning Systems 28(11), 2660\u20132673 (2017) 76. Samek, W., Wiegand, T., M\u00a8 uller, K.R.: Explainable arti ?cial intelligence: Under- standing, visualizing and interpreting deep learning mode ls. ITU Journal: ICT Discoveries - Special Issue 1 - The Impact of Arti?cial Intel ligence (AI) on Com- munication Networks and Services 1(1), 39\u201348 (2018) 77. S\u00b4 anchez, J., Perronnin, F., Mensink, T., Verbeek, J.J. : Image classi?cation with the Fisher vector: Theory and practice. International Jour nal of Computer Vision 105(3), 222\u2013245 (2013) 78. Sch\u00a8 utt, K.T., Arbabzadah, F., Chmiela, S., M\u00a8 uller, K. R., Tkatchenko, A.: Quantum-chemical insights from deep tensor neural network s. Nature Commu- nications 8, 13890 (2017) 79. Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Pa rikh, D., Batra, D.: Grad- cam: Visual explanations from deep networks via gradient-b ased localization. In: IEEE International Conference on Computer Vision (CVPR). p p. 618\u2013626 (2017) 80. Shapley, L.S.: A value for n-person games. Contribution s to the Theory of Games 2(28), 307\u2013317 (1953) 81. Shrikumar, A., Greenside, P., Kundaje, A.: Learning Imp ortant Features Through Propagating Activation Di?erences. arXiv preprint arXiv: 1704.02685 (2017) 82. Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L ., Van Den Driessche, G., et al.: Mastering the game of Go with deep neural networks and tree search. Nature 529(7587), 484\u2013489 (2016) 83. Silver, D., Schrittwieser, J., Simonyan, K., Antonoglo u, I., Huang, A., Guez, A., Hubert,T., Baker, L., Lai, M., Bolton, A., et al.: Mastering the game ofGo without human knowledge. Nature 550(7676), 354\u2013359 (2017) 84. Simonyan, K., Vedaldi, A., Zisserman, A.: Deep inside co nvolutional networks: Visualising image classi?cation models and saliency maps. In: ICLR Workshop. (2014) 85. Smilkov, D., Thorat, N., Kim, B., Vi\u00b4 egas, F., Wattenber g, M.: Smoothgrad: re- moving noise by adding noise. arXiv preprint arXiv:1706.03 825 (2017) 86. Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmil ler, M.: Striving for simplic- ity: The all convolutional net. In: ICLR Workshop. (2015) 87. Sturm, I., Lapuschkin, S., Samek, W., M\u00a8 uller, K.R.: Int erpretable deep neural networks for single-trial eeg classi?cation. Journal of Ne uroscience Methods 274, 141\u2013145 (2016) 88. Sundararajan, M., Taly, A., Yan, Q.: Axiomatic attribut ion for deep networks. In: International Conference on Machine Learning (ICML). pp. 3 319\u20133328 (2017) 89. Thomas, A.W., Heekeren, H.R., M\u00a8 uller, K.R., Samek, W.: Analyzing neuroimag- ing data through recurrent deep learning models. arXiv prep rint arXiv:1810.09945 (2018) 90. Van Den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vin yals, O., Graves, A., Kalchbrenner, N., Senior, A.W., Kavukcuoglu, K.: Wavenet: A generative model for raw audio. SSW 125(2016) 91. Weller, A.: Transparency: Motivations and Challenges. In: Explainable AI: Inter- preting, Explaining and Visualizing Deep Learning. Lectur e Notes in Computer Science11700, Springer (2019)1. Towards Explainable Arti?cial Intelligence 19 92. Wu, D., Wang, L., Zhang, P.: Solving statistical mechani cs using variational au- toregressive networks. Physical Review Letters 122(8), 080602 (2019) 93. Yosinski, J., Clune, J., Nguyen, A., Fuchs, T., Lipson, H .: Understanding neural networks through deep visualization. arXiv preprint arXiv :1506.06579 (2015) 94. Zeiler, M.D., Fergus, R.: Visualizing and understandin g convolutional networks. In: European Conference Computer Vision (ECCV). pp. 818\u201383 3 (2014) 95. Zhang, J., Lin, Z.L., Brandt, J., Shen, X., Sclaro?, S.: T op-down neural attention by excitation backprop. In: European Conference on Compute r Vision (ECCV). pp. 543\u2013559 (2016) 96. Zhou, B., Bau, D., Oliva, A., Torralba, A.: Comparing the interpretability of deep networks via network dissection. In: Explainable AI: Inter preting, Explaining and Visualizing Deep Learning. Lecture Notes in Computer Scien ce11700, pp. 243252. Springer (2019) 97. Zintgraf, L.M., Cohen, T.S., Adel, T., Welling, M.: Visu alizing deep neural network decisions: Prediction di?erence analysis. In: Internatio nal Conference on Learning Representations (ICLR). (2017)", "21": "Transformers in Time Series: A Survey Qingsong Wen1, Tian Zhou2, Chaoli Zhang2, Weiqi Chen2, Ziqing Ma2, Junchi Yan3, Liang Sun1 1DAMO Academy, Alibaba Group, Bellevue, USA 2DAMO Academy, Alibaba Group, Hangzhou, China 3Department of CSE, MoE Key Lab of Arti?cial Intelligence, Shanghai Jiao Tong University {qingsong.wen, tian.zt, chaoli.zcl, jarvus.cwq, maziqing.mzq, liang.sun }@alibaba-inc.com, yanjunchi@sjtu.edu.cn Abstract Transformers have achieved superior performances in many tasks in natural language processing and computer vision, which also triggered great inter- est in the time series community. Among multiple advantages of Transformers, the ability to capture long-range dependencies and interactions is espe- cially attractive for time series modeling, leading to exciting progress in various time series appli- cations. In this paper, we systematically review Transformer schemes for time series modeling by highlighting their strengths as well as limitations. In particular, we examine the development of time series Transformers in two perspectives. From the perspective of network structure, we summarize the adaptations and modi?cations that have been made to Transformers in order to accommodate the chal- lenges in time series analysis. From the perspective of applications, we categorize time series Trans- formers based on common tasks including forecast- ing, anomaly detection, and classi?cation. Empiri- cally, we perform robust analysis, model size anal- ysis, and seasonal-trend decomposition analysis to study how Transformers perform in time series. Fi- nally, we discuss and suggest future directions to provide useful research guidance. A corresponding resource that has been continuously updated can be found in the GitHub repository1. 1 Introduction The innovation of Transformer in deep learning [Vaswani et al. , 2017 ]has brought great interests recently due to its excellent performances in natural language process- ing (NLP) [Kenton and others, 2019 ], computer vision (CV) [Dosovitskiy et al. , 2021 ], and speech processing [Dong et al. , 2018 ]. Over the past few years, numerous Transform- ers have been proposed to advance the state-of-the-art per- formances of various tasks signi?cantly. There are quite a few literature reviews from different aspects, such as in NLP applications [Han et al. , 2021 ], CV applications [Han et al. , 2022 ], and ef?cient Transformers [Tayet al. , 2022 ]. 1https://github.com/qingsongedu/time-series-transformers-reviewTransformers have shown great modeling ability for long- range dependencies and interactions in sequential data and thus are appealing to time series modeling. Many variants of Transformer have been proposed to address special chal- lenges in time series modeling and have been successfully applied to various time series tasks, such as forecasting [Li et al. , 2019; Zhou et al. , 2022 ], anomaly detection [Xuet al., 2022; Tuli et al. , 2022 ], and classi?cation [Zerveas et al., 2021; Yang et al. , 2021 ]. Speci?cally, seasonality or pe- riodicity is an important feature of time series [Wen et al. , 2021a ]. How to effectively model long-range and short-range temporal dependency and capture seasonality simultaneously remains a challenge [Wuet al. , 2021; Wen et al. , 2022 ]. We note that there exist several surveys related to deep learning for time series, including forecasting [Lim and Zohren, 2021; Benidis et al. , 2022; Torres et al. , 2021 ], classi?cation [Is- mail Fawaz et al. , 2019 ], anomaly detection [Choi et al. , 2021; Bl \u00b4azquez-Garc \u00b4iaet al. , 2021 ], and data augmenta- tion[Wen et al. , 2021b ], but there is no comprehensive sur- vey for Transformers in time series. As Transformer for time series is an emerging subject in deep learning, a systematic and comprehensive survey on time series Transformers would greatly bene?t the time series community. In this paper, we aim to ?ll the gap by summarizing the main developments of time series Transformers. We ?rst give a brief introduction about vanilla Transformer, and then propose a new taxonomy from perspectives of both network modi?cations and application domains for time series Trans- formers. For network modi?cations, we discuss the improve- ments made on both low-level (i.e. module) and high-level (i.e. architecture) of Transformers, with the aim to optimize the performance of time series modeling. For applications, we analyze and summarize Transformers for popular time series tasks including forecasting, anomaly detection, and classi?cation. For each time series Transformer, we analyze its insights, strengths, and limitations. To provide practical guidelines on how to effectively use Transformers for time series modeling, we conduct extensive empirical studies that examine multiple aspects of time series modeling, including robustness analysis, model size analysis, and seasonal-trend decomposition analysis. We conclude this work by discussing possible future directions for time series Transformers, in- cluding inductive biases for time series Transformers, Trans- formers and GNN for time series, pre-trained TransformersarXiv:2202.07125v5  [cs.LG]  11 May 2023for time series, Transformers with architecture level variants, and Transformers with NAS for time series. To the best of our knowledge, this is the ?rst work to comprehensively and systematically review the key developments of Transformers for modeling time series data. We hope this survey will ignite further research interests in time series Transformers. 2 Preliminaries of the Transformer 2.1 Vanilla Transformer The vanilla Transformer [Vaswani et al. , 2017 ]follows most competitive neural sequence models with an encoder-decoder structure. Both encoder and decoder are composed of multi- ple identical blocks. Each encoder block consists of a multi- head self-attention module and a position-wise feed-forward network while each decoder block inserts cross-attention models between the multi-head self-attention module and the position-wise feed-forward network. 2.2 Input Encoding and Positional Encoding Unlike LSTM or RNN, the vanilla Transformer has no recur- rence. Instead, it utilizes the positional encoding added in the input embeddings, to model the sequence information. We summarize some positional encodings below. Absolute Positional Encoding In vanilla Transformer, for each position index t, encoding vector is given by PE(t)i={sin(?it)i%2 = 0 cos(?it)i%2 = 1(1) where ?iis the hand-crafted frequency for each dimension. Another way is to learn a set of positional embeddings for each position which is more ?exible [Kenton and others, 2019; Gehring et al. , 2017 ]. Relative Positional Encoding Following the intuition that pairwise positional relationships between input elements is more bene?cial than positions of elements, relative positional encoding methods have been proposed. For example, one of such methods is to add a learnable relative positional embedding to keys of attention mechanism [Shaw et al. , 2018 ]. Besides the absolute and relative positional encodings, there are methods using hybrid positional encodings that combine them together [Keet al. , 2021 ]. Generally, the po- sitional encoding is added to the token embedding and fed to Transformer. 2.3 Multi-head Attention With Query-Key-Value (QKV) model, the scaled dot-product attention used by Transformer is given by Attention (Q,K,V) =softmax (QKT vDk)V (2) where queries Q? RN\u00d7Dk, keys K? RM\u00d7Dk, values V?RM\u00d7Dv,N, M denote the lengths of queries and keys (or values), and Dk, Dvdenote the dimensions of keys (or queries) and values. Transformer uses multi-head attention Time SeriesTransformersNetwork ModificationsApplicationDomainsPositional EncodingAttentionModuleArchitectureLevelForecastingAnomaly DetectionClassificationTime Series ForecastingSpatio-Temporal ForecastingEvent ForecastingVanilla EncodingLearnable EncodingTimestamp EncodingFigure 1: Taxonomy of Transformers for time series modeling from the perspectives of network modi?cations and application domains. withHdifferent sets of learned projections instead of a sin- gle attention function as MultiHeadAttn( Q,K,V) = Concat ( head 1,\u00b7\u00b7\u00b7, head H)WO, where head i=Attention (QWQ i,KWK i,VWV i). 2.4 Feed-forward and Residual Network The feed-forward network is a fully connected module as FFN (H') =ReLU (H'W1+b1)W2+b2, (3) where H'is outputs of previous layer, W1? RDm\u00d7Df, W2?RDf\u00d7Dm,b1?RDf,b2?RDmare trainable pa- rameters. In a deeper module, a residual connection module followed by a layer normalization module is inserted around each module. That is, H'= LayerNorm( SelfAttn (X) +X), (4) H= LayerNorm( FFN (H') +H'), (5) where SelfAttn (.)denotes self-attention module and LayerNorm (.)denotes the layer normalization operation. 3 Taxonomy of Transformers in Time Series To summarize the existing time series Transformers, we pro- pose a taxonomy from perspectives of network modi?cations and application domains as illustrated in Fig. 1. Based on the taxonomy, we review the existing time series Transform- ers systematically. From the perspective of network modi- ?cations, we summarize the changes made on both module level and architecture level of Transformer in order to ac- commodate special challenges in time series modeling. From the perspective of applications, we classify time series Trans- formers based on their application tasks, including forecast- ing, anomaly detection, and classi?cation. In the following two sections, we would delve into the existing time series Transformers from these two perspectives. 4 Network Modi?cations for Time Series 4.1 Positional Encoding As the ordering of time series matters, it is of great impor- tance to encode the positions of input time series into Trans- formers. A common design is to ?rst encode positional infor- mation as vectors and then inject them into the model as anadditional input together with the input time series. How to obtain these vectors when modeling time series with Trans- formers can be divided into three main categories. Vanilla Positional Encoding. A few works [Liet al. , 2019 ]simply introduce vanilla positional encoding (Section 2.2) used in [Vaswani et al. , 2017 ], which is then added to the input time series embeddings and fed to Transformer. Al- though this approach can extract some positional information from time series, they were unable to fully exploit the impor- tant features of time series data. Learnable Positional Encoding. As the vanilla posi- tional encoding is hand-crafted and less expressive and adap- tive, several studies found that learning appropriate posi- tional embeddings from time series data can be much more effective. Compared to ?xed vanilla positional encoding, learned embeddings are more ?exible and can adapt to spe- ci?c tasks. [Zerveas et al. , 2021 ]introduces an embedding layer in Transformer that learns embedding vectors for each position index jointly with other model parameters. [Lim et al., 2021 ]uses an LSTM network to encode positional em- beddings, which can better exploit sequential ordering infor- mation in time series. Timestamp Encoding. When modeling time series in real-world scenarios, the timestamp information is com- monly accessible, including calendar timestamps (e.g., sec- ond, minute, hour, week, month, and year) and special times- tamps (e.g., holidays and events). These timestamps are quite informative in real applications but hardly leveraged in vanilla Transformers. To mitigate the issue, Informer [Zhou et al. , 2021 ]proposed to encode timestamps as additional positional encoding by using learnable embedding layers. A similar timestamp encoding scheme was used in Autoformer [Wuet al., 2021 ]and FEDformer [Zhou et al. , 2022 ]. 4.2 Attention Module Central to Transformer is the self-attention module. It can be viewed as a fully connected layer with weights that are dynamically generated based on the pairwise similarity of in- put patterns. As a result, it shares the same maximum path length as fully connected layers, but with a much less num- ber of parameters, making it suitable for modeling long-term dependencies. As we show in the previous section the self-attention mod- ule in the vanilla Transformer has a time and memory com- plexity ofO(N2)(Nis the input time series length), which becomes the computational bottleneck when dealing with long sequences. Many ef?cient Transformers were proposed to reduce the quadratic complexity that can be classi?ed into two main categories: (1) explicitly introducing a sparsity bias into the attention mechanism like LogTrans [Liet al. , 2019 ] and Pyraformer [Liuet al. , 2022a ]; (2) exploring the low-rank property of the self-attention matrix to speed up the computa- tion, e.g. Informer [Zhou et al. , 2021 ]and FEDformer [Zhou et al. , 2022 ]. Table 1 shows both the time and memory com- plexity of popular Transformers applied to time series mod- eling, and more details about these models will be discussed in Section 5.Table 1: Complexity comparisons of popular time series Transform- ers with different attention modules. MethodsTraining Testing Time Memory Steps Transformer [Vaswani et al. , 2017 ]O( N2) O( N2) N LogTrans [Liet al. , 2019 ]O(NlogN)O(NlogN) 1 Informer [Zhou et al. , 2021 ]O(NlogN)O(NlogN) 1 Autoformer [Wuet al. , 2021 ]O(NlogN)O(NlogN) 1 Pyraformer [Liuet al. , 2022a ]O(N)O(N) 1 Quatformer [Chen et al. , 2022 ]O(2cN)O(2cN) 1 FEDformer [Zhou et al. , 2022 ]O(N)O(N) 1 Crossformer [Zhang and Yan, 2023 ]O(D L2segN2)O(N) 1 4.3 Architecture-based Attention Innovation To accommodate individual modules in Transformers for modeling time series, a number of works [Zhou et al. , 2021; Liuet al. , 2022a ]seek to renovate Transformers on the archi- tecture level. Recent works introduce hierarchical architec- ture into Transformer to take into account the multi-resolution aspect of time series. Informer [Zhou et al. , 2021 ]inserts max-pooling layers with stride 2 between attention blocks, which down-sample series into its half slice. Pyraformer [Liu et al. , 2022a ]designs a C-ary tree-based attention mecha- nism, in which nodes at the ?nest scale correspond to the orig- inal time series, while nodes in the coarser scales represent series at lower resolutions. Pyraformer developed both intra- scale and inter-scale attentions in order to better capture tem- poral dependencies across different resolutions. Besides the ability to integrate information at different multi-resolutions, a hierarchical architecture also enjoys the bene?ts of ef?cient computation, particularly for long-time series. 5 Applications of Time Series Transformers In this section, we review the applications of Transformer to important time series tasks, including forecasting, anomaly detection, and classi?cation. 5.1 Transformers in Forecasting Here we examine three common types of forecasting tasks here, i.e. time series forecasting, spatial-temporal forecast- ing, and event forecasting. Time Series Forecasting A lot of work has been done to design new Transformer variants for time series forecasting tasks in the latest years. Module-level and architecture-level variants are two large categories and the former consists of the majority of the up- to-date works. Module-level variants In the module-level variants for time series forecasting, their main architectures are similar to the vanilla Transformer with minor changes. Researchers introduce various time series inductive biases to design new modules. The following summarized work consists of three different types: designing new attention modules, exploring the innovative way to normalize time series data, and utilizing the bias for token inputs, as shown in Figure 2. The ?rst type of variant for module-level Transformers is to design new attention modules, which is the category with the largest proportion. Here we ?rst describe six typical works: LogTrans [Liet al. , 2019 ], Informer [Zhou et al. , 2021 ],Figure 2: Categorization of module-level Transformer variants for time series forecasting. AST [Wuet al. , 2020a ], Pyraformer [Liuet al. , 2022a ], Quat- former [Chen et al. , 2022 ], and FEDformer [Zhou et al. , 2022 ], all of which exploit sparsity inductive bias or low-rank approximation to remove noise and achieve a low-order cal- culation complexity. LogTrans [Liet al. , 2019 ]proposes con- volutional self-attention by employing causal convolutions to generate queries and keys in the self-attention layer. It introduces sparse bias, a Logsparse mask, in self-attention model that reduces computational complexity from O(N2) toO(NlogN). Instead of using explicit sparse bias, In- former [Zhou et al. , 2021 ]selects dominant queries based on queries and key similarities, thus achieving similar improve- ments as LogTrans in computational complexity. It also de- signs a generative style decoder to produce long-term fore- casting directly and thus avoids accumulative error in us- ing one forward-step prediction for long-term forecasting. AST [Wuet al. , 2020a ]uses a generative adversarial encoder- decoder framework to train a sparse Transformer model for time series forecasting. It shows that adversarial training can improve time series forecasting by directly shaping the output distribution of the network to avoid error accumula- tion through one-step ahead inference. Pyraformer [Liuet al., 2022a ]designs a hierarchical pyramidal attention mod- ule with a binary tree following the path, to capture temporal dependencies of different ranges with linear time and mem- ory complexity. FEDformer [Zhou et al. , 2022 ]applies at- tention operation in the frequency domain with Fourier trans- form and wavelet transform. It achieves a linear complex- ity by randomly selecting a ?xed-size subset of frequency. Note that due to the success of Autoformer and FEDformer, it has attracted more attention in the community to explore self-attention mechanisms in the frequency domain for time series modeling. Quatformer [Chen et al. , 2022 ]proposes learning-to-rotate attention (LRA) based on quaternions that introduce learnable period and phase information to depict in- tricate periodical patterns. Moreover, it decouples LRA using a global memory to achieve linear complexity. The following three works focus on building an explicit interpretation ability of models, which follows the trend of Explainable Arti?cial Intelligence (XAI). TFT [Lim et al. ,2021 ]designs a multi-horizon forecasting model with static covariate encoders, gating feature selection, and temporal self-attention decoder. It encodes and selects useful infor- mation from various covariates to perform forecasting. It also preserves interpretability by incorporating global, tem- poral dependency, and events. ProTran [Tang and Matteson, 2021 ]and SSDNet [Linet al. , 2021 ]combine Transformer with state space models to provide probabilistic forecasts. ProTran designs a generative modeling and inference proce- dure based on variational inference. SSDNet ?rst uses Trans- former to learn the temporal pattern and estimate the param- eters of SSM, and then applies SSM to perform the seasonal- trend decomposition and maintain the interpretable ability. The second type of variant for module-level Transformers is the way to normalize time series data. To the best of our knowledge, Non-stationary Transformer [Liuet al. , 2022b ]is the only work that mainly focuses on modifying the normal- ization mechanism as shown in Figure 2. It explores the over- stationarization problem in time series forecasting tasks with a relatively simple plugin series stationary and De-stationary module to modify and boost the performance of various at- tention blocks. The third type of variant for module-level Transformer is utilizing the bias for token input. Autoformer [Wuet al. , 2021 ]adopts a segmentation-based representation mecha- nism. It devises a simple seasonal-trend decomposition ar- chitecture with an auto-correlation mechanism working as an attention module. The auto-correlation block measures the time-delay similarity between inputs signal and aggre- gates the top-k similar sub-series to produce the output with reduced complexity. PatchTST [Nie et al. , 2023 ]utilizes channel-independent where each channel contains a single univariate time series that shares the same embedding within all the series, and subseries-level patch design which seg- mentation of time series into subseries-level patches that are served as input tokens to Transformer. Such ViT [Dosovit- skiy et al. , 2021 ]alike design improves its numerical perfor- mance in long-time time-series forecasting tasks a lot. Cross- former [Zhang and Yan, 2023 ]proposes a Transformer-based model utilizing cross-dimension dependency for multivariate time series forecasting. The input is embedded into a 2D vector array through the novel dimension-segment-wise em- bedding to preserve time and dimension information. Then, a two-stage attention layer is used to ef?ciently capture the cross-time and cross-dimension dependency. Architecture-level variants Some works start to design a new transformer architecture beyond the scope of the vanilla transformer. Triformer [Cirstea et al. , 2022 ]design a triangular,variable-speci?c patch attention. It has a triangular tree-type structure as the later input size shrinks exponentially and a set of variable-speci?c parameters making a multi- layer Triformer maintain a lightweight and linear complex- ity. Scaleformer [Shabani et al. , 2023 ]proposes a multi-scale framework that can be applied to the baseline transformer- based time series forecasting models (FEDformer [Zhou et al. , 2022 ], Autoformer [Wuet al. , 2021 ], etc.). It can improve the baseline model\u2019s performance by iteratively re?ning the fore- casted time series at multiple scales with shared weights.Remarks Note that DLinear [Zeng et al. , 2023 ]questions the necessity of using Transformers for long-term time series forecasting, and shows that a simpler MLP-based model can achieve better results compared to some Transformer base- lines through empirical studies. However, we notice that a re- cent Transformer model PatchTST [Nieet al. , 2023 ]achieves a better numerical result compared to DLinear for long-term time series forecasting. Moreover, there is a thorough the- oretical study [Yun et al. , 2020 ]showing that the Trans- former models are universal approximators of sequence-to- sequence functions. It is a overclaim to question the poten- tial of any type of method for time series forecasting based solely on experimental results from some variant instanti- ations of such method, especially for Transformer models which already demonstrate the performances in most machine learning-based tasks. Therefore, we conclude that summariz- ing the recent Transformer-based models for time series fore- casting is necessary and would bene?t the whole community. Spatio-Temporal Forecasting In spatio-temporal forecasting, both temporal and spatio- temporal dependencies are taken into account in time series Transformers for accurate forecasting. Traf?c Transformer [Caiet al. , 2020 ]designs an encoder- decoder structure using a self-attention module to capture temporal-temporal dependencies and a graph neural network module to capture spatial dependencies. Spatial-temporal Transformer [Xuet al. , 2020 ]for traf?c ?ow forecasting takes a step further. Besides introducing a temporal Transformer block to capture temporal dependencies, it also designs a spatial Transformer block, together with a graph convolu- tion network, to better capture spatial-spatial dependencies. Spatio-temporal graph Transformer [Yuet al. , 2020 ]designs an attention-based graph convolution mechanism that is able to learn a complicated temporal-spatial attention pattern to improve pedestrian trajectory prediction. Earthformer [Gao et al. , 2022 ]proposes a cuboid attention for ef?cient space- time modeling, which decomposes the data into cuboids and applies cuboid-level self-attention in parallel. It shows that Earthformer achieves superior performance in weather and climate forecasting. Recently, AirFormer [Liang et al. , 2023 ] devises a dartboard spatial self-attention module and a causal temporal self-attention module to ef?ciently capture spatial correlations and temporal dependencies, respectively. Fur- thermore, it enhances Transformers with latent variables to capture data uncertainty and improve air quality forecasting. Event Forecasting Event sequence data with irregular and asynchronous times- tamps are naturally observed in many real-life applications, which is in contrast to regular time series data with equal sampling intervals. Event forecasting or prediction aims to predict the times and marks of future events given the his- tory of past events, and it is often modeled by temporal point processes (TPP) [Yanet al. , 2019; Shchur et al. , 2021 ]. Recently, several neural TPP models incorporate Trans- formers in order to improve the performance of event pre- diction. Self-attentive Hawkes process (SAHP) [Zhang et al. , 2020 ]and Transformer Hawkes process (THP) [Zuo et al. , 2020 ]adopt Transformer encoder architecture to summarizethe in?uence of historical events and compute the intensity function for event prediction. They modify the positional en- coding by translating time intervals into sinusoidal functions such that the intervals between events can be utilized. Later, a more ?exible named attentive neural datalog through time (A- NDTT) [Mei et al. , 2022 ]is proposed to extend SAHP/THP schemes by embedding all possible events and times with at- tention as well. Experiments show that it can better capture sophisticated event dependencies than existing methods. 5.2 Transformers in Anomaly Detection Transformer based architecture also bene?ts the time se- ries anomaly detection task with the ability to model tem- poral dependency, which brings high detection quality [Xu et al. , 2022 ]. Besides, in multiple studies, including TranAD [Tuli et al. , 2022 ], MT-RV AE [Wang et al. , 2022 ], and TransAnomaly [Zhang et al. , 2021 ], researchers pro- posed to combine Transformer with neural generative models, such as V AEs [Kingma and Welling, 2014 ]and GANs [Good- fellow et al. , 2014 ], for better performance in anomaly detec- tion. We will elaborate on these models in the following part. TranAD [Tuli et al. , 2022 ]proposes an adversarial train- ing procedure to amplify reconstruction errors as a sim- ple Transformer-based network tends to miss small devia- tion of anomaly. GAN style adversarial training procedure is designed by two Transformer encoders and two Trans- former decoders to gain stability. Ablation study shows that, if Transformer-based encoder-decoder is replaced, F1 score drops nearly 11%, indicating the effect of Transformer archi- tecture on time series anomaly detection. MT-RV AE [Wang et al. , 2022 ]and TransAnomaly [Zhang et al. , 2021 ]combine V AE with Transformer, but they share different purposes. TransAnomaly combines V AE with Transformer to allow more parallelization and reduce training costs by nearly 80%. In MT-RV AE, a multiscale Transformer is designed to extract and integrate time-series information at different scales. It overcomes the shortcomings of traditional Transformers where only local information is extracted for sequential analysis. GTA [Chen et al. , 2021c ]combines Transformer with graph-based learning architecture for multivariate time series anomaly detection. Note that, MT-RV AE is also for multi- variate time series but with few dimensions or insuf?cient close relationships among sequences where the graph neu- ral network model does not work well. To deal with such challenge, MT-RV AE modi?es the positional encoding mod- ule and introduces feature-learning module. Instead, GTA contains a graph convolution structure to model the in?uence propagation process. Similar to MT-RV AE, GTA also consid- ers \u201cglobal\u201d information, yet by replacing vanilla multi-head attention with a multi-branch attention mechanism, that is, a combination of global-learned attention, vanilla multi-head attention, and neighborhood convolution. AnomalyTrans [Xuet al. , 2022 ]combines Transformer and Gaussian prior-Association to make anomalies more dis- tinguishable. Sharing similar motivation as TranAD, Anom- alyTrans achieves the goal in a different way. The insight is that it is harder for anomalies to build strong associations with the whole series while easier with adjacent time points com-pared with normality. In AnomalyTrans, prior-association and series-association are modeled simultaneously. Besides reconstruction loss, the anomaly model is optimized by the minimax strategy to constrain the prior- and series- associa- tions for more distinguishable association discrepancy. 5.3 Transformers in Classi?cation Transformer is proved to be effective in various time series classi?cation tasks due to its prominent capability in captur- ing long-term dependency. GTN [Liuet al. , 2021 ]uses a two-tower Transformer with each tower respectively work- ing on time-step-wise attention and channel-wise attention. To merge the feature of the two towers, a learnable weighted concatenation (also known as \u2018gating\u2019) is used. The proposed extension of Transformer achieves state-of-the-art results on 13 multivariate time series classi?cations. [Ru\u00dfwurm and K\u00a8orner, 2020 ]studied the self-attention based Transformer for raw optical satellite time series classi?cation and obtained the best results compared with recurrent and convolutional neural networks. Recently, TARNet [Chowdhury et al. , 2022 ] designs Transformers to learn task-aware data reconstruction that augments classi?cation performance, which utilizes at- tention score for important timestamps masking and recon- struction and brings superior performance. Pre-trained Transformers are also investigated in classi?ca- tion tasks. [Yuan and Lin, 2020 ]studies the Transformer for raw optical satellite image time series classi?cation. The au- thors use self-supervised pre-trained schema because of lim- ited labeled data. [Zerveas et al. , 2021 ]introduced an unsu- pervised pre-trained framework and the model is pre-trained with proportionally masked data. The pre-trained models are then ?ne-tuned in downstream tasks such as classi?cation. [Yang et al. , 2021 ]proposes to use large-scale pre-trained speech processing model for downstream time series classi- ?cation problems and generates 19 competitive results on 30 popular time series classi?cation datasets. 6 Experimental Evaluation and Discussion We conduct preliminary empirical studies on a typical chal- lenging benchmark dataset ETTm2 [Zhou et al. , 2021 ]to analyze how Transformers work on time series data. Since classic statistical ARIMA/ETS [Hyndman and Khandakar, 2008 ]models and basic RNN/CNN models perform inferior to Transformers in this dataset as shown in [Zhou et al. , 2021; Wuet al. , 2021 ], we focus on popular time series Transform- ers with different con?gurations in the experiments. Robustness Analysis A lot of works we describe above carefully design attention modules to lower the quadratic calculation and memory com- plexity, though they practically use a short ?xed-size input to achieve the best result in their reported experiments. It makes us question the actual usage of such an ef?cient design. We perform a robust experiment with prolonging input sequence length to verify their prediction power and robustness when dealing with long-term input sequences in Table 2. As in Table 2, when we compare the prediction results with prolonging input length, various Transformer-based modelTable 2: The MSE comparisons in robustness experiment of fore- casting 96 steps for ETTm2 dataset with prolonging input length. Model Transformer Autoformer Informer Reformer LogFormerInput Len96 0.557 0.239 0.428 0.615 0.667 192 0.710 0.265 0.385 0.686 0.697 336 1.078 0.375 1.078 1.359 0.937 720 1.691 0.315 1.057 1.443 2.153 1440 0.936 0.552 1.898 0.815 0.867 Table 3: The MSE comparisons in model size experiment of fore- casting 96 steps for ETTm2 dataset with different number of layers. Model Transformer Autoformer Informer Reformer LogFormerLayer Num3 0.557 0.234 0.428 0.597 0.667 6 0.439 0.282 0.489 0.353 0.387 12 0.556 0.238 0.779 0.481 0.562 24 0.580 0.266 0.815 1.109 0.690 48 0.461 NaN 1.623 OOM 2.992 deteriorates quickly. This phenomenon makes a lot of care- fully designed Transformers impractical in long-term fore- casting tasks since they cannot effectively utilize long input information. More works and designs need to be investigated to fully utilize long sequence input for better performance. Model Size Analysis Before being introduced into the ?eld of time series predic- tion, Transformer has shown dominant performance in NLP and CV communities [Vaswani et al. , 2017; Kenton and oth- ers, 2019; Han et al. , 2021; Han et al. , 2022 ]. One of the key advantages Transformer holds in these ?elds is being able to increase prediction power through increasing model size. Usually, the model capacity is controlled by Transformer\u2019s layer number, which is commonly set between 12 to 128. Yet as shown in the experiments of Table 3, when we compare the prediction result with different Transformer models with various numbers of layers, the Transformer with 3 to 6 layers often achieves better results. It raises a question about how to design a proper Transformer architecture with deeper layers to increase the model\u2019s capacity and achieve better forecast- ing performance. Seasonal-Trend Decomposition Analysis In recent studies, researchers [Wuet al. , 2021; Zhou et al. , 2022; Lin et al. , 2021; Liu et al. , 2022a ]begin to realize that the seasonal-trend decomposition [Cleveland et al. , 1990; Wen et al. , 2020 ]is a crucial part of Transformer\u2019s perfor- mance in time series forecasting. As an experiment shown in Table 4, we adopt a simple moving average seasonal-trend decomposition architecture proposed in [Wuet al. , 2021 ]to test various attention modules. It can be seen that the simple seasonal-trend decomposition model can signi?cantly boost model\u2019s performance by 50 % to 80%. It is a unique block and such performance boosting through decomposition seems a consistent phenomenon in time series forecasting for Trans- former\u2019s application, which is worth further investigating for more advanced and carefully designed time series decompo- sition schemes. 7 Future Research Opportunities Here we highlight a few directions that are potentially promising for future research of Transformers in time series.Table 4: The MSE comparisons in ablation experiments of seasonal-trend decomposition analysis. \u2019Ori\u2019 means the original version without the decomposition. \u2019Decomp\u2019 means with decomposition. The experiment is performed on ETTm2 dataset with prolonging output length. Model FEDformer Autoformer Informer LogTrans Reformer Transformer Promotion MSE Ori Decomp Ori Decomp Ori Decomp Ori Decomp Ori Decomp Ori Decomp RelativeOut Len96 0.457 0.203 0.581 0.255 0.365 0.354 0.768 0.231 0.658 0.218 0.604 0.204 53% 192 0.841 0.269 1.403 0.281 0.533 0.432 0.989 0.378 1.078 0.336 1.060 0.266 62% 336 1.451 0.325 2.632 0.339 1.363 0.481 1.334 0.362 1.549 0.366 1.413 0.375 75% 720 3.282 0.421 3.058 0.422 3.379 0.822 3.048 0.539 2.631 0.502 2.672 0.537 82% 7.1 Inductive Biases for Time Series Transformers Vanilla Transformer does not make any assumptions about data patterns and characteristics. Although it is a general and universal network for modeling long-range dependen- cies, it also comes with a price, i.e., lots of data are needed to train Transformer to improve the generalization and avoid data over?tting. One of the key features of time series data is its seasonal/periodic and trend patterns [Wen et al. , 2019; Cleveland et al. , 1990 ]. Some recent studies have shown that incorporating series periodicity [Wuet al. , 2021 ]or fre- quency processing [Zhou et al. , 2022 ]into time series Trans- former can enhance performance signi?cantly. Moreover, it is interesting that some studies adopt a seemly opposite in- ductive bias, but both achieve good numerical improvement: [Nieet al. , 2023 ]removes the cross-channel dependency by utilizing a channel-independent attention module, while an interesting work [Zhang and Yan, 2023 ]improves its experi- mental performance by utilizing cross-dimension dependency with a two-stage attention mechanism. Clearly, we have noise and signals in such a cross-channel learning paradigm, but a clever way to utilize such inductive bias to suppress the noise and extract the signal is still desired. Thus, one future direc- tion is to consider more effective ways to induce inductive biases into Transformers based on the understanding of time series data and characteristics of speci?c tasks. 7.2 Transformers and GNN for Time Series Multivariate and spatio-temporal time series are becoming increasingly common in applications, calling for additional techniques to handle high dimensionality, especially the abil- ity to capture the underlying relationships among dimen- sions. Introducing graph neural networks (GNNs) is a natural way to model spatial dependency or relationships among di- mensions. Recently, several studies have demonstrated that the combination of GNN and Transformers/attentions could bring not only signi?cant performance improvements like in traf?c forecasting [Caiet al. , 2020; Xu et al. , 2020 ]and multi- modal forecasting [Liet al. , 2021 ], but also better understand- ing of the spatio-temporal dynamics and latent causality. It is an important future direction to combine Transformers and GNNs for effectively spatial-temporal modeling in time se- ries. 7.3 Pre-trained Transformers for Time Series Large-scale pre-trained Transformer models have signif- icantly boosted the performance for various tasks in NLP [Kenton and others, 2019; Brown et al. , 2020 ]and CV[Chen et al. , 2021a ]. However, there are limited works on pre-trained Transformers for time series, and existing stud- ies mainly focus on time series classi?cation [Zerveas et al. ,2021; Yang et al. , 2021 ]. Therefore, how to develop appro- priate pre-trained Transformer models for different tasks in time series remains to be examined in the future. 7.4 Transformers with Architecture Level Variants Most developed Transformer models for time series main- tain the vanilla Transformer\u2019s architecture with modi?cations mainly in the attention module. We might borrow the idea from Transformer variants in NLP and CV which also have architecture-level model designs to ?t different purposes, such as lightweight [Wuet al. , 2020b; Mehta et al. , 2021 ], cross-block connectivity [Bapna et al. , 2018 ], adaptive com- putation time [Dehghani et al. , 2019; Xin et al. , 2020 ], and recurrence [Daiet al. , 2019 ]. Therefore, one future direction is to consider more architecture-level designs for Transform- ers speci?cally optimized for time series data and tasks. 7.5 Transformers with NAS for Time Series Hyper-parameters, such as embedding dimension and the number of heads/layers, can largely affect the performance of Transformers. Manual con?guring these hyper-parameters is time-consuming and often results in suboptimal perfor- mance. AutoML technique like Neural architecture search (NAS) [Elsken et al. , 2019; Wang et al. , 2020 ]has been a popular technique for discovering effective deep neural archi- tectures, and automating Transformer design using NAS in NLP and CV can be found in recent studies [Soet al. , 2019; Chen et al. , 2021b ]. For industry-scale time series data which can be of both high dimension and long length, automatically discovering both memory- and computational-ef?cient Trans- former architectures is of practical importance, making it an important future direction for time series Transformers. 8 Conclusion We have provided a survey on time series Transformers. We organize the reviewed methods in a new taxonomy consisting of network design and application. We summarize represen- tative methods in each category, discuss their strengths and limitations by experimental evaluation, and highlight future research directions. References [Bapna et al. , 2018 ]Ankur Bapna, Mia Xu Chen, Orhan Firat, Yuan Cao, and Yonghui Wu. Training deeper neural machine translation models with transparent attention. In EMNLP , 2018. [Benidis et al. , 2022 ]Konstantinos Benidis, Syama Sundar Ranga- puram, Valentin Flunkert, Yuyang Wang, Danielle Maddix, , et al. Deep learning for time series forecasting: Tutorial and literature survey. ACM Computing Surveys , 55(6):1\u201336, 2022.[Bl\u00b4azquez-Garc \u00b4iaet al. , 2021 ]Ane Bl \u00b4azquez-Garc \u00b4ia, Angel Conde, Usue Mori, et al. A review on outlier/anomaly detection in time series data. ACM Computing Surveys , 54(3):1\u201333, 2021. [Brown et al. , 2020 ]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, et al. Lan- guage models are few-shot learners. NeurIPS , 2020. [Caiet al. , 2020 ]Ling Cai, Krzysztof Janowicz, Gengchen Mai, Bo Yan, and Rui Zhu. Traf?c transformer: Capturing the conti- nuity and periodicity of time series for traf?c forecasting. Trans- actions in GIS , 24(3):736\u2013755, 2020. [Chen et al. , 2021a ]Hanting Chen, Yunhe Wang, Tianyu Guo, Chang Xu, Yiping Deng, Zhenhua Liu, Siwei Ma, Chunjing Xu, et al. Pre-trained image processing transformer. In CVPR , 2021. [Chen et al. , 2021b ]Minghao Chen, Houwen Peng, Jianlong Fu, and Haibin Ling. AutoFormer: Searching transformers for vi- sual recognition. In CVPR , 2021. [Chen et al. , 2021c ]Zekai Chen, Dingshuo Chen, Xiao Zhang, Zix- uan Yuan, and Xiuzhen Cheng. Learning graph structures with transformer for multivariate time series anomaly detection in IoT. IEEE Internet of Things Journal , 2021. [Chen et al. , 2022 ]Weiqi Chen, Wenwei Wang, Bingqing Peng, Qingsong Wen, Tian Zhou, and Liang Sun. Learning to rotate: Quaternion transformer for complicated periodical time series forecasting. In KDD , 2022. [Choi et al. , 2021 ]Kukjin Choi, Jihun Yi, Changhwa Park, and Sungroh Yoon. Deep learning for anomaly detection in time- series data: Review, analysis, and guidelines. IEEE Access , 2021. [Chowdhury et al. , 2022 ]Ranak Roy Chowdhury, Xiyuan Zhang, Jingbo Shang, Rajesh K Gupta, and Dezhi Hong. TARNet: Task- aware reconstruction for time-series transformer. In KDD , 2022. [Cirstea et al. , 2022 ]Razvan-Gabriel Cirstea, Chenjuan Guo, Bin Yang, Tung Kieu, Xuanyi Dong, and Shirui Pan. Triformer: Tri- angular, variable-speci?c attentions for long sequence multivari- ate time series forecasting. In IJCAI , 2022. [Cleveland et al. , 1990 ]Robert Cleveland, William Cleveland, Jean McRae, et al. STL: A seasonal-trend decomposition procedure based on loess. Journal of Of?cial Statistics , 6(1):3\u201373, 1990. [Daiet al. , 2019 ]Zihang Dai, Zhilin Yang, Yiming Yang, Jaime G. Carbonell, Quoc V . Le, et al. Transformer-XL: Attentive lan- guage models beyond a ?xed-length context. In ACL, 2019. [Dehghani et al. , 2019 ]Mostafa Dehghani, Stephan Gouws, Oriol Vinyals, Jakob Uszkoreit, and Lukasz Kaiser. Universal trans- formers. In ICLR , 2019. [Dong et al. , 2018 ]Linhao Dong, Shuang Xu, and Bo Xu. Speech- transformer: a no-recurrence sequence-to-sequence model for speech recognition. In ICASSP , 2018. [Dosovitskiy et al. , 2021 ]Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, et al. An image is worth 16x16 words: Transformers for image recognition at scale. In ICLR , 2021. [Elsken et al. , 2019 ]Elsken, Thomas, Jan Hendrik Metzen, and Frank Hutter. Neural architecture search: A survey. Journal of Machine Learning Research , 2019. [Gao et al. , 2022 ]Zhihan Gao, Xingjian Shi, Hao Wang, Yi Zhu, Bernie Wang, Mu Li, et al. Earthformer: Exploring space-time transformers for earth system forecasting. In NeurIPS , 2022. [Gehring et al. , 2017 ]Jonas Gehring, Michael Auli, David Grang- ier, Denis Yarats, and Yann N Dauphin. Convolutional sequence to sequence learning. In ICML , 2017.[Goodfellow et al. , 2014 ]Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, et al. Generative adversarial nets. NeurIPS , 2014. [Han et al. , 2021 ]Xu Han, Zhengyan Zhang, Ning Ding, Yuxian Gu, Xiao Liu, Yuqi Huo, Jiezhong Qiu, Liang Zhang, et al. Pre- trained models: Past, present and future. AI Open , 2021. [Han et al. , 2022 ]Kai Han, Yunhe Wang, Hanting Chen, Xinghao Chen, Jianyuan Guo, Zhenhua Liu, Yehui Tang, An Xiao, et al. A survey on vision transformer. IEEE TPAMI , 45(1):87\u2013110, 2022. [Hyndman and Khandakar, 2008 ]Rob J Hyndman and Yeasmin Khandakar. Automatic time series forecasting: the forecast pack- age for r. Journal of statistical software , 27:1\u201322, 2008. [Ismail Fawaz et al. , 2019 ]Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, and Pierre- Alain Muller. Deep learning for time series classi?cation: a review. Data mining and knowledge discovery , 2019. [Keet al. , 2021 ]Guolin Ke, Di He, and Tie-Yan Liu. Rethinking positional encoding in language pre-training. In ICLR , 2021. [Kenton and others, 2019 ]Jacob Devlin Ming-Wei Chang Kenton et al. BERT: Pre-training of deep bidirectional transformers for language understanding. In NAACL-HLT , 2019. [Kingma and Welling, 2014 ]Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In ICLR , 2014. [Liet al. , 2019 ]Shiyang Li, Xiaoyong Jin, Yao Xuan, Xiyou Zhou, Wenhu Chen, Yu-Xiang Wang, and Xifeng Yan. Enhancing the locality and breaking the memory bottleneck of transformer on time series forecasting. In NeurIPS , 2019. [Liet al. , 2021 ]Longyuan Li, Jian Yao, Li Wenliang, Tong He, Tianjun Xiao, Junchi Yan, David Wipf, and Zheng Zhang. Grin: Generative relation and intention network for multi-agent trajec- tory prediction. In NeurIPS , 2021. [Liang et al. , 2023 ]Yuxuan Liang, Yutong Xia, Songyu Ke, Yiwei Wang, Qingsong Wen, Junbo Zhang, Yu Zheng, and Roger Zim- mermann. AirFormer: Predicting nationwide air quality in china with transformers. In AAAI , 2023. [Lim and Zohren, 2021 ]Bryan Lim and Stefan Zohren. Time- series forecasting with deep learning: a survey. Philosophical Transactions of the Royal Society , 2021. [Lim et al. , 2021 ]Bryan Lim, Sercan \u00a8O Arik, Nicolas Loeff, and Tomas P?ster. Temporal fusion transformers for interpretable multi-horizon time series forecasting. International Journal of Forecasting , 37(4):1748\u20131764, 2021. [Linet al. , 2021 ]Yang Lin, Irena Koprinska, and Mashud Rana. SSDNet: State space decomposition neural network for time se- ries forecasting. In ICDM , 2021. [Liuet al. , 2021 ]Minghao Liu, Shengqi Ren, Siyuan Ma, Jiahui Jiao, Yizhou Chen, Zhiguang Wang, and Wei Song. Gated trans- former networks for multivariate time series classi?cation. arXiv preprint arXiv:2103.14438 , 2021. [Liuet al. , 2022a ]Shizhan Liu, Hang Yu, Cong Liao, Jianguo Li, Weiyao Lin, Alex X. Liu, and Schahram Dustdar. Pyraformer: Low-complexity pyramidal attention for long-range time series modeling and forecasting. In ICLR , 2022. [Liuet al. , 2022b ]Yong Liu, Haixu Wu, Jianmin Wang, and Ming- sheng Long. Non-stationary transformers: Exploring the station- arity in time series forecasting. In NeurIPS , 2022. [Mehta et al. , 2021 ]Sachin Mehta, Marjan Ghazvininejad, Srini Iyer, Luke Zettlemoyer, and Hannaneh Hajishirzi. Delight: Deep and light-weight transformer. In ICLR , 2021.[Meiet al. , 2022 ]Hongyuan Mei, Chenghao Yang, and Jason Eis- ner. Transformer embeddings of irregularly spaced events and their participants. In ICLR , 2022. [Nieet al. , 2023 ]Yuqi Nie, Nam H. Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. A time series is worth 64 words: Long- term forecasting with transformers. In ICLR , 2023. [Ru\u00dfwurm and K \u00a8orner, 2020 ]Marc Ru\u00dfwurm and Marco K \u00a8orner. Self-attention for raw optical satellite time series classi?cation. ISPRS J. Photogramm. Remote Sens. , 169:421\u2013435, 11 2020. [Shabani et al. , 2023 ]Amin Shabani, Amir Abdi, Lili Meng, and Tristan Sylvain. Scaleformer: iterative multi-scale re?ning trans- formers for time series forecasting. In ICLR , 2023. [Shaw et al. , 2018 ]Peter Shaw, Jakob Uszkoreit, and Ashish Vaswani. Self-attention with relative position representations. In NAACL , 2018. [Shchur et al. , 2021 ]Oleksandr Shchur, Ali Caner T \u00a8urkmen, Tim Januschowski, and Stephan G \u00a8unnemann. Neural temporal point processes: A review. In IJCAI , 2021. [Soet al. , 2019 ]David So, Quoc Le, and Chen Liang. The evolved transformer. In ICML , 2019. [Tang and Matteson, 2021 ]Binh Tang and David Matteson. Proba- bilistic transformer for time series analysis. In NeurIPS , 2021. [Tayet al. , 2022 ]Yi Tay, Mostafa Dehghani, Dara Bahri, and Don- ald Metzler. Ef?cient transformers: A survey. ACM Computing Surveys , 55(6):1\u201328, 2022. [Torres et al. , 2021 ]Jos\u00b4e F. Torres, Dalil Hadjout, Abderrazak Se- baa, Francisco Mart \u00b4inez- \u00b4Alvarez, and Alicia Troncoso. Deep learning for time series forecasting: a survey. Big Data , 2021. [Tuliet al. , 2022 ]Shreshth Tuli, Giuliano Casale, and Nicholas R Jennings. TranAD: Deep transformer networks for anomaly de- tection in multivariate time series data. In VLDB , 2022. [Vaswani et al. , 2017 ]Ashish Vaswani, Noam Shazeer, Niki Par- mar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, et al. Attention is all you need. In NeurIPS , 2017. [Wang et al. , 2020 ]Xiaoxing Wang, Chao Xue, Junchi Yan, Xi- aokang Yang, Yonggang Hu, et al. MergeNAS: Merge operations into one for differentiable architecture search. In IJCAI , 2020. [Wang et al. , 2022 ]Xixuan Wang, Dechang Pi, Xiangyan Zhang, et al. Variational transformer-based anomaly detection approach for multivariate time series. Measurement , page 110791, 2022. [Wen et al. , 2019 ]Qingsong Wen, Jingkun Gao, Xiaomin Song, Liang Sun, Huan Xu, et al. RobustSTL: A robust seasonal-trend decomposition algorithm for long time series. In AAAI , 2019. [Wen et al. , 2020 ]Qingsong Wen, Zhe Zhang, Yan Li, and Liang Sun. Fast RobustSTL: Ef?cient and robust seasonal-trend decom- position for time series with complex patterns. In KDD , 2020. [Wen et al. , 2021a ]Qingsong Wen, Kai He, Liang Sun, Yingying Zhang, Min Ke, et al. RobustPeriod: Time-frequency mining for robust multiple periodicities detection. In SIGMOD , 2021. [Wen et al. , 2021b ]Qingsong Wen, Liang Sun, Fan Yang, Xiaomin Song, Jingkun Gao, Xue Wang, and Huan Xu. Time series data augmentation for deep learning: A survey. In IJCAI , 2021. [Wen et al. , 2022 ]Qingsong Wen, Linxiao Yang, Tian Zhou, and Liang Sun. Robust time series analysis and applications: An in- dustrial perspective. In KDD , 2022. [Wuet al. , 2020a ]Sifan Wu, Xi Xiao, Qianggang Ding, Peilin Zhao, Ying Wei, and Junzhou Huang. Adversarial sparse trans- former for time series forecasting. In NeurIPS , 2020.[Wuet al. , 2020b ]Zhanghao Wu, Zhijian Liu, Ji Lin, Yujun Lin, and Song Han. Lite transformer with long-short range attention. InICLR , 2020. [Wuet al. , 2021 ]Haixu Wu, Jiehui Xu, Jianmin Wang, and Ming- sheng Long. Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting. In NeurIPS , 2021. [Xinet al. , 2020 ]Ji Xin, Raphael Tang, Jaejun Lee, Yaoliang Yu, and Jimmy J. Lin. DeeBERT: Dynamic early exiting for acceler- ating bert inference. In ACL, 2020. [Xuet al. , 2020 ]Mingxing Xu, Wenrui Dai, Chunmiao Liu, Xing Gao, Weiyao Lin, Guo-Jun Qi, and Hongkai Xiong. Spatial- temporal transformer networks for traf?c ?ow forecasting. arXiv preprint arXiv:2001.02908 , 2020. [Xuet al. , 2022 ]Jiehui Xu, Haixu Wu, Jianmin Wang, and Ming- sheng Long. Anomaly Transformer: Time series anomaly detec- tion with association discrepancy. In ICLR , 2022. [Yanet al. , 2019 ]Junchi Yan, Hongteng Xu, and Liangda Li. Mod- eling and applications for temporal point processes. In KDD , 2019. [Yang et al. , 2021 ]Chao-Han Huck Yang, Yun-Yun Tsai, and Pin- Yu Chen. V oice2series: Reprogramming acoustic models for time series classi?cation. In ICML , 2021. [Yuet al. , 2020 ]Cunjun Yu, Xiao Ma, Jiawei Ren, Haiyu Zhao, and Shuai Yi. Spatio-temporal graph transformer networks for pedes- trian trajectory prediction. In ECCV , 2020. [Yuan and Lin, 2020 ]Yuan Yuan and Lei Lin. Self-supervised pre- training of transformers for satellite image time series classi?ca- tion. IEEE J-STARS , 14:474\u2013487, 2020. [Yunet al. , 2020 ]Chulhee Yun, Srinadh Bhojanapalli, Ankit Singh Rawat, Sashank J. Reddi, et al. Are transformers universal ap- proximators of sequence-to-sequence functions? In ICLR , 2020. [Zeng et al. , 2023 ]Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu. Are transformers effective for time series forecasting? In AAAI , 2023. [Zerveas et al. , 2021 ]George Zerveas, Srideepika Jayaraman, Dhaval Patel, Anuradha Bhamidipaty, and Carsten Eickhoff. A transformer-based framework for multivariate time series repre- sentation learning. In KDD , 2021. [Zhang and Yan, 2023 ]Yunhao Zhang and Junchi Yan. Cross- former: Transformer utilizing cross-dimension dependency for multivariate time series forecasting. In ICLR , 2023. [Zhang et al. , 2020 ]Qiang Zhang, Aldo Lipani, Omer Kirnap, and Emine Yilmaz. Self-attentive Hawkes process. In ICML , 2020. [Zhang et al. , 2021 ]Hongwei Zhang, Yuanqing Xia, et al. Unsu- pervised anomaly detection in multivariate time series through transformer-based variational autoencoder. In CCDC , 2021. [Zhou et al. , 2021 ]Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang. In- former: Beyond ef?cient transformer for long sequence time- series forecasting. In AAAI , 2021. [Zhou et al. , 2022 ]Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin. FEDformer: Frequency en- hanced decomposed transformer for long-term series forecasting. InICML , 2022. [Zuoet al. , 2020 ]Simiao Zuo, Haoming Jiang, Zichong Li, Tuo Zhao, and Hongyuan Zha. Transformer Hawkes process. In ICML , 2020.", "22": "FeatureSelection: A Data Perspective JUNDONGLI,KEWEI CHENG, SUHANGWANG, FREDMORSTATTER,and ROBERT P.TREVINO ,Arizona StateUniversity JILIANGTANG ,Michigan State University HUANLIU ,Arizona StateUniversity Featureselection,asadatapreprocessingstrategy,hasbeenproventobeeffectiveandefficientinpreparing data (especially high-dimensional data) for various data-mining and machine-learning problems. The objec- tivesoffeatureselectionincludebuildingsimplerandmorecomprehensiblemodels,improvingdata-mining performance, and preparing clean, understandable data. The recent proliferation of big data has presented some substantial challenges and opportunities to feature selection. In this survey, we provide a comprehen- sive and structured overview of recent advances in feature selection research. Motivated by current chal- lenges and opportunities in the era of big data, we revisit feature selection research from a data perspective andreviewrepresentativefeatureselectionalgorithmsforconventionaldata,structureddata,heterogeneous data and streaming data. Methodologically, to emphasize the differences and similarities of most existing feature selection algorithms for conventional data, we categorize them into four main groups: similarity- based, information-theoretical-based, sparse-learning-based, and statistical-based methods. To facilitate and promote the research in this community, we also present an open source feature selection repository that consistsofmostofthepopularfeatureselectionalgorithms(http://featureselection.asu.edu/).Also,weuseit as an example to show how to evaluate feature selection algorithms. At the end of the survey, we present a discussionabout someopen problems and challenges that requiremoreattention in futureresearch. CCSConcepts:\u2022 Computing methodologies ?Feature selection ; Additional KeyWords and Phrases:Feature selection ACM Reference format: Jundong Li, Kewei Cheng, Suhang Wang, Fred Morstatter, Robert P. Trevino, Jiliang Tang, and Huan Liu. 2017. Feature Selection: A Data Perspective. ACM Comput.Surv. 50, 6, Article 94(December 2017), 45 pages. https://doi.org/10.1145/3136625 1 INTRODUCTION We are now in the era of big data, where huge amounts of high-dimensional data become ubiq- uitous in a variety of domains, such as social media, healthcare, bioinformatics, and online edu- cation. The rapid growth of data presents challenges for effective and efficient data management. It is desirable to apply data-mining and machine-learning techniques to automatically discover knowledge fromdataof varioussorts. This materialis basedon work supported by,or inpartby,theNSF grants1217466and1614576. Authors\u2019 addresses: J. Li, K. Cheng, S. Wang, F. Morstatter, R. P. Trevino, and H. Liu, Computer Science and Engineering, ArizonaStateUniversity,Tempe,AZ85281;emails:{jundongl,kcheng18,swang187,fmorstat,rptrevin,huan.liu}@asu.edu; J.Tang,Michigan StateUniversity, EastLansing,MI48824;email:tangjili@msu.edu. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requires prior specific permission and/or a fee.Request permissions from permissions@acm.org. \u00a9 2017ACM 0360-0300/2017/12-ART94$15.00 https://doi.org/10.1145/3136625 ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017. 94:2 J. Liet al. Fig.1. An illustrativeexample of relevant, redundant,andirrelevant features. When data-mining and machine-learning algorithms are applied on high-dimensional data, a criticalissueisknownasthecurseofdimensionality.Itreferstothephenomenonthatdatabecome sparser in high-dimensional space, adversely affecting algorithms designed for low-dimensional space (Hastie et al. 2005). Also, with a large number of features, learning models tend to overfit, which may cause performance degradation on unseen data. Data of high dimensionality can sig- nificantly increasethememory storagerequirementsandcomputationalcostsfordata analytics. Dimensionalityreductionisoneofthemostpowerfultoolstoaddressthepreviouslydescribed issues. It can be mainly categorized into two main components: feature extraction and feature selection.Featureextractionprojectstheoriginalhigh-dimensionalfeaturestoanewfeaturespace with low dimensionality. The newly constructed feature space is usually a linear or nonlinear combinationoftheoriginalfeatures.Featureselection,ontheotherhand,directlyselectsasubset of relevant featuresfor modelconstruction(Guyon andElisseeff 2003;Liu and Motoda 2007). Both feature extraction and feature selection have the advantages of improving learning per- formance, increasing computational efficiency, decreasing memory storage, and building better generalization models. Hence, they are both regarded as effective dimensionality reduction tech- niques.Ononehand,formanyapplicationswheretherawinputdatadonotcontainanyfeatures understandable to a given learning algorithm, feature extraction is preferred. On the other hand, asfeatureextractioncreatesasetofnewfeatures,furtheranalysisisproblematicaswecannotre- tainthephysicalmeaningsofthesefeatures.Incontrast,bykeepingsomeoftheoriginalfeatures, feature selection maintains physical meanings of the original features and gives models better readability and interpretability. Therefore, feature selection is often preferred in many applica- tions suchas text mining and genetic analysis.It should benoted thatin some cases even though feature dimensionality is often not that high, feature extraction/selection still plays an essential rolesuchasimprovinglearningperformance,preventingoverfitting,andreducingcomputational costs. Real-world data contain a lot of irrelevant, redundant, and noisy features. Removing these fea- tures by feature selection reduces storage and computational cost while avoiding significant loss ofinformationordegradationoflearningperformance.Forexample,inFigure 1(a),feature f1isa relevant feature that is able to discriminate two classes (clusters). However, given feature f1,f e a - turef2in Figure 1(b) is redundant as f2is strongly correlated with f1. In Figure 1(c), feature f3is an irrelevant feature, as it cannot separate two classes (clusters) at all. Therefore, the removal of f2andf3will notnegatively impactthelearningperformance. 1.1 Traditional Categorizationof Feature Selection Algorithms 1.1.1 Supervision Perspective. According to the availability of supervision (such as class labels inclassificationproblems),featureselectioncanbebroadlyclassifiedassupervised,unsupervised, and semi-supervisedmethods. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:3 Supervised feature selection is generally designed for classification or regression problems. It aimstoselectasubsetoffeaturesthatareabletodiscriminatesamplesfromdifferentclasses(clas- sification) or to approximate the regression targets (regression). With supervision information, featurerelevanceisusuallyassessedviaitscorrelationwiththeclasslabelsortheregressiontarget. The training phase highly depends on the selected features: After splitting the data into training andtestingsets,classifiersorregressionmodelsaretrainedbasedonasubsetoffeaturesselected by supervised feature selection. Note that the feature selection phase can be independent of the learningalgorithms(filtermethods),itmayiterativelytakeadvantageofthelearningperformance ofaclassifieroraregressionmodeltoassessthequalityofselectedfeaturessofar(wrappermeth- ods),ormakeuseoftheintrinsicstructureofalearningalgorithmtoembedfeatureselectioninto theunderlyingmodel(embeddedmethods).Finally,thetrainedclassifierorregressionmodelpre- dictsclasslabelsorregressiontargetsofunseensamplesinthetestsetwiththeselectedfeatures. Inthefollowingcontext,forsupervisedmethods,wemainlyfocusonclassificationproblems,and uselabelinformation,supervisioninformation interchangeably. Unsupervised feature selection is generally designed for clustering problems. As acquiring la- beled data are particularly expensive in both time and effort, unsupervised feature selection has gained considerable attention recently. Without label information to evaluate the importance of features, unsupervised feature selection methods seek alternative criteria to define feature rel- evance. Different from supervised feature selection, unsupervised feature selection usually uses all instances that are available in the feature selection phase. The feature selection phase can be independent of the unsupervisedlearning algorithms (filter methods), it relies on the learning al- gorithms to iteratively improve the quality of selected features (wrapper methods), or it embeds thefeatureselectionphaseintounsupervisedlearningalgorithms(embeddedmethods).Afterthe featureselectionphase,itoutputstheclusterstructureofalldatasamplesontheselectedfeatures by using a standard clustering algorithm (Guyon and Elisseeff 2003; Liu and Motoda 2007;T a n g etal.2014). Supervised feature selection works when sufficient label information is available while unsu- pervisedfeatureselectionalgorithmsdonotrequireanyclasslabels.However,inmanyreal-world applications,weusuallyhavealimitednumberoflabeleddata.Therefore,itisdesirabletodevelop semi-supervisedmethodsby exploitingbothlabeledand unlabeleddatasamples. 1.1.2 SelectionStrategyPerspective. Concerningdifferentselectionstrategies,featureselection methodscanbe broadlycategorizedas wrapper,filter,and embeddedmethods. Wrapper methods rely on the predictive performance of a predefined learning algorithm to evaluate the quality of selected features. Given a specific learning algorithm, a typical wrapper method performs two steps: (1) searches for a subset of features and (2) evaluates the selected features. It repeats (1) and (2) until some stopping criteria are satisfied. The feature set search component first generates a subset of features, and then the learning algorithm acts as a black box to evaluate the quality of these features based on the learning performance. For example, the whole process works iteratively until the highest learning performance is achieved or the desired number of selected features is obtained. Then the feature subset that gives the highest learning performance is returned as the selected features. Unfortunately, a known issue of wrappermethodsisthatthesearchspacefor dfeaturesis2d,whichisimpracticalwhen disvery large. Therefore, different search strategies such as sequential search (Guyon and Elisseeff 2003), hill-climbing search, best-first search (Kohavi and John 1997;A r a ie ta l . 2016), branch-and-bound search (Narendra and Fukunaga 1977), and genetic algorithms (Golberg 1989) are proposed to yield a local optimum learning performance. However, the search space is still extremely huge for high-dimensionaldatasets.As aresult,wrappermethodsare seldomusedinpractice. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:4 J. Liet al. Filtermethodsareindependentofanylearningalgorithms.Theyrelyoncharacteristicsofdata to assess feature importance. Filter methods are typically more computationally efficient than wrapper methods. However, due to the lack of a specific learning algorithm guiding the feature selection phase, the selected features may not be optimal for the target learning algorithms. A typical filter method consists of two steps. In the first step, feature importance is ranked accord- ing to some feature evaluation criteria. The feature importance evaluation process can be either univariateormultivariate.Intheunivariatescheme,eachfeatureisrankedindividuallyregardless of other features, while the multivariate scheme ranks multiple features in a batch way. In the second step of a typical filter method, lowly ranked features are filtered out. In the past decades, different evaluation criteria for filter methods have been proposed. Some representative criteria include feature discriminative ability to separate samples (Kira and Rendell 1992; Robnik-\u0160ikonja andKononenko 2003;Y angetal. 2011;Duetal. 2013;T angetal. 2014),featurecorrelation(Koller andSahami 1995;GuyonandElisseeff 2003),mutualinformation(YuandLiu 2003;Pengetal. 2005; Nguyen et al. 2014;S h i s h k i ne ta l . 2016; Gao et al. 2016), feature ability to preserve data manifold structure (He et al. 2005; Zhao and Liu 2007;G ue ta l . 2011b; Jiang and Ren 2011), and feature ability toreconstructtheoriginaldata(Masaelietal. 2010;Farahatetal. 2011;L ietal.2017a). Embeddedmethodsisatradeoffbetweenfilterandwrappermethodsthatembedthefeaturese- lectionintomodellearning.ThustheyinheritthemeritsofwrapperandfiltermethodsL(1)They include the interactions with the learning algorithm and (2) they are far more efficient than the wrappermethods,sincetheydonotneedtoevaluatefeaturesetsiteratively.Themostwidelyused embeddedmethodsaretheregularizationmodelsthattargettofitalearningmodelbyminimizing thefittingerrorsandforcingfeaturecoefficientstobesmall(orexactzero)simultaneously.After- wards,boththeregularizationmodeland selectedfeaturesetsarereturnedasthefinalresults. It should be noted that some literature classifies feature selection methods into four categories (fromtheselectionstrategyperspective)byincludingthehybridfeatureselectionmethods(Saeys et al.2007;S h e ne ta l . 2012; Ang et al. 2016). Hybrid methods can be regarded as a combination ofmultiplefeatureselectionalgorithms(e.g.,wrapper,filter,andembedded).Themaintargetisto tackletheinstabilityandperturbationissuesofmanyexistingfeatureselectionalgorithms.Forex- ample,forsmall-sizedhigh-dimensionaldata,asmallperturbationonthetrainingdatamayresult intotallydifferentfeatureselectionresults.Byaggregatingmultipleselectedfeaturesubsetsfrom different methods together, the results are more robust, and hence the credibility of the selected featuresisenhanced. 1.2 Feature Selection Algorithmsfroma Data Perspective The recent popularity of big data presents unique challenges for traditional feature selection (Li and Liu2017), and some characteristics of big data such as velocity and variety necessitate the development of novel feature selection algorithms. Here we briefly discuss some major concerns whenapplyingfeatureselectionalgorithms. Streamingdataandfeatureshavebecomemoreandmoreprevalentinreal-worldapplications.It poseschallengestotraditionalfeatureselectionalgorithms,whicharedesignedforstaticdatasets withfixeddatasamplesandfeatures.Forexample,inTwitter,newdatalikepostsandnewfeatures likeslangwordsarecontinuouslybeingusergenerated.Itisimpracticaltoapplytraditionalbatch- modefeatureselectionalgorithmstofindrelevantfeaturesfromscratchwhennew dataoranew featurearrives.Moreover,thevolumeofdatamaybetoolargetobeloadedintomemory.Inmany cases, a single scan of data is desired as further scans are either expensive or impractical. Given thereasonsmentionedintheprevioustext,itisappealingtoapplyfeatureselectioninastreaming fashionto dynamically maintain aset ofrelevant features. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:5 Fig. 2. Featureselection algorithmsfrom thedataperspective. Most existing algorithms of feature selection are designed to handle tasks with a single data source and always assume that data is independent and identically distributed ( i.i.d.). However, data could come from multiple sources in many applications. For example, in social media, data come from heterogeneous sources such as text, images, tags, and videos. In addition, linked data are ubiquitous and presents in various forms such as user-post relations and user-user relations. The availability of multiple data sources brings unprecedented opportunities, as we can leverage shared intrinsic characteristics and correlations to find more relevant features. However, chal- lenges are also unequivocally presented. For instance, with link information, the widely adopted i.i.d.assumption in most learning algorithms does not hold. How to appropriately utilize link in- formation forfeatureselectionisstillachallengingproblem. Features can also exhibit certain types of structures. Some well-known structures among fea- turesaregroup,tree,andgraphstructures.Whenperformingfeatureselection,ifthefeaturestruc- tureisnottakenintoconsideration,thentheintrinsicdependenciesmaynotbecaptured,andthus theselectedfeaturesmaynotbesuitableforthetargetapplication.Incorporatingpriorknowledge offeaturestructurescanhelpselectrelevantfeaturestoimprovethelearningperformancegreatly. The aforementioned reasons motivate the investigation of feature selection algorithms from a different view. In this survey, we revisit feature selection algorithms from a data perspective; the categorization is illustrated in Figure 2. It is shown that data consist of static data and stream- ing data. For the static data, it can be grouped into conventional data and heterogeneous data. In conventional data, features can either be flat or possess some inherent structures. Traditional feature selection algorithms are proposed to deal with these flat features in which features are considered to be independent. The past few decades have witnessed hundreds of feature selec- tion algorithms. Based on their technical characteristics, we propose to classify them into four main groups, that is, similarity-based, information-theoretical-based, sparse-learning-based, and statistical-based methods. It should be noted that this categorization only involves filter meth- ods and embedded methods while the wrapper methods are excluded. The reason for excluding wrappermethodsisthattheyarecomputationallyexpensiveandareusuallyusedinspecificappli- cations.Moredetailsaboutthesefourcategorieswillbepresentedlater.Wepresentothermethods thatcannotbefittedintothesefourcategories,suchashybridmethods,deep-learning-basedmeth- ods, and reconstruction-based methods. When features express some structures, specific feature ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:6 J. Liet al. selectionalgorithmsaremoredesired.Datacanbeheterogeneoussuchthatdatacouldcomefrom multiple sourcesand could be linked.Hence, we also show how new feature selectionalgorithms copewiththesesituations.Second,inthestreamingsettings,dataarrivesequentiallyinastream- ing fashion where the size of data instances is unknown, and feature selection algorithms that make only one pass over the data is proposed accordingly. Similarly, in an orthogonal setting, features can also be generated dynamically. Streaming feature selection algorithms are designed to determine if one should accept the newly added features and remove existing but outdated features. 1.3 Differences with Existing Surveys Currently, there exist some other surveys that give a summarization of feature selection algo- rithms, such as those in Guyon and Elisseeff ( 2003), Alelyani et al. ( 2013), Chandrashekar and Sahin(2014),andTangetal.( 2014).Thesestudieseitherfocusontraditionalfeatureselectionalgo- rithmsorspecificlearningtaskslikeclassificationandclustering.However,noneofthemprovidea comprehensiveandstructuredoverviewoftraditionalfeatureselectionalgorithmsinconjunction with recent advances in feature selection from a data perspective. In this survey, we will intro- duce representative feature selection algorithms to cover all components mentioned in Figure 2. We also release a feature selection repository in Python, named scikit-feature , that is built on the widely used machine-learning package scikit-learn (http://scikit-learn.org/stable/) and two scien- tific computing packages Numpy(http://www.numpy.org/ )a n dScipy(http://www.scipy.org/ ). It includes near 40 representative feature selection algorithms. The web page of the repository is available at http://featureselection.asu.edu/ . 1.4 Notations We summarize some symbols used throughout this survey in Table 1.W eu s eb o l du p p e r c a s e characters for matrices (e.g., A), bold lowercase characters for vectors (e.g., a), and calligraphic fontsforsets(e.g., F).WefollowthematrixsettingsinMatlabtorepresent ithrowofmatrix Aas A(i,:),jth column of AasA(:,j),(i,j)thentry of AasA(i,j),transposeof AasA', and trace of A astr(A). For any matrix A?Rn\u00d7d, its Frobenius norm is defined as ?A?F=v?n i=1?d j=1A(i,j)2, and itsl2,1-norm is?A?2,1=?n i=1v?d j=1A(i,j)2. For any vector a=[a1,a2,...,an]',i t sl2-norm is defined as?a?2=v?n i=1a2 i, and itsl1-norm is?a?1=?n i=1|ai|.Iis an identity matrix and 1is a vectorwhoseelements areall1\u2019s. 2 FEATURE SELECTION ON CONVENTIONAL DATA Since the mid-1990s, hundreds of feature selection algorithms have been proposed. In this sec- tion,webroadlygrouptraditionalfeatureselectionalgorithmsforconventionaldataassimilarity- based, information-theoretical-based, sparse-learning-based, and statistical-based methods, and othermethodsaccordingto theusedtechniques. 2.1 Similarity-Based Methods Different feature selection algorithms exploit various types of criteria to define the relevance of features. Among them, there is a family of methods assessing feature importance by their ability to preserve data similarity. We refer to them as similarity-based methods. For supervised feature selection, data similarity can be derived from label information; while for unsupervised feature selection methods, most methods take advantage of different distance metric measures to obtain data similarity. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:7 Table 1. Symbols Notations DefinitionsorDescriptions n numberof instancesin thedata d numberof featuresin thedata k numberof selectedfeatures c numberof classes(ifexist) F originalfeaturesetwhichcontains dfeatures S selectedfeaturesetwhichcontains kselectedfeatures {i1,i2,...,ik} indexofkselectedfeaturesin S f1,f2,...,fd doriginalfeatures fi1,fi2,...,fik kselectedfeatures x1,x2,...,xn ndatainstances f1,f2,..., fddfeaturevectorscorrespondingto f1,f2,...,fd fi1,fi2,..., fikkfeaturevectorscorrespondingto fi1,fi2,...,fik x1,x2,...,xnndatavectorscorrespondingto x1,x2,...,xn y1,y2,...,yn classlabelsof all ninstances(ifexist) X?Rn\u00d7ddatamatrixwith ninstancesand dfeatures XS?Rn\u00d7kdatamatrixon theselected kfeatures y?Rnclasslabelvectorfor all ninstances(ifexist) Given a dataset X?Rn\u00d7dwithninstancesand dfeatures,pairwisesimilarity among instances can be encoded in an affinity matrix S?Rn\u00d7n. Suppose that we want to select kmost relevant featuresS; one way is to maximize their utility: max SU(S),w h e r eU(S)denotes the utility of the feature subset S. As algorithms in this family often evaluate features individually, the utility maximization over featuresubset Scan befurtherdecomposedinto thefollowing form: max SU(S)=max S? f?SU(f)=max S? f?S\u02c6f'\u02c6S\u02c6f, (1) whereU(f)is a utility function for feature f.\u02c6fdenotes the transformation (e.g., scaling, nor- malization, etc.) result of the original feature vector f.\u02c6Sis a new affinity matrix obtained from affinity matrix S. The maximization problem in Equation ( 1) shows that we would select a subset offeaturesfromSsuchthattheycanwellpreservethedatamanifoldstructureencodedin \u02c6S.This problem is usually solved by greedily selecting the top kfeatures that maximize their individual utility.Methodsinthiscategoryvaryinthewaytheaffinitymatrix \u02c6Sisdesigned.Wesubsequently discuss some representative algorithms in this group that can be reformulated under the unified utilitymaximization framework. 2.1.1 Laplacian Score. Laplacian Score (He et al. 2005) is an unsupervised feature selection algorithm that selects features that can best preserve the data manifold structure. It consists of three phases. First, it constructs the affinity matrix such that S(i,j)=e-?xi-xj?2 2 tifxiis among thep-nearest neighbor of xj; otherwise, S(i,j)=0. Then, the diagonal matrix Dis defined as D(i,i)=?n j=1S(i,j)and the Laplacian matrix LisL=D-S. Last, the Laplacian Score of each ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:8 J. Liet al. featurefiis computedas laplacian _score(fi)=\u02dcf' iL\u02dcfi \u02dcf' iD\u02dcfi,where\u02dcfi=fi-f' iD1 1'D11. (2) As Laplacian Score evaluates each feature individually, the task of selecting the kfeatures can be solved by greedily picking the top kfeatures with the smallest Laplacian Scores. The Laplacian Scoreof eachfeaturecanbe reformulatedas laplacian _score(fi)=1-/parenlefttpA /parenleftbtA\u02dcfi ?D1 2\u02dcfi?2/parenrighttpA /parenrightbtA' S/parenlefttpA /parenleftbtA\u02dcfi ?D1 2\u02dcfi?2/parenrighttpA /parenrightbtA, (3) where?D1 2\u02dcfi?2is the standard data variance of feature fi, and the term \u02dcfi/?D1 2\u02dcfi?2is interpreted as a normalized feature vector of fi. Therefore, it is obvious that Laplacian Score is a special case of utility maximization in Equation( 1). 2.1.2 SPEC. SPEC (Zhao and Liu 2007) is an extension of Laplacian Score that works for both supervised and unsupervised scenarios. For example, in the unsupervised scenario, the data sim- ilarity is measured by RBF kernel; while in the supervised scenario, data similarity can be de- fined by S(i,j)={1 nlifyi=yj=l 0 otherwise,w h e r enlis the number of data samples in the lth class. Af- ter obtaining the affinity matrix Sand the diagonal matrix D, the normalized Laplacian matrix Lnorm=D-1 2(D-S)D-1 2. The basic idea of SPEC is similar to Laplacian Score: a feature that is consistentwiththedatamanifoldstructureshouldassignsimilarvaluestoinstancesthatarenear eachother.InSPEC,thefeaturerelevanceis measuredbythreedifferentcriteria: SPEC_score1(fi)=\u02c6fi'?(Lnorm)\u02c6fi=n? j=1a2 j?(?j) SPEC_score2(fi)=\u02c6fi'?(Lnorm)\u02c6fi 1-(\u02c6fi'?1)2=?n j=2a2 j?(?j) ?n j=2a2 j SPEC_score3(fi)=m? j=1(?(2)-?(?j))a2 j.(4) Intheearlierequations, \u02c6fi=D1 2fi/?D1 2fi?2;(?j,?j)isthejtheigenpairofthenormalizedLaplacian matrixLnorm;aj=cos?j,?jistheanglebetween ?jandfi;?(.)isanincreasingfunctiontopenalize high-frequencycomponentsoftheeigensystemtoreducenoise.Ifthedataarenoisefree,thenthe function?(.)canberemovedand ?(x)=x.Whenthesecondevaluationcriterion SPEC_score2(fi) isused,SPECisequivalenttotheLaplacianScore.For SPEC_score3(fi),itusesthetop meigenpairs to evaluatetheimportanceof feature fi. Allthesethreecriteriacanbereducedtothetheunifiedsimilarity-basedfeatureselectionframe- work in Equation ( 1) by setting \u02c6fiasfi?D1 2fi?2,(fi-\u00b51)/?D1 2fi?2,fi?D1 2fi?2;a n d\u02c6SasD1 2U(I- ?(S))U'D1 2,D1 2U(I-?(S))U'D1 2,D1 2Um(?(2I)-?(Sm))U' mD1 2inSPEC_score1,SPEC_score2,and SPEC_score3,respectively. UandSarethesingularvectorsandsingularvaluesofthenormalized Laplacian matrix Lnorm. 2.1.3 Fisher Score. Fisher Score (Duda et al. 2012) is a supervised feature selection algorithm. It selects features such that the feature values of samples within the same class are similar while thefeaturevaluesofsamplesfromdifferentclassesaredissimilar.TheFisherScoreofeachfeature ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:9 fiisevaluated asfollows: fisher_score(fi)=?c j=1nj(\u00b5ij-\u00b5i)2 ?c j=1njs2 ij, (5) wherenj,\u00b5i,\u00b5ij,a n ds2 ijindicate the number of samples in class j, mean value of feature fi, mean value of feature fifor samples in class j, variance value of feature fifor samples in class j, respectively. Similar to Laplacian Score, the top kfeatures can be obtained by greedily selecting thefeatureswiththelargest FisherScores. AccordingtoHeetal.( 2005),FisherScorecanbeconsideredasaspecialcaseofLaplacianScore as long as the affinity matrix is S(i,j)={1 nlifyi=yj=l 0 otherwise,. In this way, the relationship between Fisher Score and Laplacian Score is fisher_score(fi)=1-1 laplacian _score(fi). Hence, the compu- tationof FisherScorecan alsobe reducedto theunified utilitymaximization framework. 2.1.4 TraceRatioCriterion. Thetraceratiocriterion(Nieetal. 2008)directlyselectstheglobal optimalfeaturesubsetbasedonthecorrespondingscore,whichiscomputedbyatracerationorm. Itbuildstwoaffinitymatrices SwandSbtocharacterizewithin-classandbetween-classdatasimi- larity.Let W=[wi1,wi2,...,wik]?Rd\u00d7kbetheselectionindicatormatrixsuchthatonlythe ijth entry inwijis 1 and all the other entries are 0. With these, the trace ratio score of the selected k featuresinSis trace_ratio(S)=tr(W'X'LbXW) tr(W'X'LwXW), (6) whereLbandLwareLaplacianmatricesof SaandSb,respectively.Thebasicideaistomaximizethe data similarity for instances from the same class while minimize the data similarity for instances from different classes. However, the trace ratio problem is difficult to solve as it does not have a closed-form solution. Hence, the trace ratio problem is often converted into a more tractable format called the ratio trace problem by maximizing tr[(W'X'LwXW)-1(W'X'LbXW)]. As an alternative, Wang et al. ( 2007) propose an iterative algorithm called ITR to solve the trace ratio problemdirectly andwas laterappliedin traceratiofeatureselection(Nieet al. 2008). Different SbandSwleadtodifferentfeatureselectionalgorithmssuchasbatch-modeLalpacian Score and batch-mode Fisher Score. For example, in batch-mode Fisher Score, the within-class data similarity and the between-class data similarity are Sw(i,j)={1/nlifyi=yj=l 0 otherwiseandSb(i,j)={1/n-1/nlifyi=yj=l 1/n otherwise,respectively.Therefore,maximizingthetraceratiocriterionisequivalentto maximizing?k s=1f' isSwfis?k s=1f' isfis=X' SSwXS X' SXS.SinceX' SXSis constant, it can be further reduced to the uni- fied similarity-based feature selection framework by setting \u02c6f=f/?f?2and\u02c6S=Sw. On the other hand, in batch-mode Laplacian Score, the within-class data similarity and the between-class data similarityare Sw(i,j)={ e-?xi-xj?2 2tifxi?N p(xj)orxj?N p(xi) 0 otherwiseandSb=(1'Dw1)-1Dw11'Dw,respec- tively. In this case, the trace ratio criterion score istr(W'X'LbXW) tr(W'X'LwXW)=?k s=1f' isDwfis?k s=1f' is(Dw-Sw)fis. Therefore, maximizing the trace ratio criterion is also equivalent to solving the unified maximization prob- lemin Equation( 1),where\u02c6f=f/?D1 2wf?2and\u02c6S=Sw. 2.1.5 ReliefF. ReliefF (Robnik-\u0160ikonja and Kononenko 2003) selects features to separate instances from different classes. Assume that ldata instances are randomly selected among all ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:10 J. Liet al. ninstances,thenthefeaturescoreof fiinReliefF isdefinedas follows: ReliefF_score(fi)=1 cl? j=1/parenlefttpA/parenleftexA /parenleftbtA-1 mj? xr?NH(j)d(X(j,i)-X(r,i)) +? y/nequalyj1 hjyp(y) 1-p(y)? xr?NM(j,y)d(X(j,i)-X(r,i))/parenrighttpA/parenrightexA /parenrightbtA,(7) whereNH(j)andNM(j,y)are the nearest instances of xjin the same class and in class y, respectively.Theirsizes are mjandhjy,respectively. p(y)is theratioofinstancesinclass y. ReliefFisequivalenttoselectingfeaturesthatpreserveaspecialformofdatasimilaritymatrix. Assumethatthedatasethasthesamenumberofinstancesineachofthe cclassesandthereare q instancesinboth NM(j)andNH(j,y).Then,accordingtoZhaoandLiu( 2007),theReliefFfeature selectioncanbe reducedto theutility maximization frameworkin Equation( 1). Discussion:Similarity-basedfeatureselectionalgorithmshavedemonstratedwithexcellentperfor- mance in both supervised and unsupervised learning problems. This category of methods is straight- forward and simple as the computation focuses on building an affinity matrix, and afterwards, the scoresoffeaturescanbeobtained.Also,thesemethodsareindependentofanylearningalgorithmsand theselectedfeaturesaresuitableformanysubsequentlearningtasks.However,onedrawbackofthese methodsisthatmostofthemcannothandlefeatureredundancy.Inotherwords,theymayrepeatedly find highlycorrelatedfeaturesduring theselectionphase . 2.2 Information-Theoretical-Based Methods A large family of existing feature selection algorithms is information-theoretical-based methods. Algorithms in this family exploit different heuristic filter criteria to measure the importance of features.AsindicatedinDudaetal.( 2012),manyhand-designedinformation-theoreticcriteriaare proposedtomaximizefeaturerelevanceandminimizefeatureredundancy.Sincetherelevanceof a feature is usually measured by its correlation with class labels, most algorithms in this family are performed in a supervised way. In addition, most information-theoretic concepts can only be applied to discrete variables. Therefore, feature selection algorithms in this family can only work with discrete data. For continuous feature values, some data discretization techniques are required beforehand. Two decades of research on information-theoretic criteria can be unified in a conditional likelihood maximization framework (Brown et al. 2012). In this subsection, we introduce some representative algorithms in this family. We first give a brief introduction about basicinformation-theoreticconcepts. Theconceptof entropymeasurestheuncertaintyofadiscreterandomvariable.Theentropyof a discreterandomvariable Xisdefinedas follows: H(X)=-? xi?XP(xi)lo?(P(xi)), (8) wherexidenotes a specific value of random variable X,P(xi)denotes the probability of xiover allpossiblevaluesof X. Second,the conditionalentropy ofXgiven anotherdiscreterandomvariable Yis: H(X|Y)=-? yj?YP(yj)? xi?XP(xi|yj)lo?(P(xi|yj)), (9) whereP(yi)is the prior probability of yi,w h i l eP(xi|yj)is the conditional probability of xigiven yj. Itshowstheuncertaintyof XgivenY. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:11 Then,informationgain ormutualinformation betweenXandYisusedtomeasuretheamount of informationsharedby XandYtogether: I(X;Y)=H(X)-H(X|Y)=? xi?X? yj?YP(xi,yj)lo?P(xi,yj) P(xi)P(yj), (10) whereP(xi,yj)is the joint probability of xiandyj. Information gain is symmetric such that I(X;Y)=I(Y;X)and iszero if thediscretevariables XandYareindependent. At last,conditional information gain (orconditional mutual information ) of discrete variables X andYgiven athird discretevariable Zis given asfollows: I(X;Y|Z)=H(X|Z)-H(X|Y,Z)=? zk?ZP(zk)? xi?X? yj?YP(xi,yj|zk)lo?P(xi,yj|zk) P(xi|zk)P(yj|zk).(11) Itshowstheamount ofmutualinformation sharedby XandYgivenZ. SearchingfortheglobalbestsetoffeaturesisNP-hard,andthusmostalgorithmsexploitheuris- ticsequentialsearchapproachestoadd/removefeaturesonebyone.Inthissurvey,weexplainthe feature selection problem by forward sequential search such that features are added into the se- lectedfeaturesetonebyone.Wedenote Sasthecurrentselectedfeaturesetthatisinitiallyempty. Yrepresentstheclasslabels. Xj?Sisaspecificfeatureinthecurrent S.J(.)isafeatureselection criterion(score)where,generally,thehigherthevalueof J(Xk),themoreimportantthefeature Xk is. In the unified conditional likelihood maximization feature selection framework, the selection criterion(score)fora new unselectedfeature Xkisgiven as follows: JCMI(Xk)=I(Xk;Y)+? Xj?S?[I(Xj;Xk),I(Xj;Xk|Y)], (12) where?(.)is a function w.r.t. two variables I(Xj;Xk)andI(Xj;Xk|Y).I f?(.)is a linear function w.r.t. these two variables, then it is referred to as a criterion by linear combinations of Shannon information termssuchthat: JCMI(Xk)=I(Xk;Y)-\u00df? Xj?SI(Xj;Xk)+?? Xj?SI(Xj;Xk|Y). (13) where\u00dfand?aretwononnegativeparametersbetweenzeroand1.Ontheotherhand,if ?(.)isa non-linearfunctionw.r.t.thesetwovariables,itisreferredasacriterionbynon-linearcombination of Shannoninformationterms. 2.2.1 MutualInformationMaximization(InformationGain). MutualInformationMaximization (MIM) (a.k.a. Information Gain) (Lewis 1992) measures the importance of a feature by its correla- tionwithclasslabels.Itassumesthatwhenafeaturehasastrongcorrelationwiththeclasslabel, it can help achieve good classification performance. The Mutual Information score for feature Xk is JMIM(Xk)=I(Xk;Y). (14) It can be observed that in MIM, the scores of features are assessed individually. Therefore, only the feature correlation is considered while the feature redundancy is completely ignored. After it obtains the MIM feature scores for all features, we choose the features with the highest feature scores and add them to the selected feature set. The process repeats until the desired number of selectedfeaturesisobtained. ItcanalsobeobservedthatMIMisaspecialcaseoflinearcombinationofShannoninformation termsin Equation( 13)wher eboth \u00dfand?areequalto zero. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:12 J. Liet al. 2.2.2 Mutual Information Feature Selection. A limitation of MIM criterion is that it assumes that features are independent of each other. In reality, good features should not only be strongly correlated with class labels but also should not be highly correlated with each other. In other words, the correlation between features should be minimized. Mutual Information Feature Se- lection (MIFS) (Battiti 1994) considers both the feature relevance and feature redundancy in the feature selection phase, the feature score for a new unselected feature Xkcan be formulated as follows: JMIFS(Xk)=I(Xk;Y)-\u00df? Xj?SI(Xk;Xj). (15) In MIFS, the feature relevance is evaluated by I(Xk;Y), while the second term penalizes features thathaveahighmutualinformationwiththecurrentlyselectedfeaturessuchthatfeatureredun- dancy isminimized. MIFScanalsobereducedtobeaspecialcaseofthelinearcombinationofShannoninformation terms inEquation( 13),where\u00dfis betweenzero and 1and ?is zero. 2.2.3 Minimum Redundancy Maximum Relevance. Peng et al. ( 2005) proposes a Minimum Re- dundancy Maximum Relevance (MRMR) criterion to set the value of \u00dfto be the reverse of the number of selectedfeatures: JMRMR(Xk)=I(Xk;Y)-1 |S|? Xj?SI(Xk;Xj). (16) Hence, with more selected features, the effect of feature redundancy is gradually reduced. The intuition is that with more non-redundant features selected, it becomes more difficult for new features to be redundant to the features that have already been in S. In Brown et al. ( 2012), it gives another interpretation that the pairwise independence between features becomes stronger as more featuresare addedto S,possiblybecauseof noiseinformationin thedata. MRMR is also strongly linked to the Conditional likelihood maximization framework if we it- eratively revisethevalue of \u00dftobe1 |S|andsettheotherparameter ?tobe zero. 2.2.4 ConditionalInfomaxFeatureExtraction. Somestudies(LinandTang 2006;ElAkadietal. 2008; Guo and Nixon 2009) show that in contrast to minimize the feature redundancy, the con- ditional redundancy between unselected features and already selected features given class labels should also be maximized. In other words, as long as the feature redundancy given class labels is strongerthantheintra-featureredundancy,thefeatureselectionwillbeaffectednegatively.Atyp- ical feature selection under this argument is Conditional Infomax Feature Extraction (CIFE) (Lin and Tang 2006),inwhichthefeaturescorefora new unselectedfeature Xkis JCIFE(Xk)=I(Xk;Y)-? Xj?SI(Xj;Xk)+? Xj?SI(Xj;Xk|Y). (17) Compared with MIFS, it adds a third term? Xj?SI(Xj;Xk|Y)to maximize the conditional redun- dancy. Also, CIFE is a special case of the linear combination of Shannon information terms by settingboth \u00dfand?tobe 1. 2.2.5 JointMutualInformation. MIFSandMRMRreducefeatureredundancyinthefeaturese- lectionprocess.An alternativecriterion,JointMutualInformation(YangandMoody 1999;Me y er et al.2008) is proposed to increase the complementary information that is shared between unse- lectedfeaturesandselectedfeaturesgiventheclasslabels.Thefeatureselectioncriterionislisted ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:13 asfollows: JJMI(Xk)=? Xj?SI(Xk,Xj;Y). (18) ThebasicideaofJMIisthatweshouldincludenewfeaturesthatarecomplementarytotheexisting featuresgiven theclasslabels. JMI cannot be directly reduced to the condition likelihood maximization framework. In Brown et al. (2012), the authors demonstrate that with simple manipulations, the JMI criterion can be re-writtenas JJMI(Xk)=I(Xk;Y)-1 |S|? Xj?SI(Xj;Xk)+1 |S|? Xj?SI(Xj;Xk|Y). (19) Therefore, it is also a special case of the linear combination of Shannon information terms by iterativelysetting \u00dfand?tobe1 |S|. 2.2.6 Conditional Mutual Information Maximization. Previously mentioned criteria could be reduced to a linear combination of Shannon information terms. Next, we show some other al- gorithms that can only be reduced to a non-linear combination of Shannon information terms. Among them, Conditional Mutual Information Maximization (CMIM) (Vidal-Naquet and Ullman 2003;Fleuret2004)iterativelyselectsfeaturesthatmaximizethemutualinformationwiththeclass labels given the selected features so far. Mathematically, during the selection phase, the feature scoreforeachnew unselectedfeature Xkcanbe formulatedasfollows: JCMIM(Xk)=min Xj?S[I(Xk;Y|Xj)]. (20) Note that the value of I(Xk;Y|Xj)is small if Xkis not strongly correlated with the class label Y or ifXkis redundant when Sis known. By selecting the feature that maximizes this minimum value, it can guarantee that the selected feature has a strong predictive ability, and it can reduce theredundancyw.r.t.theselectedfeatures. TheCMIMcriterionisequivalenttothefollowing formaftersome derivations: JCMIM(Xk)=I(Xk;Y)-max Xj?S[I(Xj;Xk)-I(Xj;Xk|Y)]. (21) Therefore, CMIM is also a special case of the conditional likelihood maximization framework in Equation( 12). 2.2.7 InformativeFragments. InVidal-NaquetandUllman( 2003),theauthorsproposeafeature selection criterion called Informative Fragments (IF). The feature score of each new unselected featuresisgiven as JIF(Xk)=min Xj?S[I(XjXk;Y)-I(Xj;Y)]. (22) The intuition behind Informative Fragments is that the addition of the new feature Xkshould maximizethevalueofconditionalmutualinformationbetween Xkandexistingfeaturesin Sover themutualinformationbetween XjandY.AninterestingphenomenonofIFisthatwiththechain rule that I(XkXj;Y)=I(Xj;Y)+I(Xk;Y|Xj), IF has the equivalent form as CMIM. Hence, it can alsobe reducedto thegeneralframework in Equation( 12). 2.2.8 InteractionCapping. InteractionCapping(Jakulin 2005)isasimilarfeatureselectioncri- terion as CMIM in Equation ( 21), it restricts the term I(Xj;Xk)-I(Xj;Xk|Y)to be nonnegative: ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:14 J. Liet al. JCMIM(Xk)=I(Xk;Y)-? Xj?Smax[0,I(Xj;Xk)-I(Xj;Xk|Y)]. (23) Apparently,itisaspecialcaseofnon-linearcombinationofShannoninformationtermsbysetting thefunction ?(.)tobe-max[0,I(Xj;Xk)-I(Xj;Xk|Y)]. 2.2.9 Double Input Symmetrical Relevance. Another class of information-theoretical-based methodssuchasDoubleInputSymmetricalRelevance(DISR)(MeyerandBontempi 2006)exploits normalization techniquestonormalize mutualinformation (Guyonet al. 2008): JDISR(Xk)=? Xj?SI(XjXk;Y) H(XjXkY). (24) ItiseasytovalidatethatDISRisanon-linearcombinationofShannoninformationtermsandcan be reducedto theconditionallikelihoodmaximization framework. 2.2.10 Fast Correlation-Based Filter. There are other information-theoretical based feature se- lectionmethodsthatcannotbesimplyreducedtotheunifiedconditionallikelihoodmaximization framework. Fast Correlation-Based Filter (FCBF) (Yu and Liu 2003) is an example that exploits feature-class correlation and feature-feature correlation simultaneously. The algorithm works as follows: (1) given a predefined threshold d, it selects a subset of features Sthat are highly corre- lated with the class labels with SU=d,w h e r eSUis the symmetric uncertainty. The SUbetween a setoffeatures XSandtheclasslabel Yisgiven asfollows: SU(XS,Y)=2I(XS;Y) H(XS)+H(Y). (25) A specific feature Xkis called predominant iff SU(Xk,Y)=d, and there does not exist a feature Xj?S(j/nequalk)such that SU(Xj,Xk)=SU(Xk,Y). Feature Xjis considered to be redundant to featureXkifSU(Xj,Xk)=SU(Xk,Y); (2) the set of redundant features is denoted as SPi,w h i c h will be further split into S+ PiandS- Piwhere they contain redundant features to feature Xkwith SU(Xj,Y)>SU(Xk,Y)andSU(Xj,Y)<SU(Xk,Y), respectively; and (3) different heuristics are applied onSP,S+ Pi,a n dS- Pito remove redundant features and keep the features that are most relevant totheclasslabels. Discussion: Unlike similarity-based feature selection algorithms that fail to tackle feature redun- dancy,mostaforementionedinformation-theoretical-basedfeatureselectionalgorithmscanbeunified inaprobabilisticframeworkthatconsidersboth\u201cfeaturerelevance\u201dand\u201cfeatureredundancy.\u201dMean- while, similar as similarity-based methods, this category of methods is independent of any learning algorithms and hence are generalizable. However, most of the existing information-theoretical-based featureselectionmethodscanonlyworkinasupervisedscenario.Withouttheguideofclasslabels,it is still not clear how to assess the importance of features. In addition, these methods can only handle discretedata andcontinuousnumericalvariables requirediscretizationpreprocessingbeforehand . 2.3 Sparse-Learning-Based Methods The third type of methods is sparse-learning-based methods that aim to minimize the fitting er- rors along with some sparse regularization terms. The sparse regularizer forces many feature co- efficients to be small, or exactly zero, and then the corresponding features can be simply elim- inated. Sparse-learning-based methods have received considerable attention in recent years due to their good performance and interpretability. In the following parts, we review some represen- tative sparse-learning-based feature selection methods from both supervised and unsupervised perspectives. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:15 2.3.1 FeatureSelectionwith lp-NormRegularizer. First,weconsiderthebinaryclassificationor univariateregressionproblem.Toachievefeatureselection,the lp-normsparsity-inducedpenalty termisaddedontheclassificationorregressionmodel,where0 =p=1.Letwdenotesthefeature coefficient,and thentheobjectivefunctionforfeatureselectionis min wloss(w;X,y)+a?w?p, (26) whereloss(.)is a loss function, and some widely used loss functions loss(.)include least squares loss,hingeloss,andlogisticloss. ?w?p=(?d i=1?wi?p)1 pisasparseregularizationterm,and aisa regularization parameter to balance the contribution of the loss function and the sparse regular- ization termfor featureselection. Typically when p=0, thel0-norm regularization term directly seeks for the optimal set of nonzeroentries(features)forthemodellearning.However,theoptimizationproblemisnaturally anintegerprogrammingproblemandisdifficulttosolve.Therefore,itisoftenrelaxedtoa l1-norm regularization problem, which is regarded as the tightest convex relaxation of the l0-norm. One mainadvantageof l1-normregularization(LASSO)(Tibshirani 1996)isthatitforcesmanyfeature coefficientstobecomesmallerand,insomecases,exactlyzero.Thispropertymakesitsuitablefor featureselection,aswecanselectfeatureswhosecorrespondingfeatureweightsarelarge,which motivatesasurgeof l1-normregularizedfeatureselectionmethods(Zhuetal. 2004;Xuetal. 2014; Wei et al. 2016a;W e ia n dY u 2016; Hara and Maehara 2017). Also, the sparse vector wenables the ranking of features. Normally, the higher the value, the more important the corresponding featureis. 2.3.2 FeatureSelectionwith lp,q-NormRegularizer. Here,wediscusshowtoperformfeaturese- lectionforthegeneralmulti-classclassificationormultivariateregressionproblems.Theproblem ismoredifficultbecauseofthemultipleclassesandmultivariateregressiontargets,andwewould like the feature selection phase to be consistent over multiple targets. In other words, we want multiple predictive models for different targets to share the same parameter sparsity patterns\u2014 each feature either has small scores or large scores for all targets. This problem can be generally solvedbythelp,q-normsparsity-inducedregularizationterm,where p>1(mostexistingworkfo- cusonp=2or8)and0=q=1(mostexistingworkfocuson q=1or0).Assumethat Xdenotes thedatamatrixand Ydenotestheone-hotlabelindicatormatrix.Thenthemodelisformulatedas follows: min Wloss(W;X,y)+a?W?p,q, (27) where?W?p,q=(?c j=1(?d i=1|W(i,j)|p)q p)1 q; and the parameter ais used to control the contribu- tion of the loss function and the sparsity-induced regularization term. Then the features can be rankedaccordingtothevalueof ?W(i,:)?2 2(i=1,...,d);thehigherthevalue,themoreimportant thefeatureis. Case 1:p=2,q=0. To find relevant features across multiple targets, an intuitive way is to use discrete optimization through the l2,0-norm regularization. The optimization problem with the l2,0-normregularization termcan bereformulatedas follows: min Wloss(W;X,y)s.t.?W?2,0=k. (28) However, solving the aforementioned optimization problem has been proven to be NP-hard, and also, due to its discrete nature, the objective function is also not convex. To solve it, a variation ofAlternatingDirectionMethodcouldbeleveragedtoseekforalocaloptimalsolution(Caietal. 2013;G ue ta l . 2012). In Zhang et al. ( 2014), the authors provide two algorithms, the proximal gradient algorithmand rank-oneupdatealgorithm, tosolve thisdiscreteselectionproblem. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:16 J. Liet al. Case2:p=2,0<q<1.Theaforementionedsparsity-reducedregularizationtermisinherently discreteandhardtosolve.InPengandFan( 2016)andPengandFan( 2017),theauthorsproposea more generalframeworkto directlyoptimizethesparsity-reducedregularizationwhen0 <q<1 and providedefficientiterativealgorithmwithguaranteedconvergencerate. Case 3:p=2,q=1. Although thel2,0-norm is more desired for feature sparsity, however, it is inherently non-convex and non-smooth. Hence, the l2,1-norm regularization is preferred and widely used in different scenarios such as multi-task learning (Obozinski et al. 2007; Zhang et al. 2008), anomaly detection (Li et al. 2017;W ue ta l . 2017), and crowdsourcing (Zhou and He 2017). Manyl2,1-normregularization-basedfeatureselectionmethodshavebeenproposedoverthepast decade (Zhao et al. 2010;G ue ta l . 2011c;Y a n ge ta l . 2011; Hou et al. 2011;L ie ta l . 2012; Qian and Zhai 2013;S h ie ta l . 2014; Liu et al. 2014;D ua n dS h e n 2015;J i a ne ta l . 2016; Liu et al. 2016b; N i ee ta l . 2016; Zhu et al. 2016;L ie ta l . 2017b). Similarly tol1-norm regularization, l2,1-norm regularizationisalsoconvexandaglobaloptimalsolutioncanbeachieved(Liuetal. 2009a),thus the following discussions about the sparse-learning-based feature selection will center around thel2,1-norm regularization term. The l2,1-norm regularization also has strong connections with grouplasso(YuanandLin 2006),whichwillbeexplainedlater.Bysolvingtherelatedoptimization problem,wecanobtainasparsematrix Wwheremanyrowsareexactzeroorofsmallvalues,and thenthefeaturescorrespondingto theserowscan beeliminated. Case 4:p=8,q=1. In addition to the l2,1-norm regularization term, the l8,1-norm regular- izationisalsowidelyusedtoachievejointfeaturesparsityacrossmultipletargets(Quattonietal. 2009).Inparticular,itpenalizesthesumofmaximumabsolutevaluesofeachrow,suchthatmany rows of thematrix willallbezero. 2.3.3 Efficient and Robust Feature Selection. N i ee ta l .( 2010) propose an efficient and robust feature selection (REFS) method by employing a joint l2,1-norm minimization on both the loss functionandtheregularization.Theirargumentisthatthe l2-norm-basedlossfunctionissensitive to noisy data while the l2,1-norm-based loss function is more robust to noise. The reason is that l2,1-normlossfunctionhasarotationalinvariantproperty(Dingetal. 2006).Consistentwithl2,1- norm regularized feature selection model, a l2,1-norm regularizer is added to the l2,1-norm loss functionto achievegroupfeaturesparsity.Theobjectivefunctionof REFSis min W?XW-Y?2,1+a?W?2,1. (29) Tosolvetheconvexbutnon-smoothoptimizationproblem,anefficientalgorithmisproposedwith strictconvergenceanalysis. ItshouldbenotedthattheaforementionedREFSisdesignedformulti-classclassificationprob- lemswhereeachinstanceonlyhasoneclasslabel.However,datacouldbeassociatedwithmultiple labelsinmanydomainssuchasinformationretrievalandmultimediaannotation.Recently,thereis asurgeofresearchworkstudymulti-labelfeatureselectionproblemsbyconsideringlabelcorrela- tions.Mostofthem,however,arealsobasedonthe l2,1-normsparseregularizationframework(Gu et al.2011a;Changetal. 2014;J ianetal . 2016). 2.3.4 Multi-ClusterFeatureSelection. Mostofexistingsparse-learning-basedapproachesbuild a learning model with the supervision of class labels. The feature selection phase is derived af- terwards on the sparse feature coefficients. However, since labeled data are costly and time- consumingtoobtain,unsupervisedsparse-learning-basedfeatureselectionhasreceivedincreasing attentioninrecentyears.Multi-ClusterFeatureSelection(MCFS)(Caietal. 2010)isoneofthefirst attempts.Withoutclasslabelstoguidethefeatureselectionprocess,MCFSproposestoselectfea- turesthatcancovermulti-clusterstructureofthedatawherespectralanalysisisusedtomeasure thecorrelationbetweendifferent features. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:17 MCFSconsistsofthreesteps.Inthefirststep,itconstructsa p-nearestneighborgraphtocapture thelocalgeometricstructureofdataandgetsthegraphaffinitymatrix SandtheLaplacianmatrix L. Then a flat embedding that unfolds the data manifold can be obtained by spectral clustering techniques. In the second step, since the embedding of data is known, MCFS takes advantage of themtomeasuretheimportanceoffeaturesbyaregressionmodelwitha l1-normregularization. Specifically,given the ithembedding ei,MCFS regardsit asa regressiontargetto minimize: min wi?Xwi-ei?2 2+a?wi?1, (30) wherewidenotes the feature coefficient vector for the ith embedding. By solving all Ksparse regression problems, MCFS obtains Ksparse feature coefficient vectors W=[w1,...,wK], and each vector corresponds to one embedding of X. In the third step, for each feature fj,t h eM C F S score for that feature can be computed as MCFS(j)=maxi|W(j,i)|. The higher the MCFS score, themore importantthefeatureis. 2.3.5l2,1-Norm Regularized Discriminative Feature Selection. In Yang et al. ( 2011), the authors propose a new unsupervised feature selection algorithm (UDFS) to select the most discrimina- tive features by exploiting both the discriminative information and feature correlations. First, assume\u02dcXis the centered data matrix such \u02dcX=HnXandG=[G1,G1,...,Gn]'=Y(Y'Y)-1 2is the weighted label indicator matrix, where Hn=In-1 n1n1' n. Instead of using global discrimina- tive information, they propose to utilize the local discriminative information to select discrimi- native features. The advantage of using local discriminative information are twofold. First, it has been demonstrated to be more important than global discriminative information in many classi- fication and clustering tasks. Second, when it considers the local discriminative information, the datamanifoldstructureisalsowellpreserved.Foreachdatainstance xi,itconstructsa p-nearest- neighborsetforthatinstance Np(xi)={xi1,xi2,...,xip}.LetXNp(i)=[xi,xi1,...,xip]denotethe local data matrix around xi, and then the local total scatter matrix S(i) tand local between class scatter matrix S(i) bare\u02dcXi'\u02dcXiand\u02dcXi'GiG' i\u02dcXirespectively, where \u02dcXiis the centered data matrix andG(i)=[Gi,Gi1,...,Gik]'.N o t et h a t G(i)is a subset from GandG(i)can be obtained by a se- lection matrix Pi?{0,1}n\u00d7(k+1)such that G(i)=P' iG. Without label information in unsupervised featureselection,UDFSassumesthatthereisalinearclassifier W?Rd\u00d7stomapeachdatainstance xi?Rdto a low-dimensional space Gi?Rs. Following the definition of global discriminative in- formation (Yang et al. 2010; Fukunaga 2013), the local discriminative score for each instance xiis DSi=tr[(S(i) t+?Id)-1S(i) b]=tr[W'X'P(i)\u02dcXi'(\u02dcXi\u02dcXi'+?Id)-1\u02dcXiP' (i)XW]. (31) Ahighlocaldiscriminativescoreindicatesthattheinstancecanbewelldiscriminatedby W.There- fore,UDFStendstotrain W,whichobtainsthehighestlocaldiscriminativescoreforallinstances inX; also it incorporates a l2,1-norm regularizer to achieve feature selection, and the objective functionis formulatedasfollows: min W'W=Idn? i=1{tr[G' (i)Hk+1G(i)-DSi]}+a?W?2,1, (32) whereais aregularization parameterto controlthesparsityof thelearnedmodel. 2.3.6 Feature Selection Using Nonnegative Spectral Analysis. Nonnegative Discriminative Fea- ture Selection (NDFS) (Li et al. 2012) performs spectral clustering and feature selection simulta- neously in a joint framework to select a subset of discriminative features. It assumes that pseudo classlabelindicatorscanbeobtainedbyspectralclusteringtechniques.Differentfrommostexist- ingspectralclusteringtechniques,NDFSimposesnonnegativeandorthogonalconstraintsduring ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:18 J. Liet al. thespectralclusteringphase.Theargumentisthatwiththeseconstraints,thelearnedpseudoclass labelsareclosertorealclusterresults.Thesenonnegativepseudoclasslabelsthenactasregression constraintstoguidethefeatureselectionphase.Insteadofperformingthesetwotasksseparately, NDFS incorporatesthesetwo phasesintoa jointframework. SimilarlytotheUDFS,weuse G=[G1,G1,...,Gn]'=Y(Y'Y)-1 2todenotetheweightedcluster indicator matrix. It is easy to show that we have GG'=In. NDFS adopts a strategy to learn the weightclustermatrixsuchthatthelocalgeometricstructureofthedatacanbewellpreserved(Shi and Malik 2000; Yu and Shi 2003). The local geometric structure can be preserved by minimizing the normalized graph Laplacian tr(G'LG),w h e r eLis the Laplacian matrix that can be derived from RBF kernel. In addition to that, given the pseudo labels G, NDFS assumes that there exists a linear transformation matrix W?Rd\u00d7sbetween the data instances Xand the pseudo labels G. These pseudo class labels are utilized as constraints to guide the feature selection process. The combinationof thesetwocomponentsresultsin thefollowing problem: min G,Wtr(G'LG)+\u00df(?XW-G?2 F+a?W?2,1) s.t.GG'=In,G=0,(33) whereais a parameter to control the sparsity of the model, and \u00dfis introduced to balance the contributionof spectralclusteringand discriminativefeatureselection. Discussion: Sparse-learning-based feature selection methods have gained increasing popularity in recent years. A merit of such type of methods is that it embeds feature selection into a typical learn- ing algorithm (such as linear regression, SVM, etc.). Thus it can often lead very good performance for the underlying learning algorithm. Also, with sparsity of feature weights, the model poses good interpretability as it enables us to explain why we make such prediction. Nonetheless, there are still some drawbacks of these methods: First, as it directly optimizes a particular learning algorithm by feature selection, the selected features do not necessary achieve good performance in other learning tasks. Second, this kind of methods often involves solving a non-smooth optimization problem, and withcomplexmatrixoperations(e.g.,multiplication,inverse,etc.)inmostcases.Hence,theexpensive computationalcostisanotherbottleneck . 2.4 Statistical-Based Methods Anothercategoryoffeatureselectionalgorithmsisbasedondifferentstatisticalmeasures.Asthey relyonvariousstatisticalmeasuresinsteadoflearningalgorithmstoassessfeaturerelevance,most of them are filter-based methods. In addition, most statistical-based algorithms analyze features individually. Hence, feature redundancy is inevitably ignored during the selection phase. We in- troducesome representativefeatureselectionalgorithmsin thiscategory. 2.4.1 Low Variance. Low Variance eliminates features whose variance are below a predefined threshold.Forexample,forthefeaturesthathavethesamevaluesforallinstances,thevarianceis0 andshouldberemoved,sinceitcannothelpdiscriminateinstancesfromdifferentclasses.Suppose thatthedatasetconsistsofonlyBooleanfeatures,thatis,thefeaturevaluesareeither0and1.As theBooleanfeatureis aBernoulli randomvariable,itsvariancevalue canbe computedas: variance_score(fi)=p(1-p), (34) wherepdenotesthepercentageofinstancesthattakethefeaturevalueof1.Afterthevarianceof featuresisobtained,thefeaturewithavariancescorebelowapredefinedthresholdcanbedirectly pruned. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:19 2.4.2 T-Score. T-score (Davis and Sampson 1986) is used for binary classification problems. Foreachfeature fi,supposethat \u00b51and\u00b52arethemeanfeaturevaluesfortheinstancesfromtwo different classes, s1ands2are the corresponding standard deviations, and n1andn2denote the numberof instancesfromthesetwo classes.Thenthe t-scoreforthefeature fiis t_score(fi)=|\u00b51-\u00b52|/v s2 1 n1+s2 2 n2. (35) The basic idea of t-score is to assess whether the feature makes the means of two classes statisti- callydifferent,whichcanbecomputedastheratiobetweenthemeandifferenceandthevariance oftwoclasses.Thehigherthe t-score,themore importantthefeatureis. 2.4.3 Chi-Square Score. Chi-square score (Liu and Setiono 1995) utilizes the test of indepen- dencetoassesswhetherthefeatureisindependentoftheclasslabel.Givenaparticularfeature fi withrdifferent featurevalues,theChi-squarescoreof thatfeaturecan becomputedas: Chi_square_score(fi)=r? j=1c? s=1(njs-\u00b5js)2 \u00b5js, (36) wherenjsisthenumberofinstanceswiththe jthfeaturevaluegivenfeature fi.Inaddition, \u00b5js= n*snj* n,w h e r enj*indicates the number of data instances with the jth feature value given feature fi,n*sdenotes the number of data instances in class r. A higher Chi-square score indicates that thefeatureisrelatively more important. 2.4.4 Gini Index. Gini index (Gini 1912) is also a widely used statistical measure to quantify if the feature is able to separate instances from different classes. Given a feature fiwithrdifferent feature values, suppose WandWdenote the set of instances with the feature value smaller or equal to the jth feature value and larger than the jth feature value, respectively. In other words, thejth feature value can separate the dataset into WandW, and then the Gini index score for thefeature fiisgiven asfollows: ?ini_index_score(fi)=min W/parenlefttpA /parenleftbtAp(W)(1-c? s=1p(Cs|W)2)+p(W)(1-c? s=1p(Cs|W)2)/parenrighttpA /parenrightbtA,(37) wherep(.)denotes the probability. For instance, p(Cs|W)is the conditional probability of class sgivenW. For binary classification, Gini Index can take a maximum value of 0.5, it can also be usedinmulti-classclassificationproblems.Unlikepreviousstatisticalmeasures,thelowertheGini indexvalue,themore relevant thefeatureis. 2.4.5 CFS. The basic idea of CFS (Hall and Smith 1999) is to use a correlation-based heuristic toevaluate theworthofa featuresubset S: CFS_score(S)=krcfv k+k(k-1)rff, (38) wheretheCFSscoreshowstheheuristic\u201cmerit\u201dofthefeaturesubset Swithkfeatures.rcfisthe meanfeatureclasscorrelationand rffistheaveragefeature-featurecorrelation.InEquation( 38), the numerator indicates the predictive power of the feature set while the denominator shows how much redundancy the feature set has. The basic idea is that a good feature subset should haveastrongcorrelationwithclasslabelsandareweaklyintercorrelated.Togetthefeature-class correlation and feature-feature correlation, CFS uses symmetrical uncertainty (Vetterling et al. 1992). As finding the globally optimal subset is computational prohibitive, it adopts a best-search strategy to find a local optimal feature subset. At the very beginning, it computes the utility of ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:20 J. Liet al. each feature by considering both feature-class and feature-feature correlation. It then starts with an empty set and expands the set by the feature with the highest utility until it satisfies some stoppingcriteria. Discussion: Most of the statistical-based feature selection methods rely on predefined statistical measurestofilteroutunwantedfeaturesandaresimpleandstraightforwardinnature.Andthecom- putationalcostsofthesemethodsareoftenverylow.Tothisend,theyareoftenusedasapreprocessing stepbeforeapplyingothersophisticatedfeatureselectionalgorithms.Also,assimilarity-basedfeature selection methods, these methods often evaluate the importance of features individually and hence cannot handle feature redundancy. Meanwhile, most algorithms in this family can only work on dis- crete data and conventional data discretization techniques are required to preprocess numerical and continuousvariables . 2.5 Other Methods Inthissubsection,wepresentotherfeatureselectionmethodsthatdonotbelongtotheaforemen- tionedfourtypesoffeatureselectionalgorithms.Inparticular,wereviewhybridfeatureselection methodsand deep-learning-basedand reconstruction-basedmethods. Hybrid feature selection methods is a kind of ensemble-based methods that aim to construct a group of feature subsets from different feature selection algorithms and then produce an aggre- gated result out of the group. In this way, the instability and perturbation issues of most single featureselectionalgorithmscanbealleviated,andthesubsequentlearningtaskscanbeenhanced. Similarlytoconventionalensemblelearningmethods(Zhou 2012),hybridfeatureselectionmeth- ods consist of two steps: (1) construct a set of different feature selection results and (2) aggregate different outputs into a consensus result. Different methods differ in the way these two steps are performed. For the first step, existing methods either ensemble the selected feature subsets of a single method on different sample subset or ensemble the selected feature subsets from multiple featureselectionalgorithms.Inparticular,asamplingmethodtoobtaindifferentsamplesubsetsis necessaryforthefirstcase;andtypicalsamplingmethodsincluderandomsamplingandbootstrap sampling. For example, Saeys et al. ( 2008) studied the ensemble feature selection that aggregates aconventionalfeatureselectionalgorithmsuchasRELIEFwithmultiplebootstrappedsamplesof the training data. In Abeel et al. ( 2010), the authors improved the stability of SVM-RFE feature selection algorithm by applying multiple random sampling on the original data. The second step involvesinaggregatingrankingsofmultipleselectedfeaturesubset.Mostoftheexistingmethods employasimpleyeteffectivelinearaggregationfunction(Saeysetal. 2008;Abeeletal. 2010;Y ang andMao2011).Nonetheless,otherrankingaggregationfunctionssuchastheMarkovchain-based method(DutkowskiandGambin 2007),distancesynthesismethod(Yangetal. 2005),andstacking method (Netzer et al. 2009) are also widely used. In addition to using the aggregation function, anotherwayistoidentifytheconsensusfeaturesdirectlyfrommultiplesamplesubsets(Loscalzo et al.2009). Nowadays, deep learning techniques are popular and successful in various real-world applica- tions,especiallyincomputervisionandnaturallanguageprocessing.Deeplearningisdistinctfrom featureselectionasdeeplearningleveragesdeepneutralnetworksstructurestolearnnewfeature representations while feature selection directly finds relevant features from the original features. Fromthisperspective,theresultsoffeatureselectionaremorehumanreadableandinterpretable. Even though deep learning is mainly used for feature learning, there are still some attempts that use deep learning techniques for feature selection. We briefly review these deep-learning-based feature selection methods. For example, in Li et al. ( 2015), a deep feature selection model (DFS) is proposed. DFS selects features at the input level of a deep neural network. Typically, it adds a sparse one-to-one linear layer between the input layer and the first hidden layer of a multilayer ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:21 perceptrons(MLP).Toachievefeatureselection,DFSimposessparseregularizationterm,andthen onlythefeaturescorrespondingtononzeroweightsareselected.Similarly,inRoyetal.( 2015),the authorsalso proposeto selectfeaturesat theinput levelof a deepneuralnetwork.Thedifference isthattheyproposeanewconcept\u2014netpositivecontribution\u2014toassessiffeaturesaremorelikely to make the neurons contribute in the classification phase. Since heterogeneous (multi-view) fea- tures are prevalent in machine-learning and pattern recognition applications, Zhao et al. ( 2015) proposestocombinedeepneuralnetworkswithsparserepresentationforgroupedheterogeneous feature selection. It first extracts a new unified representation from each feature group using a multi-modalneuralnetwork.Thentheimportanceoffeaturesislearnedbyakindofsparsegroup lasso method. In Wang et al. ( 2014a), the authors propose an attentional neural network, which guides feature selection with cognitive bias. It consists of two modules, a segmentation module, and a classification module. First, given a cognitive bias vector, segmentation module segments out an object belonging to one of classes in the input image. Then, in the classification module, a reconstruction function is applied to the segment to gate the raw image with a threshold for classification. When features are sensitive to a cognitive bias, the cognitive bias will activate the correspondingrelevant features. Recently, data reconstruction error emerged as a new criterion for feature selection, especially for unsupervised feature selection. It defines feature relevance as the capability of features to ap- proximatetheoriginaldataviaareconstructionfunction.Amongthem,ConvexPrincipalFeature Selection(CPFS)(Masaelietal. 2010)reformulatesthefeatureselectionproblemasaconvexcon- tinuousoptimizationproblemthatminimizesamean-squared-reconstructionerrorwithlinearand sparsity constraint. GreedyFS (Farahat et al. 2011) uses a projection matrix to project the original dataontothespanofsomerepresentativefeaturevectorsandderivesanefficientgreedyalgorithm toobtaintheserepresentativefeatures.Zhaoetal.( 2016)formulatestheproblemofunsupervised feature selection as the graph regularized data reconstruction. The basic idea is to make the se- lectedfeatureswellpreservethedatamanifoldstructureoftheoriginaldataandreconstructeach data sample via linear reconstruction. A pass-efficient unsupervised feature selection is proposed in Maung and Schweitzer ( 2013). It can be regarded as a modification of the classical pivoted QR algorithm, the basic idea is still to select representative features that can minimize the recon- structionerrorvialinearfunction.Theaforementionedmethodsmostlyuselinearreconstruction functions; Li et al. ( 2017a) argues that the reconstruction function is not necessarily linear and proposestolearnthereconstructionfunctionautomaticallyfunctionfromdata.Inparticular,they definea schemetoembed thereconstructionfunctionlearningintofeatureselection. 3 FEATURE SELECTIONWITH STRUCTURED FEATURES Existingfeatureselectionmethodsforconventionaldataarebasedonastrongassumptionthatfea- turesareindependentofeachother(flat)whileignoringtheinherentfeaturestructures.However, in many real applications features could exhibit various kinds of structures, for example, spatial or temporal smoothness, disjoint groups, overlap groups, trees and graphs (Tibshirani et al. 2005; Jenattonetal. 2011;Y uanetal. 2011;Huangetal. 2011;Zhouetal. 2012;W angandY e 2015).Ifthis is the case, then feature selection algorithms incorporating knowledge about the structure infor- mationmayhelpfindmorerelevantfeaturesandthereforecanimprovesubsequentlearningtasks. One motivating example is from bioinformatics, in the study of array CGH, features have some naturalspatialorder,incorporatingsuchspatialstructurecanhelpselectmoreimportantfeatures andachievemoreaccurateclassificationaccuracy.Therefore,inthissection,wediscusssomerep- resentativefeatureselectionalgorithmsthatexplicitlyconsiderfeaturestructures.Specifically,we willfocuson groupstructure,treestructure,andgraphstructure. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:22 J. Liet al. Fig. 3. Illustration of Lasso, Group Lasso, and Sparse Group Lasso. The feature set can be divided into four groups,G1,G2,G3,a n dG4. The column with dark color denotes selected features while the column with light color denotes unselectedfeatures. A popular and successful approach to achieve feature selection with structured features is to minimize an empiricalerrorpenalizedbya structuralregularization term: w=argmin wloss(w;X,y)+apenalty (w,G), (39) whereGdenotes the structures among features and ais a tradeoff parameter between the loss functionandthestructuralregularizationterm.Toachievefeatureselection, penalty(w,G)isusu- ally set to be a sparse regularization term. Note that the aforementioned formulation is similar to that in Equation ( 26); the only difference is that for feature selection with structured features, we explicitlyconsiderthestructuralinformation Gamongfeaturesinthesparseregularizationterm. 3.1 Feature Selection withGroupFeature Structures First, features could exhibit group structures. One of the most common examples is that in mul- tifactor analysis-of-variance (ANOVA), each factor is associated with several groups and can be expressed by a set of dummy features (Yuan and Lin 2006). Some other examples include differ- ent frequency bands represented as groups in signal processing (McAuley et al. 2005) and genes with similar functionalities acting as groups in bioinformatics (Ma et al. 2007). Therefore, when performingfeatureselection,itis moreappealingto modelthegroupstructureexplicitly. 3.1.1 Group Lasso. Group Lasso (Yuan and Lin 2006; Bach2008; Jacob et al. 2009; Meier et al. 2008),whichderivesfeaturecoefficientsfromcertaingroupstobesmallorexactzero,isasolution tothisproblem.Inotherwords,itselectsorignoresagroupoffeaturesasawhole.Thedifference between Lasso and Group Lasso is shown by the illustrative example in Figure 3. Suppose that these features come from four different groups and there is no overlap between these groups. Lassocompletelyignoresthegroupstructuresamongfeatures,andtheselectedfeaturesarefrom four different groups. On the contrary, Group Lasso tends to select or not select features from different groups as a whole. As shown in the figure, Group Lasso only selects the second and the fourth groups G2andG4, and features in the other two groups G1andG3are not selected. Mathematically,GroupLassofirstusesa l2-normregularizationtermforfeaturecoefficients wiin each group Gi, and then it performs a l1-norm regularization for all previous l2-norm terms. The objectivefunctionof GroupLasso isformulatedas follows: min wloss(w;X,y)+a?? i=1hi?wGi?2, (40) wherehiis a weight for the ith group wGi, which can be considered as a prior to measuring the contributionof the ithgroupin thefeatureselectionprocess. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:23 3.1.2 Sparse Group Lasso. Once Group Lasso selects a group, all the features in the selected groupwillbekept.However,inmanycases,notallfeaturesintheselectedgroupcouldbeuseful, and it is desirable to consider the intrinsic feature structures and select features from different selected groups simultaneously (as illustrated in Figure 3). Sparse Group Lasso (Friedman et al. 2010;Pengetal. 2010)takesadvantageofbothLassoandGroupLasso,anditproducesasolution withsimultaneousintra-groupandinter-groupsparsity.ThesparseregularizationtermofSparse GroupLasso isa combinationof thepenaltytermof Lassoand GroupLasso: min wloss(w;X,y)+a?w?1+(1-a)?? i=1hi?wGi?2, (41) whereais parameter between 0 and 1 to balance the contribution of inter-group sparsity and intra-group sparsity for feature selection. The difference among Lasso, Group Lasso, and Sparse GroupLasso isshownin Figure 3. 3.1.3 Overlapping Sparse Group Lasso. The above methods consider the disjoint group struc- tures among features. However, groups may also overlap with each other (Jacob et al. 2009; Jenattonetal. 2011;Zhaoetal. 2009).Onemotivatingexampleistheusageofbiologicallymeaning- ful gene/protein groups mentioned in Ye and Liu ( 2012). Different groups of genes may overlap, that is, one protein/gene may belong to multiple groups. A general Overlapping Sparse Group Lasso regularization is similar to the regularization term of Sparse Group Lasso. The difference is thatdifferentfeaturegroups Gicanhaveanoverlap,thatis,thereexistatleasttwogroups Giand Gjsuchthat Gi?Gj/nequal\u00d8. 3.2 Feature Selection with Tree Feature Structures In addition to the group structures, features can also exhibit tree structures. For example, in face recognition,differentpixelscanberepresentedasatree,wheretherootnodeindicatesthewhole face,itschildnodescanbedifferentorgans,andeachspecificpixelisconsideredasaleafnode.An- othermotivatingexampleisthatgenes/proteinsmayformcertainhierarchicaltreestructures(Liu and Ye2010). Recently, Tree-guided Group Lasso is proposed to handle the feature selection for features that can be represented in an index tree (Kim and Xing 2010; Liu and Ye 2010; Jenatton etal.2010). 3.2.1 Tree-Guided Group Lasso. In Tree-guided Group Lasso (Liu and Ye 2010), the structure over the features can be represented as a tree with leaf nodes as features. Each internal node denotes a group of features such that the internal node is considered as a root of a subtree and thegroupoffeaturesisconsideredasleafnodes.Eachinternalnodeinthetreeisassociatedwith a weight that represents the height of its subtree or how tightly the features in this subtree are correlated. InTree-guidedGroupLasso,foranindextree Gwithadepthof d,Gi={Gi 1,Gi 2,...,Gi ni}denotes the whole set of nodes (features) in the ith level (the root node is in level 0), and nidenotes the number of nodes in the level i. Nodes in Tree-guided Group Lasso have to satisfy the following two conditions: (1) internal nodes from the same depth level have non-overlapping indices, that is,Gi j?Gi k=\u00d8,?i=1,2,...,d,j/nequalk,i=j,k=ni, and (2) if Gi-1 mis the parent node of Gi j,t h e n Gi j?Gi-1 m. WeexplaintheseconditionsviaanillustrativeexampleinFigure 4.Inthefigure,wecanobserve that eight features are organized in an indexed tree of depth 3. For the internal nodes in each level,wehave G0 1={f1,f2,f3,f4,f5,f6,f7,f8},G1 1={f1,f2},G1 2={f3,f4,f5,f6,f7},G1 3={f8},G2 1= {f1,f2},G2 2={f3,f4},G2 3={f5,f6,f7}.G0 1is the root node of the index tree. In addition, internal ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:24 J. Liet al. Fig. 4. Illustration of the tree structure among features. These eight features form a simple index tree with ad e p t ho f3 . nodes from the same level do not overlap while the parent node and the child node have some overlapsuchthatthefeaturesofthechildnodeisasubsetofthoseoftheparentnode.Inthisway, theobjectivefunctionof Tree-guidedGroupLassois min wloss(w;X,y)+ad? i=0ni? j=1hi j?wGi j?2, (42) wherea=0 is a regularization parameter and hi j=0 is a predefined parameter to measure the contribution of the internal node Gi j. Since a parent node is a superset of its child nodes, thus, if a parent nodeis not selected,allof its child nodes willnot be selected.For example, as illustrated in Figure 4, if the internal node G1 2is not selected, both of its child nodes G2 2andG2 3will not be selected. 3.3 Feature Selection withGraphFeature Structures In many cases, features may have strong pairwise interactions. For example, in natural language processing,ifwetakeeachwordasafeature,thenwehavesynonymsandantonymsrelationships betweendifferentwords(Fellbaum 1998).Moreover,manybiologicalstudiesshowthatthereexist strong pairwise dependencies between genes. Since features show certain kinds of dependencies in these cases, we can model them by an undirected graph, where nodes represent features and edges among nodes show the pairwise dependencies between features (Sandler et al. 2009;K i m andXing 2009;Y angetal. 2012).Wecanuseanundirectedgraph G(N,E)toencodethesedepen- dencies. Assume that there are nnodesN={N1,N2,...,Nn}and a set of eedges{E1,E2,...,Ee} inG(N,E).T h e nn o d e Nicorresponds to the ith feature and the pairwise feature dependencies can berepresentedbyan adjacencymatrix A?RNn\u00d7Nn. 3.3.1 Graph Lasso. Since features exhibit graph structures, when two nodes (features) Niand Njare connected by an edge in G(N,E), the features fiandfjare more likely to be selected together, and they should have similar feature coefficients. One way to achieve this target is via Graph Lasso\u2014adding a graph regularizer for the feature graph on the basis of Lasso (Ye and Liu 2012).Theformulation is min wloss(w;X,y)+a?w?1+(1-a)? i,jA(i,j)(wi-wj)2, (43) ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:25 where the first regularization term a?w?1is from Lasso while the second term ensures that if a pairoffeaturesshowstrongdependency,thatis,large A(i,j),theirfeaturecoefficientsshouldalso besimilar to eachother. 3.3.2 GFLasso. In Equation ( 43), Graph Lasso encourages features connected together have similar feature coefficients. However, features can also be negatively correlated. In this case, the feature graphG(N,E)is represented by a signed graph, with both positive and negative edges. GFLasso(KimandXing 2009)isproposedtomodelbothpositiveandnegativefeaturecorrelations, theobjectivefunctionis min wloss(w;X,y)+a?w?1+(1-a)? i,jA(i,j)|wi-sign(ri,j)wj|, (44) whereri,jindicates the correlation between two features fiandfj. When two features are posi- tively correlated, we have A(i,j)=1a n dri,j>0, and the penalty term forces the feature coeffi- cientswiandwjto be similar; on the other hand, if two features are negatively correlated, then we haveA(i,j)=1andri,j<0,andthepenaltytermmakesthefeaturecoefficients wiandwjto be dissimilar. A major limitation of GFLasso is that it uses pairwise sample correlations to mea- surefeaturedependencies,whichmayleadtoadditionalestimationbias.Thefeaturedependencies cannotbecorrectlyestimatedwhenthesamplesize issmall. 3.3.3 GOSCAR. To address the limitations of GFLasso, Yang et al. ( 2012) propose GOSCAR by putting al8-norm regularization to enforce pairwise feature coefficients to be equivalent if two featuresareconnectedin thefeaturegraph.Theformulation is min wloss(w;X,y)+a?w?1+(1-a)? i,jA(i,j)max(|wi|,|wj|). (45) In the aforementioned formulation, the l1-norm regularization is used for feature selection while thepairwisel8-normtermpenalizeslargecoefficients.Thepairwise l8-normtermcanbedecom- posed as max (|wi|,|wj|)=1 2(|wi+wj|+|wi-wj|)=|u'w|+|v'w|,w h e r euandvare sparse vectorswithonlytwo nonzero entriessuchthat ui=uj=1 2,vi=-vj=1 2. Discussion:Thisfamilyofalgorithmsexplicitlytakethestructuresamongfeaturesaspriorknowl- edgeandfeedintofeatureselection.Therefore,theselectedfeaturescouldenhancesubsequentlearning tasks.However,mostofthesemethodsarebasedonthesparselearningframeworkandofteninvolves insolvingcomplexoptimizationalgorithms.Thus,computationalcostscouldberelativelyhigh.More- over, the feature structure are often given a priori, it is still a challenging problem to automatically inferthestructuresfromdata forfeatureselection . 4 FEATURE SELECTIONWITH HETEROGENEOUSDATA Traditional feature selection algorithms are heavily based on the data i.i.d. assumption. However, heterogeneousdatafromdifferentsourcesisbecomingmoreandmoreprevalentintheeraofbig data.Forexample,inthemedicaldomain,genesareoftenassociatedwithdifferenttypesofclinical features.Sincedataofeachsourcecanbenoisy,partial,orredundant,howtofindrelevantsources and how to fuse them together for effective feature selection is a challenging problem. Another example is in social media platforms, instances of high dimensionality are often linked together, finding a way to integrate link information to guide feature selection is another difficult prob- lem. In this section, we review current feature selection algorithms for heterogeneous data from threeaspects:(1)featureselectionforlinkeddata,(2)multi-sourcefeatureselection,and(3)multi- viewfeatureselection.Notethatmulti-sourceandmulti-viewfeatureselectionaredifferentintwo ways: First, multi-source feature selection aims to select features from the original feature space ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:26 J. Liet al. Fig.5. An illustrativeexample of linkeddata. by integrating multiple sources while multi-view feature selection selects features from different feature spaces for all views simultaneously. Second, multi-source feature selection normally ig- noresthecorrelationsamongsourceswhilemulti-viewfeatureselectionexploitsrelationsamong featuresfromdifferent sources. 4.1 Feature Selection AlgorithmswithLinked Data Linkeddataareubiquitousinreal-worldapplicationssuchasTwitter(tweetslinkedbyhyperlinks), Facebook (users connected by friendships), and biological systems (protein interactions). Due to different typesof links,theyaredistinctfrom traditionalattribute-valuedata(or \u201cflat\u201ddata). Figure5illustrates an example of linked data and its representation. Figure 5(a) shows eight linked instances, and the feature information is illustrated in the left part of Figure 5(b). Linked dataprovidesanextrasourceofinformation,whichcanberepresentedbyanadjacencymatrix,il- lustratedintherightpartofFigure 5(b).Manylinked-data-relatedlearningtasksareproposedsuch ascollectiveclassification(MacskassyandProvost 2007;Senetal. 2008),relationallearning(Long etal.2006,2007;Lietal.2017b),linkprediction(Liben-NowellandKleinberg 2007;Backstromand Leskovec 2011;C h e ne ta l . 2016), and active learning (Bilgic et al. 2010;H ue ta l . 2013), but the taskoffeatureselectionisnotwellstudiedduetosomeofitsuniquechallenges:(1)howtoexploit relations among data instances, (2) how to take advantage of these relations for feature selection, and(3)becauselinkeddataareoftenunlabeled,howtoevaluatetherelevanceoffeatureswithout labels. Recent years have witnessed a surge of research interests in performing feature selection onlinkeddata(GuandHan 2011;TangandLiu 2012a,2012b,2013;Weietal. 2015,2016b;Lietal. 2015,2016,2016; Cheng et al. 2017). Next, we introduce some representative algorithms in this family. 4.1.1 Feature Selection on Networks. In Gu and Han ( 2011), the authors propose a supervised featureselectionalgorithm(FSNet)basedonLaplacianRegularizedLeastSquares(LapRLS).Inde- tail,theyproposetousealinearclassifiertocapturetherelationshipbetweencontentinformation andclasslabelsandincorporatelinkinformationbygraphregularization.Supposethat X?Rn\u00d7d denotes the content matrix and Y?Rn\u00d7cdenotes the one-hot label matrix, Adenotes the adja- cency matrix for all nlinked instances. FSNet first attempts to learn a linear classifier W?Rd\u00d7c to mapXtoY: min W?XW-Y?2 F+a?W?2,1+\u00df?W?2 F. (46) The term?W?2,1is included to achieve joint feature sparsity across different classes. ?W?2 Fpre- ventstheoverfittingofthemodel.Tocapturethecorrelationbetweenlinkinformationandcontent informationtoselectmorerelevantfeatures,FSNetusesthegraphregularizationandthebasicas- sumptionisthatiftwoinstancesarelinked,theirclasslabelsarelikelytobesimilar,whichresults ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:27 in thefollowingobjectivefunction: min W?XW-Y?2 F+a?W?2,1+\u00df?W?2 F+?tr(W'X'LXW), (47) wheretr(W'X'LXW)is the graph regularization and ?balances the contribution of content in- formation andlink information forfeatureselection. 4.1.2 Feature Selection for Social Media Data (LinkedFS). Tang and Liu ( 2012a) investigate the feature selection problem on social media data by evaluating various social relations such as CoPost, CoFollowing, CoFollowed, and Following. These four types of relations are supported by social correlation theories such as homophily (McPherson et al. 2001) and social influence (MarsdenandFriedkin 1993).WeusetheCoPostrelationasanexampletoillustratehowtheserela- tionscanbeintegratedintofeatureselection.Let p={p1,p2,...,pN}bethepostsetand X?RN\u00d7d bethematrixrepresentationoftheseposts; Y?Rn\u00d7cdenotesthelabelmatrix; u={u1,u2,...,un} denotesthesetof nusersandtheirlinkinformationisencodedinanadjacencymatrix A;P?Rn\u00d7N denotestheuser-postrelationshipssuchthat P(i,j)=1ifuipostspj;otherwise,0.Tointegratethe CoPost relations among users into the feature selection framework, the authors propose to add a regularizationtermtoenforcethehypothesisthattheclasslabels(i.e.,topics)ofpostsbythesame useraresimilar,resultinginthefollowing objectivefunction: min W?XW-Y?2 F+a?W?2,1+\u00df? u?u? {pi,pj}?pu?X(i,:)W-X(j,:)W?2 2, (48) wherepudenotes the set of posts by user u. The parameter acontrols the sparsity of Win rows acrossallclasslabelsand \u00dfcontrolsthecontributionof theCoPostrelations. 4.1.3 Unsupervised Feature Selection for Linked Data. Linked Unsupervised Feature Selection (LUFS)(TangandLiu 2012b)isanunsupervisedfeatureselectionframeworkforlinkeddata.With- outlabelinformationtoassessfeaturerelevance,LUFSassumestheexistenceofpseudolabelsand usesY?Rn\u00d7cto denote the pseudo label matrix such that each row of Yhas only one nonzero entry. Also, LUFS assumes a linear mapping matrix W?Rd\u00d7cbetween feature XandY. First, to consider the constraints from link information, LUFS employs social dimension approach (Tang and Liu2009) to obtain the hidden factors Hthat incur the interdependency among instances. Then, according to the Linear Discriminative Analysis, within, between, and total hidden factor scatter matrices Sw,Sb,a n dStare defined as Sw=Y'Y-Y'FF'Y,Sb=Y'FF'Y,a n dSt=Y'Y,r e - spectively, where F=H(H'H)-1 2is the weighted hidden factor matrix. Considering the fact that instances with similar hidden factors are similar and instances with different hidden factors are dissimilar, the constraint from link information can be incorporated by maximizing tr((St)-1Sb). Second,totakeadvantageoffeatureinformation,LUFSobtainstheconstraintsbyspectralanalysis tominimize tr(Y'LY),whereListheLaplacianmatrixderivedfromfeatureaffinitymatrix S.With these,theobjectivefunction ofLUFS isformulated asfollows: min Wtr(Y'LY)-atr((St)-1Sb), (49) whereais a regularization parameter to balance the contribution from these two constraints. To achieve feature selection, LUFS further adds a l2,1-norm regularization term on W,a n dw i t h spectralrelaxationofthepseudo-classlabelmatrix,theobjectivefunctioninEquation( 49)canbe eventually representedas min Wtr(W'(X'LX+aX'(In-FF'))W)+\u00df?W?2,1 s.t.W'(X'X+?Id)W=Ic,(50) where\u00dfcontrolsthesparsityof Win rows and ?IdmakesX'X+?Idinvertible. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:28 J. Liet al. 4.1.4 RobustUnsupervisedFeatureSelectionforNetworkedData. LUFSperformsnetworkstruc- ture modeling and feature selection separately, and the feature selection heavily depends on the qualityofextractedlatentrepresentations.Inotherwords,theperformanceofLUFSwillbejeop- ardized when there are a lot of noisy links in the network. Li et al. ( 2016) propose a robust unsu- pervisedfeatureselectionframework(NetFS)toembedlatentrepresentationlearningintofeature selection.Specifically,let X?Rn\u00d7dandA?Rn\u00d7ndenotethefeaturematrixandadjacencymatrix, respectively.NetFSfirstuncoversalow-ranklatentrepresentation UbyasymmetricNMFmodel. Thelatentrepresentationdescribesasetofdiverseaffiliationfactorshiddeninanetwork,andin- stanceswithsimilarlatentrepresentationsaremorelikelytobeconnectedtoeachotherthanthe instanceswithdissimilarlatentrepresentations.Aslatentfactorsencodesomehiddenattributesof instances,theyshouldberelatedtosomefeatures.Thus,NetFStakes Uasaconstrainttoperform featureselectionvia min U=0,W?XW-U?2 F+a?W?2,1+\u00df 2?A-UU'?2 F, (51) whereaand\u00dfaretwobalanceparameters.Byembeddinglatentrepresentationlearningintofea- ture selection, these two phases could help and boost each other. Feature information can help learnbetterlatentrepresentationsthatarerobusttonoisylinks,andbetterlatentrepresentations canfillthegapoflimitedlabelinformationandrichlinkinformationtoguidefeatureselection.The authors further extended the NetFS model to the dynamic case to obtain a subset of relevant fea- turescontinuouslywhenboththefeatureinformationandnetworkstructureevolveovertime(Li et al.2016). In addition to positive links, many real-world networks also contain negative links, such as distrust relations in Epinions and foes in Slashdot. Based on NetFS, the authors in Cheng et al. (2017) further study if negative links have added value over positive links in finding more relevant features. 4.2 Multi-SourceFeature Selection For many learning tasks, we often have multiple data sources for the same set of data instances. Forexample,recentadvancementsinbioinformaticsrevealthatnon-codingRNAspeciesfunction acrossavarietyofbiologicalprocess.Thetaskofmulti-sourcefeatureselectioninthiscaseisfor- mulatedasfollows:Given msourcesofdatadepictingthesamesetof ninstances,andtheirmatrix representations X1?Rn\u00d7d1,X2?Rn\u00d7d2,...,Xm?Rn\u00d7dm(whered1,...,dmdenotethefeaturedi- mensions), select a subset of relevant features from a target source (e.g., Xi) by taking advantage of all information from msources. 4.2.1 Multi-Source Feature Selection via Geometry-Dependent Covariance Analysis (GDCOV). Tointegrateinformationfrommultiplesources, ZhaoandLiu( 2008)proposeanintuitivewayto learn a global geometric pattern from all sources that reflects the intrinsic relationships among instances(Lanckrietetal. 2004).Theyintroduceaconceptofgeometry-dependentcovariancethat enablestheusageoftheglobalgeometricpatternincovarianceanalysisforfeatureselection.Given multiple local geometric patterns in multiple affinity matrices Si,w h e r eidenotes the ith data source,aglobalpatterncanbeobtainedbylinearlycombiningallaffinitymatricesas S=?m i=1aiSi, whereaicontrols the contribution of the ith source. With the global geometric pattern obtained from multiple data sources, one can build a geometry-dependent sample covariance matrix for the target source XiasC=1 n-1?X' i(S-S11'S 1'S1)Xi?,w h e r e?is a diagonal matrix with ?(j,j)= ?D1 2Xi(:,j)?-1,a n dDisalso a diagonal matrixfrom SwithD(k,k)=?n j=1S(k,j). After getting a geometry-dependent sample covariance matrix, a subsequent question is how to use it effectively for feature selection. Basically, two methods are proposed. The first method, GPCOVvar sorts the diagonal of the covariance matrix and selects the features that have the ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:29 Fig.6. Differences between multi-sourceand multi-viewfeatureselection. highest variances. Selecting features based on this approach is equivalent to choosing features that are consistent with the global geometry pattern. The second method, GPCOVspca, applies SparsePrincipalComponentAnalysis(SPCA)(d\u2019Aspremontetal. 2007)toselectfeaturesthatcan retainthetotalvariancemaximally.Hence,itconsidersinteractionsamongfeaturesandcanselect featureswithlessredundancy. 4.3 Feature Selection Algorithmswith Multi-ViewData Multi-View data representdifferent facets of data instances in different feature spaces.These fea- ture spaces are naturally dependent and high-dimensional. Hence, the task of multi-view feature selection arises (Feng et al. 2013;T a n ge ta l . 2013;W a n ge ta l . 2013; Liu et al. 2016a), which aims to select features from different feature spaces simultaneously by using their relations. One mo- tivating example is to select relevant features in pixels, tags, and terms associated with images simultaneously. Since multi-view feature selection is designed to select features across multiple viewsbyusingtheirrelations,theyarenaturallydifferentfrommulti-sourcefeatureselection.The differencebetweenmulti-sourcefeatureselectionandmulti-viewfeatureselectionisillustratedin Figure6.Forsupervisedmulti-viewfeatureselection,themostcommonapproachisSparseGroup Lasso (Friedman et al. 2010;P e n ge ta l . 2010). In this subsection, we review some representative algorithms forunsupervisedmulti-view featureselection. 4.3.1 Adaptive Multi-View Feature Selection. Adaptive unsupervised multi-view feature se- lection (AUMFS) (Feng et al. 2013) takes advantages of the data cluster structure, the data similarity and the correlations among views simultaneously. Specifically, let X1?Rn\u00d7d1,X2? Rn\u00d7d2,...,X1?Rn\u00d7dmdenotethedescriptionof ninstancesfrom mdifferentviews,respectively, X=[X1,X2,...,Xm]?Rddenotes the concatenated data, where d=d1+d2+\u00b7\u00b7\u00b7+dm.A U M F S firstbuildsa featureselectionmodelby using l2,1-normregularizedleast squareslossfunction: min W,F?XW-F?2,1+a?W?2,1, (52) whereF?Rn\u00d7cisthepseudoclasslabelmatrix.The l2,1-normlossfunctionisimposed,sinceitis robusttooutliersand l2,1-normregularizationselectsfeaturesacrossall cpseudoclasslabelswith joint sparsity. Then AUMFS uses spectral clustering on an affinity matrix from different views to learn the shared pseudo class labels. For the data matrix Xiin each view, it first builds an affinity matrixSibased on the data similarity on that view and gets the corresponding Laplacian matrix Li.Thenitaimstolearnthepseudoclasslabelmatrixbyconsideringthespectralclusteringfrom ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:30 J. Liet al. allviews.IntegratingitwithEquation( 52),we havethefollowing objectivefunction: mintr/parenlefttpA /parenleftbtAF'm? i=1?iLiF/parenrighttpA /parenrightbtA+\u00df(?XW-F?2,1+a?W?2,1) s.t.F'F=Ic,F=0,m? i=1?i=1,?i=0.(53) wherethecontributionofeachviewforthejointspectralclusteringisbalancedbyanonnegative weight?iand the summation of all ?iequals 1. \u00dfis a parameter to balance the contribution of spectralclusteringand featureselection. 4.3.2 UnsupervisedFeatureSelectionforMulti-ViewData. AUMFS(Fengetal. 2013)learnsone featureweightmatrixforallfeaturesfromdifferentviewstoapproximatethepseudoclasslabels. Tangetal.( 2013)proposeanovelunsupervisedfeatureselectionmethodcalledMulti-ViewFeature Selection(MVFS).SimilarlytoAUMFS,MVFSusesspectralclusteringwiththeaffinitymatrixfrom different views to learn the pseudo class labels. It differs from AUMFS as it learns one feature weight matrix for each view to fit the pseudo class labels by the joint least squares loss and l2,1- normregularization.Theoptimization problemof MVFScanbeformulated asfollows: mintr/parenlefttpA /parenleftbtAF'm? i=1?iLiF/parenrighttpA /parenrightbtA+m? i=1\u00df(?XiWi-F?2,1+a?Wi?2,1) s.t.F'F=Ic,F=0,m? i=1?i=1,?i=0.(54) Theparameter ?iisemployed to controlthecontributionof eachviewand?m i=1?i=1. 4.3.3 Multi-ViewClusteringandFeatureLearningviaStructuredSparsity. Insomecases,features fromacertainviewcontainmorediscriminativeinformationthanfeaturesfromotherviews.One exampleisthatinimageprocessing,thecolorfeaturesaremoreusefulthanothertypesoffeatures in identifying stop signs. To address this issue in multi-view feature selection, a novel feature selection algorithm is proposed in Wang et al. ( 2013) with a joint group l1-norm andl2,1-norm regularization. For the feature weight matrix W1,...,Wmfrommdifferent views, the group l1-norm is de- finedas?W?G1=?c j=1?m i=1?Wi(:,j)?.Crucially,thegroup l1-normregularizationtermisableto capture the global relations among different views and is able to achieve viewwise sparsity such that only a few views are selected. In addition to group l1-norm, al2,1-norm regularizer on Wis also included to achieve feature sparsity among selected views. Hence, the objective function of theproposedmethodisformulated asfollows: min W,F?XW-F?2 F+a?W?2,1+\u00df?W?G1 s.t.F'F=Ic,F=0,(55) whereaand\u00dfareusedtocontrolinter-viewsparsityand intra-viewsparsity. Discussion: Feature selection algorithms for heterogeneous data can handle various types of data simultaneously.Byfusingmultipledatasourcestogether,theselectedfeaturesareabletocapturethe inherentcharacteristicsofdataandcouldbetterserveotherlearningproblemsonsuchdata.However, most of the proposed algorithms in this family use matrices to represent the data and often convert thefeatureselectionproblemintoanoptimizationalgorithm.Theresultedoptimizationproblemoften requires complex matrix operations which is computationally expensive and limits the scalability of ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:31 these algorithms for large-scale data. How to design efficient and distributed algorithms to speed up thecomputationisstilla fertilearea andneeds deeperinvestigation . 5 FEATURE SELECTIONWITH STREAMINGDATA Previousmethodsassumethatalldatainstancesandfeaturesareknowninadvance.However,itis not the case in many real-world applicationsthat we are more likely faced with data streams and featurestreams.Intheworstcases,thesizeofdataorfeaturesareunknownoreveninfinite.Thus it is not practical to wait until all data instances or features are available to perform feature se- lection.Forstreamingdata,onemotivatingexampleonlinespamemaildetectionproblem,where newemailsarecontinuouslyarriving;itisnoteasytoemploybatch-modefeatureselectionmeth- ods to select relevant features in a timely manner. On an orthogonal setting, feature selection for streaming features also has its practical significances. For example, Twitter produces more than 500milliontweetseveryday,andalargeamountofslangwords(features)arecontinuouslybeing generated.Theseslangwordspromptlygrabusers\u2019attentionandbecomepopularinashorttime. Therefore,itispreferredtoperformstreamingfeatureselectiontoadapttothechangesonthefly. Therearealsosomeattemptstostudythesetwodualproblemstogether,whichisreferredasfea- tureselectiononTrapezoidaldatastreams(Zhangetal. 2015).Wewillreviewsomerepresentative algorithms forthesetwoorthogonalproblems. 5.1 Feature Selection Algorithmswith Feature Streams Forthefeatureselectionproblemswithstreamingfeatures,thenumberofinstancesisconsidered to be constant while candidate features arrive one at a time; the task is to timely select a subset of relevant features from all features seen so far (Perkins and Theiler 2003;Z h o ue ta l . 2005;W u et al.2010;Y ue ta l . 2014;L ie ta l . 2015). At each time step, a typical streaming feature selection algorithm first determines whether to accept the most recently arrived feature; if the feature is added to the selected feature set, it then determines whether to discard some existing features. The process repeats until no new features show up anymore. Different algorithms have different implementations in the first step. The second step which checks existing features is an optional step. 5.1.1 Grafting Algorithm. The first attempt to perform streaming feature selection is credited to Perkins and Theiler ( 2003). Their method is based on a stagewise gradient descent regularized risk framework (Perkins et al. 2003). Grafting is a general technique that can deal with a variety of models that are parameterized by a feature weight vector wsubject tol1-norm regularization, suchasLasso. ThebasicideaofGraftingisbasedontheobservationthatincorporatinganewfeatureintothe Lasso model involves adding a new penalty term into the model. For example, at the time step j, when a new feature fjarrives, it incurs a regularization penalty of a|wj|. Therefore, the addition of the new feature fjreduces the objective function value in Lasso only when the reduction in the loss function part loss(w;X,y)outweighs the increase in the l1-norm regularization. With thisobservation,theconditionofacceptingthenewfeature fjis|?loss(w;X,y) ?wj|>a.Otherwise,the Graftingalgorithmwillsetthefeaturecoefficient wjofthenewfeature fjtobezero.Inthesecond step, when new features are accepted and included in the model, Grafting adopts a conjugate gradient (CG) procedure to optimize the model with respect to all current parameters to exclude some outdatedfeatures. 5.1.2 Alpha-Investing Algorithm. Alpha-investing (Zhou et al. 2005) is an adaptive complex- ity penalty method that dynamically changes the threshold of error reduction that is required to ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:32 J. Liet al. acceptanewfeature.Itismotivatedbyadesiretocontrolthefalsediscoveryrate(FDR)ofnewly arrived features, such that a small portion of spurious features do not affect the model\u2019s accu- racy significantly. The detailed algorithm works as follows: (1) it initializes w0=0 (probability of false positives), i=0 (index of features), and selected features in the model to be empty; (2) it setsai=wi/2iwhen a new feature arrives; (3) it sets wi+1=wi-aiifp_value(fi,SF)=ai;o r setwi+1=wi+a?-ai,SF=SF?fiifp_value(fi,SF)<ai.Thethreshold aicorrespondstothe probabilityofselectingaspuriousfeatureatthetimestep i.Itisadjustedbythewealth wi,which denotes the acceptable number of false positively detected features at the current moment. The wealthwiincreaseswhena feature is added tothe model. Otherwise,it decreaseswhen a feature isnotincludedtosaveforfuturefeatures.Moreprecisely,ateachtimestep,themethodcalculates thep- v a l u eb yu s i n gt h ef a c tt h a t ?Logliklohood is equivalent to t-statistics. The p-value denotes theprobabilitythatafeaturecoefficientcouldbesettononzerowhenitisnot(falsepositivelyde- tected).Thebasicideaofalpha-investingistoadaptivelyadjustthethresholdsuchthatwhennew featuresareselectedandincludedintothemodel,itallowsahigherchanceofincludingincorrect featuresinthefuture.Ontheotherhand,eachtimewhenanewfeatureisnotincluded,thewealth is wastedand lowers thechanceof findingmore spuriousfeatures. 5.1.3 Online Streaming Feature Selection Algorithm. Some other researchers study the stream- ingfeatureselectionproblemfromaninformation-theoreticperspective(Wuetal. 2010).Accord- ingtothedefinition,thewholefeaturesetconsistsoffourtypesoffeatures:irrelevant,redundant, weakly relevant but non-redundant, and strongly relevant features. An optimal feature selection should select non-redundant and strongly relevant features. But as features continuously arrive in a streaming fashion, it is difficult to find all strongly relevant and non-redundant features. The proposedmethod,OSFSisabletocapturethesenon-redundantandstronglyrelevantfeaturesvia twosteps:(1)onlinerelevanceanalysisand(2)onlineredundancyanalysis.Intheonlinerelevance analysis step, OSFS discovers weakly relevant and strongly relevant features, and these features are added into the best candidate features (BCF). Otherwise, if the newly arrived feature is not relevanttotheclasslabel,thenitisdiscardedandnotconsideredinfuturesteps.Inonlineredun- dancyanalysisstep,OSFSdynamicallyeliminatesredundantfeaturesintheselectedsubsetusing aMarkovBlanket.Foreachfeature fjinthebestcandidateset BCF,ifthereexistsasubsetof BCF makingfjand theclasslabelconditionallyindependent,then fjis removed from BCF. 5.1.4 Unsupervised Streaming Feature Selection in Social Media. The vast majority of stream- ingfeatureselectionmethodsaresupervised,whichmeanstheyutilizelabelinformationtoguide feature selection. However, in social media, it is easy to amass vast quantities of unlabeled data, while it is time and labor consuming to obtain labels. To deal with large-scale unlabeled data in social media, Li et al. ( 2015) propose the USFS algorithm to tackle unsupervised streaming fea- ture selection. The key idea of USFS is to utilize source information such as link information. USFS first uncovers hidden social factors from link information by mixed membership stochastic blockmodel(Airoldietal. 2009).Afterobtainingthesociallatentfactors ??Rn\u00d7kforeachlinked instance, USFS takes advantage of them as a constraint to perform selection. At a specific time stept,l e tX(t),W(t)denote the corresponding feature matrix and feature coefficient respectively. To model feature information, USFS constructs a graph Gto represent feature similarity and A(t) denotes the adjacency matrix of the graph, L(t)is the corresponding Laplacian matrix from X(t). Thentheobjectivefunctiontoachievefeatureselectionatthetime step tisgiven as follows: min W(t)1 2?X(t)W(t)-??2 F+ak? i=1?(w(t))i?1+\u00df 2?W(t)?2 F+? 2?(X(t)W(t))'(L(t))1 2?2 F,(56) ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:33 whereais a sparse regularization parameter, \u00dfcontrols the robustness of the model, and ?bal- ances link information and feature information. Assume at the next time step t+1 a new feature arrives, to test the new feature, and USFS takes a similar strategy as Grafting to perform gradi- ent test. Specifically, if the inclusion of the new feature is going to reduce the objective function in Equation ( 56), then the feature is accepted; otherwise, the new feature can be removed. When newfeaturesarecontinuouslybeinggenerated,someexistingfeaturesmaybecomeoutdated,and, therefore,USFSalsoinvestigatesifitisnecessarytoremoveanyexistingfeaturesbyre-optimizing themodelthroughaBFGS method(Boyd and Vandenberghe 2004). 5.2 Feature Selection Algorithmswith Data Streams Inthissubsection,wereviewtheproblemoffeatureselectionwithdatastreams,whichisconsid- ereda dualproblemof streamingfeatureselection. 5.2.1 Online Feature Selection. In Wang et al. ( 2014b), an online feature selection algorithm (OFS) for binary classification is proposed. Let {x1,x2,...,xt...}and{y1,y2,...,yt...}denote a sequence of input data instances and input class labels, respectively, where each data instance xi?Rdisinad-dimensionalspaceandclasslabel yi?{-1,+1}.ThetaskofOFSistolearnalinear classifier w(t)?Rdthatcanbeusedtoclassifyeachinstance xibyalinearfunctionsign( w(t)'xi). To achieve feature selection, it requires that the linear classifier w(t)has at most B-nonzero el- ements such that?w(t)?0=B. It indicates that at most Bfeatures will be used for classification. Witharegularizationparameter ?andastepsize ?,thealgorithmofOFSworksasfollows:(1)get anewdatainstance xtanditsclasslabel yt;(2)makeaclasslabelpredictionsign( w(t)'xt)forthe new instance; (3) if xtis misclassified such that yiw(t)'xt<0, then\u02dcwt+1=(1-??)wt+?ytxt, \u02c6wt+1=min{1,1/v ??\u02dcwt+1?2}\u02dcwt+1,a n dwt+1=Truncate (\u02c6wt+1,B);( 4 )wt+1=(1-??)wt.I np a r - ticular,eachtimewhenatraininginstance xtismisclassified, wtisfirstupdatedbyonlinegradient descentandthenitisprojectedtoa l2-normballtoensurethattheclassifierisbounded.Afterthat, the new classifier \u02c6wt+1is truncated by taking the most important Bfeatures. A subset of Bfea- turesisreturnedateachtimestep.Theprocessrepeatsuntiltherearenonewdatainstancesarrive anymore. 5.2.2 UnsupervisedFeatureSelectiononDataStreams. Totimelyselectasubsetofrelevantfea- tures when unlabeled data are continuously being generated, Huang et al. ( 2015)p r o po s ean o v e l unsupervised feature selection method (FSDS) with only one pass of the data and with limited storage. The basic idea of FSDS is to use matrix sketching to efficiently maintain a low-rank ap- proximationofthecurrentobserveddataandthenapplyregularizedregressiontoobtainthefea- ture coefficients, which can further be used to obtain the importance of features. The authors empirically show that when some orthogonality conditions are satisfied, the ridge regression can replace the Lasso for feature selection, which is more computationally efficient. Assume at a spe- cifictimestep t,X(t)?Rnt\u00d7ddenotesthedatamatrixatthattimestep,thefeaturecoefficientscan beobtainedby minimizing thefollowing: min W(t)?B(t)W(t)-{e1,...,ek}?2 F+a?W(t)?2 F, (57) whereB(t)?Rl\u00d7ddenote the sketching matrix of X(t)(l\u00abnt),ei?Rlis a vector with its ith location as 1 and other locations as 0. By solving the optimization problem in Equation ( 57), the importanceofeachfeature fiisscore(j)=maxi|W(t)(j,i)|.Thehigherthefeaturescore,themore importantthefeatureis. Discussion:As data are oftennot staticand are generated ina streamingfashion,feature selection algorithms for both feature and data streams are often more desired in practical usage. Most of the ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:34 J. Liet al. existingalgorithmsinthisfamilyemployvariousstrategiestospeeduptheselectionprocesssuchthat it can deal with new data samples or new features on the arrival. However, it should be mentioned that most of these algorithms require multiple pass of the data and some even need to store all the historicallygenerateddata,whichjeopardizestheusageofthesealgorithmswhenweonlyhavelimited memory or disk storage. It requires further efforts to design streaming algorithms that are effective and efficientwithlimitedstoragecosts . 6 PERFORMANCE EVALUATION Wefirstintroduceoureffortsindevelopinganopen-sourcefeatureselectionrepository.Thenwe usealgorithmsincludedintherepositoryasanexampletoshowhowtoevaluatedifferentfeature selectionalgorithms. 6.1 Feature Selection Repository First, we introduce our attempt in developing a feature selection repository\u2014 scikit-feature .T h e purpose of this feature selection repository is to collect some widely used feature selection algo- rithms that have been developed in the feature selection research to serve as a platform to facili- tatetheirapplication,comparison,andjointstudy.Thefeatureselectionrepositoryalsoeffectively assists researchers to achieve more reliable evaluation in the process of developing new feature selectionalgorithms. Wedeveloptheopensourcefeatureselectionrepository scikit-feature byoneofthemostpopular programminglanguages\u2014python.Itcontainsaround40popularfeatureselectionalgorithms.Itis builtononewidelyusedmachine-learningpackage scikit-learn andtwoscientificcomputingpack- ages,NumpyandScipy.Atthesametime,wealsomaintainawebsite( http://featureselection.asu. edu/)forthisprojectwhichoffersseveralsourcessuchaspublicallyavailablebenchmarkdatasets, performanceevaluationofalgorithms,andtestcasestoruneachalgorithm.Thesourcecodeofthis repository is available at Github ( https://github.com/jundongl/scikit-feature ). An interactive tool oftherepositoryisalsoavailable(Chengetal. 2016).Wewelcomeresearchersinthiscommunity to contributealgorithmsand datasetstoourrepository. 6.2 EvaluationMethodsand Metrics As an example, we empirically show how to evaluate the performance of feature selection algo- rithms in the repository. The experimental results can be obtained from our repository project website(http://featureselection.asu.edu/datasets.php ).Inourprojectwebsite,foreachdataset,we list all applicable feature selection algorithms along with its evaluation on either classification or clustering. Next, we will provide detailed information about how these algorithms are evaluated, includingevaluationcriteriaandexperimentalsetup.Differentfeatureselectionalgorithmscanbe categorized by the following two criteria: (1) labels: supervised or unsupervised; (2) output: fea- tureweightingorsubsetselection.Thefirstcriteriondetermineswhetherweneedtousethelabel informationtoperformfeatureselectionornot.Thesecondcriterioncategorizesthesealgorithms basedontheoutput.Featureweighingalgorithmsgiveeachfeatureascoreforrankingandfeature subsetalgorithmsonly showwhichfeaturesare selected. Next,weintroducethewidelyadoptedwaytoevaluatetheperformanceoffeatureselectional- gorithms.Wehavedifferentevaluationmetricsforsupervisedandunsupervisedmethods.Fordif- ferentoutputtypes,differentevaluationstrategiesareused:(1)Ifitisafeatureweightingmethod that outputs the feature scores, then the quality of the first {5,10,15,...,295,300}features are evaluated respectively; (2) if it is a feature subset selection method that only outputs which fea- turesareselected,thenwe usealltheselectedfeaturestoperformtheevaluation. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:35 Supervised Methods . To test the performance of supervised feature selection algorithms, we divide the whole dataset into two parts: the training set Tand test setU. Feature selection algorithmswillbefirstappliedtothetrainingset Ttoobtainasubsetofrelevantfeatures S.Then the test set on the selected features acts as input to a classification model for the testing purpose. In the experiments, we use classification accuracy to evaluate the classification performance and three classification models, Linear SVM, Decision Tree, and Na\u00efve Bayes are used. To get more reliable results, 10-fold cross-validation is used. Normally, the higher the classification performance,thebettertheselectedfeaturesare. Unsupervised Methods . Following the standard way to assess unsupervised feature selection, we evaluate unsupervised algorithms in terms of clustering performance. Two commonly used clusteringperformancemetrics(Caietal. 2010),thatis,normalizedmutualinformation (NMI)and accuracy (ACC), are used. Each feature selection algorithm is first applied to select features; then k-meansclusteringisperformedbasedontheselectedfeatures.Werepeatthe k-meansalgorithm 20timesandreporttheaverageclusteringresults,since k-meansmayconvergetoalocaloptimal. Thehighertheclusteringperformance,thebettertheselectedfeaturesare. We also list the following information of main algorithms reviewed in this article in Table 2: (1) the type of data: conventional data or other types of data; (2) usage of labels: supervised or unsupervised1; (3) output: feature weighting or subset selection; (4) feature type: numerical vari- ables or discrete variables (numerical variables can also be divided into continuous variables and discrete variables). For supervised feature selection methods, we also list if the methods are de- signed to tackle binary-class or multi-class classification problems. Based on the aforementioned information, the practitioners can have a more intuitive sense about the applicable scenarios of differentmethods. 7 OPEN PROBLEMSANDCHALLENGES Since the mid-1990s, there has been a significant number of attempts in developing feature selec- tionalgorithmsforboththeoreticalanalysisandreal-worldapplications.However,westillbelieve thereismoreworkthatcanbedoneinthisfield.Hereareseveralchallengesandconcernsthatwe needtomention and discuss. 7.1 Scalability With the tremendous growth in the size of data, the scalability of most current feature selection algorithms may be jeopardized. In many scientific and business applications, data are usually measured in terabyte (1TB =1012bytes). Normally, datasets in the scale of terabytes cannot be loaded into the memory directly and therefore limits the usability of most feature selection algorithms. Currently, there are some attempts to use distributed programming frameworks to perform parallel feature selection for large-scale datasets (Singh et al. 2009; Zhao et al. 2013; Yamada et al. 2014; Zadeh et al. 2017). In addition, most of the existing feature selection methods have a time complexity proportional to O(d2)or evenO(d)3,w h e r edis the feature dimension. Recently,big data of ultrahigh-dimensionality has emerged in many real-world applicationssuch as text mining and information retrieval. Most feature selection algorithms do not scale well on the ultrahigh-dimensional data whose efficiency deteriorates quickly or is even computationally infeasible. In this case, well-designed feature selection algorithms in linear or sublinear running time are preferred (Fan et al. 2009; Tan et al. 2014). Moreover, in some online classification or online clustering tasks, the scalability of feature selection algorithms is also a big issue. For 1Feature selection for regression can also be regarded as a supervised method, and here we focus on feature selection for classificationproblems. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:36 J. Liet al.Table 2. Detailed Informationof Main Feature Selection AlgorithmsReviewed in theArticle Data MethodsSupervision Output ofFeatures Feature Type Binary Multi-class Unsupervised Ranking SubsetNumerical Categorical Continuous Discrete Conventional\u2013FlatFeaturesFisher Score(Duda et al.2012) ? ? ? ? ? ReliefF (Robnik-Sikonjaand Kononenko2003) ? ? ? ? ? TraceRatio(Nie et al.2008) ? ? ? ? ? LaplacianScore(Heet al.2005) ? ? ? ? SPEC(Zhaoand Liu2007) ? ? ? ? ? ? MIM (Lewis 1992) ? ? ? ? ? MIFS(Battiti1994) ? ? ? ? ? MRMR (Peng etal.2005) ? ? ? ? ? CIFE(Lin and Tang2006) ? ? ? ? ? JMI(Meyer et al.2008) ? ? ? ? ? CMIM(Fleuret 2004) ? ? ? ? ? IF (Vidal-Naquetand Ullman 2003) ? ? ? ? ? ICAP(Jakulin2005) ? ? ? ? ? DISR(Meyer andBontempi 2006) ? ? ? ? ? FCBF(Yuand Liu2003) ? ? ? ? ? lp-regularized (Liuet al.2009b) ? ? ? ? lp,q-regularized (Liu et al.2009b) ? ? ? ? REFS(Nieet al.2010) ? ? ? ? ? MCFS(Cai et al.2010) ? ? ? ? UDFS (Yanget al. 2011) ? ? ? ? NDFS(Li et al.2012) ? ? ? ? LowVariance (Pedregosa et al.2011) ? ? ? ? T-score(Davis and Sampson1986) ? ? ? ? Chi-square(Liuand Setiono1995) ? ? ? ? ? Gini(Gini 1912) ? ? ? ? ? CFS(Halland Smith1999) ? ? ? ? ? (Continued) ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:37 Table 2. (Continued) Data MethodsSupervision Output of Features Feature Type Binary Multi-class Unsupervised Ranking SubsetNumerical Categorical Continuous Discrete Conventional\u2013Structured FeatureGroupLasso ? ? ? ? Sparse GroupLasso (Friedman et al.2010) ? ? ? ? Tree Lasso(Liu and Ye2010) ? ? ? ? Graph Lasso (Yeand Liu 2012) ? ? ? ? GFLasso (Kimand Xing 2009) ? ? ? ? GOSCAR(Yanget al.2012) ? ? ? ? Linked DataFSNet(Guand Han2011) ? ? ? ? ? LinkedFS (Tangand Liu2012a) ? ? ? ? ? LUFS (TangandLiu 2012b) ? ? ? ? NetFS (Lieal.2016) ? ? ? ? Multi-Source GDCOV(Zhaoand Liu2008) ? ? ? ? Multi-ViewAUMFS(Fenget al.2013) ? ? ? ? MVFS (Tanget al.2013) ? ? ? ? StreamingFeatureGrafting (Perkins and Theiler 2003) ? ? ? ? Alpha-Investing(Zhouet al.2005) ? ? ? ? OSFS(Wu et al.2010) ? ? ? ? USFS (Li etal.2015) ? ? ? ? Streaming DataOFS(Wang et al.2014b) ? ? ? ? FSDS (Huanget al.2015) ? ? ? ? ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:38 J. Liet al. example, the data streams or feature streams may be infinite and cannot be loaded into the memory,hencewecanonlymakeonepassofthedatawherethesecondpassiseitherunavailable or computationally expensive. Even though feature selection algorithms can reduce the issue of scalability for online classification or clustering, these methods either require to keep all features in the memory or require iterative processes to visit data instances more than once, which limits their practical usage. In conclusion, even though there is some preliminary work to increase the scalability of feature selection algorithms, we believe that more focus should be given to the scalabilityproblemtokeepingpacewiththerapidgrowthofverylarge-scaleandstreamingdata. 7.2 Stability For supervised feature selection algorithms, their performance is usually evaluated by the clas- sification accuracy. In addition to accuracy, the stability of these algorithms is also an important considerationwhendevelopingnewfeatureselectionalgorithms.Itisdefinedasthesensitivityof a feature selection algorithm to perturbation in the training data (Kalousis et al. 2007;H ea n dY u 2010; Saeys et al. 2008; Loscalzo et al. 2009; Yang and Mao 2011). The perturbation of data could be in various format such as addition/deletion of data samples and the inclusion of noisy/outlier samples. More rigorous definition on the stability of feature selection algorithms can be referred toKalousisetal.( 2007).Thestabilityoffeatureselectionalgorithmshassignificantimplicationsin practiceasitcanhelpdomainexpertsgainmoreconfidenceontheselectedfeatures.Amotivating example in bioinformatics indicates that domain experts would like to see the same set or similar setofgenes(features)selectedeachtimewhentheyobtainnewdatasamples.Otherwise,domain expertswouldnottrustthesealgorithmsandmayneverusethemagain.Itisobservedthatmany well-knownfeatureselectionalgorithmssufferfromthelowstabilityproblemafterthesmalldata perturbationisintroducedinthetrainingset.ItisalsofoundinAlelyanietal.( 2011)thattheunder- lyingcharacteristicsofdatamaygreatlyaffectthestabilityoffeatureselectionalgorithmsandthe stabilityissuemayalsobedatadependent.Thesefactorsincludethedimensionalityofthefeature, the number of data instances, and so on. In contrast to supervised feature selection, the stability of unsupervised feature selection algorithms has not been well studied yet. Studying stability for unsupervised feature selection is much more difficult than that of the supervised methods. The reason is that in unsupervised feature selection, we do not have enough prior knowledge about the cluster structure of the data. Thus, we are uncertain that if the new data instance, that is, the perturbation belongs to any existing clusters or will introduce new clusters. While in supervised featureselection,wehavepriorknowledgeaboutthelabelofeachdatainstance,andanewsample that does not belong to any existing classes will be considered as an outlier and we do not need to modify the selected feature set to adapt to the outliers. In other words, unsupervised feature selectionismore sensitivetonoise andthenoisewillaffectthestabilityof thesealgorithms. 7.3 ModelSelection For most feature selection algorithms especially for feature weighting methods, we have to spec- ify the number of selected features. However, it is often unknown what is the optimal number of selected features. A large number of selected features will increase the risk in including noisy, redundant,andirrelevantfeatures,whichmayjeopardizethelearningperformance.Ontheother hand, it is also not good to include too-small a number of selected features, since some relevant featuresmaybeeliminated.Inpractice,weusuallyadoptaheuristicwaytogridsearchthenumber ofselectedfeaturesandpickthenumberthathasthebestclassificationorclusteringperformance, but the whole process is computationally expensive. It is still an open and challenging problem to determine the optimal number of selected features. In addition to the optimal number of se- lectedfeatures,wealsoneedtospecifythenumberofclustersorpseudoclassesforunsupervised ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:39 feature selection algorithms. In real-world problems, we usually have limited knowledge about the clustering structure of the data. Choosing different numbers of clusters may merge totally different small clusters into one big cluster or split one big cluster into smaller ones. As a conse- quence, it may result in finding totally different subsets of features. Some work has been done to estimatethesetrickyparameters.Forinstance,inTibshiranietal.( 2001),aprincipledwaytoesti- mate the number of suitable clusters in a dataset is proposed. However, it is still not clear how to find the best number of clusters directly for unsupervised feature selection. All in all, we believe thatthemodelselectionis animportantissueandneedsdeeperinvestigation. 8 CONCLUSION Featureselectionis effective in preprocessingdata and reducingdata dimensionality.Meanwhile, itisessentialtosuccessfuldata-miningandmachine-learningapplications.Ithasbeenachalleng- ingresearchtopicwithpracticalsignificanceinmanyareassuchasstatistics,patternrecognition, machine learning, and data mining (including web, text, image, and microarrays). The objectives of feature selection include building simpler and more comprehensive models, improving data- miningperformance,andhelpingpreparecleanandunderstandabledata.Thepastfewyearshave witnessed the development of many new feature selection methods. This survey article aims to provideacomprehensivereviewaboutrecentadvancesinfeatureselection.Wefirstintroduceba- sicconceptsoffeatureselectionandemphasizetheimportanceofapplyingfeatureselectionalgo- rithmstosolvepracticalproblems.Thenweclassifyconventionalfeatureselectionmethodsfrom thelabelperspectiveandtheselectionstrategyperspective.Ascurrentcategorizationcannotmeet therapiddevelopmentoffeatureselectionresearchespeciallyintheeraofbigdata,weproposeto review recent advances in feature selection algorithms from a data perspective. In particular, we surveyfeatureselectionalgorithmsinfourparts:(1)featureselectionwithconventionaldatawith flatfeatures;(2)featureselectionwithstructuredfeatures;(3)featureselectionwithheterogeneous data; and (4) feature selection with streaming data. Specifically, we further classify conventional featureselectionalgorithmsforconventionaldata(flatfeatures)intosimilarity-based,information- theoretical-based, sparse-learning-based, and statistical-based methods, and other types of meth- ods according to the used techniques. For feature selection with structured features, we consider three types of structured features, namely group, tree, and graph features. The third part studies featureselectionwithheterogeneousdata,includingfeatureselectionwithlinkeddataandmulti- source and multi-view feature selection. The last part consists of feature selection algorithms for streamingdataandstreamingfeatures.Weanalyzetheadvantagesandshortcomingsofthesedif- ferent types of feature selection algorithms. To facilitate the research on feature selection, this surveyisaccompaniedbyafeatureselectionrepository, scikit-feature ,whichincludessomeofthe mostpopularfeatureselectionalgorithmsthathavebeendevelopedinthepastfewdecades.Some suggestions are given on how to evaluate these feature selection algorithms, either supervised or unsupervisedmethods.Attheendofthesurvey,wepresentsomeopenproblemsthatrequirefu- tureresearch.Italsoshouldbementionedthattheaimofthesurveyisnottoclaimthesuperiority of some feature selection algorithms over others but to provide a comprehensive structured list of recent advances in feature selection algorithms from a data perspectiveand a feature selection repositoryto promotetheresearchin thiscommunity. REFERENCES ThomasAbeel,ThibaultHelleputte,YvesVandePeer,PierreDupont,andYvanSaeys.2010.Robustbiomarkeridentification forcancer diagnosis withensemblefeatureselectionmethods. Bioinformatics 26,3 (2010),392\u2013398. EdoardoM.Airoldi,DavidM.Blei,StephenE.Fienberg,andEricP.Xing.2009.Mixedmembershipstochasticblockmodels. InNIPS.33\u201340. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:40 J. Liet al. Salem Alelyani, Huan Liu,and LeiWang.2011.The effect of the characteristics of thedataseton the selection stability.In ICTAI.970\u2013977. Salem Alelyani, Jiliang Tang, and Huan Liu. 2013. Feature selection for clustering: A review. Data Clustering: Algorithms and Applications 29(2013). JunChinAng,AndriMirzal,HabibollahHaron,andHazaNuzlyAbdullHamed.2016.Supervised,unsupervised,andsemi- supervised featureselection:A review on geneselection. IEEE/ACMTCBB 13,5(2016),971\u2013989. HiromasaArai,CrystalMaung,KeXu,andHaimSchweitzer.2016.Unsupervisedfeatureselectionbyheuristicsearchwith provablebounds on suboptimality.In AAAI.666\u2013672. FrancisR.Bach.2008.Consistencyofthegrouplassoandmultiplekernellearning. J.Mach.Learn.Res. 9(2008),1179\u20131225. LarsBackstromandJureLeskovec.2011.Supervisedrandomwalks:Predictingandrecommendinglinksinsocialnetworks. InWSDM.635\u2013644. RobertoBattiti.1994.Usingmutualinformationforselectingfeaturesinsupervisedneuralnetlearning. IEEETrans.Neural Network. 5,4(1994),537\u2013550. MustafaBilgic,LilyanaMihalkova,andLise Getoor.2010.Active learningfornetworked data.In ICML.79\u201386. Stephen BoydandLievenVandenberghe.2004. ConvexOptimization . CambridgeUniversity Press. GavinBrown,AdamPocock,Ming-JieZhao,andMikelLuj\u00e1n.2012.Conditionallikelihoodmaximisation:Aunifyingframe- work for information-theoretic featureselection. J.Mach. Learn.Res. 13,1(2012),27\u201366. DengCai,Chiyuan Zhang,andXiaofeiHe. 2010.Unsupervised featureselection for multi-clusterdata.In KDD.333\u2013342. XiaoCai,FeipingNie,andHengHuang.2013.Exacttop-kfeatureselectionvia l2,0-normconstraint.In IJCAI.1240\u20131246. GirishChandrashekarandFeratSahin.2014.Asurveyonfeatureselectionmethods. Comput.Electr.Eng. 40,1(2014),16\u201328. XiaojunChang,FeipingNie,YiYang,andHengHuang.2014.Aconvexformulationforsemi-supervisedmulti-labelfeature selection.In AAAI.1171\u20131177. ChenChen,HanghangTong,LeiXie,LeiYing,andQingHe.2016.FASCINATE:Fastcross-layerdependencyinferenceon multi-layerednetworks. In KDD.765\u2013774. KeweiCheng,JundongLi,andHuanLiu.2016.FeatureMiner:Atoolforinteractivefeatureselection.In CIKM.2445\u20132448. KeweiCheng,JundongLi,andHuanLiu.2017.Unsupervisedfeatureselectioninsignedsocialnetworks.In KDD.777\u2013786. Alexandre d\u2019Aspremont, Laurent El Ghaoui, Michael I. Jordan, and Gert R. G. Lanckriet. 2007. A direct formulation for sparse PCA usingsemidefiniteprogramming. SIAMRev. 49,3(2007),434\u2013448. John C.DavisandRobert J.Sampson.1986. Statistics andData Analysisin Geology .Vol. 646.Wiley.NewYork. ChrisDing,DingZhou,XiaofengHe,andHongyuanZha.2006.R1-PCA:Rotationalinvariant l1-normprincipalcomponent analysisfor robust subspacefactorization. In ICML.281\u2013288. LiangDuandYi-Dong Shen. 2015.Unsupervised featureselectionwithadaptivestructure learning.In KDD.209\u2013218. LiangDu,ZhiyongShen,XuanLi,PengZhou,andYi-DongShen.2013.Localandglobaldiscriminativelearningforunsu- pervisedfeatureselection.In ICDM.131\u2013140. Richard O.Duda,Peter E.Hart, andDavidG.Stork. 2012. Pattern Classification . John Wiley& Sons. Janusz Dutkowski andAnnaGambin.2007.Onconsensus biomarker selection. BMC Bioinform. 8,5(2007),S5. AliElAkadi,AbdeljalilElOuardighi,andDrissAboutajdine.2008.Apowerfulfeatureselectionapproachbasedonmutual information. Int.J.Comput.Sci. Netw.Secur. 8,4(2008),116. JianqingFan,RichardSamworth,andYichaoWu.2009.Ultrahighdimensionalfeatureselection:Beyondthelinearmodel. J.Mach. Learn.Res. 10(2009),2013\u20132038. AhmedK.Farahat,AliGhodsi,andMohamedS.Kamel.2011.Anefficientgreedymethodforunsupervisedfeatureselection. InICDM.161\u2013170. Christiane Fellbaum.1998. WordNet.WileyOnlineLibrary. Yinfu Feng, Jun Xiao, Yueting Zhuang, and Xiaoming Liu. 2013. Adaptive unsupervised multi-view feature selection for visual conceptrecognition.In ACCV.343\u2013357. Fran\u00e7ois Fleuret.2004.Fastbinary featureselectionwithconditional mutualinformation. JMLR5(2004),1531\u20131555. Jerome Friedman, Trevor Hastie, and Robert Tibshirani. 2010. A note on the group lasso and a sparse group lasso. arXiv preprint arXiv:1001.0736 (2010). Keinosuke Fukunaga. 2013. Introduction toStatistical Pattern Recognition . AcademicPress. Shuyang Gao, Greg Ver Steeg, and Aram Galstyan. 2016. Variational information maximization for feature selection. In NIPS.487\u2013495. C. W. Gini. 1912. Variability and mutability, contribution to the study of statistical distribution and relaitons. Studi Economico-Giuricici DellaR (1912). DavidE. Golberg.1989.Geneticalgorithms insearch, optimization,andmachinelearning.Addison-Wesley. Quanquan Gu, Marina Danilevsky, Zhenhui Li, and Jiawei Han. 2012. Locality preserving feature learning. In AISTATS. 477\u2013485. Quanquan GuandJiaweiHan.2011.Towards featureselection innetwork. In CIKM.1175\u20131184. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:41 QuanquanGu,Zhenhui Li,and JiaweiHan.2011a.Correlated multi-labelfeatureselection.In CIKM.ACM, 1087\u20131096. QuanquanGu,Zhenhui Li,and JiaweiHan.2011b.Generalized fisher score for featureselection.In UAI. 266\u2013273. QuanquanGu,Zhenhui Li,and JiaweiHan.2011c.Jointfeatureselection andsubspacelearning.In IJCAI.1294\u20131299. Baofeng Guo and Mark S. Nixon. 2009. Gait feature subset selection by mutual information. IEEE TMSC(A) 39, 1 (2009), 36\u201346. IsabelleGuyon andAndr\u00e9 Elisseeff. 2003.An introduction to variableandfeatureselection. JMLR3(2003),1157\u20131182. IsabelleGuyon,SteveGunn,MasoudNikravesh,andLoftiAZadeh.2008. FeatureExtraction:FoundationsandApplications . Springer. Mark A. Hall and Lloyd A. Smith. 1999. Feature selection for machine learning: Comparing a correlation-based filter ap- proachto the wrapper.In FLAIRS.235\u2013239. Satoshi HaraandTakanori Maehara.2017.Enumeratelasso solutions forfeatureselection. In AAAI.1985\u20131991. Trevor Hastie, Robert Tibshirani, Jerome Friedman, and James Franklin. 2005. The elements of statistical learning: Data mining,inferenceandprediction. Math.Intell. 27,2(2005),83\u201385. XiaofeiHe, DengCai,andParthaNiyogi. 2005.Laplacianscore forfeatureselection. In NIPS.507\u2013514. Zengyou He and Weichuan Yu. 2010. Stable feature selection for biomarker discovery. Comput. Biol. Chem. 34, 4 (2010), 215\u2013225. Chenping Hou, Feiping Nie, Dongyun Yi, and Yi Wu. 2011. Feature selection via joint embedding learning and sparse regression. In IJCAI.1324\u20131329. Xia Hu, Jiliang Tang, Huiji Gao, and Huan Liu. 2013. ActNeT: Active learning for networked texts in microblogging. In SDM.306\u2013314. Hao Huang, Shinjae Yoo, and S Kasiviswanathan. 2015. Unsupervised feature selection on data streams. In CIKM. 1031\u2013 1040. JunzhouHuang,TongZhang,andDimitrisMetaxas.2011.Learningwithstructuredsparsity. J.Mach.Learn.Res. 12(2011), 3371\u20133412. Laurent Jacob, Guillaume Obozinski, and Jean-Philippe Vert. 2009. Group lasso with overlap and graph lasso. In ICML. 433\u2013440. Aleks Jakulin. 2005. Machine Learning Based onAttribute Interactions .Ph.D. Dissertation.Univerza vLjubljani. RodolpheJenatton,Jean-YvesAudibert,andFrancisBach.2011.Structuredvariableselectionwithsparsity-inducingnorms. J.Mach.Learn. Res. 12(2011),2777\u20132824. Rodolphe Jenatton, Julien Mairal, Francis R. Bach, and GuillaumeR. Obozinski. 2010. Proximal methods for sparse hierar- chicaldictionary learning.In ICML.487\u2013494. LingJian,Jundong Li,KaiShu, andHuan Liu.2016.Multi-labelinformed featureselection. In IJCAI.1627\u20131633. Yi JiangandJiangtaoRen.2011.Eigenvaluesensitivefeatureselection. In ICML.89\u201396. Alexandros Kalousis, Julien Prados, and Melanie Hilario. 2007. Stability of feature selection algorithms: A study on high- dimensionalspaces. Knowl.Inf. Syst. 12,1(2007),95\u2013116. SeyoungKimandEricPXing.2009.Statisticalestimationofcorrelatedgenomeassociationstoaquantitativetraitnetwork. PLoSGenet. 5,8(2009). Seyoung Kim and Eric P Xing. 2010. Tree-guided group lasso for multi-task regression with structured sparsity. In ICML. 543\u2013550. KenjiKira andLarry A. Rendell.1992.Apracticalapproachto featureselection. In ICMLWorkshop .249\u2013256. RonKohavi andGeorgeH. John. 1997.Wrappersfor featuresubset selection. Artif. Intell. 97,1(1997),273\u2013324. DaphneKoller andMehran Sahami.1995.Towardoptimalfeatureselection. In ICML.284\u2013292. Gert R. G. Lanckriet, Nello Cristianini, Peter Bartlett, Laurent El Ghaoui, and Michael I. Jordan. 2004. Learning the kernel matrixwithsemidefiniteprogramming. J.Mach. Learn.Res. 5 (2004),27\u201372. David D. Lewis. 1992. Feature selection and feature extraction for text categorization. In Proceedings of the Workshop on Speech and Natural Language . 212\u2013217. JundongLi,HarshDani,XiaHu,andHuanLiu.2017.Radar:Residualanalysisforanomalydetectioninattributednetworks. InIJCAI.2152\u20132158. JundongLi,XiaHu,LingJian,andHuanLiu.2016.Towardtime-evolvingfeatureselectionondynamicnetworks.In ICDM. 1003\u20131008. JundongLi,XiaHu,JiliangTang,andHuanLiu.2015.Unsupervised streamingfeatureselectioninsocialmedia.In CIKM. 1041\u20131050. Jundong Li, Xia Hu, Liang Wu, and Huan Liu. 2016. Robust unsupervised feature selection on networked data. In SDM. 387\u2013395. Jundong LiandHuan Liu.2017.Challengesof featureselection forbigdataanalytics. IEEEIntell.Syst. 32,2(2017),9\u201315. Jundong Li, Jiliang Tang, and Huan Liu. 2017a. Reconstruction-based unsupervised feature selection: An embedded ap- proach.In IJCAI.2159\u20132165. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:42 J. Liet al. Jundong Li,LiangWu, OsmarR.Za\u00efane,and HuanLiu.2017b.Towardpersonalized relationallearning.In SDM.444\u2013452. Yifeng Li, Chih-Yu Chen, and Wyeth W. Wasserman. 2015. Deep feature selection: Theory and application to identify enhancers andpromoters. In RECOMB.205\u2013217. Zechao Li, Yi Yang, Jing Liu, Xiaofang Zhou, and Hanqing Lu. 2012. Unsupervised feature selection using nonnegative spectralanalysis. In AAAI.1026\u20131032. DavidLiben-NowellandJonKleinberg.2007.Thelink-predictionproblemforsocialnetworks. J.AssistInf.Sci.Technol. 58, 7(2007),1019\u20131031. Dahua Lin and Xiaoou Tang. 2006. Conditional infomax learning: An integrated framework for feature extraction and fusion. In ECCV.68\u201382. Hongfu Liu,Haiyi Mao,andYun Fu. 2016a.Robust multi-viewfeatureselection. In ICDM.281\u2013290. Huan LiuandHiroshi Motoda.2007. Computational Methods ofFeature Selection . CRCPress. Huan LiuandRudy Setiono. 1995.Chi2: Feature selectionand discretization of numeric attributes.In ICTAI.388\u2013391. Hongfu Liu,MingShao, and Yun Fu. 2016b.Consensus guidedunsupervised featureselection. In AAAI.1874\u20131880. Jun Liu, Shuiwang Ji, and Jieping Ye. 2009a. Multi-task feature learning via efficient l2,1-norm minimization. In UAI. 339\u2013 348. Jun Liu, Shuiwang Ji, and Jieping Ye. 2009b. SLEP: Sparse Learning with Efficient Projections . Arizona State University. Re- trievedfrom http://www.public.asu.edu/ ~jye02/Software/SLEP . Jun LiuandJiepingYe. 2010.Moreau-Yosida regularizationfor grouped tree structure learning.In NIPS.1459\u20131467. XinwangLiu, LeiWang,JianZhang,JianpingYin, andHuan Liu. 2014.Globalandlocal structure preservation for feature selection. Trans. Neur.Netw.Learn. Syst. 25,6(2014),1083\u20131095. Bo Long, Zhongfei Mark Zhang, Xiaoyun Wu, and Philip S. Yu. 2006. Spectral clustering for multi-type relational data. In ICML.585\u2013592. BoLong,ZhongfeiMarkZhang,andPhilipSYu.2007.Aprobabilisticframeworkforrelationalclustering.In KDD.470\u2013479. Steven Loscalzo,LeiYu, andChris Ding.2009.Consensus group stablefeatureselection. In KDD.567\u2013576. Shuangge Ma, Xiao Song, and Jian Huang. 2007. Supervised group Lasso with applications to microarray data analysis. BMC Bioinf. 8,1(2007),60. Sofus A Macskassy and Foster Provost. 2007. Classification in networked data: A toolkit and a univariate case study. J. Mach. Learn.Res. 8(2007),935\u2013983. PeterV.MarsdenandNoahEFriedkin.1993.Networkstudiesofsocialinfluence. Sociol.MethodsRes. 22,1(1993),127\u2013151. Mahdokht Masaeli, Yan Yan, Ying Cui, Glenn Fung, and Jennifer G. Dy. 2010. Convex principal feature selection. In SDM. 619\u2013628. Crystal Maungand Haim Schweitzer. 2013.Pass-efficient unsupervised featureselection.In NIPS.1628\u20131636. JamesMcAuley,JiMing,DarrylStewart,andPhilipHanna.2005.Subbandcorrelationandrobustspeechrecognition. IEEE Trans.Speech AudioProcess. 13,5(2005),956\u2013964. MillerMcPherson,LynnSmith-Lovin,andJamesMCook.2001.Birdsofafeather:Homophilyinsocialnetworks. Ann.Rev. Sociol.(2001),415\u2013444. LukasMeier,SaraVanDeGeer,andPeterB\u00fchlmann.2008.Thegrouplassoforlogisticregression. J.Roy .Stat.Soc.B 70,1 (2008),53\u201371. Patrick E. Meyer and Gianluca Bontempi. 2006. On the use of variable complementarity for feature selection in cancer classification.In Applications ofEvolutionary Computing . 91\u2013102. Patrick Emmanuel Meyer, Colas Schretter, and Gianluca Bontempi. 2008. Information-theoretic feature selection in mi- croarray datausing variablecomplementarity. IEEEJ.Select.Top. Sign. Process. 2,3(2008),261\u2013274. PatrenahalliMNarendraandKeinosukeFukunaga.1977.Abranchandboundalgorithmforfeaturesubsetselection. IEEE Trans.Comput. 100,9(1977),917\u2013922. Michael Netzer, Gunda Millonig, Melanie Osl, Bernhard Pfeifer, Siegfried Praun, Johannes Villinger, Wolfgang Vogel, and Christian Baumgartner. 2009. A new ensemble-based algorithm for identifying breath gas marker candidates in liver disease usingion moleculereaction massspectrometry. Bioinformatics 25,7(2009),941\u2013947. Xuan Vinh Nguyen, Jeffrey Chan, Simone Romano, and James Bailey. 2014. Effective global approaches for mutual infor- mationbasedfeatureselection.In KDD.512\u2013521. Feiping Nie, Heng Huang, Xiao Cai, and Chris H Ding. 2010. Efficient and robust feature selection via joint l2,1-norms minimization.In NIPS.1813\u20131821. Feiping Nie, Shiming Xiang, Yangqing Jia, Changshui Zhang, and Shuicheng Yan. 2008. Trace ratio criterion for feature selection.In AAAI.671\u2013676. FeipingNie,WeiZhu,XuelongLi,andothers.2016.Unsupervisedfeatureselectionwithstructuredgraphoptimization.In AAAI.1302\u20131308. GuillaumeObozinski,BenTaskar,andMichaelJordan.2007. JointCovariateSelectionforGroupedClassification .Technical Report.Technical Report,Statistics Department,UC Berkeley. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:43 FabianPedregosa,Ga\u00eblVaroquaux,AlexandreGramfort,VincentMichel,BertrandThirion,OlivierGrisel,MathieuBlondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, and others. 2011. Scikit-learn: Machine learning in python. J. Mach. Learn.Res. 12,Oct(2011),2825\u20132830. Hanyang Peng and Yong Fan. 2016. Direct sparsity optimization based feature selection for multi-class classification. In IJCAI.1918\u20131924. HanyangPengandYongFan.2017.Ageneralframeworkforsparsityregularizedfeatureselectionviaiterativelyreweighted leastsquare minimization.In AAAI.2471\u20132477. Hanchuan Peng, Fuhui Long, and Chris Ding. 2005. Feature selection based on mutual information criteria of max- dependency,max-relevance,and min-redundancy. IEEETrans.Pattern Anal.Mach. Intell. 27,8(2005),1226\u20131238. JiePeng,JiZhu,AnnaBergamaschi,WonshikHan,Dong-YoungNoh,JonathanRPollack,andPeiWang.2010.Regularized multivariateregressionforidentifyingmasterpredictorswithapplicationtointegrativegenomicsstudyofbreastcancer. Ann.Appl.Stat. 4,1(2010),53. SimonPerkins,KevinLacker,andJamesTheiler.2003.Grafting:Fast,incrementalfeatureselectionbygradientdescentin functionspace. J.Mach.Learn. Res. 3(2003),1333\u20131356. Simon Perkins andJamesTheiler. 2003.Onlinefeatureselection using grafting.In ICML.592\u2013599. MingjieQianandChengxiangZhai. 2013.Robust unsupervised featureselection.In IJCAI.1621\u20131627. AriadnaQuattoni,XavierCarreras,MichaelCollins,andTrevorDarrell.2009.Anefficientprojectionfor l1,8regularization. InICML.857\u2013864. Marko Robnik-\u0160ikonja and Igor Kononenko. 2003. Theoretical and empirical analysis of relieff and rrelieff. Mach. Learn. 53,1-2 (2003),23\u201369. Debaditya Roy, K Sri Rama Murty, and C Krishna Mohan. 2015. Feature selection using deep neural networks. In IJCNN. 1\u20136. Yvan Saeys, Thomas Abeel, and Yves Van de Peer. 2008. Robust feature selection using ensemble feature selection tech- niques. In ECMLPKDD (2008),313\u2013325. YvanSaeys,I\u00f1akiInza,andPedroLarra\u00f1aga.2007.Areviewoffeatureselectiontechniquesinbioinformatics. Bioinformatics 23,19(2007),2507\u20132517. Ted Sandler, John Blitzer, Partha P. Talukdar, and Lyle H. Ungar. 2009. Regularized learning with networks of features. In NIPS.1401\u20131408. PrithvirajSen,GalileoNamata,MustafaBilgic,LiseGetoor,BrianGalligher,andTinaEliassi-Rad.2008.Collectiveclassifi- cationinnetwork data. AIMag.29,3 (2008),93. QiangShen, Ren Diao,andPanSu. 2012.Feature selectionensemble. Turing-100 10(2012),289\u2013306. Jianbo Shi and Jitendra Malik. 2000.Normalized cuts and image segmentation. IEEE Trans. Pattern Anal. Mach. Intell. 22, 8 (2000),888\u2013905. LeiShi,LiangDu,andYi-DongShen.2014.Robustspectrallearningforunsupervisedfeatureselection.In ICDM.977\u2013982. Alexander Shishkin, Anastasia Bezzubtseva, Alexey Drutsa, Ilia Shishkov, Ekaterina Gladkikh, Gleb Gusev, and Pavel Serdyukov. 2016. Efficient high-order interaction-aware feature selection based on conditional mutual information. InNIPS.4637\u20134645. Sameer Singh, Jeremy Kubica, Scott Larsen, and Daria Sorokina. 2009. Parallel large scale feature selection for logistic regression. In SDM.1172\u20131183. Mingkui Tan, Ivor W Tsang, and Li Wang. 2014. Towards ultrahigh dimensional feature selection for big data. J. Mach. Learn.Res. 15,1(2014),1371\u20131429. Jiliang Tang, Salem Alelyani, and Huan Liu. 2014. Feature selection for classification: A review. Data Classification: Algo- rithms and Applications (2014),37. Jiliang Tang, Xia Hu, Huiji Gao, and Huan Liu. 2013. Unsupervised feature selection for multi-view data in social media. InSDM.270\u2013278. Jiliang Tang, Xia Hu, Huiji Gao, and Huan Liu. 2014. Discriminant analysis for unsupervised feature selection. In SDM. 938\u2013946. JiliangTangandHuan Liu.2012a.Feature selectionwithlinked datainsocial media.In SDM.118\u2013128. JiliangTangandHuan Liu.2012b.Unsupervised featureselectionfor linked social mediadata.In KDD.904\u2013912. JiliangTangandHuanLiu.2013.Coselect:Featureselectionwithinstanceselectionforsocialmediadata.In SDM.695\u2013703. LeiTangandHuan Liu.2009.Relationallearningvia latentsocial dimensions.In KDD.817\u2013826. RobertTibshirani.1996.Regression shrinkage andselection viathe lasso. J .R o y .S t a t .S oc .B (1996),267\u2013288. RobertTibshirani,MichaelSaunders,SaharonRosset,JiZhu,andKeithKnight.2005.Sparsityandsmoothnessviathefused lasso.J.Roy. Stat. Soc.B 67,1(2005),91\u2013108. Robert Tibshirani, Guenther Walther, and Trevor Hastie. 2001. Estimating the number of clusters in a data set via the gap statistic.J .R o y .S t a t .S oc .B 63,2(2001),411\u2013423. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.94:44 J. Liet al. WilliamT.Vetterling,SaulA.Teukolsky,andWilliamH.Press.1992. NumericalRecipes:ExampleBook(C) .PressSyndicate of the University of Cambridge. Michel Vidal-Naquet and Shimon Ullman. 2003. Object recognition with informative features and linear classification. In ICCV.281\u2013288. HuaWang,FeipingNie,andHengHuang.2013.Multi-viewclusteringandfeaturelearningviastructuredsparsity.In ICML. 352\u2013360. HuanWang,ShuichengYan,DongXu,XiaoouTang,andThomasHuang.2007.Traceratiovs.ratiotracefordimensionality reduction. In CVPR.1\u2013 8. Jie Wang and Jieping Ye. 2015. Multi-layer feature reduction for tree structured group lasso via hierarchical projection. In NIPS.1279\u20131287. Jialei Wang, Peilin Zhao, Steven C. H. Hoi, and Rong Jin. 2014b. Online feature selection and its applications. IEEE TKDE 26,3(2014),698\u2013710. Qian Wang, Jiaxing Zhang, Sen Song, and Zheng Zhang. 2014a. Attentional neural network: Feature selection using cog- nitivefeedback.In NIPS.2033\u20132041. Xiaokai Wei, BokaiCao, andPhilip S.Yu. 2016a.Nonlinearjointunsupervised featureselection. In SDM.414\u2013422. XiaokaiWei,BokaiCao,andPhilipS.Yu.2016b.Unsupervisedfeatureselectiononnetworks:Agenerativeview.In AAAI. 2215\u20132221. Xiaokai Wei, Sihong Xie, and Philip S. Yu. 2015. Efficient partial order preserving unsupervised feature selection on net- works. In SDM.82\u201390. Xiaokai Wei and Philip S. Yu. 2016. Unsupervised feature selection by preserving stochastic neighbors. In AISTATS. 995\u2013 1003. Liang Wu, Jundong Li, Xia Hu, and Huan Liu. 2017. Gleaning wisdom from the past: Early detection of emerging rumors insocial media.In SDM.SIAM, 99\u2013107. Xindong Wu, KuiYu, HaoWang,andWei Ding.2010.Onlinestreamingfeatureselection. In ICML.1159\u20131166. Zhixiang Xu, Gao Huang, Kilian Q. Weinberger, and Alice X. Zheng. 2014. Gradient boosted feature selection. In KDD. 522\u2013531. Makoto Yamada, Avishek Saha, Hua Ouyang, Dawei Yin, and Yi Chang. 2014. N3LARS: Minimum redundancy maximum relevancefeatureselection for largeandhigh-dimensional data. arXiv preprint arXiv:1411.2331 (2014). Feng Yang and K. Z. Mao. 2011. Robust feature selection for microarray data based on multicriterion fusion. IEEE/ACM Trans.Comput. Biol.Bioinform. 8,4 (2011),1080\u20131092. Howard Hua Yang and John E. Moody. 1999. Data visualization and feature selection: New algorithms for nongaussian data.InNIPS.687\u2013693. Sen Yang, Lei Yuan, Ying-Cheng Lai, Xiaotong Shen, Peter Wonka, and Jieping Ye. 2012. Feature grouping and selection over anundirected graph.In KDD.922\u2013930. Yi Yang, Heng Tao Shen, Zhigang Ma, Zi Huang, and Xiaofang Zhou. 2011. l2,1-norm regularized discriminative feature selection forunsupervised learning.In IJCAI.1589\u20131594. YiYang,DongXu,FeipingNie,ShuichengYan,andYuetingZhuang.2010.Imageclusteringusinglocaldiscriminantmodels andglobalintegration. IEEETrans.Inf. Process. 19,10(2010),2761\u20132773. YeeHwaYang,YuanyuanXiao,andMarkR.Segal.2005.Identifyingdifferentiallyexpressedgenesfrommicroarrayexper- imentsviastatistic synthesis. Bioinformatics 21,7(2005),1084\u20131093. JiepingYe andJun Liu.2012.Sparse methods for biomedicaldata. ACMSIGKDDExplor.Newslett. 14,1(2012),4\u201315. Kui Yu, Xindong Wu, Wei Ding, and Jian Pei. 2014. Towards scalable and accurate online feature selection for big data. In ICDM.660\u2013669. Lei Yu and Huan Liu. 2003. Feature selection for high-dimensional data: A fast correlation-based filter solution. In ICML. 856\u2013863. StellaX. Yu andJianboShi. 2003.Multiclassspectral clustering.In ICCV.313\u2013319. LeiYuan, Jun Liu,andJiepingYe.2011.Efficient methods for overlappinggroup lasso.In NIPS.352\u2013360. Ming Yuan and Yi Lin. 2006. Model selection and estimation in regression with grouped variables. J. Roy Stat. Soc. B 68, 1 (2006),49\u201367. SepehrAbbasiZadeh,MehrdadGhadiri,VahabS.Mirrokni,andMortezaZadimoghaddam.2017.Scalablefeatureselection viadistributed diversity maximization.In AAAI.2876\u20132883. Jian Zhang, Zoubin Ghahramani, and Yiming Yang. 2008. Flexible latent variable models for multi-task learning. Mach. Learn.73,3(2008),221\u2013242. MiaoZhang,ChrisH.Q.Ding,YaZhang,andFeipingNie.2014.Featureselectionatthediscretelimit.In AAAI.1355\u20131361. Qin Zhang, Peng Zhang, Guodong Long, Wei Ding, Chengqi Zhang, and Xindong Wu. 2015. Towards mining trapezoidal datastreams.In ICDM.1111\u20131116. ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.Feature Selection: A Data Perspective 94:45 LeiZhao,QinghuaHu,andWenwuWang.2015.Heterogeneousfeatureselectionwithmulti-modaldeepneuralnetworks andsparse group lasso. IEEETrans.Multimedia 17,11(2015),1936\u20131948. Peng Zhao, Guilherme Rocha, and Bin Yu. 2009. The composite absolute penalties family for grouped and hierarchical variableselection. TheAnnalsof Statistics (2009),3468\u20133497. ZhouZhao,XiaofeiHe,DengCai,LijunZhang,WilfredNg,andYuetingZhuang.2016.Graphregularizedfeatureselection withdatareconstruction. IEEETrans. Knowl.Data Eng. 28,3(2016),689\u2013700. ZhengZhaoandHuanLiu.2007.Spectralfeatureselectionforsupervisedandunsupervisedlearning.In ICML.1151\u20131157. Zheng Zhao and Huan Liu. 2008. Multi-source feature selection via geometry-dependent covariance analysis. In FSDM. 36\u201347. ZhengZhao,LeiWang,HuanLiu,andothers.2010.Efficientspectralfeatureselectionwithminimumredundancy.In AAAI. 673\u2013678. Zheng Zhao, Ruiwen Zhang, James Cox, David Duling, and Warren Sarle. 2013. Massively parallel feature selection: An approachbasedon variancepreservation. Mach. Learn. 92,1(2013),195\u2013220. Jing Zhou, Dean Foster, Robert Stine, and Lyle Ungar. 2005. Streaming feature selection using alpha-investing. In KDD. 384\u2013393. JiayuZhou, Jun Liu,VaibhavA Narayan,andJiepingYe. 2012.Modelingdisease progression viafused sparse group lasso. InKDD.1095\u20131103. YaoZhou andJingrui He.2017.A randomized approachfor crowdsourcing inthe presenceof multipleviews.In ICDM. Zhi-Hua Zhou. 2012. EnsembleMethods:Foundationsand Algorithms .CRCPress. JiZhu, Saharon Rosset,Robert Tibshirani,andTrevor J. Hastie.2004.1-norm support vector machines. In NIPS.49\u201356. Pengfei Zhu, Qinghua Hu, Changqing Zhang, and Wangmeng Zuo. 2016. Coupled dictionary learning for unsupervised featureselection. In AAAI.2422\u20132428. Received September 2016; revisedJuly 2017; accepted August 2017 ACM ComputingSurveys, Vol. 50,No. 6,Article 94.Publicationdate:December2017.", "23": "Algorithms for eature Selection: An Evaluation  Douglas Zongker  Department of Computer Science  Michigan State University  East Lansing, Michigan, USA  zongker@cps.msu.edu  Abstract  A large number of algorithms have been proposed for  doing feature subset selection. The goal of this paper is  to evaluate the quality of feature subsets generated by the  various algorithms, and also compare their computational  requirements. Our results show that the sequential forward  floating selection (SFFS) algorithm, proposed by Pudil et  al., dominates the other algorithms tested. This paper also  illustrates the dangers of using feature selection in small  sample size situations. It gives the results of applying fea-  ture selection to land use class$cation of SAR satellite im-  ages using four different texture models. Pooling features  derived from difSerent texture models, followed by a feature  selection results in a substantial improvement in the classi-  $cation accuracy. Application of feature selection to clas-  s$cation of handprinted characters illustrates the value of  feature selection in reducing the number of features needed  for classi$er design.  1. Introduction  The problem of feature selection is to take a set of candi-  date features and select a subset that performs the best under  some classification system. This procedure can reduce not  only the cost of recognition by reducing the number of fea-  tures that need to be collected, but in some cases it can also  provide better classification accuracy due to finite sample  size effects [2]. There has been a resurgence of interest in  applying feature selection methods due to the large numbers  of features encountered in the following types of problems:  (1) Applications where data taken by multiple sensors are  fused. (2) Integration of multiple models, where all the pa-  rameters from the different models can be used for classifi-  cation; and (3) Data mining applications, where the goal is  to recover the hidden relationships among the features.  The goal of this paper is to evaluate the performance of  various feature selection methods on some synthetic data  1015-4651/96 $5.00 0 1996 IEEE  Proceedings of ICPR \u201996 18 Ani1 Jain  Department of Computer Science  Michigan State University  East Lansing, Michigan, USA  j ain@cps . msu . edu  sets. Several well-known and some recently proposed fea-  ture selection algorithms have been implemented and tested.  Based on these results, the sequential forward floating selec-  tion (SFFS) method introduced in [7] has been found to be  extremely powerful. This method has been applied to large  datasets in two different application domains. Experimen-  tal results indicate that feature selection can not only elim-  inate a large number of redundant features, but also avoid  the curse of dimensionality.  2. Feature Selection Algorithms  Let Y be the original set of features, with cardinality n.  Let d represent the desired number of features in the se-  lected subset X, X c Y. Let the feature selection criterion  function for the set X be represented by J(X). Without  any loss of generality, let us consider a higher value of J  to indicate a better feature subset. Formally, the problem  of feature selection is to find a subset X c Y such that 1x1 = dand  J(X) = max J(Z).  ZCV,jZl=d  A taxonomy of all the available feature selection algo-  rithms into broad categories is presented in Figure 1. We  first divide methods into those based on statistical pattern  recognition (SPR) techniques, and those using artificial neu-  ral networks (ANN). The SPR category is then split into  those guaranteed to find the optimal solution and those that  may result in a suboptimal feature set. The suboptimal  methods are further divided into those that store just one  \u201ccurrent\u201d feature subset and make modifications to it, ver-  sus those that maintain a population of subsets. Another  distinction is made between algorithms that are determin-  istic, producing the same subset on a given problem every  time, and those that have a random element which could  produce different subsets on every run. Some representa-  tive feature selection algorithms are listed beneath each leaf  node in the tree.  Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:16:03 UTC from IEEE Xplore.  Restrictions apply. feature selection A  SPR ANN  suboptimal optimal  single solution many solutionr  delerminbtk stochastic deterministic stochastic  PTAW SA beamsearch GA  flwring  Mar-Min  Figure 1. A taxonomy of feature selection al-  gorithms.  The first group of methods begin with a single solution  (a feature subset) and iteratively add or remove features un-  til some termination criterion is met. These \u201csequential\u201d  methods can be divided into two categories, those that start  with the empty set and add features (the \u201cbottom-up,\u2019\u2019 or  \u201cforward\u201d methods) and those that start with the full set and  delete features (the \u201ctop-down,\u201d or \u201cbackward\u201d methods).  We have implemented the following well-known sequential  algorithms:  SFS Sequential forward selection  SBS Sequential backward selection  GSFS( .)  GSBS(.) Generalized sequential backward selection  PTA(I, r)  SFFS Sequential forward floating selection  SFBS Sequential backward floating selection  MM Max-Min search  The two \u201cfloating\u201d selection methods are described in Pudil  et al. [7]. All of the other methods are given in detail in Kit-  tler [3]. Siedlecki and Sklansky [9] introduced the use of  genetic algorithms (GA) for feature selection, a technique  that is also evaluated in [I]. The branch-and-bound feature  selection algorithm, proposed by Narendra and Fukunaga  [6], can be used to find the optimal subset of features much  more quickly than exhaustive search. One drawback is that  the branch-and-bound procedure requires the feature selec-  tion criterion function to be monotone, i.e. the addition of  new features to a feature subset can never decrease the value  of the criterion function. We know from the curse of dimen-  sionality phenomenon that in small sample size situations  this may not be true. Generalized sequential forward selection  Plus I-take away T Mao er al. [4] use a multilayer feedforward network with  a backpropagation learning algorithm for pattern classifica-  tion. They define a node saliency measure and present an  algorithm for pruning the least salient nodes to reduce the  complexity of the network after it has been trained. The  pruning of input nodes is equivalent to removing the corre-  sponding features from the feature set. The node-pruning  method simultaneously develops both the optimal feature  set and the optimum classifier.  3. Experimental Results  We have compared different feature selection algorithms  in terms of classification error and run time on a 20-  dimensional, 2-class Gaussian data set which was used by  Pudil et al. [7]. Our criterion function for assessing the  \u201cgoodness\u201d of a feature subset was the Mahalanobis dis-  tance between the class means-the larger the Mahalanobis  distance, the better the feature subset. Maximum likelihood  estimates of the covariance matrix and mean vectors were  computed from the data. A total of thirteen feature selection  algorithms, listed in Table 1, were evaluated and compared.  Execution times reported are processor ticks (0.01 second)  SFS SBS GSFS(2)  GSBS(2) GSFS(3) GSBS(3)  SFFS SFBS PTA((1)7 (2))  \u201c(1)1(3)) PTA((2)1(3))  Branch-and-Bound Max-Min  Table 1. Feature selection algorithms used in  experimental evaluation.  spent in user space on a SUN SPARCserver 1OOO. Ten  randomly generated data sets, each with 1 ,OOO patterns per  class were tested and the averages of the runs are reported.  Figure 2 shows the results. The solid line in each figure in-  dicates the optimal result for each target feature subset of  size d, obtained using the branch-and-bound method.  The following conclusions can be drawn based on these  empirical results:  0 The Max-Min algorithm, while very fast, gives poor  results compared to the other algorithms.  0 The SFS and SBS algorithms have comparable per-  formance, but show nesting problems. (For instance,  the optimal 3-subset is not contained in the optimal 4-  subset.) The forward method is faster than its back-  ward counterpart, as expected. This is also true of the  generalized methods (GSFS and GSBS).  6 The floating methods (SFFS, SFBS) show results Com-  parable to the branch-and-bound algorithm and are, for  the most part, faster than it.  19  Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:16:03 UTC from IEEE Xplore.  Restrictions apply. I4  I2  I ...  ii i 08 1  06  04  01 .-\u2022  MM .+  PECC &  $'  Figure 2. Performance of some feature selec-  tion algorithms: (a) criterion value, (b) execu-  tion time.  0 The PTA((l), (r)) methods, while generally giving  near-optimal performance, are far slower than the  branch-and-bound method.  Overall, the floating methods perform better than their  non-floating counterparts, giving near-optimal results  with reasonable execution times.  4. Effect of Training Set Size  How reliable are the feature selection results in the pres-  ence of small amounts of training data? In the case where  Mahalanobis distance is used as the criterion, the error aris-  ing from estimating the covariance matrix can lead the fea-  ture selection process astray, producing inferior results (rel-  ative to the true distributions) on independent test data even  if the selected subset is optimal for the given training data  [SI. This phenomenon, which is related to the curse of di-  mensionality, is illustrated by running the feature selection algorithm on varying amounts of training data drawn from  known distributions. Trunk [ 1 11 used the following simple  example to illustrate the curse of dimensionality. The two  multivariate Gaussian class-conditional densities, are given  below:  where  and 1 denotes the identity matrix. Note that for these class-  conditional densities, the optimal d-feature subset is the first  d features.  Various size data sets, ranging from 10 to 5,000 train-  ing patterns per class, were generated from the two 20-  dimensional distributions (equations (1) and (2)). For each  training set size, five data sets were generated, and the re-  suits averaged. The quality of each selected feature subset  was calculated by taking the number of commonalities in  the resulting subset when compared with the optimal subset  of the true distribution: features that were included in both  sets, and features that were excluded from both sets. This  count was divided by the number of dimensions, and that  value was averaged over values of d from 1 to 19 inclusive  to give a final quality value for the set. Note that this value  is not a measure of the classification error, but a measure  of the difference between the subset produced by a feature  selection method and the ideal feature subset. The average  quality for each training set size for the branch and bound  and SFS methods is shown in Figure 3.  I  brsnchdbound c  SFS --  Figure 3. Quality of selected feature subsets  as a function of the size of training data.  For this dataset, since the features are all independent  with identical variance, only the difference in means along  a feature axis is significant. Therefore, any feature selection  20  Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:16:03 UTC from IEEE Xplore.  Restrictions apply. Figure 4. Sample SAR images. oas  t 08-  07s  i! 07-  065  algorithm should perform well on such a simple classifi-  cation problem. Indeed, the curve for the SFS algorithm  closely matches that of the branch-and-bound algorithm.  Note that as expected, the quality of the feature subset for  small training sets is low, but improves as the training set  size increases. -  -  -  5. Selection of Texture Features  We have applied various feature selection algorithms to  select the best subset of texture features for the problem  of land use classification using SAR (Synthetic Aperture  Radar) images (see Figure 4). Solberg and Jain [lo] have  used texture features computed from SAR images to clas-  sify each pixel. A total of 18 features per pattern (pixel)  were computed from four different texture models: local  statistics (5 features), gray level co-ocurrence matrices (6  features), fractal features (2 features), and a lognormal ran-  dom field model (5 features). Our goal is to determine  whether the classification error can be reduced by applying  feature selection to this set of 18 features from four differ-  ent texture models. A similar feature selection study for 2D  shape features was reported by You and Jain [ 121.  We report results for one SAR image (the October 17  image from [IO]), containing approximately 22,000 pixels.  This data was split evenly to form independent training and  test sets. The recognition rate of the 3\" classifier is used  as the feature selection criterion. Based on its consistently  high performance for the synthetic data in Section 3, we  chose to apply the SFFS method to the texture data set. The  results of these runs are shown in Figure 5.  The best recognition rate obtained by SFFS was 88.4%,  with an 1 1-feature subset. Notice that the recognition rate  does not monotonically increase as the number of features  is increased. The feature selection process is not just us-  ing the features derived from a single texture model but is  utilizing features from different models to provide a better  performance. For instance, in every run, the five-feature I 09J 09 t  f I  SPS. 3NN f  SFFS. INN -+-  0 2 4 6 8 IO 12 14 16  lsslum mblct size  Figure 5. Recognition rates of SFS and SFFS  methods on texture feature data.  subset selected contained features from at least three differ-  ent texture models. The best individual texture model for  this data set was the random field model with a classifica-  tion accuracy of 68.8% [lo]. Pooling features from fourdif-  ferent models and then applying feature selection increased  the classification accuracy.  6. Selection of Handprinted Character  Features  We have also applied feature selection to aid the classifi-  cation of a subset of the NIST SD-3 handprinted character  set. The classes correspond to the 26 lowercase letters (see  Figure 6). A total of 2,439 patterns are used for training  and 1,525 are used for testing. The features used are the 88  contour direction features from Mohiuddin and Mao [5].  We again applied the SFFS algorithm to this data set.  While our best recognition rates (88.7% with 5 1 features us-  ing INN, 89.6% with 71 features using 3\") did not reach  those reported by Mohiuddin and Mao [5] using different,  non-nearest neighbor-based classifier methods, this data set  illustrates one of the major advantages of performing fea-  ture selection-it can dramatically reduce the number of  features with only a small drop in recognition rate. For in-  stance, the 1NN recognition rate reaches 87.7% accuracy  using only 36 of the 88 features. Over half the features can  be culled from the data set for only a 1% drop in the recog-  nition rate!  7. Summary  This paper illustrates the merits of various methods of  feature selection. In particular, the practicality of finding  the optimal subsets in feature spaces of moderately high di-  mension using the branch-and-bound algorithm (where the  21  Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:16:03 UTC from IEEE Xplore.  Restrictions apply. aaaaaabbbbbbbccccccddd  ~ ~~  ssssssstttttuuuuuuuvvv  Figure 6. Sample handprinted characters.  I  0.8  t  a  04  0.2  0  Figure 7. Recognition rates as a function of  feature subset size for character data.  monotonicity requirement for the criterion function is sat-  isfied), and the quality of the results given by the floating  search methods are illustrated. The floating search methods  show a great promise of being useful in situations where the  branch-and-bound method can not be used, due to either the  nonmonotonicity of the feature selection criterion or com-  putational reasons.  We also show the pitfalls of using feature selection with  limited training data. By using feature selection on a clas-  sification problem with known distributions and comparing  the selected subsets (under finite sample size) with the true  ideal subsets, the quality of the selected subset can be quan-  tified. Our experiments with the Trunk distributions show  the problems associated with sparse data in a high dimen-  sional space. Results on texture data show that feature se- lection is useful in utilizing feature derived from different  texture models while at the same time avoiding the curse of  dimensionality. Experiments on handprinted character data  illustrate that a large number of feature can be eliminated  without a significant loss of classification performance.  References  [l] F. Ferri, P. Pudil, M. Hatef, and J. Kittler. Comparative study  of techniques for large-scale feature selection. In E. Gelsma  and L. Kamal, editors, Pattern Recognition in Practice IV,  pages 403-41 3. Elsevier Science B.V., 1994.  [2] A. K. Jain and B. Chandrasekaran. Dimensionality and sam-  ple size considerations. In P. R. Krishnaiah and L. N. Kanal,  editors, Pattern Recognition Practice, volume 2, chapter 39,  pages 835-855. North-Holland, 1982.  [3] J. Kittler Feature set search algorithms. In C. H. Chen, ed-  itor, Pattern Recognition and Signal Processing, pages 41-  60. Sijthoff and Noordhoff, Alphen aan den Rijn, Nether-  lands, 1978.  [4] J. Mao, K. Mohiuddin, and A. K. Jain. Parsimonious net-  work design and feature selection through node pruning.  In Proceedings of 12th ICPR, Jerusalem, pages 622-624,  1994.  [5] K. M. Mohiuddin and J. Mao. A comparative study of dif-  ferent classifiers for handprinted character recognition. In  E. S. Gelsema and L. N. Kanal, editors, Pattern Recogni-  tion in Practice IV: Multiple Paradigms, Comparative Stud-  ies and Hybrid Systems, pages 437448. Elsevier Science  B.V., 1994.  [6] P. M. Narendra and K. Fukunaga. A branch and bound al-  gorithm for feature subset selection. IEEE Transactions on  Computers, C-26(9):917-922, September 1977.  Floating search  methods in feature selection. Pattern Recognition Letters,  15:1119-1125,November 1994.  [8] S. J. Raudys and A. K. Jain. Small sample size effects in  statistical pattem recognition: Recommendations for prac-  titioners. IEEE Transactions on Pattern Analysis and Ma-  chine Intelligence, 13(3):252-264, March 1991.  [9] W. Siedlecki and J. Sklansky. A note on genetic algorithms  for large-scale feature selection. Pattern Recognition Let-  ters, 10:335-347, November 1989.  [lo] A. H. S. Solberg and A. K. Jain. A study of the invari-  ance properties of textural features in SAR images. In Proc.  IGARS Conference, pages 670-672, Florence, Italy, July  1995.  111 G. V. Trunk. A problem of dimensionality: A simple ex-  ample. IEEE Transactions on Pattern Analysis and Machine  Intelligence, PAMI- 1 (3):306-307, July 1979.  121 Z. You and A. K. Jain. Performance evaluation of shape  matching via chord length distribution. Computer Wsion,  Graphics and Image Processing, 28:185-198.1984. [7] P. Pudil, J. NovoviEovB, and J. Kittler.  22  Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:16:03 UTC from IEEE Xplore.  Restrictions apply. ", "24": " Procedia Computer Science   91  ( 2016 )  919 \u2013 926 Available online at www.sciencedirect.com 1877-0509 \u00a9 2016 Published by Elsevier B.V . This is an open access article under the CC BY-NC-ND license  (http://creativecommons.org/licenses/by-nc-nd/4.0/). Peer -review under responsibility of the Organizing Committee of ITQM 2016 doi: 10.1016/j.procs.2016.07.111 ScienceDirect Information Technology and Quantitative Management (ITQM 2016) A Survey on Feature Selection Jianyu Miaoa,c, Lingfeng Niub,c,* aSchool of Mathematical Sciences, University of Chinese Academy of Sciences, Beijing, 100019, China bResearch Center on Fictitious Economy &Data Science, Chinese Academy of Sciences, Beijing, 100190, China cKey Laboratory of Big Data Mining and Knowledge Management, Chinese Academy of Sciences, Beijing, 100190, China Abstract Feature selection, as a dimensionality reduction technique, aims to choosing a small subset of the relevant features from the original features by removing irrelevant, redundant or noisy features. Feature selection usually can lead to better learning performance, i.e.,higher learning accuracy, lower computational cost, and better model interpretability. Recently, researchers from computer vision, text mining and so on have proposed a variety of feature selection algorithms and in terms of theory and experiment, show the e?ectiveness of their works. This paper is aimed at reviewing the state of the art on these techniques. Furthermore, a thorough experiment is conductedto check if the use of feature selection can improve the performance of learning, considering some of the approaches mentioned in the literature. The experimental results show that unsupervised feature selection algorithms bene?ts machine learning tasks improving the performance of clustering. c?2016 The Authors. Published by Elsevier B.V . Selection and/or peer-review under responsibility of ITQM2016. Keywords: feature selection; machine learning; unsupervised; clustering 1. Introduction Recently, available data has increased explosively in both number of samples and dimensionality in many machine learning applications such as text mining, computer vision and biomedical. In order to knowledge acquisition, it is im- portant and necessary to study how to utilize these large scale data. Our interest focus mainly on the high dimensionalityof data. The huge number of high dimensional data has imposed signi?cantly big challenge on existing machine leaningmethods. Due to presence of noisy, redundant and irrelevant dimensions, they can not only make learning algorithms veryslow and even degenerate the performance of learning tasks, but also can lead to di ?culty on interpretability of model. Feature selection are capable of choosing a small subset of relevant features from the original ones by removing noisy, irrelevant and redundant features. In terms of availability of label information, feature selection technique can be roughly classi?ed into three families: supervised methods [1, 2, 3, 4], semi-supervised methods [5, 6, 7], and unsupervised methods [8, 9, 10, 11, 12]. The availability of label information allows supervised feature selection algorithms to e ?ectively select discriminative and relevant features to distinguish samples from di?erent classes. Some supervised methods have been proposed and studied[3, 13]. When a small portion of data is labeled, we can utilize semi-supervised feature selection which can take advantageof both labeled data and unlabeled data. Most of the existing semi-supervised feature selection algorithms [5, 14] rely onthe construction of the similarity matrix and select those features that best ?t the similarity matrix. Due to the absenceof labels that are used for guiding the search for discriminative features, unsupervised feature selection is considered as amuch harder problem [9]. In order to attain the goal of feature selection, several criteria have been proposed to evaluatefeature relevance [2, 15]. Email address:niulf@ucas.ac.cn c?The Authors. Published by Elsevier B.V . Selection and/or peer-review under responsibility of ITQM2016 *Corresponding author. Tel.: +010-8268-0684\u00a9 2016 Published by Elsevier B.V . This is an open access article under the CC BY-NC-ND license  (http://creativecommons.org/licenses/by-nc-nd/4.0/). Peer -review under responsibility of the Organizing Committee of ITQM 2016920   Jianyu Miao and Lingfeng Niu  /  Procedia Computer Science   91  ( 2016 )  919 \u2013 926  Based on the di?erent strategies of searching, feature selection can also be classi?ed into three methods, i.e., ?lter methods, wrapper methods and embedded methods. Filter methods select the most discriminative features through the character of data. Generally, ?lter methods perform feature selection before classi?cation and clustering tasks and usuallyfall into a two-step strategy. First, all features are ranked according to certain criteria. Then, the features with the highestrankings are selected. Many ?lter-type methods have been used, including reliefF [16, 17], F-statistic [18], mRMR [19] and information gain [17]. Wrapper methods use the intended learning algorithm itself to evaluate the features. Thework [20] utilizes Support Vector Machine methods based on Recursive Feature Elimination (RFE) to select the mostrelevant gene to cancers. Embedded models perform feature selection in the process of model construction. Figure 1 showsthe classi?cation of feature selection methods. Feature  Selection Label InformationSearch Strategy SupervisedSemi- supervisedUnsupervised Wrapper Filter Embedded Fig. 1. Feature selection category Sparsity regularization recently is very important to make the model learned robust in machine learning and recently has been applied to feature selection. l1-SVM method [21, 22] based on l1-norm regularization has been proposed to perform feature selection. The work [23] used logistic regression with l1norm regularization for feature selection. By combiningl1-norm andl2-norm, Hybrid Huberized SVM (HHSVM), a more structured regularization, has been proposed in [24]. The authors in [25, 26] developed a model with l2,1-norm regularization to select features shared by multi tasks. The work [3] employed a joint l2,1-norm minimization on both loss function and regularization. The rest of paper is organized as follows. Section 2 introduces the related work. The state of the art feature selection algorithms are introduced in Section 3. In section 4, we conduct extensive experiments and report experimental results.Finally, we provide the conclusions in section 5. 2. Related work Supervised feature selection approaches are for those data which are labeled. Traditional supervised methods such as Fisher Score [27] rank features individually according to the criterion, which can not consider the correlation among di?erent features. Linear discriminant analysis (LDA for short) [28] was proposed to elevate features by maximizing the ratio between the class scatter and within class scatter. Unfortunately, LDA su?ers from the small sample size problem because it needs to calculate the inverse matrix of within class scatter, which is singular when the number of trainingsamples is smaller than the dimensionality of the data [29]. To avoid this problem, maximum margin criterion(MMC forshort) based algorithm is proposed in [30], which uses a linear combination of traces between class scatter and within classscatter in the objective function and introduces a constraint of orthogonal weight matrix. However, all supervised methodshave the common limitation of the requirement of su?cient labeled data, which is very expensive to obtain in practice. The performances of such supervised methods, however, usually drop dramatically when the labeled training data are scarce[31]. Semi-supervised feature selections, by contrast, exploit not only labeled but also unlabeled training data. As a result, semi-supervised methods are able to select features by utilizing unlabeled data when there is limited number of labeled data. Among others, graph Laplacian based semi-supervised methods assumes that most data examples lie on a low-dimensional manifold, such as semi-supervised Discriminant Analysis (SDA) [32]. In graph Laplacian based methods,graph Laplacian matrix is introduced to harness the unlabeled samples. However, they are usually less e?cient on handling large-scale data because of the time-consuming computation of the graph [33]. Therefore, it is necessary and important tostudy unsupervised feature selection. Due to the absence of label information that is used for guiding the search for discriminative features, unsupervised feature selection is considered as a much harder problem [9]. Many researchers have proposed some criterions to de?nefeature relevance. One commonly used criterion is choosing those features that can best preserve the manifold structureof the original data. Another frequently used method is to seek cluster indicators through clustering algorithms and then921  Jianyu Miao and Lingfeng Niu  /  Procedia Computer Science   91  ( 2016 )  919 \u2013 926  transform the unsupervised feature selection into a supervised framework. There are two di?erent ways to use this method. One way is to seek cluster indicators(considered as pseudo labels) and simultaneously perform the supervised feature selection within one uni?ed framework. The works [10] and [34] integrated nonnegative spectral cluster and structurallearning into a joint framework. Another ?rst seeks cluster indicators, then perform feature selection to remove or selectcertain features, and ?nally to repeat these two steps iteratively until certain criteria is met. The authors in [8] ?rst usespectral analysis to obtain indicator matrix of data points, then use indicator matrix to perform feature selection likesupervised one. 3. Algorithms Before going to introduce the state of the art feature selection algorithms, we would like to give some notations to be used in our paper. We assume that we have ndata pointsX={x i}n i=1and each xihas dfeatures{f1,f2,\u00b7\u00b7\u00b7,fd}. And we use Xto denote as data matrix. Given a square matrix A, the trace of Ais the sum of the diagonal elements of A. And the Frobenius norm of A?Rm\u00d7nis given by ?A?F=?vm? i=1n? j=1A2 ij Following the previous work [35], we give l2,1norm of the matrix A?Rm\u00d7n ?A?2,1=m? i=1?vn? j=1A2 ij=m? i=1?ai?2 where aiis the i-th row of Aand?\u00b7? 2is Euclidean norm. The a?nity matrix is de?ned as follows Sij=???????exp(-?xi-xj?2 s2)xi?N k(xj)o r xj?N k(x)i) 0 otherise which can be used to exploit the local data structure of data points, where Nk(xj) denotes the set of knearest neighbors of xi. Following [36], the normalized Graph Laplacian matrix is de?ned as L=D-1/2(D-S)D-1/2, where Dis a diagonal matrix, whose the i-th diagonal element is the sum of the i-th column of S, i.e., Dii=? jSij. Relief [16] and its multi-class extension ReliefF [37] are supervised feature weighting algorithms of the ?lter model. Assuming that pinstances are randomly sampled from data, for the case where there are two classes, the evaluation criterion of Relief is de?ned as SC(fi)=1 2p? t=1d(ft,i-fNM(xt),i)-d(ft,i-fNH(xt),i) (1) where ft,idenotes the value of sample xton feature fi,fNM(xt),iand fNH(xt),idenote the values on the i-th feature of the nearest points to xtwith the same and di?erent class label, respectively. d(\u00b7) is a distance measurement. To handle multi- class problems, the above criterion Eq.(1) can be extended to the following formulation: SC(fi)=1 pp? t=1?????????-1 mxt? xj?NH(xt)d(ft,i-fj,i)+? y/nequaly xt1 mxt,yP(y) 1-P(y xt)? xj?NM(xt,y)d(ft,i-fj,i)?????????(2) where y xtis the class label of the instance xtand P(y) is the probability of an instance being from the class y.NH(x) and NM(x,y) denote a set of nearest points to x with the same class of xa n dad i?erent class (the class y), respectively. mxtand mxt;yare the sizes of the sets NH(x) and NM(x,y), respectively. Usually, the size of both NH(x) and NM(x,y),?y/nequalyxt,i s set to a prespeci?ed constant k. The evaluation criteria of Relief and ReliefF suggest that the two algorithms select features contributing to the separation of samples from di?erent classes. Laplacian Score was proposed in [15] to select features that can retain sample locality speci?ed by an a?nity matrix K. Given K, its corresponding degree matrix Dand Laplacian matrix Lare obtained. Then the Laplacian Score of a feature f is calculated in the following way: LS=\u02c6fTL\u02c6f \u02c6fD\u02c6f,where \u02c6f=f-fTD1 1TD1(3) where 1 is a vector of the same size with vector f. Since features are evaluated independently in Laplacian Score, selecting kfeatures with Laplacian Score can be achieved by greedily picking the top kfeatures which have the minimal LSvalues.922   Jianyu Miao and Lingfeng Niu  /  Procedia Computer Science   91  ( 2016 )  919 \u2013 926  Proposed in [2], SPEC is an extension of Laplacian Score. In SPEC, given the a?nity matrix K, the degree matrix D, and the normalized Laplacian matrix L, three evaluation criteria are proposed for weighting feature relevance in the following ways: SC 1(fi)=\u02dcfT i?(L)\u02dcfi=n? j=1a2 j?(?j) (4a) SC 2(fi)=\u02dcfT i?(L)\u02dcfi 1-(\u02dcfT i?1)2=?n j=2a2 j?(?j) ?n j=2a2 j(4b) SC 3(fi)=k? j=1(?(2)-?(?j))a2 j (4c) where \u02c6fi=(D1 2fi)\u00b7?D1 2fi)?-1,(?(j),?(j) is the j-th eigenvalue and the eigenvector pair of L.aj=cos?j, where?jis the angle between \u02c6fiand?j; and?(\u00b7) is an increasing function which is used to re-scale the eigenvalues of Lfor denoising. The top eigenvectors of Lare the optimal soft cluster indicators of the data [36]. By comparing with these eigenvectors, SPEC selects features that assign similar values to instances that are similar according to K. In [2], it is shown that Laplacian Score is a special case of the second criterion, SC 2de?ned in SPEC. Note that SPEC also evaluates features independently. SPFS [38] performs feature selection by preserving sample similarity, which can handle feature redundancy. The problem can be formulated by: min ?W? 2,1=?n? i,j=1(xT iWWTxj-Sij)2(5) Here?>0 is a hyper-parameter. MCFS [8] adopt a two-step strategy to select those features such that the multi-cluster structure of data can be best preserved. To be speci?c, ?rstly, cluster indicator can be obtained through spectral clustering(problem (6a)), then use the indicator matrix to perform feature selection(problem (6b)). Consider the two following optimization problem: min FTF=ITr(FTLF) (6a) min wi?fi-XTwi?+\u00df?w i?1 (6b) where?wi?1is thel1norm of wi. Since the formulation only involves a sparse eigen-problem and a L1regularized least squares problem, problem (6) can be e?ciently. Under the assumption that the class label of input data can be predicted by a linear classi?er, UDFS [10] incorporated discriminative analysis and l2,1-norm minimization into a joint framework for unsupervised feature selection. Feature selection can be performed by optimizing the following problem min WTW=ITr(WTXLXTW)+\u00df?W?2,1 (7) where\u00df=0 is a regularization parameter. NDFS [39] performs spectral clustering to learn the cluster labels of the input samples, during which the feature selection is performed simultaneously. The joint learning of the cluster labels and feature selection matrix enables NDFS to select the most discriminative features. To learn more accurate cluster labels, a nonnegative constraint is explicitlyimposed to the class indicators. Its formulation is presented as follows min W,FTr(TTLF)+a?F-XTW?2 F+\u00df?W?2,1 s.t.FTF=I,F=0(8) wherea=0 and\u00df=0 are balance parameters. Due to the presence of orthogonal constraint, optimization of problem (8) is di?cult. NDFS use the idea of penalty function to solve the formulation. Matrix factorization has been proven to be e?ective to perform feature selection. EUFS [40] embeds feature selection into a clustering algorithm via sparse learning without transformation. The problem can be formulated as min U,V?X-UVT?2,1+a?V?2,1+\u00dfTr( UTLU) s.t.UTU=I,U=0(9) wherea=0 and\u00df=0 are balance parameters. l2,1norm is applied to cost function to reduce the e?ect of noise and outliers. In order to obtain more sparse solution, l2,1regularization has been used. The authors in [40] has developed a novel iterative method called Alternating Direction Method of Multiplier (ADMM for short) to optimize problem (9).923  Jianyu Miao and Lingfeng Niu  /  Procedia Computer Science   91  ( 2016 )  919 \u2013 926  4. Experiments Due to the space limitation of paper, in this section, we conduct extensive experiments only for unsupervised feature selection. In our experiments, we used 12 publicly available data sets. 4.1. Datasets The experiments are conducted on 12 publicly available datasets, including ?ve image datasets (PIX10P, PIE10P, COIL20, ORL and JAFFE), two handwritten digit datasets (MNISIT and BA), two text datasets (tr11 and oh15), three microarray datasets (TOX-171, Tumors9 and Leukemia1). Table 1 summarizes the statistics of these data sets. Table 1. Datasets Description Domain Dataset # of Features Size # of Classes Domain Dataset # of Features Size # of Classes Image,FacePIE10P 2420 210 10 BioPIX10P 10000 100 10 Leukemia1 5327 72 3 COIL20 1024 1440 20 Tumors9 5726 60 9 JAFFE 676 213 10 TOX-171 5748 171 4 ORL 1024 400 40 Handwritten,DigitsBA 1404 320 36Texttr11 6429 414 9 MNIST 5000 784 10 oh15 3100 913 10 4.2. Compared Algorithms In our experiment, the state of the art unsupervised feature selection methods mentioned above have been considered. we list them as follows: All Features: Using all features perform clustering MaxVar: Features corresponding to the maximum variance are selected to clusterLaplacian Score [15]: Features consistent with Gaussian Laplacian matrix are selected to best preserve the local manifold structureSPEC [2]: Features are selected using spectral regression SPFS-SFS [38]: The traditional forward search strategy is utilized for similarity preserving feature selection in the SPFS frameworkMCFS [8]: Features are selected based on spectral analysis and sparse regression problem UDFS [10]: Features are selected by a joint framework of discriminative analysis and l 2,1norm minimization NDFS [39]: Discriminative features are selected by a joint framework of nonnegative spectral analysis and linear regres- sion withl2,1norm regularization EUFS [40]: Unsupervised feature selection which embeds feature selection into a clustering algorithm via sparse learning without transformation. 4.3. Experiment setting Since most of feature selection algorithms selected in experiment have one or more parameters, we have to set them before conducting experiments. In order to fairly compare with each other, we choose the best result from several di?erentparameters setting for each algorithm. In this subsection, we give parameters setting used in these algorithms. Based on [34], for Laplacian Score, SPEC, SPFS-SFS, MCFS, UDFS, NDFS and EUFS, we would like to ?x the neighborhood size Kto be 5 for all data sets. To ?nd the best clustering results for these algorithms, a well-known technique called grid-search strategy can be used, where the parameters range from {10 -8,10-6,..., 106,108}. In experiments, we also need to specify the number of selected features. It is not realistic to know the optimal number of features . we empirically choose the number of selected features from {50,100, 150, 200, 250, 300}. Based on the selected features, We use K-means algorithm to cluster the data points into cgroups. Because the initial center points have great impact on performance of K-means algorithm, we conduct K-means algorithm 20 times repeatedly with random initialization. Then, we report the averageresults with standard deviation. 4.4. Evaluation Metrics There are two commonly used metrics which can be used to evaluate performance of clustering. They are clustering accuracy(ACC for short) and normalized mutual information(NMI for short). Generally speaking, the larger ACC and NMI are, the better performance of clustering is. We present the concrete mathematical formulations as below.924   Jianyu Miao and Lingfeng Niu  /  Procedia Computer Science   91  ( 2016 )  919 \u2013 926  Clustering Accuracy(Acc): Like classi?cation accuracy, we can compare the label obtained from clustering with true label to get clustering accuracy. Acc=n? i=1d(map(l i),yi) n where liand yiare the cluster label and true class label of xi, respectively, nis the total number of data points, d(x,y) is the delta function that equals 1 if x=yand equals 0 otherwise, and map(l i) is the permutation mapping function that maps each cluster label rito equivalent label from data set. Normalized Mutual Information(NMI): NMI can be used to evaluate the quality of clusters. Now given a clustering result, the NMI can be calculated with the following formulation NMI=c? i=1c? j=1nijlognij ni\u02c6nj v (c? i=1nilogni n)(c? j=1\u02c6njlog\u02c6nj n) where niand \u02c6 njdenote the number of contained in the cluster Ciand class Ljfori=1,2..., c,j=1,2..., c, respectively, and nijis the number of data that are in the intersection between cluster Ciand class Lj. 4.5. Experiment Results We give the clustering results of di?erent methods on the 12 real life datasets in Table 2(ACC) and Table 3(NMI). The results include the average and the standard deviation of clustering accuracy and normalized mutual information, respectively. From the two tables, we can make the following several observations. First, feature selection is necessary ande?ective. It can not only signi?cantly reduce the numbers of feature and make machine learning algorithms more e?cient,but also can improve the performance. Secondly, in general, almost no one feature selection method can obtain the bestresult on all data sets. Table 2. Clustering results of di?erent methods on 12 data sets. The best result for each data set is highlighted in bold face. DatasetACC\u00b1std(%) All Features MaxVar Laplacian Score SPFS-SFS SPEC MCFS UDFS NDFS EUFS PIE10P 26.7 \u00b11.5 27.1\u00b11.1 30.1\u00b10.4 28.9\u00b12.1 27.5\u00b10.8 29.3\u00b12.1 29.5\u00b13.3 29.4\u00b11.6 47.5\u00b12.3 PIX10P 85.2 \u00b13.3 82.9\u00b13.6 86.9\u00b14.7 86.2\u00b13.2 86.1\u00b15.2 88.1\u00b16.7 83.6\u00b12.9 83.3\u00b17.5 86.5\u00b14.0 COIL20 62.7 \u00b13.1 61.4\u00b11.6 62.2\u00b11.9 64.3\u00b12.1 65.5\u00b13.8 65.9\u00b12.2 65.5\u00b12.9 63.9\u00b12.4 66.2\u00b12.7 ORL 49.7\u00b13.2 50.8\u00b11.4 49.9\u00b12.4 50.4\u00b11.2 51.4\u00b12.2 57.0\u00b13.2 53.8\u00b1 3.0 57.6\u00b11.7 50.2\u00b12.3 JAFFE 85.3 \u00b16.1 85.5\u00b14.2 86.2\u00b13.7 87.1\u00b13.3 85.9\u00b15.1 90.7\u00b16.1 90.5\u00b11.4 91.0\u00b13.4 80.1\u00b16.2 MNIST 51.8\u00b12.0 52.0\u00b11.7 52.6\u00b11.8 54.1\u00b11.1 52.4\u00b10.5 52.2\u00b10.3 57.1\u00b11.2 49.6\u00b11.1 53.2\u00b12.1 BA 40.9\u00b11.6 41.7\u00b11.3 43.3\u00b11.9 43.9\u00b11.4 42.7\u00b11.1 42.9\u00b11.8 43.8\u00b11.6 42.9\u00b11.8 45.6\u00b11.4 tr11 31.8\u00b12.2 31.4\u00b12.4 39.5\u00b13.2 37.6\u00b11.2 38.0\u00b13.1 32.1\u00b11.8 35.5\u00b12.1 34.6\u00b11.4 35.5\u00b11.9 oh15 31.6\u00b12.7 32.2\u00b12.1 34.7\u00b12.4 35.2\u00b11.9 34.2\u00b12.0 32.5\u00b11.3 32.6\u00b12.4 34.5\u00b11.7 34.2\u00b11.9 TOX-171 42.8 \u00b12.1 42.9\u00b11.6 43.1\u00b11.4 44.5\u00b10.3 40.4\u00b10.0 42.9\u00b11.6 45.6\u00b11.2 46.9\u00b11.5 42.0\u00b11.8 T umors9 40.8 \u00b13.7 41.2\u00b12.6 42.3\u00b12.6 42.9\u00b12.7 35.8\u00b12.4 42.4\u00b13.6 43.3\u00b13.5 45.6\u00b14.6 42.2\u00b13.9 Leukemia1 61.0 \u00b15.9 61.3\u00b14.2 62.5\u00b10.0 79.2\u00b12.1 81.6\u00b11.6 69.7\u00b13.2 81.0\u00b13.8 90.5\u00b12.5 72.5\u00b14.2 Table 3. Clustering results of di?erent methods on 12 data sets. The best result for each data set is highlighted in bold face. DatasetNMI\u00b1std(%) All Features MaxVar Laplacian Score SPFS-SFS SPEC MCFS UDFS NDFS EUFS PIE10P 25.5 \u00b13.4 28.6\u00b12.7 30.5\u00b12.5 30.8\u00b10.5 25.3\u00b11.5 31.9\u00b13.1 49.9\u00b12.7 30.1\u00b13.1 49.3\u00b11.8 PIX10P 88.0 \u00b12.1 89.1\u00b11.6 89.8\u00b10.7 90.0\u00b13.2 91.0\u00b11.9 91.7\u00b13.1 85.6\u00b11.9 86.8\u00b14.5 91.5\u00b11.3 COIL20 77.1 \u00b11.3 71.9\u00b10.7 72.5\u00b11.1 73.7\u00b10.5 75.3\u00b11.6 74.5\u00b11.2 76.0\u00b11.3 74.3\u00b11.8 76.6\u00b11.7 ORL 70.0\u00b11.7 70.7\u00b12.1 71.1\u00b11.3 70.9\u00b11.2 71.4\u00b11.3 75.2\u00b11.7 73.4\u00b11.5 75.6\u00b11.6 70.5\u00b11.3 JAFFE 87.5 \u00b13.8 83.1\u00b13.4 87.2\u00b12.4 90.8\u00b13.7 87.4\u00b12.2 91.4\u00b13.8 90.3\u00b15.2 89.4\u00b12.1 82.3\u00b13.4 MNIST 48.9\u00b11.0 47.6\u00b10.4 48.1\u00b11.0 48.9\u00b10.4 48.3\u00b10.4 52.0\u00b10.2 50.0\u00b10.9 44.8\u00b10.5 47.5\u00b10.7 BA 57.2\u00b11.1 57.7\u00b10.9 58.7\u00b10.7 58.9\u00b11.2 58.3\u00b10.8 58.6\u00b10.8 59.1\u00b10.9 58.1\u00b10.9 58.4\u00b10.9 tr11 5.7\u00b11.6 8.9\u00b12.2 15.2\u00b13.5 15.3\u00b13.4 14.5\u00b13.0 7.1\u00b11.7 11.1\u00b11.6 9.9\u00b13.5 12.7\u00b13.9 oh15 20.5\u00b12.1 23.2\u00b11.6 25.7\u00b11.9 26.2\u00b11.3 24.9\u00b11.6 23.4\u00b11.1 23.2\u00b12.1 22.3\u00b11.8 24.5\u00b12.7 TOX-171 13.6 \u00b12.3 11.4\u00b13.2 12.5\u00b11.7 20.2\u00b13.2 9.7\u00b10.0 12.7\u00b10.4 16.7\u00b14.8 22.3\u00b11.8 13.0\u00b11.7 T umors9 39.5 \u00b13.1 40.2\u00b12.5 41.0\u00b12.3 41.3\u00b12.1 34.5\u00b12.4 41.1\u00b12.7 41.5\u00b13.5 44.1\u00b13.4 41.1\u00b13.2 Leukemia1 37.6 \u00b110.7 36.1\u00b15.5 36.7\u00b10.0 49.3\u00b12.6 58.5\u00b11.7 53.5\u00b11.3 59.6\u00b14.5 66.2\u00b17.4 61.8\u00b10.9925  Jianyu Miao and Lingfeng Niu  /  Procedia Computer Science   91  ( 2016 )  919 \u2013 926  5. Conclusions This paper gives a survey on feature selection methods proposed in literature. Several state of the art feature selection methods are introduced. As we can see in our experiments, there are one or more parameters to be set. However, in practice, we do not and can not know the best parameters corresponding to the given data set. So How to select theadaptive hyper-parameters and the number of selected features are open problems and also are our future work. Acknowledgements The authors would like to express their sincere thanks to the associate editor and the reviewers who made great con- tributions to the improvement of this paper. This work was partially supported by National Science Foundation of Chi- na(No.71110107026, No.91546201 and No.71331005). References [1] L. Wolf, A. Shashua, Feature selection for unsupervised and supervised inference: The emergence of sparsity in a weight-based approach, The Journal of Machine Learning Research 6 (2005) 1855\u20131887. [2] Z. Zhao, H. Liu, Spectral feature selection for supervised and unsupervised learning, in: Proceedings of the 24th international conference on Machine learning, ACM, 2007, pp. 1151\u20131157. [3] F. Nie, H. Huang, X. Cai, C. H. Ding, E?cient and robust feature selection via joint ?2, 1-norms minimization, in: Advances in neural information processing systems, 2010, pp. 1813\u20131821. [4] J. Li, Z. Chen, L. Wei, W. Xu, G. Kou, Feature selection via least squares support feature machine, International Journal of Information Technology & Decision Making 6 (04) (2007) 671\u2013686. [5] Z. Zhao, H. Liu, Semi-supervised feature selection via spectral analysis., in: SDM, SIAM, 2007, pp. 641\u2013646. [6] Z. Xu, I. King, M. R.-T. Lyu, R. Jin, Discriminative semi-supervised feature selection via manifold regularization, Neural Networks, IEEE Trans- actions on 21 (7) (2010) 1033\u20131047. [7] P. Wang, Y . Li, B. Chen, X. Hu, J. Yan, Y . Xia, J. Yang, Proportional hybrid mechanism for population based feature selection algorithm, Interna- tional Journal of Information Technology & Decision Making (2013) 1\u201330. [8] D. Cai, C. Zhang, X. He, Unsupervised feature selection for multi-cluster data, in: Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, ACM, 2010, pp. 333\u2013342. [9] J. G. Dy, C. E. Brodley, Feature selection for unsupervised learning, The Journal of Machine Learning Research 5 (2004) 845\u2013889. [10] Y . Yang, H. T. Shen, Z. Ma, Z. Huang, X. Zhou, l2, 1-norm regularized discriminative feature selection for unsupervised learning, in: IJCAI Proceedings-International Joint Conference on Arti?cial Intelligence, V ol. 22, Citeseer, 2011, p. 1589. [11] E. R. Hruschka, E. R. Hruschka Jr, T. F. Cov \u02dcoes, N. F. Ebecken, Bayesian feature selection for clustering problems, Journal of Information & Knowledge Management 5 (04) (2006) 315\u2013327. [12] R. Liu, R. Rallo, Y . Cohen, Unsupervised feature selection using incremental least squares, International Journal of Information Technology & Decision Making 10 (06) (2011) 967\u2013987. [13] B. Krishnapuram, A. Harternink, L. Carin, M. A. Figueiredo, A bayesian approach to joint feature selection and classi?er design, Pattern Analysis and Machine Intelligence, IEEE Transactions on 26 (9) (2004) 1105\u20131111. [14] Q. Cheng, H. Zhou, J. Cheng, The ?sher-markov selector: fast selecting maximally separable feature subset for multiclass classi?cation with applications to high-dimensional data, Pattern Analysis and Machine Intelligence, IEEE Transactions on 33 (6) (2011) 1217\u20131233. [15] X. He, D. Cai, P. Niyogi, Laplacian score for feature selection, in: Advances in neural information processing systems, 2005, pp. 507\u2013514.[16] K. Kira, L. A. Rendell, A practical approach to feature selection, in: Proceedings of the ninth international workshop on Machine learning, 1992, pp. 249\u2013256. [17] L. E. Raileanu, K. Sto?el, Theoretical comparison between the gini index and information gain criteria, Annals of Mathematics and Arti?cial Intelligence 41 (1) (2004) 77\u201393. [18] C. Ding, H. Peng, Minimum redundancy feature selection from microarray gene expression data, Journal of bioinformatics and computational biology 3 (02) (2005) 185\u2013205. [19] H. Peng, F. Long, C. Ding, Feature selection based on mutual information criteria of max-dependency, max-relevance, and min-redundancy, Pattern Analysis and Machine Intelligence, IEEE Transactions on 27 (8) (2005) 1226\u20131238. [20] I. Guyon, J. Weston, S. Barnhill, V . Vapnik, Gene selection for cancer classi?cation using support vector machines, Machine learning 46 (1-3) (2002) 389\u2013422. [21] P. S. Bradley, O. L. Mangasarian, Feature selection via concave minimization and support vector machines., in: ICML, V ol. 98, 1998, pp. 82\u201390. [22] G. Fung, O. L. Mangasarian, Data selection for support vector machine classi?ers, in: Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining, ACM, 2000, pp. 64\u201370. [23] A. Y . Ng, Feature selection, l 1 vs. l 2 regularization, and rotational invariance, in: Proceedings of the twenty-?rst international conference on Machine learning, ACM, 2004, p. 78. [24] L. Wang, J. Zhu, H. Zou, Hybrid huberized support vector machines for microarray classi?cation, in: Proceedings of the 24th international confer- ence on Machine learning, ACM, 2007, pp. 983\u2013990. [25] G. Obozinski, B. Taskar, M. Jordan, Multi-task feature selection, Statistics Department, UC Berkeley, Tech. Rep. [26] A. Evgeniou, M. Pontil, Multi-task feature learning, Advances in neural information processing systems 19 (2007) 41. [27] R. O. Duda, P. E. Hart, D. G. Stork, Pattern classi?cation, John Wiley & Sons, 2012. [28] R. A. Fisher, The use of multiple measurements in taxonomic problems, Annals of eugenics 7 (2) (1936) 179\u2013188. [29] K. Fukunaga, Introduction to statistical pattern recognition, Academic press, 2013. [30] H. Li, T. Jiang, K. Zhang, E?cient and robust feature extraction by maximum margin criterion, Neural Networks, IEEE Transactions on 17 (1) (2006) 157\u2013165. [31] Y . Luo, D. Tao, C. Xu, D. Li, Vector-valued multi-view semi-supervised learning for multi-label image classi?cation, in: Proceedings of the 27th AAAI Conference on Arti?cial Intelligence, AAAI 2013, 2013.926   Jianyu Miao and Lingfeng Niu  /  Procedia Computer Science   91  ( 2016 )  919 \u2013 926  [32] D. Cai, X. He, J. Han, Semi-supervised discriminant analysis, in: Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on, IEEE, 2007, pp. 1\u20137. [33] X. Chang, F. Nie, Y . Yang, H. Huang, A convex formulation for semi-supervised multi-label feature selection., in: AAAI, 2014, pp. 1171\u20131177. [34] Z. Li, J. Liu, Y . Yang, X. Zhou, H. Lu, Clustering-guided sparse structural learning for unsupervised feature selection, Knowledge and Data Engineering, IEEE Transactions on 26 (9) (2014) 2138\u20132150. [35] C. Ding, D. Zhou, X. He, H. Zha, R 1-pca: rotational invariant l 1-norm principal component analysis for robust subspace factorization, in: Proceedings of the 23rd international conference on Machine learning, ACM, 2006, pp. 281\u2013288. [36] U. V on Luxburg, A tutorial on spectral clustering, Statistics and computing 17 (4) (2007) 395\u2013416.[37] I. Kononenko, Estimating attributes: analysis and extensions of relief, in: Machine Learning: ECML-94, Springer, 1994, pp. 171\u2013182. [38] Z. Zhao, L. Wang, H. Liu, J. Ye, On similarity preserving feature selection, Knowledge and Data Engineering, IEEE Transactions on 25 (3) (2013) 619\u2013632. [39] Z. Li, Y . Yang, J. Liu, X. Zhou, H. Lu, Unsupervised feature selection using nonnegative spectral analysis., in: AAAI, 2012. [40] S. Wang, J. Tang, H. Liu, Embedded unsupervised feature selection, in: Twenty-Ninth AAAI Conference on Arti?cial Intelligence, 2015.", "25": "Feature Selection from Huge Feature Sets  Jose Bins  Faculdade de Informdtica  Pontifkia Universidade Cat6lica (RS)  Port0 Alegre, RS 906 19-900, Brazil  Bins @ i nf.pucrs. br  Abstract  The number of features that can be computed over an  image is, for practical purposes, limitless. Unfortunately,  the number of features that can be computed and exploited  by most computer vision systems is considerably less. As  a result, it is important to develop techniques for selecting  features from very large data sets that include many irrel-  evant or redundant features. This work addresses the fea-  ture selection problem by proposing a three-step algorithm.  The first step uses a variation of the well known Relief al-  gorithm [ll] to remove irrelevance; the second step clus-  ters features using K-means to remove redundancy; and the  thirdstep is a standard conibinatoriulfeature selection algo-  rithm. This three-step combination is shown to be more ef-  fective than standurd,feature selection algorithms for large  data sets with lots of irrelevant and redundant features. It  is also shown to be no worse than standard techniques for  duta sets that do not have these properties. Finally, we show  a third experiment in which a data set with 4096 features is  reduced to 5% of its original size with very little itforniation  loss.  1. Introduction  The number of features that can be computed over an  image is, for all practical purposes, limitless. Examples of  common image features include Fourier coefficients, PCA  eigenvectors, Zernike moments, Gabor energy functions,  Wavelet responses, probe sets, and histogramkorrelogram  features, not to mention simple set features like the mean and  standard deviation of an image. Moreover, this list of pop-  ular features barely scratches the surface; in [23], Tieu and  Viola compute 45,000 image features without using any of  those mentioned above. The feature set available for object  classification is therefore very large.  Unfortunately, large feature sets are problematic. Real-  time systems cannot afford the time to compute or apply Bruce A. Draper  Computer Science Department  Colorado State University  Fort Collins, CO 80523, USA  Draper @cs.colostate.edu  them. More relevent to this paper, statistical model fitting  and/or supervised learning systems generally do not have  enough labeled training instances to fit accurate models over  very large feature spaces, due to finite sample effects [9]. At  the same time, in many cases it is difficult or impossible to  know without training which features are relevent to a given  task, and which are effectively noise. As a result, the ability  to select features from a huge feature set is critical for com-  puter vision.  Given a feature set of size M, the feature selection prob-  lem is to find a feature subset of size n (n << M) that maxi-  mizes the system\u2019s ability to classify object instances. Find-  ing the optimal set of features is usually intractable [ 141, and  many problems related to feature selection have been shown  to be NP-hard ([2], [SI). For most practical problems, an op-  timal solution can only be guaranteed if a monotonic crite-  rion for evaluating features can be found, but this assump-  tion rarely holds in the real-world [ 131. As a result, we are  forced to find heuristic solutions that represent a trade-off  between solution quality and time.  We are interested in the problem of feature selection in  the context of computer vision. In particular, we are inter-  ested in problems with the following characteristics:  0 Large numbers of features, on the order of thousands.  0 Many irrelevant features, with regard to a given task.  0 Many redundant features, with regard to a given task.  0 Noisy data, since image noist will affect all measured  0 Continuous data, since most features listed above pro-  0 Small training sets, relative to the size of the initial fea- features.  duce continuous values.  ture set.  2. Previous Work  The literature covering feature selection is extensive and  spread across many fields, including document classifica-  tion, data mining, object recognition, biometrics, remote  159 0-7695-1143-0/01 $10.00 0 2001 IEEE  Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:17:19 UTC from IEEE Xplore.  Restrictions apply. sensing and computer vision. It is relevent to any task where  the number of features or attributes is larger than the number  of training samples, or too large to be computationally fea-  sible. Feature selection is also related to four other areas of  research: dimensionality reduction [24]; space partitioning  [ 171; feature extraction and decision trees [21].  Many algorithms have been proposed for feature selec-  tion, from simple algorithms like Sequential Forward Selec-  tion (SFS) [ 181 to more complex algorithms such as neural  net prunning [6] and genetic selection [22]. Surveys of fea-  ture selection algorithms are given by Kittler [ 121, Siedlecki  and Sklansky [22] and Bins [I]. For this work, the most  relevant algorithms are: Relief, proposed by Kira and Ken-  dell [ 111 in 1992 and extended by Kononenko [ 151 to handle  noisy, incomplete and multi-class data sets; and Sequential  Floating Forward Selection (SFFS) and Sequential Floating  Backward Selection (SFBS), proposed in 1994 by Pudil et  al. [20]. Relief has been shown to detect relevance well,  even when features interact [5], and SFFS/SFBS has been  shown to be much faster than Branch and Bound (BB) while  obtaining comparable results on at least some data sets [20].  3 The proposed system  3.1 A Three-step Algorithm  The goal of our system is to reduce a large set of fea-  tures (on the order of thousands) to a small subset of fea-  tures (on the order of tens), without significantly reducing  the system\u2019s ability to approximate functions or classify ob-  jects. Our approach, shown in Figure 1, is a three step sys-  tem: first the irrelevant features are removed, then the re-  dundant features are removed, and finally a traditional com-  binatorial feature selection algorithm is applied to the re-  maining features. The idea is that each step is a filter that  reduces the number of candidate features, until finally only  a small subset remains. As will be discussed later, we com-  bine these filters into three algorithms (R+K+B, R+K+F, and  R+K), depending on the domain and task statement.  3.2 The Component Filters  The first filter removes irrelevant features using a modi-  fied form of the Relief algorithm [ 11, 151. For readers who  are not familiar with Relief, it assigns relevance values to  features by treating training samples as points in feature  space. For each sample, it finds the nearest \u201chit\u201d (another  sample of the same class) and \u201cmiss\u201d (a sample of a differ-  ent class), and adjusts the relevance value of each feature  according to the square of the feature difference between  the sample and the hit and miss. Kononenko [ 151 suggests  several modifications to Relief to generalize it for continu-  ous features and to make it more robust in the presence of Figure 1. High level system architecture.  noise. We adopt Kononenko\u2019s modifications, and modify  Relief again to remove a bias against non-monotonic fea-  tures, as described in [ 11.  Within our feature selection system, Relief is used as a  relevance filter. We therefore threshold the relevance values  to divide the feature set into relevant and irrelevant features.  This can be done either by thresholding the relevance value  directly, or by selecting the highest n values and discarding  the remaining features. In either case, Relief does not de-  tect redundancy, so the remaining feature set still contains  redundant features.  The second step is a redundancy filter that uses the K-  means algorithm [ 161 to cluster features according to how  well they correlate to each other. When feature clusters are  discovered, only the feature with the highest Relief score is  kept; the other features in the cluster are removed from the  feature set. This is an unusual application of K-means clus-  tering, in that features are clustered (instead of samples), and  correlation is used as the distance measure. A correlation  threshold of 0.97 is used to detect when the features in a clus-  ter are not sufficiently similar, in which case the cluster is  split to make sure that potentially usefull features are not re-  moved from the feature set.  The third and final filter is a combinatorial feature selec-  tion algorithm. When possible, we use the Sequential Float-  ing Backward Selection (SFBS) algorithm [20]. Unfortu- ,:  160  Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:17:19 UTC from IEEE Xplore.  Restrictions apply. nately, we find that SFBS is not feasible for feature sets of  more than about 110 features. (Ng, et al, have previously  reported a limit of 100 features [ 191.) Therefore, when the  number of features remaining after the relevence and redun-  dancy filters exceeds 110, we switch to the slightly less ef-  fective but more efficient Sequential Floating Forward Se-  lection (SFFS) algorithm [20]. We use a Mahalanobis dis-  tance measure inside both SFFS and SFBS.  The order of these three filters is important. The asymp-  totic complexity of Relief is O(s2f), where s is the number  of training samples, and f is the number of features. Since  the number of features is much larger than the number of  samples, the complexity of Relief is linear in terms of the  most significant size factor. K-means, on the other hand,  does more work per feature. The complexity of one itera-  tion of K-means is O(ksf), where k is the number of clus-  ters. Unfortunately, since we recursively split clusters using  a very tight correlation threshold, IC is not a constant, but in-  stead k M f. Thus the complexity of one iteration of K-  means is O(sf2). (The number of iterations also increases  with the number of features.) Since f can be very large, it  is important to filter irrelevent features before filtering re-  dundant ones. Of course, SFFS and SFBS are more complex  then either of the first two filters, and must be run last.  3.3 Running the system  There are two ways for an application to use our feature  selection system. If the application does not require a fixed  feature set size, but simply needs to ensure that there are  no irrelevent or redundant features, then only the first two  stages are run. We call this version R+K, and users need  only to provide one parameter, to threshold the relief scores.  (We have not encountered any reason to adjust the clustering  threshold of 0.97.)  Alternatively, if an application requires a target number  of features, then a third filter is used to reduce the set of  relevent and non-redundant features to the target feature set  size. If fewer than 110 features survive the first two filters,  SFBS is used (we call this version R+K+B). Otherwise, the  final filter is SWS (creating R+K+F).  4. Evaluating the Feature Selection System  To evaluate our system, we conducted three experiments  over three different data sets. The first data set contains re-  gions of interest (i.e. subimages) extracted from aerial im-  ages of Fort Hood, Texas. Each region of interest is a hy-  pothesized house, and the goal of the system is to judge  which hypotheses are accurate. This is a regression task,  since the accuracy of hypotheses are measured on a scale of  zero to one. The second data set are features extracted from images of hand-written characters. This data set was first de-  scribed by Breuklen et al. [3,4], and has also been used by  Jain et al. [ 101. It has the disadvantage that it contains only  649 features\u2019, and that none of these features are completely  irrelevent or redundant. The third data set contains images  of cats and dogs, and has been previously used as a testbed  to compare appearance-based recognition methods [25].  4.1. Experiment #1: aerial images  The first data set consist of 891 features computed over  regions of interest extracted from aerial images of Fort Hood  [7]. Typical features here are statistical features (mean, st.  dev., etc.) computed over the raw image or first or sec-  ond derivatives of the raw image, and repeated at differ-  ent scales. Other features include eigenprojections, probes,  histograms comparisons, etc. These features match the as-  sumptions underlying our system, in that there are more fea-  tures (891) then training samples (200), and many of the fea-  tures are irrelevant for judging house hypotheses, or are re-  dundant with other features.  The first experiment tests if all three steps of the algo-  rithm are necessary. Since the system is composed of filters,  any filter can be removed and the system will still work\u2019. To  test whether all three filter are needed, all feasible combina-  tions of modules of the system were applied to the task of  selecting the best subset of ten features.  Each combination of modules selects features in a differ-  ent,way, and consequently the number of features selected  at each step may vary. Where possible, the Relief threshold  was set to select the 300 most relevent features. By default,  the clustering threshold was 0.97; however, when cluster-  ing was followed by SFBS, only the best 110 or fewer clus-  ters according to their Relief score were used, and when K-  means was the final filtering stage, only ten clusters were  used. SFFS and SFBS were set to select exactly 10 features.  Table 1 shows the eight feasible combinations of features  and how many features were selected by each module.  For each feature set, 100 neural nets were trained and  tested. When training a net, the data is randomly divided  into three sets: a learning set (70%); a validation set (15%)  and a test set (15%). Each net was trained for 15,000  epochs, with an \u201cearly termination\u201d routine saving the net  state with the lowest MSE on the validation set. Each net is  then evaluated in terms of its MSE on the test set. The av-  erage MSE for the 100 neural nets is shown in table 2 for  each combination of filters. As can be seen, the best perfor-  mance is achieved by using all three filters. The results are  particularly good when the third filter is SFBS.  \u2018The original images are no longer available. so we cannot compute ad-  \u2019SFBS is not practical if it is applied to more than I10 features. ditional features.  161  Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:17:19 UTC from IEEE Xplore.  Restrictions apply. I System 1 Original I R I K 1 F/B I Final set I  IR I891 1101-1-1 10 I System  R+K+F R R+K R+F K+F F  Ho F F F TF  P = 0 6.2e-15 1.5e-11 %le-01 =O F  R+K 891 - - 10 10  891 300 10 - 10  Table 1. Number of features selected at each  module of each filter combination tested. R,  #, F, and B correspond to Relief, &means,  SFES, and SFBS. 1 1 I I  System 1 R+k+F R+B K+F  R+K+B I Hn F F F R+F  R+B  K+F  0.0269  0.0236  0.0247  0.0154 891 110 - 10 IO  891 110 - 10 10  891 - - 10 10  R+K+F  R+K+B  Table 2. MSE for each tested combination of  modules of the system. 891 300 110 10 10  891 300 110 10 10  The differences between filter combinations are statisti-  cally relevant. Table 3 shows the result of a T-test compar-  ing the combinations of filters. The null hypothesis (Ho)  for the T-test is that the two samples have the same average  MSE (a = 0.005). The row of Table 3 labeled HO shows the  result of the T-tests (true or false); the row labeled P shows  the probability of observing the given result by chance if the  null hypothesis is true.  The first line of Table 3 compares the whole system using  SFFS against other combinations using SFFS (or no combi-  natorial filter). This shows that it is significantly better to run  the whole system than just part of the system. The only case  where the difference is not statistically significant is in com-  parison to K+F. Even here, however, the three-step version  outperformed the two-step version, although not by enough  to rule out the possibility of a statistical fluke. More impor-  tantly, when the whole system was run using SFBS as the fi-  nal filter, its performance greatly surpasses all other options.  This indicates that when most features are irrelevant and/or  redundant, the best option is to run the three steps of the sys- System  Relief MSE  0.0696  R+K+F  R+K+B I 1 P 1 zo i zo i 2.2e-15 I  0.0156  0.0093 Table 3. Result of the T-test (Ho) and proba-  bility of observing the given result by chance  given that the null hypothesis is true (P) for  pairs of filters. Values of P z 0 indicate that  the probability is so small that it exceeds the  capability of representation used by the sta-  tistical package.  tem, i.e. Relief, K-means and SFBS.  Although the goal of this test was to check the necessity  of every component, a second but equally important goal  was achieved. Relief and SFFS, running alone, are two of  the best feature selection algorithms in the literature. Thus,  by showing that our system outperforms these two filters, we  also show that our three-step algorithm outperforms its pri-  mary competitors.  4.2 Experiment #2: The Digits Data  The second data set contains features extracted from im-  ages of handwritten numerals (\u20180\u2019 - \u20189\u2019) extracted from a col-  lection of Dutch utility maps. There are 200 samples per  digit, for a total of 2,000 samples. Each sample has 649 fea-  tures: 76 Fourier coefficients of the character shapes; 216  profile correlations; 64 Karhunen-Loeve coefficients; 240  pixel averages over 2 x 3 windows; 47 Zernike moments;  and 6 morphological features.  Unlike the aerial image data set, this data set does not  obey the assumptions that motivated our system design. In  particular, it has more training samples (2,000) than fea-  tures (649), which makes it possible to train classifiers on  the whole feature set, without performing feature selection.  It also has no irrelevent features, and no two features are re-  dundant.  The goal of the first part of this experiment was to test a  \u201cdo no harm\u201d philosophy. The digit data set is small enough  to run SFFS on all 649 features. Since our three-step sys-  tem uses SFFS, we wanted to be sure that the three-step al-  gorithm did as well as SFFS alone, even when the assump-  tions underlying the first two filters were not met. Table 4  shows the results. The full system (R+K+F) actually per-  formed slightly better than SFFS alone.  The full system with SFBS performed worse than SFFS  alone, because we had to raise the Relief threshold artifi-  162  Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:17:19 UTC from IEEE Xplore.  Restrictions apply. 1 System 1 #Feat 1 MSE I  I R+K+B I 649 I 0.0132 I  R+K+F 649.. 0.0049  -1  Table 4. Average MSE for 100 nets (5000  epochs each) for combinations of the system  on the original Digits data. R, K, F, and B cor-  respond to Relief, &means, SFES, and SFBS.  cially high in order to reduce the number of features prior to  SFBS below 110. This is a warning: although Relief is good  at detecting irrelevent features, it should not be relied on to  select the best from among relevent features. The combina-  torial selection algorithms are better at that. If there are more  than 1 10 relevent and non-redundant features, use SFFS.  Having shown that our three-step algorithm does no  harm, we next show that it filters redundant and irrelevent  features when we know they are present. We modify the dig-  its data set by creating a redundant feature set out of the 649  original digits features, plus a second copy of each of the  original features with 10% Gaussian noise added, for a total  of I298 features. We then extended this to a redundant and  irrelevent feature set by adding a third copy of each original  feature, this time with 60% Gaussian noise added (render-  ing the new features almost useless). Finally, we created a  mixed feature set out of the original 649 features plus four  versions of each original feature with added noise ranging  from 1070 to 55%. The results of applying our three-step al-  gorithm to each of these data sets is shown on Table 5.  [ System I Feat. Set I #Feat 1 MSE ]  Table 5. Average MSE of 100 nets on the mod-  ified Digits data sets. R, K, F, and B corre-  spond respectively to Relief, E-means, SFES,  and SFBS.  Results from Table 5 show that the system was able to re-  move the irrelevant and redundant features, because its per-  formance is statistically the same as the results for the origi-  nal data set (see Table 4). In comparison, the performance of  SFFS degrades when enough irrelevant and redundant fea-  tures are included. 4.3 Experiment #3: Cats and Dogs  In the third experiment, we use the system to remove ir-  relevent and redundant features without specifying a target  feature set size. As a result, the third filter (SFFS or SFBS)  is discarded. Instead, we apply a \u201cR+K\u201d algorithm to re-  move irrelevent features and redundant features, and return  as many relevent and unique features as the data will sup-  port.  In this experiment, the data set is composed of two hun-  dred images of cat faces and dog faces. Each sample is a  black-and-white 64x64 pixel image, and the images have  been registered by aligning the eyes. The performance task  is to distinguish cats from dogs. The standard technique, as  described in [25], is to compute eigenvectors from a gallery  of 160 out of the 200 images. The remaining 40 probe  images are projected into the eigenspace, and the nearest  gallery image to each is returned as its match. A match is  said to be correct if it of the same species as the probe. Fig-  ure 2 shows 24 examples extracted from the cats and dogs  data set.  Figure 2. Examples of images on the Cats and  Dogs data set (12 cats and 12 dogs).  Once again, the data contradicts one of our original as-  sumptions, in this case the implicit assumption that features  are expensive to compute and store. For principal compo-  nents analysis, the features are the 4096 pixel values. Since  these features do not have to be computed, and PCA can eas-  ily handle thousands of features, it is not necessary to do  feature selection for this task.  Nonetheless, there are two good reasons to select features  from this data set. The first is provide an intuition about  what pixels are important for this data set and task. The sec-  ond is to allow PCA to be applied to much larger images.  Current systems would be hard pressed to compute basis  vectors for 5 12x5 12 images, but it would be much more fea-  163  Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:17:19 UTC from IEEE Xplore.  Restrictions apply. sible to select a few thousand pixels from such images and  apply PCA to the reduced feature vectors.  This experiment also emphasizes the system\u2019s ability to  detect relationships between features. The cats in the data  set run the gamut of intensities from black to white; so do  the dogs. As a result, the intensity of a single pixel is almost  meaningless. It is only the differences between pixels that  distinguish cats from dogs. Fortunately, Relief is sensitive  enough to relations among features that it is still able to de-  tect relevance.  Since the features are pixels, the results of Relief and K-  means can be seen visually for this domain. Figure 3 shows  images representing the result of the two filters. In these im-  ages, a pixel is zero (black) if it was eliminated from the fea-  ture set by the filter. Otherwise, rhe relevence value com-  puted by Relief is used as the pixel\u2019s intensity.  Figure 3(a) is the image after the relevance filter. The  relevence filter removes all but 615 pixels, reducing the vol-  ume of data by 85%. The remaining pixels highlight the dif-  ferences betwee dogs and cats: dogs have relatively higher  foreheads then cats, as well as wider muzzles. Cats have ears  in the upper corners of the images. Cats\u2019 eyes are also larger,  in proportion to their spacing.  Figure 3(b) shows the result of the redundancy filter,  which further reduces the data set down to just 217 pixels.  What the redundancy filter finds is that in many cases, the  information in a pixel is the same as the information in the  neighboring pixel. As a result, it produces a checkerboard  effect, in which a pixel is selected and its neighbors are re-  jected.  The question, of course, is how much information has  been lost by reducing the feature set from 4096 pixels to just  2 17. To test this, we applied a standard \u201ceigenfaces\u201d recog-  niton system to the complete set of 4096 pixels, and then  again to the reduced set of 217 pixels. In both cases, we  trained the system on 160 images, holding forty images out  for testing. We repeated this process five times in a cross-  validation mode, so that every image was used as a test im-  age exactly once.  The classifier used was a PCA-based l-nearest neighbor.  This classifier computes all eigenvectors for a learning set  and the sample projections over this basis. When a new sam-  ple is presented its projection over all eigen-vectors is com-  puted and the result of the classification is the label (class)  of the closest neighbor, in terms of Euclidean distance, to the  sample projection.  To test if both data sets achieve the same performance, we  used McNemar\u2019s test. This test is similar to a binomial test,  but it considers only the difference in classification between  the data sets. As a result, it is more sensitive to differences  between algorithms than a binomial test. McNemar\u2019s test in-  dicates that the difference in classification accuracy between  the original pixel set and the reduced pixel set is not statisti- Figure 3. Result of the Relief and Kmeans fil-  ters over the Cats and Dogs dataset. The  value of each pixel is zero if it passed the filter  or the Relief score it it did not passed the fil-  ter. a) after Relief filter (615 features/pixels  selected); b) after k-means filter (217 fea-  tures/pixels selected).  cally significant. In other words, the data sets have approxi-  mately the same information despite the fact that the filtered  version contains only 5% of the pixels in the original one.  5. Summary and Conclusions  The proposed system selects features from a large feature  set via three filters. The first is based on the Relief algo-  rithm ([11, 151); it filters out irrelevant features. The sec-  ond filter is based on K-means([ 161); it filters out redundant  features. The final filter is a combinatorial feature selection  algorithm (SFFS or SFBS [20]); it selects the final subset  of features. We recommend three algorithms, depending on  the situation. The R+K+B algorihm is best for producing a  feature set of a particular size, if the number of relevent and  non-redundant features in the domain is less than 110. Oth-  erwise, R+K+F is the best algorithm to select a feature sub-  set of a specific size. If the size of the feature subset may  vary, use R+K.  The system was tested with three different data sets. The  Fort Hood aerial image hypothesis data set has many irrel-  evant and redundant features, and allowed us to show that  R+K+B outperforms other algorithms from the iiterature, as  well as other versions of this system. The digits data set  [3, 101 is composed of hand-picked sets of features. It does  not contain irrelevent or redundant features, and was used to  show that the system \u201cdoes no harm\u201d when such features are  not present. It also allowed us to demonstrate that the per-  formance of the system does not degrade as irrelevent and  redundant features are added. The third data set, composed  of images of cats and dogs, allowed us to visualize the results  of the first two filters, and to demonstrate that the system is  sensitive to relationships between features.  The main contribution of this work is the system and  164  Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:17:19 UTC from IEEE Xplore.  Restrictions apply. the algorithms (R+K+B, R+K+F, R+K). As far as we know,  these are the first algorithms (outside of text classification  systems) that can handle such large data sets. It is also the  first feature selection system which explicitly filters for ir-  relevance and redundancy.  References  J. Bins, \u201cFeature Selection of Huge Feature Sets in the Con-  text of Computer Vision\u201d, Ph. D. Dissertation, Computer Sci-  ence Department, Colorado State University, 2000.  A. L. Blum and R. L. Rivest, \u201cTraining a 3-node Neural Net-  work is NP-complete \u201d, Neural Networks, 5: 1 17-1 27, 1992.  M. van Breukelen, R.P.W. Duin, D.M.J. Tax and J.E. den Har-  tog, \u201cCombining ClassiJiers for the Recognition of Handwrit-  ten digits\u201d, Kybemetika, 34(4):381-386, 1998.  M. van Breukelen, R.P.W. Duin, D.M.J. Tax and J.E. den Har-  tog, \u201cHandwritten Digit Recognition by Combined Classi-  fiers\u201d, lSt IAPR Workshop on Statistical Techniques in Pat-  tern Recognition, Prague, 1997, pp. 13-18.  R. Caruana and D. Freitag, \u201cGreedy Attribute Selection \u201d, llth  International Conference on Machine Leaming, 1994.  G. Castelano, A.M. Fanelli and M. Pelillo, \u201cAn Iterative P run-  ning Algorithm for Feedfonvard Neural Networks\u201d, IEEE  Transactions on Neural Networks, 8(3):5 19-531, 1997.  B. A. Draper, J. Bins, K. Baek. \u201cADORE: Adaptive Object  Recognition \u201d, Videre 1 (4):86-99, 2000.  L. Hyafil and R. L. Rivest, \u201cConstructing Optimal Binaty De-  cision Trees is NP -complete \u201d, Information Processing Letters,  5(1):15-17, 1976.  A. Jain and B. Chandrasekaran, \u201cDimensionality and Sample  Size Considerations\u201d, Pattern Recognition Practice, V. 2, Kr-  ishnaiah and I.N. Kana1 editors, pp. 835-855, North-Holland,  1982.  [IO] A.K. Jain, R.P.W. Duin, and J. Mao, \u201cStatistical Pattern  Recognition: A review\u201d, IEEETransactions on Pattern Recog-  nition and Machine Intelligence, 22( l), Jan. 2000.  [ 1 I] K. Kira and L.A. Rendell, \u201cThe Feature Selection Problem:  Traditional Methods and a New Algorithm\u201d, loth National  Conference on Machine Intelligence, pp. 129-134, 1992.  [ 121 J. Kittler,\u201cFeature Set search Algorithms\u201d, Pattem Recogni-  tion and Signal Processing; C.H. Chen Editor, Sijthoff & No-  ordhoff, Alphen aan den Rijn, The Netherlands, 1978, pp. 41-  60. [14] R. Kohavi and G.H. John, \u201cWrappers for Feature Subset  Selection \u201d, Artificial Intelligence Journal, 97( 1-2):273-324,  1997.  [ 151 I.. Kononenko, \u201cEstimation attributes: Analysis and Exten-  sions of RELIEF\u201d, European Conference on Machine Learn-  ing, Catana, Italy, pp. 171-182, 1994.  [16] J. MacQueen, \u201cSome Methods for Classification and  Analysys of Multivariate Observations\u201d, Proceedings of the  Fifth Berkley Symposium on Mathematics, Statistics and  Probability, L. M. LeCam and J. Neyman eds., pp. 281-297,  University of Califomia Press, Berkeley, 1967.  [I71 D.P. Mandal, \u201cPartitioning of Feature Space For Pattern  Class$cation Pattern Recognition, 30( 12): 1971 - 1990, 1997.  [ 181 T. Marill and D.M. Green, \u201cOn the Effectiveness of Recep-  tors in Recognition Systems\u201d, IEEE transactions on Informa-  tion Theory, 9:11-17, 1963.  [I91 H.T. Ng, W.B. Goh and K.L. Low, \u201cFeati~re Selection, Per-  ceptron Learning, and a Usabilit?, Case Study for text Catego-  rization \u201d. 20th annual international ACM SIGIR conference  on Research and development in information retrieval, July  27-3 1, Philadelphia, pp. 67-73, 1997.  [20] P. Pudil, J. Novovicova and J. Kittler, \u201cFloating Search  Methods in Feature Selection \u201d, Pattern Recognition Letters,  (131 119- 1125, 1994.  [21] J.R. Quinlan, \u201cDecision Trees and Multivalued Attributes\u201d,  J. Richards, ed., Machine Intelligence, V. 11, Oxford, Eng-  land, Oxford Univ. Press, pp. 305-31 8, 1988.  [22] W. Siedlecki and J. Sklansky, \u201cOn Automatic Feature Selec-  tion \u201d, International Journal of Pattern Recognition and Artifi-  cial Intelligence, 2(2): 197-220, 1988.  [23] K. Tieu and P. Viola. \u201cBoosting Image Retrieval\u201d, IEEECon-  ference on Computer Vision and Pattern Recognition, Hilton  Head, June 13- 15, 2000, pp. 228-235.  [24] M. Turk and A. Pentland, \u201cEigenfaces for Recognition\u201d,  Journal of Cognitive Neuroscience, 3( l), 199 1.  [25] W. Yambor, \u201cAnal.ysis of PCA-based and Fisher  Discriminant-Based Image Recognition Algorithms\u201d,  M.S. Thesis, Department of Computer Science, Colorado  State University, May 2000.  [ 131 R. Kohavi, \u201cFeature Subset Selection as Search with Prob-  abilistic Estimates\u201d, AAA1 Fall Symposium on Relevance,  1994.  165  Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:17:19 UTC from IEEE Xplore.  Restrictions apply. ", "26": "1388 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 7, JULY 2015 FREL: A Stable Feature Selection Algorithm Yun Li, Member, IEEE , Jennie Si, Fellow, IEEE , Guojing Zhou, Shasha Huang, and Songcan Chen Abstract \u2014 Two factors characterize a good feature selection algorithm: its accuracy and stability. This paper aims at intro-ducing a new approach to stable feature selection algorithms.The innovation of this paper centers on a class of stable featureselection algorithms called feature weighting as regularizedenergy-based learning (FREL). Stability properties of FRELusing L1 or L2 regularization are investigated. In addition,as a commonly adopted implementation strategy for enhancedstability, an ensemble FREL is proposed. A stability bound forthe ensemble FREL is also presented. Our experiments usingopen source real microarray data, which are challenging highdimensionality small sample size problems demonstrate that ourproposed ensemble FREL is not only stable but also achievesbetter or comparable accuracy than some other popular stablefeature weighting methods. Index Terms \u2014 Energy-based learning, ensemble, feature selection, feature weighting, uniform weighting stability. I. I NTRODUCTION FEATURE selection has been an active research area in machine learning and data m ining for decades. It is an important and frequently used technique for data dimensionreduction by removing irrelevant and redundant information from a data set. It is also a knowledge discovery tool for providing insights on the problem through interpretations of the most relevant features [1]. Discussions on feature selec- tion usually center on two technical aspects: search strategyand evaluation criteria. Algorithms designed with different strategies broadly fall into three categories: ?lter, wrapper, and hybrid or embedded models [2]. On the other hand,if the categorization is based on output characteristics, fea- ture selection algorithms can be divided into either feature weighting/ranking algorithms or subset selection algorithms. In this paper, we focus on feature weighting. A comprehensive survey of existing feature selection techniques and a generalframework for their uni?cation can be found in [1]\u2013[3]. In addition to classi?cation accuracy, another important measure is stability when evaluating the quality of a feature Manuscript received August 20, 2013; revised April 21, 2014; accepted July 15, 2014. Date of publication August 12, 2014; date of current versionJune 16, 2015. This work was supported in part by the National NaturalScience Foundation of China unde r Grant 60973097, Grant 61035003, Grant 61073114, Grant 61170151, and Grant 61300165, in part by the National Science Foundation of Jiangsu Provi nce under Grant BK20131378 and Grant BK20140885, in part by the Jiangsu Government Scholarship, and in part by the Jiangsu Qinglan Project. Y . Li, G. Zhou, and S. Huang are with the Jiangsu High Technology Research Key Laboratory for Wireless Sensor Networks, College of Com-puter Science, Nanjing University of Posts and Telecommunications, Nanjing 210023, China (e-mail: liyun@njupt.edu.cn). J. Si is with the School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ 85287 USA (e-mail: si@asu.edu). S. Chen is with the College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing 210016, China (e-mail:s.chen@nuaa.edu.cn). Digital Object Identi?er 10.1109/TNNLS.2014.2341627selection algorithm. Here, stability means the insensitivity of the result of a feature selection algorithm to variations in the training data set [4]. This issue is particularly important for some applications where feature selection is used as a knowledge discovery tool for identifying characteristic mark- ers to explain the observed phenomena. A feature selectionalgorithm without stability constraint usually results in signif- icantly different feature subsets due to variations in the training data. Even though most of these feature subsets are as goodas they can be in terms of classi?cation accuracy, unstable feature selection results can shake the con?dence of domain experts when experimentally validating the selected features to interpret important discoveries [5]. For instance, in analyzing cancer biomarkers, such as leukemia, the available data setsusually are high dimensional yet with small sample size. Among the thousands of genetic expression levels, a critical subset is to be discovered that links to two leukemia labels.It is therefore necessary that th e selected predictive genes are common to variations of training samples. Otherwise, the results will lead to less con?dent diagnosis. In consideration of the importance of stability in applications, several stable fea- ture selection algorithms have been proposed. The ensemblemethods [4], [6]\u2013[8], sample weighting [9], [10], and feature grouping [5], [11] are a few examples. A comprehensive survey of earlier work can be found in [12]. Those existingstable feature selection algorithms make use of empirical criteria for stability measurements, and they fell short of explicitly providing a stability analysis. The pressing need for an analytical examin ation of stable feature selection algorithms beyond the simple empirical approach is thus evident. In this paper, guided by energy-based learning [13], a new algorithm framework for featur e weighting as regularized energy-based learning (FREL) is proposed. Stability of theproposed FREL algorithms under an L1 or L2 regularizer is examined. In addition, an ensemble FREL is also introduced and analyzed for its stability. The proposed FREL is then applied to open source real microarray data to demonstrate its effectiveness for both stability and accuracy in high dimen-sionality small sample size (HDSSS) application problems. This paper is organized as follows. The framework of FREL and ensemble FREL are introduced in Section II.Section III analyzes the stability of feature weighting with an L1 or L2 regularizer. In addition, the stability analysis of ensemble FREL is presented. The experimental results on microarray data are shown in Section IV . This paper concludes in Section V . II. E NERGY -BASED LEARNING FOR FEATURE WEIGHTING Energy-based learning [13] provides a uni?ed framework for many probabilistic and nonprobabilistic approaches to 2162-237X \u00a9 2014 I EEE. Personal u se is perm itted, but republication/redistri bution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:18:01 UTC from IEEE Xplore.  Restrictions apply. LIet al. : FREL: A STABLE FEATURE SELECTION ALGORITHM 1389 learning for prediction, classi?cation, decision-making, sample ranking, detection, and conditional density estimation. In this paper, we consider an energy-based learning framework for the design of feature weighting algorithms. Speci?cally, wewill focus on developing FREL. An ensemble FREL will also be discussed. In addition to these feature weighting algorithms as well as the implementations of these algorithms, this paperprovides stability analysis for these algorithms. A. Energy-Based Learning Consider an inference model between input variable xand inferred variable y. The goodness of ?t of each possible model con?guration relating xtoycan be measured by an energy function E(y,x). The value of this energy function can be viewed as the degree of compatibility of a given con?guration between xandy. Conventionally, small energy values correspond to highly compatible con?gurations, while large energy values correspond to highly incompatible con?g- urations. When applying such an inference model, for a giveninput x, the model produces the most compatible answer y ? such that y?=argminy?YE(y,x). The energy-based learning entails ?nding an energy function that produces the best yfor ag i v e n x. To search for the best energy function, a family of parameterized energy functions of the form F={E(w,y,x): w?W}is proposed, where wis the model parameter [13]. B. Regularized Energy-Based Learning To train an energy-based model, we are given a training setDcontaining nsamples, D={ X,Y}={ xi,yi}n i=1, where xiis the ith training input and yiis the corresponding desired answer such as a label, but not limited to that. Each sample input is represented by a d-dimensional vector, i.e., xi? Rd. To ?nd the best energy function in the family F, we need to assess the quality of an energy function, only with information from the training set Dand possible prior knowledge about the task where data were collected.This quality measure is a loss functional, i.e., a function of functions, denoted by L D(w). We call it the objective loss function. Accordingly, the learning problem becomes ?nding thew'that minimizes the objective loss w'=argminw?WLD(w). (1) Usually, an objective loss function based on data set Dis de?ned as follows: LD(w)=1 nn? i=1L(w,xi)+?R(w). (2) On the right-hand side of (2), L(w,xi)is the per-sample loss function. Then, the ?rst term (1/n)?n i=1L(w,xi)is the sample-averaged loss function, which is taken over n respective per-sample loss function, and is denoted by JD(w) for simplicity JD(w)=1 nn? i=1L(w,xi). (3) TheR(w) in (2) is a regularizing term that can be used to embed prior knowledge about which energy functions arepreferable to others. In this paper, the classical L1 and L2 regularizer are respectiv ely examined. Parameter ?in (2) is a cost balancing factor. Based on the discussion of energy-based learning above, it is evident that the per-sample loss function should be designed in such a way that it assigns a low loss to well-behaved energy functions, i.e., the energy functions that give the lowest energyto the correct answers and higher energy to all other including incorrect answers. Conversely, the energy functions that do not assign the lowest energy to the correct answers would have a high loss [13]. The generalized margin loss functions, for example, meet those conditions [13]. It is thus used asthe per-sample loss function L(w,x i). Before introducing the generalized margin loss function, the following de?nition is needed. De?nition 1: Letybe a discrete variable. The most offending incorrect answer is the one that has the lowest energy among all the answers that are incorrect yi=argminy?Y,y?=yiE(w,y,xi). (4) Then, a generalized margin loss function for per-sample loss can be described as follows : L(w,xi)=Q?(E(w,yi,xi),E(w, yi,xi)) (5) where E(w,yi,xi), which is consequently denoted as Eifor notation simpli?cation, is the energy of a correct answer forxi;E(w, yi,xi), denoted by  Ei, is the energy of the most offending incorrect answer for xi;?is a positive parameter called the margin, and it is the energy gap between theincorrect answers and the correct ones. As discussed in [13], the function Q ?(Ei, Ei)? Ris assumed to be convex, which can be easily satis?ed. Moreover, consider the energy spacede?ned by E i\u00d7 Ei,a n dl e t ?Q?/?Eiand?Q?/? Eidenote the gradient of Q?along Eiand Ei, respectively. Then, in general, it holds true that ?Q?/?Ei-?Q?/? Ei>0 in the region where Ei+?>  Eiin the energy space. This means wherever  Eiis smaller than Eiplus?, the gradient along Eiis larger than the gradient along  Ei. Then, Q?pushes down the value of Eiand pulls up the value of  Ei. This causes the Q?loss surface to be slanted toward low values of Eiand high values of Ei[13]. This meets the speci?cation in Section II-A that the energy value between xiand its compatible answer yibe small, while the energy value between xiand its incompatible answer  yiis large. Remark 1: There are many possible realizations of Q? in (5) such as the hinge, log, s quare-square, and square- exponential losses [13]. For example, when the log loss with in?nite margin and the square-square loss with margin ?are selected, the corresponding per-sample loss functions in (5) are as follows : L(w,xi)=log(1+exp(E(w,yi,xi)-E(w, yi,xi))) (6) L(w,xi)=E(w,yi,xi)2+(max(0,?-E(w, yi,xi)))2.(7) If the parameter win energy function Eis de?ned as the feature weight vector, then a feature weighting algorithmsimply ?nds the w 'that minimizes the objective loss func- tion de?ned in (2). In Section IV-D, the log and square- square losses are chosen as two representative per-sample loss Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:18:01 UTC from IEEE Xplore.  Restrictions apply. 1390 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 7, JULY 2015 functions to construct the objective loss functions and to derive speci?c feature weighting algor ithms. However, the theoretical results obtained in this paper are not limited to log and square- square losses in the feature weighting stability analysis. C. Feature Weighting as Regularized Energy-Based Learning In short, for a feature weighting problem to be considered an energy-based learning problem, ?rst, the parameter win the energy function should be relevant to the feature weightvectors. Second, a generalized margin loss function should be selected as per-sample loss function L(w,x i)a ss h o w ni n( 2 ) to construct the objective loss function LD(w). After that, the correct answer and the most offending incorrect answer for a sample should be explic itly identi?ed. To summarize, the following issues are critical to the feature weightingalgorithm design: 1) using appropriate criteria to determine the correct answer and the most offending incorrect answer for each sample and 2) properly designing the structure of an energy function E, which is needed in the per-sample loss function of (5) and consequently (2). By properly addressingthese issues, learning leads to ?nding the appropriate energy function such that the per-sample loss function of (5) will be pushed down for correct answers and pulled up for incorrectanswers while maintaining an energy gap or margin. To address the ?rst issue of developing appropriate cri- teria to determine the correct answer and the most offend- ing incorrect answer for each sample, we resort to the nearest neighbor (NN) classi?cation scheme. Note that, theNN classi?er is a nonlinear mapping between input patterns and class labels. It is a simple algorithm but has received considerable attention aga in recently since they have been demonstrated highly ef?cient in some state-of-the-art real- world applications [14], [15]. Additionally, the NN classi?er can be viewed as an energy-based learning where the energy function is a sample distance measure. Consider a sample x i, its NN in the same class denoted by NH(xi)can be determined easily so long as a distance measure is de?ned. Also, the NH(xi)can be considered as the nearest correct answer. Similarly, the NN with a different label denoted by NM(xi), can be considered as the most offending incorrect answer based on De?nition 1. Once the correct and the most offending incorrect answers are identi?ed as NH(xi)and NM(xi), respectively, parame- terized energy functions E(w,yi,xi)andE(w, yi,xi)needed in the generalized margin loss function of (5) can be de?ned as weighted Manhattan distances as shown in the following: E(w,yi,xi)=E(w,NH(xi),xi)=wT|xi-NH(xi)|(8) E(w, yi,xi)=E(w,NM(xi),xi)=wT|xi-NM(xi)|(9) where |\u00b7| denotes an element-wise ab solute value operator on each component of the argument vector, which is of dimension din the cases of (8) and (9), Tdenotes transpose, andwis the parameter associated with the energy function. As discussed above, the solution to the general energy-basedlearning problem with energy function shown in (2) becomes the feature weighting vector w={w(1),w( 2) ,...,w( d)}in our current problem setting. Algorithm 1 FREL Algorithm Step 1 . Input training data set D={xi,yi}n i=1,xi?Rd, margin ?in (5) and regularization parameter ?in (2). Step 2 . Initialize w=(1,1,..., 1)?Rd. Step 3 .F o r i=1,2,..., n (a) Given xi,? n dt h e NH(xi)andNM(xi)based on NN algorithm. (b) From (8) and (9), calculate E(w,NH(xi),xi), E(w,NM(xi),xi) and obtain the generalized margin loss Q?, i.e., L(w,xi),i n( 5 ) . (c)?=1 n?L(w,xi) ?w+??R(w) ?w. (d)w=w-? ||?|| 2. Step 4 . Output the feature weighting vector w'=w. The optimal feature weight w'can then be found by many different optimization approaches. As an example, the gradientdescent algorithm is used to illustrate the minimization of the objective loss function (2) next. With the above discussions in place, we are in a position to summarize our proposed FRELas Algorithm 1. Once the parameterized energy functions Ein (8) and (9) are de?ned, respectively, we can employ a generalized margin loss function of the form (5) as the per-sample loss function L(w,x i). As discussed, many different generalized margin loss functions mentioned in Remark 1 such as the hinge and the log losses can be integrated with different regularizers, (e.g., L1 or L2 regularizer) to make up different objectiveloss functions L D(w) in (2). Therefore, a family of feature weighting algorithms could consequently be derived. Note that the local learning-based featur e weighting algorithm described in [16] is a special case of FREL when the log loss and L1 regularizer are adopted. Moreover, if the log loss is combinedwith L2 regularizer, which is used to enhance diversity among base feature selectors in ensemble feature selection, the algo- rithm in [7] can be obtained and it is another special case ofFREL. Note, however, this is the ?rst time that the algorithms, including those in [7] and [16], are analyzed from an energy- based learning perspective under the proposed framework of FREL, and their respective stability properties are provided. It also should be pointed out that for the purposes of this paper, we use Manhattan distance to determine the NNs and to de?ne energy functions in (8) and (9). Nonetheless, other standard distance measures such as Euclidean distance are alsoeligible candidates without creating any problem in obtaining the results in this paper. To summarize, resorting to NN classi?cation, the feature weighting problem is described as regularized energy-based learning and the feature weighting vector corresponds to the parameter win the objective loss function de?ned in (2). The generalized margin loss function Q ?, which is convex, in (5) is adopted as per-sample loss function L(w,xi)in energy-based learning. For the regularizer in the objective loss function (2), the classical L1 and L2 regularizers are considered in this paper. Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:18:01 UTC from IEEE Xplore.  Restrictions apply. LIet al. : FREL: A STABLE FEATURE SELECTION ALGORITHM 1391 Algorithm 2 Ensemble FREL Step 1 . Input training data set D={xi,yi}n i=1,xi?Rd, margin ?in (5), regularization parameter ?in (2), random sampling parameters aandm. Step 2 . Initialize wE=(0,0,..., 0)?Rd. Step 3 .F o r t=1,2,..., m (a) Produce a bootstrap subset D(rt)with size ?an?. (b) Perform FREL on D(rt)to obtain a base weighting result wD(rt). (c)wE=wE+1 mwD(rt). Step 4 . Output the ensemble feature weighting result wE. D. Ensemble FREL Ensemble learning is an effective approach for producing robust and accurate learning solutions in machine learn- ing [17], [18] as demonstrated by many signi?cant applica- tions [19]\u2013[21]. For instance, a popular ensemble learningmaking use of the bagging approach [22] consists in averaging several estimators built from random subsamples of the original data set. Similar to the ensemble models for supervised learning, there are two essential steps in ensemble feature selection. The ?rst step involves creating a set of different base feature selectors, each provides its output, while the second step aggregates the results of all base feature selectors [4]. In our case, bootstrap-based strategy as in [4] and [7] is used to train base feature selectors derived from FREL onmdifferent bootstrap subsets of the original training set D={x i,yi}n i=1. Ensemble feature weighting result is achieved by averaging the obtained solutions from the base feature selectors. Let 0 <a< 1a n d ?an?be the integer closest to an.F o r t=1,..., m,l e t rt={rt(1),rt(2) ,..., rt(?an?)}be an index sequence randomly draw n from the natural sequence {1,..., n}without replacement. We denote the mbootstrap subsets by D(rt)={xrt(k),yrt(k)}?an? k=1fort=1,..., mand the subsets are all drawn independently. LetwD(rt)denote the outcome of the feature weighting algorithm after FREL is applied on the tth bootstrap training subset D(rt). Therefore, we obtain mbase feature weight- ing results {wD(r1),wD(r2),...,w D(rm)}. In this paper, the ensemble result is obtained as wE=1 mm? t=1wD(rt) (10) which is aggregated by averaging the outputs of base feature selectors. The pseudocode for the above discussed ensemble FREL is provided in Algorithm 2. III. S TABILITY ANALYSIS In this paper, the stability of FREL is considered in the following sense: variations in outputs are small or boundedin response to small variations in the input of the data set. This may entail the following two scenarios. The ?rst is perturbation at the instance level caused by, for example,removing samples from or adding samples to the data set. The second is perturbation at the feature level caused by, for example, adding noise to the features in the data set. In addition, a combination of both types of perturbations mayimpose on a data set and cause stability concerns [4]. The stability of several classi?cation, regression, and sample ranking methods has been analyzed thoroughly [23]\u2013[25] inthe sense similar to that descr ibed above. However, the sta- bility of feature selection algorithms has only been examined empirically. This paper aims at pr oviding a theoretical analysis for the stability of so me feature weighting algorithms under FREL. To account for small instance level perturbations, we only need to consider removing one sample from the data set and then analyzing the stability property of a feature weightingalgorithm. Stability consideration after adding a sample fol- lows directly from the result of removing a sample. To account for small feature level perturbations, we need to consider changing one sample and examine its impact on the stability of the algorithm. Before we proceed to analyzing both scenarios described above, consider the following. For a given training set Dof size nfrom a certain distribution P, its samples are drawn independent identically distributed (i.i.d.) from P.L e t D \\idenote a modi?ed training data set by removing the ith training sample (xi,yi)from the original training data set D,w h e r e i?{1,\u00b7\u00b7\u00b7,n}. We denote byDi, the training set obtained by changing one sample from (xi,yi)to(x' i,y' i). De?nition 2: Consider a feature weighting algorithm Awith output feature weight vectors denoted by wDandwD\\ifor data set Dand D\\i, respectively. Algorithm Aisuniformly weighting stable with stability bound \u00df(\u00df=0) if for any D of size nand any i?{1,..., n},w eh a v e ||wD-wD\\i||2=\u00df. (11) Intuitively, a smaller value of \u00dfcorresponds to greater stability. To consider stability properties of algorithm Awith theith data sample distorted from the original ith data sample, i.e., the training data set is changed from DtoDi,w el e tt h e feature weight vector wDidenote the output of algorithm A for data set Di. Based on the uniform weighting stability de?- nition in (11) and by applying the triangle inequality, we have ||wD-wDi||2=| |(wD-wD\\i)-(wDi-wD\\i)||2 =| |wD-wD\\i||2+| |wDi-wD\\i||2 =2\u00df. (12) Therefore, according to (12), the stability of changing one sample can be reduced for analyzing the stability of removingone sample. In other words, the uniform weighting stability formulated under the removal of one training data sample implies the same stability con cept under the condition of one sample deviates from the original data sample. As such, stabil- ity in the sense of De?nition 2 can be used for analyzing thestability of algorithm Aunder the perturbations at both instance and feature levels, which are described at the beginning of this section. Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:18:01 UTC from IEEE Xplore.  Restrictions apply. 1392 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 7, JULY 2015 In the following sections, we will discuss the stability of FREL with L2 and L1 regularizers, and the stability of ensemble FREL, respectively. A. Stability Analysis for FREL With L2 Regularizer In this section, we examine stability properties of FREL withR(w)in (2) being an L2 regularizer. Remark 2: For this part of the stability analysis, given the choice of the energy functions as in (8) and (9), we use the shorthand notation of L(wTzi)in place of the per-sample loss function L(w,xi)in (5), where ziis considered a trans- formation of xi. For different loss functions in Remark 1, the expressions of ziare different. For instance, if the log loss is used, then zi=|xi-NH(xi)|-| xi-NM(xi)|. Furthermore, if the training samples xi\u2019s are bounded and can be normalized, then ||zi||2should be as well. We denote this by||zi||2=f. Then, according to (2) and Remark 2 above, the objective functions LD(w)andLD\\i(w)with L2 regularizer are, respec- tively, de?ned as follows : LD(w)=1 nn? j=1L(wTzj)+?||w||2 2 (13) LD\\i(w)=1 nn? j=1,j?=iL(wTzj)+?||w||2 2. (14) Theorem 1: Consider the FREL with L2 regularizer and a given training set D.L e t Dcontain ninput samples xi? Rdwith its corresponding transformation ziprovided as in Remark 2, and that ||zi||2=f(i=1,..., n). Assume that the per-sample loss function L(wTzi)in (5) is Lipchitz with constant d.L e twDandwD\\ibe the feature weighting results through minimizing the convex objective functions LD(w) andLD\\i(w)in (13) and (14), respectively. Then, FREL with L2 regularizer is uniformly weighting stable with stabilitybound \u00df=df/n?. Proof: Refer to Appendix A. Remark 3: Theorem 1 shows that FREL with L2 regularizer has uniform weighting stability. Furthermore, the stability bound approaches zero as O(1/n). Therefore, this is a tight bound. Remark 4: To consider stability in the sense of De?nition 2, for the case of removing qsamples, the corresponding stability bound can be obtained similarly to that for a single sample removed and the bound is qtimes that of a single sample removed as well. B. Stability Analysis for FREL With L1 Regularizer Now, we turn to stability analysis for FREL with L1 regu- larizer. Due to the nature of the L1-norm, the feature selection algorithm with L1 regularizer usually results in sparse solu- tions, i.e., the feature vector output contains some elements that are zero. Xu et al. [26] proved that sparsity and stability are at odds with each other for classi?cation and regression problems. They show that sparse algorithms are not stable, as de?ned in [23]. Speci?cally, if an algorithm encouragessparsity, then it is susceptible to small variations in input. They also proved that a sparse algorithm can identify redundant features (IRFs). Being IRF means that if the two features are highly dependent on each othe r, then removing one of the features would not affect the class-discriminative power of the algorithm. Therefore, a sparse algorithm may have nonunique optimal solutions and thus may be ill-posed. In this paper, weprovide some constraints so that the stability of FREL with L1 regularizer in the sense of De?nition 2 can be preserved. For a given training set Dfrom distribution P, assume that there exists a true unique unknown feature weighting vector w ?.L e twDandwD\\ibe the optimal estimates of w?, respectively, where the optimality refers to that wDandwD\\i are optimal solutions as a result of minimizing the objective loss functions LD(w)andLD\\i(w), respectively LD(w)=1 nn? j=1L(w,xj)+?||w||1 (15) LD\\i(w)=1 nn? j=1,j?=iL(w,xj)+?||w||1. (16) Then, we have ||wD-wD\\i||2=| |wD-w?-(wD\\i-w?)||2 =| |wD-w?||2+| |wD\\i-w?||2.(17) Let||?w1||2=| |wD-w?||2and||?w2||2=| |wD\\i-w?||2. Then ||wD-wD\\i||2=| |? w1||2+| |? w2||2. (18) To carry on the discussion of uniform weighting stability for FREL with L1 regularizer, we de?ne the exactly sparse model below. De?nition 3: If some feature weights in the feature weight- ing vector are exactly zero, then this feature weighting model isexactly sparse. Moreover, to analyze the stability of FREL with L1 regu- larizer, we also need some additional conditions, such as the sample-averaged loss functions JD(w)=1/n?n j=1L(w,xj) andJD\\i(w)=1/n?n j=1,j?=iL(w,xj)as in (3) are differ- entiable and they satisfy the strong convexity condition [27]de?ned below. De?nition 4: The sample-averaged loss function J D(w)has thestrong convexity with parameter ?D=0, if JD(w?+?w1)-JD(w?)=? ?JD(w?),?w1? +?D|| ?w1||2 2 (19) where ?,?is the inner product. Similarly, we can de?ne strong convexity for JD\\i(w)on?w2with parameter ?D\\i=0. Remark 5: Refer to Remark 1 where we elaborated on some per-sample loss functions for L(w,xj). Among these func- tions, the log, square-square, a nd square-exponential losses are differentiable. Therefore, the corresponding sample-averaged loss functions JD(w)andJD\\i(w)are also differentiable. Remark 6: For those differentiable per-sample loss functions in Remark 5, it is evident that the square-exponential and square-square losses are strongly convex. Just as introduced Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:18:01 UTC from IEEE Xplore.  Restrictions apply. LIet al. : FREL: A STABLE FEATURE SELECTION ALGORITHM 1393 in [28], the log loss is also strongly convex. Then, their corresponding sample-averaged loss functions JD(w) and JD\\i(w)are also strongly convex. Theorem 2: Consider FREL with L1 regularizer and a given training set Dfrom distribution P.L e t Dcontain n input samples xi?Rd(i=1,..., n)andw?be the true unique unknown feature weighting vector, and it is exactlysparse. Assume the sample-averaged loss function J D(w)and JD\\i(w)are differentiable and have the strong convexity with parameter ?D=0a n d ?D\\i=0 as in De?nition 4, respec- tively. Let wDandwD\\ibe the sparse feature weighting results from minimizing the convex objective functions LD(w) and LD\\i(w) in (15) and (16), respectively. Then, for parameter ?=max[|| ?JD(w?)||8,|| ?JD\\i(w?)||8], FREL with L1 regularizer is uniformly weighting stable with stabilitybound \u00df=2v d?(1/?D+1/?D\\i). Proof: Refer to Appendix B. Remark 7: For FREL with L1 regularizer, if its output is exactly sparse and the sample-averaged loss functions are strongly convex, then th e feature weighting stability bound is inversely affected by the strong convexity constants ?Dand?D\\i. Remark 8: The bound also scales with the regularization parameter ?. This makes sense since the more sparse solutions lead to less feature weighting stability properties. Remark 9: Consider stability in De?nition 2 for the case of removing qsamples. Let the corresponding sample-averaged loss function be strongly convex with parameter ?D\\\\q=0. Then, the st ability bound for qremoved samples can be obtained similarly to that for a single sample remove, and the stability bound is 2v d?(1/?D+1/?D\\\\q). C. Stability for Ensemble FREL Based on De?nition 2, the uniform weighting stability of the ensemble FREL proposed in Section II-D is de?ned asfollows. De?nition 5: For a given training data set D={x i,yi}n i=1 and any i?{1,..., n}, the ensemble FREL is uniformly weighting stable with stability bound \u00dfE,i f ?????E r1,...,rm[ 1 mm? t=1wD(rt)] -Er1,...,rm[ 1 mm? t=1wD\\i(rt)]????? 2 =\u00dfE(20) where wD(rt)is the base feature weighting result of FREL on bootstrap subset D(rt)whose size is ?an?(0<a< 1), andwD\\i(rt)is the base feature weighting result of FREL on bootstrap subset D(rt)with xi,i?{1,..., n}, removed, mis the number of bootstrap subsets, Eis the expectation, and for t=1,..., m,rt={rt(1),rt(2) ,..., rt(?an?)}is an index sequence randomly draw n from the natural sequence {1,..., n}without replacement. Theorem 3: Consider ensemble FREL described in Algorithm 2 and a given data set Dcontaining ninput samples xi(i=1,..., n). Bootstrap strategy is adopted with the samp ling parameter a(0<a< 1)to create mbootstrap subsets D(rt)with size ?an?fort=1,..., m, where rt={rt(1),rt(2) ,..., rt(?an?)}is an index sequencerandomly drawn from the natural sequence {1,..., n}without replacement, and r1,..., rmare i.i.d. Let \u00dfbe the uniform stability bound of the base feature weighting algorithm FREL. Then, ensemble FREL is uniformly weighting stable withstability bound \u00df E=a\u00df. Proof: Refer to Appendix C. Remark 10: Theorem 3 indicates that ensemble feature weighting has tighter stability bound than its base feature weighting, which is consistent with observations from exper- iments in [4] and [6] that ensemble strategy usually improves feature selection stability. Remark 11: For the case of removing qsamples, the corresponding stability bound can be obtained similarly to that for a single removed sample and the bound is approximately aq\u00df\\\\q,w h e r e \u00df\\\\qis the stability bound for the base feature weighting with qsamples removed. IV . E XPERIMENTS In this section, we evaluate stability and accuracy of (ensemble) FREL in comparisons with some popular fea- ture weighting algorithms. Four real life problems areconsidered. The HDSSS problem is among the most challenging prob- lems for feature selection, particularly if output stability is desired. To evaluate and illustrate algorithm accuracy and stability of FREL for HDSSS problems, we analyzed real-world microarray data including TOX, SMK, leukemia [29], and prostate [30]. The ?rst two data sets are downloaded from http://featureselection.asu.edu/datasets.php, while the later twoare available in [29] and [30]. The goal of analyzing these four HDSSS problems is to identify those genetic expressions that are linked to respective diseases. The TOX data set contains 171 instances with 5748 genes. They consist of myocarditis and dilated cardiomyopathy (DCM) infected males and females as well as uninfected males and females. The DCM is often caused by viral infec- tions and can occur more frequently in men than women.DCM infection increases a person\u2019s risk of dying from heart failure. The SMK data set contains 187 smokers either with or without lung cancer. The total number of genes to be tested is 19 993. Leukemias are primary disorders of the bone marrow. They are malignant neoplasms of hematopoietic stem cells. The leukemia data set to be analyzed includes 72 samples to betested, which are from acute le ukemia patients, either acute lymphoblastic leukemia or acute myelogenous leukemia. The total number of genes to be tested is 7129. The prostate data set contai ns 136 samples of prostate cancer patients, which have 12 600 genes to be studied. Among the samples, 77 are tumor and 59 are normal. As described, the four data sets (TOX, SMK, leukemia, and prostate) share the common traits of small samples (171, 187,72, and 136) with an extremely high dimensionality in latent variables (5748, 19 993, 7129, and 12 600). They are typical HDSSS problems. Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:18:01 UTC from IEEE Xplore.  Restrictions apply. 1394 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 7, JULY 2015 A. Algorithms for Comparison For HDSSS problems, it is generally accepted that conven- tional feature selection algorithm should not be used directlyfor obtaining stable feature outputs [6], [7], [10]. Instead, ensemble algorithms are expected to improve stability proper- ties of feature selection. We therefore focus on the ensembleFREL provided in Algorithm 2 when conducting comparisons in this paper. However, we still provide classi?cation accuracy results using the original FREL presented in Algorithm 1. For comparison purposes, we consider three speci?c FREL-based algorithms, as described in Algorithm 1:Log+L2, Log +L1, and Square +L2. The Log +L2 consists of log loss in (6) as per-sample loss function and L2 regularizer ||w|| 2 2is used. For the Log +L1 algorithm, the per-sample loss function is the same as in Log +L2, but L1 regularizer ||w||1is used. The Square +L2 is based on square-square loss function in (7) and L2 regularizer. For a sample xi,t h em a r g i n ?in Square+L2 is set as the Manhattan distance between NM(xi) and NH(xi). The ensemble versions of these three algo- rithms according to Algor ithm 2 are named as En-Log +L2, En-Log +L1, and En-Square +L2, respectively. Since the focus of this paper is on feature weighting, we therefore chose some popular feature weighting algorithms for comparison. The algorithms include Relief, ReliefF [31]\u2013[33], Fisher score [34], En-Relief [4], En-ReliefF, En-Fisher, and variance reduction (VR)-Lmba. En-Relief, En-ReliefF, and En-Fisher are the ensemble versions of Relief, ReliefF,and Fisher score, respectivel y. The implementations of the En-Relief, En-ReliefF, and En-Fisher are similar to the ensem- ble FREL as described in Algorithm 2 with Relief, ReliefF,and Fisher score in place of the FREL, respectively. The Relief algorithm is considered one of the most suc- cessful feature selection algorithms due to its simplicity and effectiveness [35]. The key idea of Relief is to iteratively estimate feature weights according to their ability to discrim-inate between the neighboring samples. In each iteration, a sample x iis randomly selected and then two NNs of xiare found, one from the same class and the other from a differentclass. The weight of the pth feature is then updated based on the distance between x iand its two NNs on the pth feature. The ReliefF is an extension of Relief by considering several NNs to deal with multiple class problems. Here, we would like to highlight the relationship between FREL and Relief (ReliefF). First of all, both algorithms can be viewed as hypothesis-margin-based approaches [36]. However, the differences between the two algorithms are evident: 1) ourproposed FREL is a systematic framework for stable feature selection based on energy-base d learning and regularization. Many speci?c algorithms can be viewed as realizations ofFREL; 2) regularizations are considered in FREL but not in Relief; 3) Relief directly calculates the feature weights based on margins (distances) while FREL obtains feature weights based on margin losses, and the loss functions can be selected from a pool of candidate functions ; and 4) a stability analysis for FREL is provided for the ?rst time. Fisher score is one of the most widely used feature selection methods. The key idea of Fisher score is to ?nd feature weightssuch that in the data space spanned by the weighted features, the distances between data points in different classes are as large as possible, while the distances between data points in the same class are as small as possible. Then, the criterionfor Fisher score prefers features that have similar values for the samples from the same class and different values for the samples from different classes. Feature weights are obtainedby computing the deviation of each feature from its mean value on all classes. The VR-Lmba is a nonensemble stable feature weighting algorithm. VR-Lmba uses a sample weighting strategy [9], [10] to improve the stability of feature weightingalgorithm\u2014Lmba [37]. The sample weighting strategy introduced in [9] and [10] is an effective approach to improve the stability for any feature selection methods. It assigns different weights to samples before performing feature selection with the aim of VR. In this paper, we combine the sample weighting strategy with Lmba to obtain a stable feature weighting algorithm VR-Lmba, as presented in [7]. The feature weighting algorithm\u2014Lmba is derivedfrom energy-based model without regularization. In other words, the objective function for Lmba is similar to that in (2) without R(w). The square-square loss mentioned in Remark 1 is used as per-sample loss function L(w,x i)in (5). Several NNs in the prede?ned range are considered in Lmba. B. Stability Measurement Since in almost all feature selection applications, the ulti- mate outputs of a feature selector should be a subset of features that are considered most prominent. Therefore, in the litera-ture, one usually makes use of the corresponding feature ranks in place of the feature weights for performance evaluation. Under the same consideration to evaluate the stability of FREL in this paper, we ?rst compute the feature weights as outputs of FREL, then these weights are turned into feature ranks, asin [4] and [7]. Therefore, our stability measure used in this paper is based on feature ranks. To be statistically signi?cant, several different sets of feature ranking results are obtained to empirically compute the stability measure. We theref ore use the bootstrap-based strategy without replacement. Consider the data set Dwith ninstances and dfeatures. Then, csampling subsets D(r l), l=1,..., c,o fs i z e ?\u00b5n?(0<\u00b5< 1)are drawn randomly from Dbased on bootstrap sampling without replacement. Note that, we name the sampling subset D(rl)as a sample subset to distinguish it from a bootstrap subset in ensemblefeature weighting procedure. Subsequently, feature weighting algorithms are performed on each of the csample subsets. Just as emphasized earlier, the feature weighting results should betransformed to feature ranking results to calculate the stability measure. As such, each algorithm will result in cfeature ranking results {R 1,R2,..., Rc}oncsample subsets. For nonensemble feature weighting algorithm, such as VR-Lmba, Log+L2, and so on, to transform its feature weighting result on each sample subset into feature ranking result, the rank value for a feature is determined as follows. The best feature with the largest weight is assigned rank 1, and the worst rank d. Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:18:01 UTC from IEEE Xplore.  Restrictions apply. LIet al. : FREL: A STABLE FEATURE SELECTION ALGORITHM 1395 For ensemble feature weighting, feature ranking is obtained as described below. Similar to the ensemble procedure described in Algorithm 2, each sample subset D(rl)with size s=?\u00b5n? (0<\u00b5< 1), is still randomly sampled using bootstrap strategy without replacement to produce mbootstrap subsets D(rlt)(t=1,..., m)with size ?as?(0<a< 1),a n d feature weighting algorithms (Relief, ReliefF, Fisher score, and our proposed FREL), are performed on each bootstrap subset D(rlt)(t=1,..., m)to obtain mbase feature weighting vectors {wD(rl1),...,w D(rlm)}. To obtain the ensemble feature ranking result for the ensemble featureweighting algorithm on each sample subset D(r l),mbase feature weighting vectors are correspondingly transformed to mbase feature ranking vectors {vD(rl1),..., vD(rlm)}based on the assignment rule above. The ?nal feature rank for each sample subset D(rl),l=1,..., c, is obtained by averaging over the respective bootstrapping subset-based feature ranks, i.e., Rl=1/m?m t=1vD(rlt)[4]. Consider a feature ranking vector set {R1,R2,..., Rc}, where Rl=(R1 l,R2 l,..., Rd l),l=1,2,..., c, is the feature ranking result for the dfeatures on the lth sample subset. Fea- ture selection stability is measured by comparing similaritiesamong the feature outputs on the csample subsets. The more similar the outputs are, the higher the stability measure is. The overall stability is de?ned as the average similarity based on all pairwise similarities between different feature ranking results R sta=2 c(c-1)c-1? l=1c? l'=l+1Sim(Rl,Rl') (21) where Sim (Rl,Rl')represents a similarity measure between feature ranking results Rland Rl'. For feature ranking, the Spearman rank correlation coef?cient [4], [38] is used to calculate the similarity Sim(Rl,Rl')=1-6d? p=1(Rp l-Rp l')2 d(d2-1). (22) C. Experiments Performed for Stability Based on the stability measurement procedure described in Section IV-B, for a given data set, c=10 sample subsets containing \u00b5=90% of the data are randomly drawn without replacement using bootstrap-based strategy. This percentage was chosen as in [4] to assess stability with respect to relatively small changes in the data set. For example, leukemia dataset is randomly drawn using bootstrap-based strategy without replacement to create 10 sam ple subsets, thus each sample subset contains 64 patient samples with 7129 genes. Then, for each sample subset, ensemble feature weighting algorithms (En-Log +L2 with ?=1, En-Log +L1 with ?= 0.01, En-Square +L2 with ?=0.1, En-Relief, En-ReliefF with 10 NNs, and En-Fisher) are applied as described in Section IV-B with a=0.9 to obtain feature ranking results. Simultaneously, the nonensemble feature weighting algorithm VR-Lmba, which is another method for improving the stability of feature selection, is also applied to each sample subset. For Fig. 1. Experimental evaluation of stability for m=20, the number of base feature selectors, for each of the seven candidate stable feature selectionalgorithms. 10 sample subsets, we obtain 10 feature ranking results for each feature weighting algorith m. For each feature weighting algorithm, the similarity between feature ranking result pairs is calculated using Spearman rank c orrelation coef?cient in (22). The stability of each feature weighting algorithm is thus the average similarity over all pairwise similarities calculated by (21). Moreover, we examine the effect of the regularization parameter ?in (2) on the stability of our FREL. As examples, one original algorithm derived from FREL, i.e., Log +L2, and one ensemble algorithm derived from ensemble FREL, i.e., En-Log +L2 with m=20, are chosen. D. Experimental Results for Stability We ?rst examine the effect of the number of bootstrap subsets used in ensemble methods, namely, how maffects the stability measure. We see that all algorithms display anupward trend in stability as mincreases, but saturates at around m=20. Since VR-Lmba is not an ensemble method, its stability remains constants. The stability results for ensemble feature weighting algorithms with m=20 and VR-Lmba are therefore shown in Fig. 1. From Fig. 1, we observethat the proposed ensemble FREL with L2 regularizer (En-log +L2 and En-Square +L2), always have the highest sta- bility among all the algorithms. Our algorithm with L1 regular-izer (En-log +L1), has the lowest stability, which is consistent with the observation in [26] that sparsity and stability are at odds with each other. On the other hand, we examine the effect of the regular- ization parameter ?in (2) on the stability of FREL (Log +L2 and En-Log +L2). Results on leukemia and prostate data sets are included. Similar results were obtained for the other two data sets. They are not included here due to space limitations.The experimental results are shown in Fig. 2. We observe that along with the increase in ?, the stability of Log +L2 and En-Log +L2 are improved, which is consistent with our theoretical analysis. E. Experiments Performed for Accuracy A good feature selector has to b e both stable and accurate. Once stable features are selected , an important consideration Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:18:01 UTC from IEEE Xplore.  Restrictions apply. 1396 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 7, JULY 2015 Fig. 2. Experimental evaluation of stability as a function of ?,t h e regularization parameter in (2), for Log +L2 and En-Log +L2 on leukemia and prostate. in many applications is the classi?cation accuracy using the selected features. The accuracy has to be evaluated in conjunc- tion with a classi?cation model based on the selected features. In experiments conducted in this paper, 1-NN (1NN) classi?er, 3-NNs (3NN) classi?er, the linear support vector machine (SVM) with C=1 [39], and SVM with polynomial kernel are used as classi?cation models since they are generally consid- ered easy to apply and good classi?ers. Each classi?er is used for classi?cation based on each of the feature weighting algo-rithms introduced in Section IV- A. Classi?cation accuracy is assessed using a 10-fold cross-validation. For each fold, a fea- ture weighting algorithm was applied to the training data to obtain the feature ranking result. For ensemble feature weight- ing algorithms (En-log +L2, En-log +L1, En-Square +L2, En-Relief, En-ReliefF, and En-Fisher), based on the exper- imental results in Sec tion IV-D, for each fold, m=20 bootstrap subsets of training data were randomly drawn witha=0.9 to create the ensemble feat ure weighting algorithms. After the features are ranked in descending order, different numbers of important features are selected with top ranks one by one to create classi?ers. Note that it is often observed in microarray data that only a small amount ( \u02dc50) of features, i.e., genes, is relevant [9], [10], [16], thus the number of selected important features from ranking results is less than 100 in our experiments. Once test result based on testingdata is obtained for each fold, the ?nal classi?cation accuracy results are obtained by averaging over the 10 folds. F . Experimental Results for Accuracy Our accuracy results are provided for the case of using 50 selected features. Fig. 3 shows a summary of the accu- racy values for regular featur e selection algorithms (Lmba, Relief, ReliefF with 10 NNs, Fisher score, Log +L2, Log +L1, and Square +L2) using 1NN, 3NN, linear SVM, and poly- nomial kernel SVM classi?er. Fig. 4 shows a summary ofaccuracy values for algorithms designed to improve stability (En-Relief, En-ReliefF, En-Fisher, En-Log +L2, En-Log +L1, En-Square +L2, and VR-Lmba) using 1NN, 3NN, linear SVM, and polynomial kernel SVM classi?er. These results as summarized in Figs. 3 and 4 show that no one algorithm is consistently better than any other on the four tested data sets. However, FREL and ensemble FREL are comparable with other algorithms most of the time. Fig. 3. Experimental results for accuracy of original feature selection methods using different classi?ers. (a) 1NN. (b) 3NN. (c) Linear SVM. (d) Polynomial SVM. G. Evaluation of Tradeoff Between Stability and Accuracy To measure the tradeoff between stability and classi?- cation accuracy of a feature selection algorithm, we take reference of the robustness-performance tradeoff in [4] to Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:18:01 UTC from IEEE Xplore.  Restrictions apply. LIet al. : FREL: A STABLE FEATURE SELECTION ALGORITHM 1397 Fig. 4. Experimental results for accuracy of methods designed for stable feature selection using different classi?ers. (a) 1NN. (b) 3NN. (c) Linear SVM.(d) Polynomial SVM. measure the tradeoff between feature stability and clas- si?cation accuracy in this paper. Speci?cally, we de?ne stability-accuracy trade-off (SAT) as SAT =(2\u00d7stability \u00d7 accuracy )/(stability +accuracy )where stability can be imple- Fig. 5. Experimental results about tradeoff between stability and accuracy for methods designed for stable feature s election using different classi?ers. (a) 1NN. (b) 3NN. (c) Linear SVM. (d) Polynomial SVM. mented by Rstain (21), accuracy is evaluated using the classi- ?cation outcome based on the selected features. The stability value for ensemble feature weighting when m=20 and the corresponding accuracy when the number of selected feature is Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:18:01 UTC from IEEE Xplore.  Restrictions apply. 1398 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 7, JULY 2015 50 are used to calculate their tradeoff. The experimental results for different classi?ers are shown in Fig. 5 where ensemble FREL with L2 regularizer is shown providing a better tradeoff between stability and accuracy than other compared methods. V. C ONCLUSION In this paper, we have proposed a new framework for FREL, which includes many useful stable feature weighting algorithms as its realizations. We also provide for the ?rst time the theoretical results for the uniform weighting stabilityof FREL with L1 and L2 regularizers. Ensemble FREL is introduced as a means of further improvement of stability, the stability of which is also provided. To evaluate FREL andensemble FREL performance, we make use of three speci?c realizations, Log +L1, Log +L2, and Square +L2, respectively. Several other popular feature selection algorithms are included in comparison with benchmark performances based on chal- lenging HDSSS problems. Our experimental results show thatour ensemble FREL when using the L2 regularizer outper- forms other algorithms in stability while providing comparable classi?cation accuracy. A PPENDIX A PROOF OF THE THEOREM 1 Proof: Let?wD=wD-wD\\i,w h e r e wDandwD\\iare the feature weighting results through minimizing the convex objective functions LD(w) and LD\\i(w) in (13) and (14), respectively. As such LD(wD)and LD\\i(wD\\i)retain mini- mum values at wDandwD\\i, respectively. Accordingly, this leads to the following for any a?[0,1]: LD(wD)-LD(wD-a?wD)=0 (23) LD\\i(wD\\i)-LD\\i(wD\\i+a?wD)=0. (24) Equations (13) and (14) are used to replace the corresponding terms in (23) and (24). It is evidentthat 1 /n? n j=1L(wT Dzj)= 1/n?n j=1,j?=iL(wT Dzj)+ 1/nL(wT Dzi). We use a shorthand notation 1 /n? j\\ifor 1/n?n j=1,j?=ifor the ease of discussion. Then, using (23) and (24) together, we have 1 n? j\\iL(wT Dzj)+1 nL(wT Dzi) -1 n? j\\iL((w D-a?wD)Tzj) -1 nL((w D-a?wD)Tzi)+1 n? j\\iL(wT D\\izj) -1 n? j\\iL((wD\\i+a?wD)Tzj)+?.||wD||2 2 -?||wD-a?wD||2 2+?||wD\\i||2 2 -?||wD\\i+a?wD||2 2 =0. (25)Since the per-sample loss function in (5) is convex, then by Jensen\u2019s inequality L((w D-a?wD)Tzj)=L((1-a)wT Dzj+awT D\\izj) =(1-a)L(wT Dzj)+aL(wT D\\izj) =L(wT Dzj) -a(L(wT Dzj)-L(wT D\\izj)).(26) Similarly, we also can obtain L((wD\\i+a?wD)Tzj))=L(wT D\\izj)+a(L(wT Dzj) -L(wT D\\izj)). (27) Substituting two identities (26) and (27) into (25) leads to ||wD||2 2-| |wD-a?wD||2 2-| |wD\\i+a?wD||2 2 +||wD\\i||2 2 =a n?(L(wT D\\izi)-L(wT Dzi)). (28) Note that the inequality L(wT D\\izi)-L(wT Dzi)=d|wT D\\izi- wT Dzi|holds because the per-sample loss function L(wTzi)is Lipchitz with d[40]. Therefore ||wD||2 2-| |wD-a?wD||2 2-| |wD\\i+a?wD||2 2 +||wD\\i||2 2=ad n?|wT D\\izi-wT Dzi| =ad n?|?wT Dzi|. (29) If we set a=1/2, the left-hand side of (29) amounts to ||wD||2 2+| |wD\\i||2 2-1 2||wD+wD\\i||2 2 =1 2||wD||2 2+1 2||wD\\i||2 2-wT DwD\\i =1 2||wD-wD\\i||2 2 =1 2|| ?wD||2 2. (30) Thus || ?wD||2 2=d n?|?wT Dzi|. (31) Then, based on the Cauchy\u2013Schwarz inequality, we have |?wT Dzi|=| |? wD||2||zi||2. (32) Combining (31) and (32) above, and using ||zi||2=f,w e obtain the uniform stability bound for FREL with L2 regular- izer ||wD-wD\\i||2=| |? wD||2=df n?. (33) \u00a6 Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:18:01 UTC from IEEE Xplore.  Restrictions apply. LIet al. : FREL: A STABLE FEATURE SELECTION ALGORITHM 1399 APPENDIX B PROOF OF THE THEOREM 2 Proof: LetwDandwD\\ibe the optimal estimates of w?, respectively, where the optimality refers to that wDand wD\\iare optimal solutions as a result of minimizing the objective loss functions LD(w)andLD\\i(w)in (15) and (16), respectively. We have ||wD-wD\\i||2=| |? w1||2+||? w2||2, as in (18). To analyze the two terms || ?w1||2and|| ?w2||2in (18), we start with the decomposability property of L1 regularizer below. In consideration of exact sparsity as de?ned in De?nition 3, the feature weighting results are d-dimensional vectors {w(1),w( 2) ,...,w( d)}with some weights being exactly zero. Suppose the number of features with nonzero weights is b.L e t Sbe an index set whose bcomponents correspond to the index of those features with nonzeroweights. For example, S={1,2}indicates that those weights fromw(3)through w(d)are zeros while b=2. Let R dbe thed-dimension real space. Then, we de?ne the subspace M as M:= {s?Rd|sp=0f o r a l l p/?S}. (34) The orthogonal complement subspace of Mis M?:= {??Rd|?p=0f o r a l l p?S}. (35) Remark 12: Subspace Mis the model subspace capturing the constraints speci?ed by the L1 regularizer in LD(w) or LD\\i(w), while M?is the orthogonal complement subspace ofM, and it is considered a perturbation subspace deviating away from the model subspace M. Then, M?M?=Rd. We are ready to de?ne the decomposability property of L1 regularizer with respect to the model subspace and itsorthogonal complement subspace as in [41]\u2013[43]. De?nition 6: Given a subspace pair MandM ?as de?ned in (34) and (35), respectively, an L1 regularizer is decompos- able with respect to (M,M?), such that ||s+?||1=| |s||1+| |?||1 (36) for all s?Mand??M?. Next, we analyze the bound of ||?w1||2in (18). To simplify the notation, we drop the subscript of ?w1and use ?winstead in this proof. Let F(?w)=LD(w?+?w)-LD(w?). (37) Since wD=w?+?wis the minimizer of LD(w) in (15), then?wmust satisfy F(?w)=0. IfLD(w)is replaced by the right-hand side of (15), F(?w) is then changed as F(?w)=JD(w?+?w)-JD(w?) +?(||w?+?w||1-| |w?||1). (38) Note that the function F(?w)consists of two differ- ences: one is between the sample-averaged loss functions, i.e.,JD(w?+?w)-JD(w?), and the other is between the regularizers, i.e., ||w?+?w||1-| |w?||1.Consider ?rst the difference between regularizers ||w?+ ?w||1-| |w?||1. Based on the subspaces MandM?de?ned above, it is evident that w?=w? M+w? M?,w h e r e w? M andw? M?are the projections of w?onto subspace Mand its orthogonal complement subspace M?, respectively. The projection operation is de?ned as w? M=/Pi1M(w?):=argminu?M||w?-u||2. (39) Similarly, we can obtain ?w=?wM+?wM?,w h e r e ?wM and?wM?are the projections of ?wonto subspaces Mand M?, respectively. The de?nitions for w? M?,?wM,a n d?wM? are given in an analogous manner to w? M. Then, by the triangle inequality, we have ||w?||1=| |w? M+ w? M?||1=| |w? M||1+| |w? M?||1and ||w?+?w||1=| |w? M+w? M?+?wM+?wM?||1 =| |w? M+?wM?||1-| |w? M?+?wM||1 =| |w? M+?wM?||1-| |w? M?||1 -|| ? wM||1. (40) By the decomposability property of L1 regularizer as in De?nition 6, ||w? M+?wM?||1=| |w? M||1+| |? wM?||1is obtained, so that ||w?+?w||1=| |w? M||1+| |? wM?||1- ||w? M?||1-| |? wM||1. Therefore ||w?+?w||1-| |w?||1=| |? wM?||1-| |? wM||1 -2||w? M?||1. (41) For an exactly sparse model as in De?nition 3, de?ne a model subspace Mcontaining w?, i.e.,w??M, to guarantee ||w? M?||1=0 [41]\u2013[43], and obtain ||w?+?w||1-| |w?||1=| |? wM?||1-| |? wM||1.(42) Now, we turn to the difference b etween the sample-averaged loss functions JD(w?+?w)-JD(w?)inF(?w),a sd e ? n e d in (38). To analyze the differences between the sample- averaged loss functions in F(?w), we let the sample-averaged loss functions JD(w) be differentiable and satisfy strong convexity as in De?nition 4. Based on (42) and the strong convexity of JD(w) in De?nition 4, the function F(?w)is expressed as F(?w)=JD(w?+?w)-JD(w?) +?(|| ?wM?||1-| |? wM||1) =? ?JD(w?),?w?+?D|| ?w||2 2 +?(|| ?wM?||1-| |? wM||1). (43) By the Cauchy\u2013Schwarz inequality application, we have |??JD(w?),?w?| = || ? JD(w?)||8|| ?w||1. (44) Without loss of generality, assume that ?=| |? JD(w?)||8. (45) We can conclude that ??JD(w?),?w?=-?|| ?w||1. Thus F(?w)=?D|| ?w||2 2+?(|| ?wM?||1-| |? wM||1) -?|| ?w||1. (46) Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:18:01 UTC from IEEE Xplore.  Restrictions apply. 1400 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 7, JULY 2015 By the triangle inequality, ||?w||1=| | ? wM?+?wM||1= || ?wM?||1+| |? wM||1, and hence F(?w)=?D|| ?w||2 2-2?|| ?wM||1. (47) Note that, ||?wM||1=v d||?wM||2. Since the projection ?wMis de?ned similarly to (39) in terms of the L2-norm, it is nonexpansive. Since 0 ?M || ?wM||2=| |/Pi1M(?w)-/Pi1M(0)||2=| |? w-0||2 =| |? w||2. (48) In the end, we obtain F(?w)=?D|| ?w||2 2-2v d?|| ?w||2. (49) As discussed above, F(?w)=0 ?D|| ?w||2 2-2v d?|| ?w||2=0. (50) Then, we obtain || ?w||2=2v d? ?D(51) and we change notation ?wback to ?w1,t h e n || ?w1||2= 2v d?/? D. Now, we analyze the bound of ?w2. Similarly, we let F(?w2)be F(?w2)=LD\\i(w?+?w2)-LD\\i(w?). (52) Similar to the analysis for F(?w)above, we can obtain || ?w2||2=2v d? ?D\\i(53) with?=| |? JD\\i(w?)||8. Based on (18) and without loss of generality, assume ?=max[|| ?JD(w?)||8,|| ?JD\\i(w?)||8] (54) we obtain the stability bound of feature weighting with L1 regularizer ||wD-wD\\i||2=| |? w1||2+| |? w2||2 =2v d?(1 ?D+1 ?D\\i) . (55) \u00a6 APPENDIX C PROOF OF THE THEOREM 3 Proof: For the uniform stability of ensemble FREL in (20), the left side can be bounded by taking the L2 norm inside the expectation by Jensen\u2019s inequality. According to Jensen\u2019sinequality, let fbe a convex function and xbe a random variable. Then, f(E(x))=E(f(x)). For our case, L2-norm is convex, so we obtain \u00df E=?????E r1,...,rm[ 1 mm? t=1wD(rt)-1 mm? t=1wD\\i(rt)]????? 2 =Er1,...,rm[?????1 mm? t=1wD(rt)-1 mm? t=1wD\\i(rt)????? 2] .(56)Since r1,..., rmare i.i.d. and suppose they have the same distribution as r, which models bootstrapping once, as in [24]. By the triangle inequality \u00dfE=1 mm? t=1Ert[||wD(rt)-wD\\i(rt)||2] =Er[||wD(r)-wD\\i(r)||2]= Er[|| ?wD(r)||2].(57) Therefore, according to (57), t he ensemble stability bound may now be considered similarly as in De?nition 2 of removing a single sample xifrom the data set D.S i n c e ris a sampled subset of {1,2,..., n}, we need to consider two possibilities of whether ibelongs to ror not. To do so, we introduce an indicator function I(.). Note that if iis not in r,w h i c h means the sample xiis not in the bootstrap subset D(r), i.e., D(r)=D\\i(r), then the term Er[|| ?wD(r)||2I(i/?r)]=0. We have the following: \u00dfE=Er[|| ?wD(r)||2(I(i?r)+I(i/?r))] =Er[|| ?wD(r)||2I(i?r)]+ Er[|| ?wD(r)||2I(i/?r)] =Er[|| ?wD(r)||2I(i?r)]. (58) The size of bootstrap subset D(r)is?an?(0<a< 1), then Er(I(i?r))=?an?/n\u02dcabecause this sampling is done without replacement, and || ?wD(r)||2=\u00dfdue to the uniform stability of the base feature weight result, then we have \u00dfE=a\u00df. (59) \u00a6 REFERENCES [1] Z. Zhao, \u201cSpectral feature selectio n for mining ultrahigh dimensional data,\u201d Ph.D. dissertation, Dept. S chool Comput., Informat., Decision Syst. Eng., Arizona State U niv., Phoenix, AZ, USA, 2010. [2] H. Liu and L. Yu, \u201cToward integrating feature selection algorithms for classi?cation and clustering,\u201d IEEE Trans. Knowl. Data Eng. , vol. 17, no. 4, pp. 494\u2013502, Apr. 2005. [3] I. Guyon and A. Elisseeff, \u201cAn introduction to variable and feature selection,\u201d J .M a c h .L e a r n .R e s . , vol. 31, pp. 1157\u20131182, Jan. 2003. [4] Y . Saeys, T. Abeel, and Y . van de Peer, \u201cRobust feature selection using ensemble feature selection techniques,\u201d in Proc. 25th Eur. Conf. Mach. Learn. Knowl. Discovery Databases , 2008, pp. 313\u2013325. [5] S. Loscalzo, L. Yu, and C. Ding, \u201cConsensus group stable feature selection,\u201d in Proc. 15th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining , 2009, pp. 567\u2013575. [6] T. Abeel, T. Helleputte, Y . van de Peer, P. Dupont, and Y . Saeys, \u201cRobust biomarker identi?cation f or cancer diagnosis with ensemble feature selection methods,\u201d Bioinformatics , vol. 26, no. 3, pp. 392\u2013398, 2010. [7] Y . Li, S. Gao, and S. Chen, \u201cEnsemble feature weighting based on local learning and diversity,\u201d in Proc. 26th AAAI Conf. Artif. Intell. , 2012, pp. 1019\u20131025. [8] A. Woznica, P. Nguyen, and A. Kalousis, \u201cModel mining for robust feature selection,\u201d in Proc. 18th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining , 2012, pp. 913\u2013921. [9] Y . Han and L. Yu, \u201cA variance reduction framework for stable feature selection,\u201d in Proc. 10th Int. Conf. Data Mining , Dec. 2010, pp. 206\u2013215. [10] L. Yu, Y . Han, and M. E. Berens, \u201cSt able gene selection from microarray data via sample weighting,\u201d IEEE/ACM Trans. Comput. Biol. Bioinform. , vol. 9, no. 1, pp. 262\u2013272, Jan./Feb. 2012. [11] L. Yu, C. Ding, and S. Loscalzo, \u201cStable feature selection via dense feature groups,\u201d in Proc. 14th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining , 2008, pp. 803\u2013811. Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:18:01 UTC from IEEE Xplore.  Restrictions apply. LIet al. : FREL: A STABLE FEATURE SELECTION ALGORITHM 1401 [12] Z. He and W. Yu, \u201cStable feature selection for biomarker discovery,\u201d Comput. Biol. Chem. , vol. 34, no. 4, pp. 215\u2013225, 2010. [13] Y . LeCun, S. Chopra, R. Hadsell, M. A. Ranzato, and F. J. Huang, A Tutorial on Energy-Based Model . Cambridge, MA, USA: MIT Press, 2006. [14] A. S. Das, M. Data r, A. Garg, and S. Rajaram, \u201cGoogle news personalization: Scalable onlin e collaborative ?ltering,\u201d in Proc. 16th Int. Conf. World Wide Web , 2007, pp. 271\u2013280. [15] S. Dudoit, J. Fridlyand, and T. P. Spee, \u201cComparison of discrimination methods for the classi?cation of tum ors using gene expression data,\u201d J. Amer. Statist. Assoc. , vol. 97, no. 457, pp. 77\u201387, 2002. [16] Y . Sun, S. Todorovic, and S. Goodi son, \u201cLocal-learning-based feature selection for high-dimensional data analysis,\u201d IEEE Trans. Pattern Anal. Mach. Intell. , vol. 32, no. 9, pp. 1610\u20131626, Sep. 2010. [17] P. Domingos, \u201cA few useful things to know about machine learning,\u201d Commun. ACM , vol. 55, no. 10, pp. 78\u201387, 2012. [18] B. Wang and H.-D. Chiang, \u201cElite: Ensemble of optimal input-pruned neural networks using TRUST-TECH,\u201d IEEE Trans. Neural Netw. , vol. 22, no. 1, pp. 96\u2013109, Jan. 2011. [19] S. Tang, Y .-T. Zheng, Y . Wang, and T.-S. Chua, \u201cSparse ensemble learning for concept detection,\u201d IEEE Trans. Multimedia , vol. 14, no. 1, pp. 43\u201354, Feb. 2012. [20] S. Gutta, J. R. J. Huang, P. Jonathon, and H. Wechsler, \u201cMixture of experts for classi?cation of gende r, ethnic origin, and pose of human faces,\u201d IEEE Trans. Neural Netw. , vol. 11, no. 4, pp. 948\u2013960, Jul. 2000. [21] L. I. Kuncheva, J. J. Rodriguez, C. O. Plumpton, D. E. J. Linden, and S. J. Johnston, \u201cRandom subspace ense mbles for fMRI classi?cation,\u201d IEEE Trans. Med. Imag. , vol. 29, no. 2, pp. 531\u2013542, Feb. 2010. [22] L. Breiman, \u201cBagging predictors,\u201d Mach. Learn. , vol. 26, no. 2, pp. 123\u2013140, Aug. 1996. [23] O. Bousquet and A. Elisseeff, \u201cStability and generalization,\u201d J. Mach. Learn. Res. , vol. 2, pp. 499\u2013526, Jan. 2002. [24] A. Elisseeff, T. Evgeniou, and M. Pontil, \u201cStability of randomized learning algorithm,\u201d J .M a c h .L e a r n .R e s . , vol. 6, pp. 55\u201379, Jan. 2005. [25] S. Agarwal and P. Niyogi, \u201cGenera lization bounds for ranking algorithm via algorithmic stability,\u201d J .M a c h .L e a r n .R e s . , vol. 10, pp. 441\u2013474, Feb. 2009. [26] H. Xu, C. Caramanis, and S. Mannor, \u201cSparse algorithms are not stable: A no-free-lunch theorem,\u201d IEEE Trans. Pattern Anal. Mach. Intell. , vol. 34, no. 1, pp. 187\u2013193, Jan. 2012. [27] Y . Nesterov, Introductory Lectures on Convex Optimization: A Basic Course . Boston, MA, USA: Kluwer, 2004. [28] M. Tan, I. W. Tsang, and L. Wang, \u201cMinimax sparse logistic regression for very high-dimensional feature selection,\u201d IEEE Trans. Neural Netw. Learn. Syst. , vol. 24, no. 10, pp. 1609\u20131622, Oct. 2013. [29] T. R. Golub et al. , \u201cMolecular classi?cation of cancer: Class discovery and class prediction by gene expression monitoring,\u201d Science , vol. 286, no. 5439, pp. 531\u2013537, 1999. [30] D. Singh et al. , \u201cGene expression correlates of clinical prostate cancer behavior,\u201d Cancer Cell , vol. 1, no. 2, pp. 203\u2013209, 2002. [31] K. Kira and L. Rendell, \u201cA practical approach to feature selection,\u201d in Proc. 9th Int. Workshop Mach. Learn. , 1992, pp. 249\u2013256. [32] I. Kononenko, \u201cEstimating attributes: Analysis and extensions of RELIEF,\u201d in Proc. Eur. Conf. Mach. Learn. , 1994, pp. 171\u2013182. [33] M. Robnik- ?Sikonja and I. Kononenko, \u201cTheoretical and empirical analysis of ReliefF and RReliefF,\u201d Mach. Learn. , vol. 53, nos. 1\u20132, pp. 23\u201369, 2003. [34] R. O. Duda, P. E. Hart, and D. G. Stork, Pattern Classi?cation , 2nd ed. New York, NY , USA: Wiley, 2001. [35] T. G. Dietterich, \u201cMachine learning research: Four current directions,\u201d AI Mag. , vol. 18, no. 4, pp. 97\u2013136, 1997. [36] K. Crammer, R. Gilad-Bachrach, A. Navot, and N. Tishby, \u201cMargin analysis of the LVQ algorithm,\u201d in Advances in Neural Information Processing Systems . Cambridge, MA, USA: MIT Press, 2002, pp. 462\u2013469. [37] Y . Li and B.-L. Lu, \u201cFeature selection based on loss margin of nearest neighbor classi?cation,\u201d Pattern Recognit. , vol. 42, no. 9, pp. 1914\u20131921, 2009. [38] A. Kalousis, J. Prados, and M. Hilario, \u201cStability of feature selection algorithms: A study on high-dimensional spaces,\u201d Knowl. Inf. Syst. , vol. 12, no. 1, pp. 95\u2013116, 2007. [39] C. C. Chang and C. J. Lin. (2002). Libsvm: A Library for Support Vector Machines . [Online]. Available: http://www.csie.ntu.edu.tw/cjlin/papers/libsvm.ps.gz [40] S. A. van de Geer, \u201cHigh-dimensional generalized linear models and the lasso,\u201d Ann. Statist. , vol. 36, no. 2, pp. 614\u2013645, 2008.[41] S. N. Negahban, P. Ravikumar , M. J. Wainwright, and B. Yu, \u201cA uni?ed framework for high- dimensional analysis of M-estimators with decomposable regularizers,\u201d Statist. Sci. , vol. 27, no. 4, pp. 538\u2013557, 2012. [42] S. N. Negahban, P. Ravikumar , M. J. Wainwright, and B. Yu, \u201cA uni?ed framework for high- dimensional analysis of M-estimators with decomposable regularizers,\u201d Dept. EECS., Univ. California, Berkeley, Berkeley, CA, USA, Tech. Rep. 797, 2010. [43] S. N. Negahban, P. Ravikumar , M. J. Wainwright, and B. Yu, \u201cA uni?ed framework for high- dimensional analysis of M-estimators with decomposable regularizers,\u201d in Advances in Neural Information Processing Systems . Red Hook, NY , USA: Curran & Associates, Inc., 2009, pp. 1348\u20131356. Yun Li (M\u201910) received the Ph.D. degree in computer science from Chongqing University, Chongqing, China. He was a Post-Doctoral Fellow with the Depart- ment of Computer Science a nd Engineering, Shang- hai Jiao Tong University, Shanghai, China. He is a Professor with the College of Computer Science,Nanjing University of Posts and Telecommunica- tions, Nanjing, China. He has published more than 30 refereed research papers. His current researchinterests include machine learning, data mining, and parallel computing. Dr. Li was the Co-Publication Chair of the 18th International Conference on Neural Information Processing in 2011. His research is currently sponsoredby the National Natural Science Founda tion of China and the Natural Science Foundation of Jiangsu. Jennie Si (F\u201908) received the B.S. and M.S. degrees from Tsinghua University, Beijing, China, and thePh.D. degree from the University of Notre Dame,Notre Dame, IN, USA. She has been with the faculty of the Department of Electrical Engineering at Arizona State University,Phoenix, AZ, USA, since 1991. She has also made new efforts to build a capability for studying some fundamental neuroscience questions in regards tothe frontal cortex. Her lab is now well equippedwith important techniques, such as multichannel single unit extracellular recording using a behaving rat model in chronic physiological experiments. Her current research interests include dynamic optimization using learning and neura l network approximation approaches, namely approximate dynamic programming. Dr. Si was an Associate Editor of the IEEE T RANSACTIONS ON SEMI- CONDUCTOR MANUFACTURING , the IEEE T RANSACTIONS ON AUTOMATIC CONTROL , and the IEEE T RANSACTIONS ON NEURAL NETWORKS . She has served on several professional organi zations\u2019 executive boards and interna- tional conference committees. She was the Vice President of Education withthe IEEE Computation Intelligence Society from 2009 to 2012, an Advisor to the NSF Social Behavioral and Economi cal Directory, and served on several proposal review panels. She consulted f or Intel, Arizona Public Service, and Medtronic. She is a Distinguished Lect urer of the IEEE Computational Intel- ligence Society, and an Action Editor of Neural Networks . She was a recipient of the National Science Foundation/Wh ite House Presidential Faculty Fellow Award in 1995, and the Motorola Engineering Excellence Award in 1995. Guojing Zhou received the bachelor\u2019s degree from the Nanjing University of Posts and Telecommunications, Nanjing, China, where he is currently pursuing the master\u2019s degree in computer science. His current research interests include machine learning. Shasha Huang received the bachelor\u2019s degree from Xuhai College, University of Mining and Technology, Xuzhou, China. She is currently pursuing the master\u2019s degree in computer science with the Nanjing University of Posts andTelecommunications, Nanjing, China. Her current research interests include machine learning. Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:18:01 UTC from IEEE Xplore.  Restrictions apply. 1402 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 26, NO. 7, JULY 2015 Songcan Chen received the B.S. degree in mathe- matics from Zhejiang University, Hangzhou, China,in 1983, the M.S. degree in computer applica- tions from Shanghai Jiao Tong University, Shanghai, China, in 1985, and the Ph.D. degree in communica-tion and information systems from the Nanjing Uni-versity of Aeronautics and Astronautics (NUAA), Nanjing, China, in 1997. He has been a full-time Professor with the Depart- ment of Computer Science and Engineering at NUAA since 1998. He has authored and co-authored over 170 scienti?c peer-reviewed papers. H is current research interests include pattern recognition, machine learning, and neural computing. Authorized licensed use limited to: National University Fast. Downloaded on February 14,2024 at 14:18:01 UTC from IEEE Xplore.  Restrictions apply. ", "3": "See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/336131051 Explainable AI: A Brief Su rvey on History, Research Areas, Approaches and Challenges Chapt er \u00b7 Sept ember 2019 DOI: 10.1007/978-3-030-32236-6_51 CITATIONS 289READS 32,293 6 author s, including: Feiyu X u Leno vo 118 PUBLICA TIONS \u00a0\u00a0\u00a01,750  CITATIONS \u00a0\u00a0\u00a0 SEE PROFILE Hans U szkoreit Deutsches F orschungsz entrum f \u00fcr K \u00fcnstliche Int ellig enz 417 PUBLICA TIONS \u00a0\u00a0\u00a04,300  CITATIONS \u00a0\u00a0\u00a0 SEE PROFILE Wei F an Leno vo 52 PUBLICA TIONS \u00a0\u00a0\u00a01,174  CITATIONS \u00a0\u00a0\u00a0 SEE PROFILE All c ontent f ollo wing this p age was uplo aded b y Feiyu X u on 24 Januar y 2020. The user has r equest ed enhanc ement of the do wnlo aded file.Explainable AI: A Brief Survey on History, Research Areas, Approaches and Challenges Feiyu Xu1, Hans Uszkoreit2, Yangzhou Du1, Wei Fan1, Dongyan Zhao3, and Jun Zhu4 1AI Lab, Lenovo Research, Lenovo Group, China {fxu,duyz1,fanwei2 }@lenovo.com 2DFKI GmbH, Germany and Giance Technologies uszkoreit@dfki.de 3Institute of Computer Science and Technology, Peking University, China zhaody@pku.edu.cn 4Department of Computer Science and Technology, Tsinghua University, China dcszj@mail.tsinghua.edu.cn Abstract. Deep learning has made signi?cant contribution to the recent progress in arti?cial intelligence. In comparison to traditional machine learning methods such as decision trees and support vector machines, deep learning methods have achieved substantial improvement in various prediction tasks. However, deep neural networks (DNNs) are comparably weak in explaining their inference processes and ?nal results, and they are typically treated as a black-box by both developers and users. Some people even consider DNNs (deep neural networks) in the current stage rather as alchemy , than as real science. In many real-world applications such as business decision, process optimization, medical diagnosis and investment recommendation, explainability and transparency of our AI systems become particularly essential for their users, for the people who are a?ected by AI decisions, and furthermore, for the researchers and developers who create the AI solutions. In recent years, the explainabil- ity and explainable AI have received increasing attention by both re- search community and industry. This paper ?rst introduces the history of Explainable AI, starting from expert systems and traditional machine learning approaches to the latest progress in the context of modern deep learning, and then describes the major research areas and the state-of- art approaches in recent years. The paper ends with a discussion on the challenges and future directions. Keywords: Explainable arti?cial intelligence \u00b7intelligible machine learn- ing\u00b7explainable interfaces \u00b7XAI\u00b7interpretability 1 A Brief History of Explainable AI In wiktionary, the word \u201cexplain\u201d means for humans \u201cto make plain, manifest, or intelligible; to clear of obscurity; to illustrate the meaning of\u201d [23]. In scienti?c research, a scienti?c explanation is supposed to cover at least two parts: 1) the2 F. Xu et al. object to be explained (the \u201cExplanandum\u201d in Latin), and 2) the content of explanation (the \u201cExplanans\u201d in Latin). Explainable AI is not a new topic. The earliest work on Explainable AI could be found in the literature published forty years ago [16] [19], where some expert systems explained their results via the applied rules. Since AI research began, scientists have argued that intelligent systems should explain the AI results, mostly when it comes to decisions. If a rule-based expert system rejects a credit card payment, it should explain the reasons for the negative decision. Since the rules and the knowledge in the expert systems are de?ned and formulated by human experts, these rules and knowledge are easy for humans to understand and interpret. Decision tree is a typical method designed with explainable structure. As illustrated in Fig. 1, starting at the top and going down, the solution path in the decision tree presents the reasoning of a ?nal decision. Fig. 1. An example of decision tree, used by starting at the top and going down, level by level, according to the de?ned logic. (Image courtesy of J. Jordan [10]) However, Explainable AI has become a new research topic in the context of modern deep learning. Without completely new explanatory mechanisms, the output of today\u2019s Deep Neural Networks (DNNs) cannot be explained, neither by the neural network itself, nor by an external explanatory component, and not even by the developer of the system. We know that there are di?erent archi- tectures of DNNs designed for di?erent problem classes and input data, such as CNN, RNN, LSTM, shown in Fig. 2. All of them have to be considered as black boxes - whose internal inference processes are neither known to the observer nor interpretable by humans [7]. Explainability of a machine learning model is usually inverse to its prediction accuracy - the higher the prediction accuracy, the lower the model explainability. The DARPA Explainable AI (XAI) program presents a nice chart to illustrate this interesting phenomena, as shown in Fig. 3, where decision trees have an excellent degree of explainability but exhibit worst prediction accuracy among the listed learning techniques. In the other extreme, Deep Learning methods areTitle Suppressed Due to Excessive Length 3 Fig. 2. A chart of several typical Deep Neural Networks (DNNs). (Image courtesy of Fjodor Van Veen [22]) better in predictive capacity than any other learning methods but they are least likely to be explicable. Fig. 3. Explainability of machine learning models appear inverse to their prediction accuracy. (Image courtesy of DARPA [21]) In recent years, AI researchers aim to open the black-box of neural networks and turn it into a transparent system. As shown in Fig. 4, there are two main strands of work in Explainable AI - transparency design and post-hoc expla- nation. The transparency design reveals how a model functions, in the view of developers. It tries to (a) understand model structure, e.g., the construction of a decision tree; (b) understand single components, e.g., a parameter in logistic regression; (c) understand training algorithms, e.g., solution seeking in a con- vex optimization. The post-hoc explanation explains why a result is inferred, in the view of users. It tries to (d) give analytic statements, e.g. why a goods is recommended in a shopping website; (e) give visualizations, e.g. saliency map is used to show pixel importance in a result of object classi?cation; (f) give ex-4 F. Xu et al. planations by example, e.g. K-nearest-neighbors in historical dataset are used to support current results. A thorough description of the categorization of expla- nation methods is found in Lipton et al. [13]. A comprehensive survey on recent development of Explainable AI is provided in [5]. Fig. 4. Two categories of Explainable AI work: transparency design and post-hoc ex- planation. 2 Relevance of Explainable AI Increasing attention has recently been paid to Explainable AI across the world both in research and in industry. In April 2017, DARPA funded the \u201cExplain- able AI (XAI) program\u201d, aimed at improving explainability of AI decision [21]. In July 2017, the Chinese government released \u201cThe Development Plan for New Generation of Arti?cial Intelligence\u201d to encourage high-explainability AI and strong-extensibility AI [18]. In May 2018, the \u201cGeneral Data Protection Regula- tion\u201d (GDPR) was published, in which the European Union grants their citizens a \u201cright to explanation\u201d if they are a?ected by algorithmic decision-making [6]. Explainable AI will become increasingly important to all groups of stakeholders, including the users, the a?ected people, and the developers of AI systems. Explainable AI is important to the users who utilize the AI system . When the AI recommends a decision, the decision makers would need to understand the underlying reason. For example, medical doctor needs to understand what pathological features in the input data were were guiding the algorithm before accepting auto-generated diagnosis reports. A maintenance engineer needs to understand which abnormal phenomena were captured by the inference algo- rithm before following the repair recommendations. A ?nancial investor wants to understand what in?uencing factors were regarded as the critical ones by the system algorithm before making the ?nal investment decision. We have to verify that the AI inference works as expected, because wrong decisions can be costly and dangerous. Caruana et al. [3] presented a famous example \u201cPneumonia - Asthma\u201d to illustrate this point. An AI system which had been trained to pre- dict the pneumonia risk of a person arrived at totally wrong conclusions. From real data the model had learned that asthmatic patients with heart problems have a much lower risk of dying of pneumonia than healthy persons. This cannot be true since asthma is a factor that negatively a?ects the recovery. The trainingTitle Suppressed Due to Excessive Length 5 data were systematically biased, because in contrast to healthy persons, the ma- jority of these asthma patients were under strict medical supervision. Hence this group had a signi?cant lower risk of dying of pneumonia. It should be noted, though, that both the learning and the inference algorithms probably worked correctly and also that the training data represented real cases. The insight that the selection of the training data was not appropriate for predictions a?ecting other populations may remain undiscovered if we have a black-box AI system. Explainable AI is important to the people who are a?ected by AI decision . If the AI makes its own decisions, e.g., braking of the car, shutting down a plant, selling shares, assessing a job, issuing a tra?c punishment order, the a?ected people must be able to understand the reason. There are already legal regula- tions that codify this demand [6]. Houston schools were using an AI algorithm, called Educational Value-Added Assessment System (EVAAS), to evaluate the performance of teachers. However, this AI system was successfully contested by teachers in court, because negative reviews of teachers could not be explained by the AI system [2]. Explainable AI could help developers to improve AI algorithm , by detecting data bias, discovering mistakes in the models, and remedying the weakness. La- puschkin et al. [11] presented an impressive example. As shown in Fig. 5, they observed that the Fisher Vector method usually shows lower accuracy than Deep Neural Networks in the task of object recognition. However, two methods reach almost equal accuracy of recognition rate in the category \u201chorse\u201d, which is unex- pected. A saliency map method called \u201cLayer-wise Relevance Propagation\u201d [12] was then employed to analyze which pixel areas exactly make the models arrive at their predictions. The authors observed that the two models use di?erent strategies to classify images of that category. The Deep Neural Network looked at the contour of the actual horse, whereas the Fisher Vector model mostly relied on a certain copyright tag, that happens to be present on many horse images. Removing the copyright tag in the test images would consequently signi?cantly decrease the accuracy of the Fisher Vector model. Fig. 5. Upper: the prediction accuracy of Fisher Vector and Deep Neural Network in tasks of object recognition; Lower: model diagnosis using saliency map method. (Image courtesy of Lapuschkin et al. [11])6 F. Xu et al. 3 Relevant Explainable AI Problems and Current Approaches As shown in Fig. 6, there are three typical approaches to understand the behavior of a Deep Neural Network: (a) making the parts of the network transparent - the color of the neuron indicates its activation status; (b) learning semantics of the network components - a neuron could have a meaning if it is often activated by a certain part of the object; (c) generation of explanations - a human-readable textual explanation tells the underlying reason to support current decision. Fig. 6. Three approaches for understanding a neural network, indicated by red-boxes (a), (b) and (c) 3.1 Making the parts in DNN transparency This section introduces two popular techniques, namely sensitivity analysis (SA) [15] [1] and layer-wise relevance propagation (LRP) [17], for explaining prediction of deep learning models. SA explains a prediction based on the model\u2019s locally evaluated gradient. Ri=?? ?xif(x)?. (1) It assumes that the most relevant input features are the most sensitive for the output. SA doesn\u2019t explain the function value f(x), but rather quanti?es the importance of each input variable xi. In contrast to SA, LRP explains predictions relative to the state of maximum uncertainty. It redistributes the prediction f(x) backwards using local redistri- bution rules until it assigns a relevance score Rito each input variable. The relevance score Riof each input variable determines the variable\u2019s importanceTitle Suppressed Due to Excessive Length 7 to the prediction. ? iRi=? jRj=...=? kRk=...=f(x). (2) The Relevance conservation is the key property of the redistribution process. This property ensures that no relevance is arti?cially added or removed during redistribution. Thus, LRP truly decomposes the function values f(x) in contrast to SA. Fig. 7. Explaining predictions of an AI system using SA and LRP. (Image courtesy of W. Samek [15]) Fig. 7 summarizes the process of explanation. The AI system correctly clas- si?es the input image as \u201crooster\u201d. SA indicates yellow ?owers which occlude part of the rooster need to be changed to make the image look more like the predicted. However, such result would not indicate which pixels are actually piv- otal for the prediction \u201crooster\u201d. In contrast to SA, the heatmap computed with LRP identi?es pixels which are pivotal for the prediction \u201crooster\u201d. Additionally, SA and LRP are evaluated on three di?erent classi?cation tasks, namely the annotation of images, the classi?cation of text documents and the recognition of human actions in videos. Fig. 8(A) shows two images from the ILSVRC2012 [4] dataset, which have been correctly classi?ed as \u201cvolcano\u201d and \u201cco?ee cup\u201d, respectively. From the ?gure, we can see that SA heatmaps are much noisier than the ones computed with LRP. SA doesn\u2019t indicate how much every pixel contributes to the prediction. LRP produces better explanations than SA. Fig. 8(B) shows SA and LRP heatmaps overlaid on top of a document from the 20Newsgroup dataset. In contrast to LPR, SA methods don\u2019t distinguish be- tween positive and negative evidence. Similarly, Fig. 8(C) shows LRP heatmaps8 F. Xu et al. not only visualizes the relevant locations of the action within a video frame, but also identi?es the most relevant time points within a video sequence. Fig. 8. Explaining prediction of three di?erent problems using SA and LRP. (Image courtesy of W. Samek [15]) 3.2 Learning semantic graphs from existing DNNs Zhang et al. [24] proposes a method that learns a graphical model, called \u201cex- planatory graph\u201d, which reveals the knowledge hierarchy hidden inside a pre- trained Convolutional Neural Network (CNN), as shown in Fig. 9. The graph consists of multiple layers, each of them corresponds to a convolutional layer in the CNN. Each node in the graph represents a speci?c part of the detected object, as shown in the right side of the ?gure. These nodes are derived from re- sponses of CNN ?lters with a disentangle algorithm. The edge connecting nodes indicates their co-activation relationship in ?lter response and the spatial rela- tionship in parts location. The layer shows di?erent granularity of the part of objects - larger parts appear in higher layers while smaller parts appear in lower layers. This work, however, adopts an explanatory graph as a bridge to under- stand the ordinary CNN. In later work [25], the authors introduce additional losses to force each convolutional ?lter in CNN to represent a speci?c object part directly, and produce an interpretable CNN.Title Suppressed Due to Excessive Length 9 Fig. 9. An explanatory graph represents the knowledge hierarchy hidden in convolu- tional layers of a CNN. (Image courtesy of Zhang et al. [24]) 3.3 Generation of Explanations This section introduces a novel framework which provides visual explanations of a visual classi?er [8]. Visual explanations are both image relevant and class relevant. From Fig. 10 we can ?nd image descriptions provides a sentence based on visual information but not necessarily class relevant, while class de?nitions are class relevant but not necessarily image relevant. In contrast, Visual explanation such as \u201cThis is a western grebe because this bird has a long white neck, pointy yellow beak, and a red eye.\u201d includes the \u201cred eye\u201d property which is important to distinguish between \u201cwestern grebe\u201d and \u201claysan albatross\u201d. Therefore, Visual explanations are both image relevant and class relevant. It explains why the predicted category is the most appropriate for the image. Fig. 10. Visual explanations are both image relevant and class relevant. (Image cour- tesy of L. A. Hendricks [9]) Fig. 11 shows the generation of explanatory text on both an image and a predicted class label. The input is run through a deep ?ne-grained recognition pipeline to pick out nuanced details of the image and classifying it. The features10 F. Xu et al. and the label are then forwarded to the LSTM stack to produce a sequence of words. Fig. 11. Generation of explanatory text with joint classi?cation and language model. (Image courtesy of L. A. Hendricks [9]) 4 Challenges and Future Directions The development of Explainable AI is facing both scienti?c and social demands. We expect AI systems could help humans make decisions in mission-critical tasks. Therefore, We need a more trustworthy and transparent AI, instead of alchemy AI [20]. Ali Rahimi, the winner of the test-of-time award in NeurIPS 2017, expressed his expectations concerning AI solutions as follows: \u201cWe are building systems that govern healthcare and mediate our civic dialogue. We would in?uence elections. I would like to live in a society whose systems are built on top of veri?able, rigorous, thorough knowledge, and not on alchemy. Let\u2019s take machine learning from alchemy to electricity\u201d [14]. The term \u201celectricity\u201d in his speech could be replaced by \u201cchemistry\u201d from our perspective, meaning that AI Deep Learning AI should become part of science. DARPA has invested 50 Million USD and launched a 5-year research pro- gram on Explainable AI (XAI) [21], aiming to produce \u201cglass-box\u201d models that are explainable to a \u201chuman-in-the-loop\u201d, without greatly sacri?cing AI perfor- mance, as shown in Fig. 12. Human users should be able to understand the AI\u2019s cognition both in real-time and after the results achieved, and furthermore might be able to determine when to trust the AI and when the AI should be distrusted. In Phase 1, it is planned to achieve initial implementations of their explainable learning systems. In Phase 2, it is to build a toolkit library consisting of machine learning and human-computer interface software modules that could be utilized for developing future explainable AI systems. It is known that humans can acquire and use both explicit knowledge and implicit knowledge. Moreover, humans can combine the two forms of knowledge to a certain degree. For humans, understanding and explaining require explicit knowledge. However, DNNs acquire and use implicit knowledge in the form of probabilistic models. As they stand, they cannot understand anything. Other AI methods model explicit knowledge, such as Knowledge Graphs. Today the two worlds in AI technology are still largely separated. Researchers are nowTitle Suppressed Due to Excessive Length 11 Fig. 12. Explainable AI (XAI) Concept presented by DARPA. (Image courtesy of DARPA XAI Program [21]) strengthening their e?orts to bring the two worlds together. The need-driven research on Explainable AI is a source and a catalyst for the work dedicated to this grand challenge. References 1. Baehrens, D., Schroeter, T., Harmeling, S., Kawanabe, M., Hansen, K., M\u00a8 uller, K.: How to explain individual classi?cation decisions. J. Mach. Learn. Res. 11, 1803\u20131831 (2010), http://portal.acm.org/citation.cfm?id=1859912 2. Cameron, L.: Houston Schools Must Face Teacher Evaluation Lawsuit (2017), https://www.courthousenews.com/houston-schools-must-face-teacher-evaluation- lawsuit/ 3. Caruana, R., Lou, Y., Gehrke, J., Koch, P., Sturm, M., Elhadad, N.: Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission. In: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. pp. 1721\u20131730. ACM (2015) 4. Deng, J., Dong, W., Socher, R., Li, L., Li, K., Li, F.: Imagenet: A large-scale hierar- chical image database. In: 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2009), 20-25 June 2009, Miami, Florida, USA. pp. 248\u2013255 (2009). https://doi.org/10.1109/CVPRW.2009.5206848, https://doi.org/10.1109/CVPRW.2009.5206848 5. Doilovi, F.K., Bri, M., Hlupi, N.: Explainable arti?cial intelligence: A survey. In: 2018 41st International Convention on Information and Communication Tech- nology, Electronics and Microelectronics (MIPRO). pp. 0210\u20130215 (May 2018). https://doi.org/10.23919/MIPRO.2018.8400040 6. Goodman, B., Flaxman, S.: European union regulations on algorithmic decision- making and a \u201dright to explanation\u201d. AI magazine 38(3), 50\u201357 (2017) 7. Guidotti, R., Monreale, A., Ruggieri, S., Turini, F., Giannotti, F., Pedreschi, D.: A survey of methods for explaining black box models. ACM Computing Surveys (CSUR) 51(2019)12 F. Xu et al. 8. Hendricks, L.A., Akata, Z., Rohrbach, M., Donahue, J., Schiele, B., Darrell, T.: Generating visual explanations. In: European Conference on Computer Vision. pp. 3\u201319. Springer (2016) 9. Hendricks, L.A., Akata, Z., Rohrbach, M., Donahue, J., Schiele, B., Darrell, T.: Generating visual explanations. In: European Conference on Computer Vision. pp. 3\u201319. Springer (2016) 10. Jeremy, J.: Decision trees (2017), https://www.jeremyjordan.me/decision-trees/ 11. Lapuschkin, S., Binder, A., Montavon, G., Muller, K.R., Samek, W.: Analyzing classi?ers: Fisher vectors and deep neural networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2912\u20132920 (2016) 12. Lapuschkin, S., Binder, A., Montavon, G., M\u00a8 uller, K.R., Samek, W.: The lrp tool- box for arti?cial neural networks. Journal of Machine Learning Research 17(114), 1\u20135 (2016), http://jmlr.org/papers/v17/15-618.html 13. Lipton, Z.C.: The mythos of model interpretability. ACM Queue - Machine Learn- ing16(2018) 14. Rahimi, A.: NIPS 2017 Test-of-Time Award presentation (2017), https://www.youtube.com/watch?v=ORHFOnaEzPc 15. Samek, W., Wiegand, T., M\u00a8 uller, K.R.: Explainable arti?cial intelligence: Un- derstanding, visualizing and interpreting deep learning models. arXiv preprint arXiv:1708.08296 (2017) 16. Scott, A.C., Clancey, W.J., Davis, R., Shortli?e, E.H.: Explanation capabilities of production-based consultation systems. American Journal of Computational Lin- guistics 62(1977) 17. Simonyan, K., Vedaldi, A., Zisserman, A.: Deep inside convolutional networks: Visualising image classi?cation models and saliency maps. In: 2nd International Conference on Learning Representations, ICLR 2014, Ban?, AB, Canada, April 14-16, 2014, Workshop Track Proceedings (2014), http://arxiv.org/abs/1312.6034 18. State Council Chinese Government: Development Plan for New Genera- tion Arti?cial Intelligence (2017), http://www.gov.cn/zhengce/content/2017- 07/20/content 5211996.htm 19. Swartout, W.R.: Explaining and justifying expert consulting programs. In: Pro- ceedings of the 7th International Joint Conference on Arti?cial Intelligence (1981) 20. Tony, P.: LeCun vs Rahimi: Has Machine Learning Become Alchemy? (2017), https://medium.com/@Synced/lecun-vs-rahimi-has-machine-learning-become- alchemy-21cb1557920d 21. Turek, M.: DARPA - Explainable Arti?cial Intelligence (XAI) Program (2017), https://www.darpa.mil/program/explainable-arti?cial-intelligence 22. Van Veen, F.: The Neural Network Zoo (2016), http://www.asimovinstitute.org/neural-network-zoo/ 23. Wiktionary: Explain (2019), https://en.wiktionary.org/wiki/explain 24. Zhang, Q., Cao, R., Shi, F., Wu, Y.N., Zhu, S.C.: Interpreting cnn knowledge via an explanatory graph. In: Thirty-Second AAAI Conference on Arti?cial Intelligence (2018) 25. Zhang, Q., Wu, Y.N., Zhu, S.C.: Interpretable convolutional neural networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 8827\u20138836 (2018) View publication stats", "7": "Explainable Arti?cial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI Alejandro Barredo Arrietaa, Natalia D \u00b4iaz-Rodr \u00b4iguezb, Javier Del Sera,c,d, Adrien Bennetotb,e,f, Siham Tabikg, Alberto Barbadoh, Salvador Garciag, Sergio Gil-Lopeza, Daniel Molinag, Richard Benjaminsh, Raja Chatilaf, and Francisco Herrerag aTECNALIA, 48160 Derio, Spain bENSTA, Institute Polytechnique Paris and INRIA Flowers Team, Palaiseau, France cUniversity of the Basque Country (UPV/EHU), 48013 Bilbao, Spain dBasque Center for Applied Mathematics (BCAM), 48009 Bilbao, Bizkaia, Spain eSegula Technologies, Parc d\u2019activit \u00b4e de Pissaloup, Trappes, France fInstitut des Syst `emes Intelligents et de Robotique, Sorbonne Universit `e, France gDaSCI Andalusian Institute of Data Science and Computational Intelligence, University of Granada, 18071 Granada, Spain hTelefonica, 28050 Madrid, Spain Abstract In the last few years, Arti?cial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the ?eld. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) ?eld, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the ?eld of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to de?ne explainability in Machine Learning, establishing a novel de?nition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this de?nition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept ofResponsible Arti?cial Intelligence , namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the ?eld of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the bene?ts of AI in their activity sectors, without any prior bias for its lack of interpretability. Keywords: Explainable Arti?cial Intelligence, Machine Learning, Deep Learning, Data Fusion, Interpretability, Comprehensibility, Transparency, Privacy, Fairness, Accountability, Responsible Arti?cial Intelligence. *Corresponding author. TECNALIA. P. Tecnologico, Ed. 700. 48170 Derio (Bizkaia), Spain. E-mail: javier.delser@tecnalia.com Preprint submitted to Information Fusion December 30, 2019arXiv:1910.10045v2  [cs.AI]  26 Dec 20191. Introduction Arti?cial Intelligence (AI) lies at the core of many activity sectors that have embraced new information technologies [ 1]. While the roots of AI trace back to several decades ago, there is a clear consensus on the paramount importance featured nowadays by intelligent machines endowed with learning, reasoning and adaptation capabilities. It is by virtue of these capabilities that AI methods are achieving unprecedented levels of performance when learning to solve increasingly complex computational tasks, making them pivotal for the future development of the human society [ 2]. The sophistication of AI-powered systems has lately increased to such an extent that almost no human intervention is required for their design and deployment. When decisions derived from such systems ultimately affect humans\u2019 lives (as in e.g. medicine, law or defense), there is an emerging need for understanding how such decisions are furnished by AI methods [3]. While the very ?rst AI systems were easily interpretable, the last years have witnessed the rise of opaque decision systems such as Deep Neural Networks (DNNs). The empirical success of Deep Learning (DL) models such as DNNs stems from a combination of ef?cient learning algorithms and their huge parametric space. The latter space comprises hundreds of layers and millions of parameters, which makes DNNs be considered as complex black-box models [ 4]. The opposite of black-box-ness istransparency , i.e., the search for a direct understanding of the mechanism by which a model works [5]. As black-box Machine Learning (ML) models are increasingly being employed to make important predictions in critical contexts, the demand for transparency is increasing from the various stakeholders in AI [6]. The danger is on creating and using decisions that are not justi?able, legitimate, or that simply do not allow obtaining detailed explanations of their behaviour [ 7]. Explanations supporting the output of a model are crucial, e.g., in precision medicine, where experts require far more information from the model than a simple binary prediction for supporting their diagnosis [ 8]. Other examples include autonomous vehicles in transportation, security, and ?nance, among others. In general, humans are reticent to adopt techniques that are not directly interpretable, tractable and trustworthy [9], given the increasing demand for ethical AI [3]. It is customary to think that by focusing solely on performance, the systems will be increasingly opaque. This is true in the sense that there is a trade-off between the performance of a model and its transparency [ 10]. However, an improvement in the understanding of a system can lead to the correction of its de?ciencies. When developing a ML model, the consideration of interpretability as an additional design driver can improve its implementability for 3 reasons: \u2022Interpretability helps ensure impartiality in decision-making, i.e. to detect, and consequently, correct from bias in the training dataset. \u2022Interpretability facilitates the provision of robustness by highlighting potential adversarial perturbations that could change the prediction. \u2022Interpretability can act as an insurance that only meaningful variables infer the output, i.e., guaranteeing that an underlying truthful causality exists in the model reasoning. All these means that the interpretation of the system should, in order to be considered practical, provide either an understanding of the model mechanisms and predictions, a visualization of the model\u2019s discrimination rules, or hints on what could perturb the model [11]. In order to avoid limiting the effectiveness of the current generation of AI systems, eXplainable AI (XAI) [ 7] proposes creating a suite of ML techniques that 1) produce more explainable models while maintaining a high level of learning performance (e.g., prediction accuracy), and 2) enable humans to understand, appropriately trust, and effectively manage the emerging generation of arti?cially intelligent partners. XAI draws as well insights from the Social Sciences [ 12] and considers the psychology of explanation. 22012 2013 2014 2015 2016 2017 2018 2019 (December 10th) Year0255075100125150175200# of contributed works in the literatureInterpretable Arti?cial Intelligence XAI Explainable Arti?cial IntelligenceFigure 1: Evolution of the number of total publications whose title, abstract and/or keywords refer to the ?eld of XAI during the last years. Data retrieved from ScopusR?(December 10th, 2019) by using the search terms indicated in the legend when querying this database. It is interesting to note the latent need for interpretable AI models over time (which conforms to intuition, as interpretability is a requirement in many scenarios), yet it has not been until 2017 when the interest in techniques to explain AI models has permeated throughout the research community. Figure 1 displays the rising trend of contributions on XAI and related concepts. This literature outbreak shares its rationale with the research agendas of national governments and agencies. Although some recent surveys [ 8,13,10,14,15,16,17] summarize the upsurge of activity in XAI across sectors and disciplines, this overview aims to cover the creation of a complete uni?ed framework of categories and concepts that allow for scrutiny and understanding of the ?eld of XAI methods. Furthermore, we pose intriguing thoughts around the explainability of AI models in data fusion contexts with regards to data privacy and model con?dentiality. This, along with other research opportunities and challenges identi?ed throughout our study, serve as the pull factor toward Responsible Arti?cial Intelligence, term by which we refer to a series of AI principles to be necessarily met when deploying AI in real applications. As we will later show in detail, model explainability is among the most crucial aspects to be ensured within this methodological framework. All in all, the novel contributions of this overview can be summarized as follows: 1.Grounded on a ?rst elaboration of concepts and terms used in XAI-related research, we propose a novel de?nition of explainability that places audience (Figure 2) as a key aspect to be considered when explaining a ML model. We also elaborate on the diverse purposes sought when using XAI techniques, from trustworthiness to privacy awareness, which round up the claimed importance of purpose and targeted audience in model explainability. 2.We de?ne and examine the different levels of transparency that a ML model can feature by itself, as well as the diverse approaches to post-hoc explainability, namely, the explanation of ML models that are not transparent by design. 3.We thoroughly analyze the literature on XAI and related concepts published to date, covering ap- proximately 400 contributions arranged into two different taxonomies. The ?rst taxonomy addresses the explainability of ML models using the previously made distinction between transparency and post-hoc explainability, including models that are transparent by themselves, Deep and non-Deep (i.e., 3shallow ) learning models. The second taxonomy deals with XAI methods suited for the explanation of Deep Learning models, using classi?cation criteria closely linked to this family of ML methods (e.g. layerwise explanations, representation vectors, attention). 4. We enumerate a series of challenges of XAI that still remain insuf?ciently addressed to date. Speci?- cally, we identify research needs around the concepts and metrics to evaluate the explainability of ML models, and outline research directions toward making Deep Learning models more understandable. We further augment the scope of our prospects toward the implications of XAI techniques in regards to con?dentiality, robustness in adversarial settings, data diversity, and other areas intersecting with explainability. 5.After the previous prospective discussion, we arrive at the concept of Responsible Arti?cial Intelligence, a manifold concept that imposes the systematic adoption of several AI principles for AI models to be of practical use. In addition to explainability, the guidelines behind Responsible AI establish that fairness, accountability and privacy should also be considered when implementing AI models in real environments. 6.Since Responsible AI blends together model explainability and privacy/security by design, we call for a profound re?ection around the bene?ts and risks of XAI techniques in scenarios dealing with sensitive information and/or con?dential ML models. As we will later show, the regulatory push toward data privacy, quality, integrity and governance demands more efforts to assess the role of XAI in this arena. In this regard, we provide an insight on the implications of XAI in terms of privacy and security under different data fusion paradigms. The remainder of this overview is structured as follows: ?rst, Section 2 and subsections therein open a discussion on the terminology and concepts revolving around explainability and interpretability in AI, ending up with the aforementioned novel de?nition of interpretability (Subsections 2.1 and 2.2), and a general criterion to categorize and analyze ML models from the XAI perspective. Sections 3 and 4 proceed by reviewing recent ?ndings on XAI for ML models (on transparent models and post-hoc techniques respectively) that comprise the main division in the aforementioned taxonomy. We also include a review on hybrid approaches among the two, to attain XAI. Bene?ts and caveats of the synergies among the families of methods are discussed in Section 5, where we present a prospect of general challenges and some consequences to be cautious about. Finally, Section 6 elaborates on the concept of Responsible Arti?cial Intelligence. Section 7 concludes the survey with an outlook aimed at engaging the community around this vibrant research area, which has the potential to impact society, in particular those sectors that have progressively embraced ML as a core technology of their activity. 2. Explainability: What, Why, What For and How? Before proceeding with our literature study, it is convenient to ?rst establish a common point of understanding on what the term explainability stands for in the context of AI and, more speci?cally, ML. This is indeed the purpose of this section, namely, to pause at the numerous de?nitions that have been done in regards to this concept (what?), to argue why explainability is an important issue in AI and ML (why? what for?) and to introduce the general classi?cation of XAI approaches that will drive the literature study thereafter (how?). 2.1. Terminology Clari?cation One of the issues that hinders the establishment of common grounds is the interchangeable misuse of interpretability and explainability in the literature. There are notable differences among these concepts. To begin with, interpretability refers to a passive characteristic of a model referring to the level at which a given model makes sense for a human observer. This feature is also expressed as transparency. By 4contrast, explainability can be viewed as an active characteristic of a model, denoting any action or procedure taken by a model with the intent of clarifying or detailing its internal functions. To summarize the most commonly used nomenclature, in this section we clarify the distinction and similarities among terms often used in the ethical AI and XAI communities. \u2022Understandability (or equivalently, intelligibility ) denotes the characteristic of a model to make a human understand its function \u2013 how the model works \u2013 without any need for explaining its internal structure or the algorithmic means by which the model processes data internally [18]. \u2022Comprehensibility : when conceived for ML models, comprehensibility refers to the ability of a learning algorithm to represent its learned knowledge in a human understandable fashion [ 19,20,21]. This notion of model comprehensibility stems from the postulates of Michalski [ 22], which stated that \u201cthe results of computer induction should be symbolic descriptions of given entities, semantically and structurally similar to those a human expert might produce observing the same entities. Components of these descriptions should be comprehensible as single \u2018chunks\u2019 of information, directly interpretable in natural language, and should relate quantitative and qualitative concepts in an integrated fashion\u201d . Given its dif?cult quanti?cation, comprehensibility is normally tied to the evaluation of the model complexity [17]. \u2022Interpretability : it is de?ned as the ability to explain or to provide the meaning in understandable terms to a human. \u2022Explainability : explainability is associated with the notion of explanation as an interface between humans and a decision maker that is, at the same time, both an accurate proxy of the decision maker and comprehensible to humans [17]. \u2022Transparency : a model is considered to be transparent if by itself it is understandable. Since a model can feature different degrees of understandability, transparent models in Section 3 are divided into three categories: simulatable models, decomposable models and algorithmically transparent models [5]. In all the above de?nitions, understandability emerges as the most essential concept in XAI. Both transparency and interpretability are strongly tied to this concept: while transparency refers to the characteristic of a model to be, on its own, understandable for a human, understandability measures the degree to which a human can understand a decision made by a model. Comprehensibility is also connected to understandability in that it relies on the capability of the audience to understand the knowledge contained in the model. All in all, understandability is a two-sided matter: model understandability and human understandability. This is the reason why the de?nition of XAI given in Section 2.2 refers to the concept ofaudience , as the cognitive skills and pursued goal of the users of the model have to be taken into account jointly with the intelligibility and comprehensibility of the model in use. This prominent role taken by understandability makes the concept of audience the cornerstone of XAI, as we next elaborate in further detail. 2.2. What? Although it might be considered to be beyond the scope of this paper, it is worth noting the discussion held around general theories of explanation in the realm of philosophy [ 23]. Many proposals have been done in this regard, suggesting the need for a general, uni?ed theory that approximates the structure and intent of an explanation. However, nobody has stood the critique when presenting such a general theory. For the time being, the most agreed-upon thought blends together different approaches to explanation drawn from diverse knowledge disciplines. A similar problem is found when addressing interpretability in AI. It appears from the literature that there is not yet a common point of understanding on what interpretability or explainability are. However, many contributions claim the achievement of interpretable models and techniques that empower explainability. 5To shed some light on this lack of consensus, it might be interesting to place the reference starting point at the de?nition of the term Explainable Arti?cial Intelligence (XAI) given by D. Gunning in [7]: \u201cXAI will create a suite of machine learning techniques that enables human users to understand, appropriately trust, and effectively manage the emerging generation of arti?cially intelligent partners\u201d This de?nition brings together two concepts (understanding and trust) that need to be addressed in advance. However, it misses to consider other purposes motivating the need for interpretable AI models, such as causality, transferability, informativeness, fairness and con?dence [ 5,24,25,26]. We will later delve into these topics, mentioning them here as a supporting example of the incompleteness of the above de?nition. As exempli?ed by the de?nition above, a thorough, complete de?nition of explainability in AI still slips from our ?ngers. A broader reformulation of this de?nition (e.g. \u201cAn explainable Arti?cial Intelligence is one that produces explanations about its functioning\u201d ) would fail to fully characterize the term in question, leaving aside important aspects such as its purpose. To build upon the completeness, a de?nition of explanation is ?rst required. As extracted from the Cambridge Dictionary of English Language, an explanation is \u201cthe details or reasons that someone gives to make something clear or easy to understand\u201d [27]. In the context of an ML model, this can be rephrased as: \u201dthe details or reasons a model gives to make its functioning clear or easy to understand\u201d . It is at this point where opinions start to diverge. Inherently stemming from the previous de?nitions, two ambiguities can be pointed out. First, the details or the reasons used to explain, are completely dependent of the audience to which they are presented. Second, whether the explanation has left the concept clear or easy to understand also depends completely on the audience. Therefore, the de?nition must be rephrased to re?ect explicitly the dependence of the explainability of the model on the audience. To this end, a reworked de?nition could read as: Given a certain audience, explainability refers to the details and reasons a model gives to make its functioning clear or easy to understand. Since explaining, as argumenting, may involve weighting, comparing or convincing an audience with logic-based formalizations of (counter) arguments [ 28], explainability might convey us into the realm of cognitive psychology and the psychology of explanations [7], since measuring whether something has been understood or put clearly is a hard task to be gauged objectively. However, measuring to which extent the internals of a model can be explained could be tackled objectively. Any means to reduce the complexity of the model or to simplify its outputs should be considered as an XAI approach. How big this leap is in terms of complexity or simplicity will correspond to how explainable the resulting model is. An underlying problem that remains unsolved is that the interpretability gain provided by such XAI approaches may not be straightforward to quantify: for instance, a model simpli?cation can be evaluated based on the reduction of the number of architectural elements or number of parameters of the model itself (as often made, for instance, for DNNs). On the contrary, the use of visualization methods or natural language for the same purpose does not favor a clear quanti?cation of the improvements gained in terms of interpretability. The derivation of general metrics to assess the quality of XAI approaches remain as an open challenge that should be under the spotlight of the ?eld in forthcoming years. We will further discuss on this research direction in Section 5. Explainability is linked to post-hoc explainability since it covers the techniques used to convert a non-interpretable model into a explainable one. In the remaining of this manuscript, explainability will be considered as the main design objective, since it represents a broader concept. A model can be explained, but the interpretability of the model is something that comes from the design of the model itself. Bearing these observations in mind, explainable AI can be de?ned as follows: Given an audience, an explainable Arti?cial Intelligence is one that produces details or reasons to make its functioning clear or easy to understand. 6This de?nition is posed here as a ?rst contribution of the present overview, implicitly assumes that the ease of understanding and clarity targeted by XAI techniques for the model at hand reverts on different application purposes, such as a better trustworthiness of the model\u2019s output by the audience. 2.3. Why? As stated in the introduction, explainability is one of the main barriers AI is facing nowadays in regards to its practical implementation. The inability to explain or to fully understand the reasons by which state-of-the-art ML algorithms perform as well as they do, is a problem that ?nd its roots in two different causes, which are conceptually illustrated in Figure 2. Without a doubt, the ?rst cause is the gap between the research community and business sectors, impeding the full penetration of the newest ML models in sectors that have traditionally lagged behind in the digital transformation of their processes, such as banking, ?nances, security and health, among many others. In general this issue occurs in strictly regulated sectors with some reluctance to implement techniques that may put at risk their assets. The second axis is that of knowledge. AI has helped research across the world with the task of inferring relations that were far beyond the human cognitive reach. Every ?eld dealing with huge amounts of reliable data has largely bene?ted from the adoption of AI and ML techniques. However, we are entering an era in which results and performance metrics are the only interest shown up in research studies. Although for certain disciplines this might be the fair case, science and society are far from being concerned just by performance. The search for understanding is what opens the door for further model improvement and its practical utility. Target audience in XAI Who? Domain experts/users of the model (e.g. medical doctors, insurance agents) Why? Trust the model itself, gain scienti?c knowledge Who? Regulatory entities/agencies Why? Certify model compliance with the Who? Users a?ected by model decisions Why? Understand their situation, verify Who? Managers and executive board members Why? Assess regulatory compliance, understand Who? Data scientists, developers, product owners... Why? Ensure/improve product e?ciency, research, corporate AI applications... new functionalities... fair decisions... legislation in force, audits, ... ? ? < / > ? $ $ $ ? ? ? Figure 2: Diagram showing the different purposes of explainability in ML models sought by different audience pro?les. Two goals occur to prevail across them: need for model understanding, and regulatory compliance. Image partly inspired by the one presented in [29], used with permission from IBM. The following section develops these ideas further by analyzing the goals motivating the search for explainable AI models. 2.4. What for? The research activity around XAI has so far exposed different goals to draw from the achievement of an explainable model. Almost none of the papers reviewed completely agrees in the goals required to describe what an explainable model should compel. However, all these different goals might help discriminate the purpose for which a given exercise of ML explainability is performed. Unfortunately, scarce contributions have attempted to de?ne such goals from a conceptual perspective [ 5,13,24,30]. We now synthesize and enumerate de?nitions for these XAI goals, so as to settle a ?rst classi?cation criteria for the full suit of papers covered in this review: 7XAI Goal Main target audience (Fig. 2) References TrustworthinessDomain experts, users of the model affected by decisions[5, 10, 24, 32, 33, 34, 35, 36, 37] CausalityDomain experts, managers and executive board members, regulatory entities/agencies[35, 38, 39, 40, 41, 42, 43] Transferability Domain experts, data scientists[5, 44, 21, 26, 45, 30, 32, 37, 38, 39, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85] Informativeness All[5,44,21,25,26,45,30,32,34,35,37,38,41,46,49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 86, 87, 88, 89, 59, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100,101,102,103,104,105,106,107,108,109,110, 111,112,113,114,115,116,117,118,119,120,121, 122,123,124,125,126,127,128,129,130,131,132, 133,134,135,136,137,138,139,140,141,142,143, 144,145,146,147,148,149,150,151,152,153,154] Con?denceDomain experts, developers, managers, regulatory entities/agencies[5, 45, 35, 46, 48, 54, 61, 72, 88, 89, 96, 108, 117, 119, 155] FairnessUsers affected by model decisions, regulatory entities/agencies[5, 24, 45, 35, 47, 99, 100, 101, 120, 121, 128, 156, 157, 158] AccessibilityProduct owners, managers, users affected by model decisions[21, 26, 30, 32, 37, 50, 53, 55, 62, 67, 68, 69, 70, 71, 74, 75, 76, 86, 93, 94, 103, 105, 107, 108, 111, 112, 113, 114, 115, 124, 129] InteractivityDomain experts, users affected by model decisions[37, 50, 59, 65, 67, 74, 86, 124] Privacy awarenessUsers affected by model decisions, regulatory entities/agencies[89] Table 1: Goals pursued in the reviewed literature toward reaching explainability, and their main target audience. \u2022Trustworthiness: several authors agree upon the search for trustworthiness as the primary aim of an explainable AI model [ 31,32]. However, declaring a model as explainable as per its capabilities of inducing trust might not be fully compliant with the requirement of model explainability. Trustwor- thiness might be considered as the con?dence of whether a model will act as intended when facing a given problem. Although it should most certainly be a property of any explainable model, it does not imply that every trustworthy model can be considered explainable on its own, nor is trustworthiness a property easy to quantify. Trust might be far from being the only purpose of an explainable model since the relation among the two, if agreed upon, is not reciprocal. Part of the reviewed papers mention the concept of trust when stating their purpose for achieving explainability. However, as seen in Table 1, they do not amount to a large share of the recent contributions related to XAI. \u2022Causality: another common goal for explainability is that of ?nding causality among data variables. Several authors argue that explainable models might ease the task of ?nding relationships that, should they occur, could be tested further for a stronger causal link between the involved variables [ 159,160]. The inference of causal relationships from observational data is a ?eld that has been broadly studied over time [ 161]. As widely acknowledged by the community working on this topic, causality requires a wide frame of prior knowledge to prove that observed effects are causal. A ML model only discovers correlations among the data it learns from, and therefore might not suf?ce for unveiling a cause-effect relationship. However, causation involves correlation, so an explainable ML model could validate the results provided by causality inference techniques, or provide a ?rst intuition of possible causal 8relationships within the available data. Again, Table 1 reveals that causality is not among the most important goals if we attend to the amount of papers that state it explicitly as their goal. \u2022Transferability: models are always bounded by constraints that should allow for their seamless transferability. This is the main reason why a training-testing approach is used when dealing with ML problems [ 162,163]. Explainability is also an advocate for transferability, since it may ease the task of elucidating the boundaries that might affect a model, allowing for a better understanding and implementation. Similarly, the mere understanding of the inner relations taking place within a model facilitates the ability of a user to reuse this knowledge in another problem. There are cases in which the lack of a proper understanding of the model might drive the user toward incorrect assumptions and fatal consequences [ 44,164]. Transferability should also fall between the resulting properties of an explainable model, but again, not every transferable model should be considered as explainable. As observed in Table 1, the amount of papers stating that the ability of rendering a model explainable is to better understand the concepts needed to reuse it or to improve its performance is the second most used reason for pursuing model explainability. \u2022Informativeness: ML models are used with the ultimate intention of supporting decision making [ 92]. However, it should not be forgotten that the problem being solved by the model is not equal to that being faced by its human counterpart. Hence, a great deal of information is needed in order to be able to relate the user\u2019s decision to the solution given by the model, and to avoid falling in misconception pitfalls. For this purpose, explainable ML models should give information about the problem being tackled. Most of the reasons found among the papers reviewed is that of extracting information about the inner relations of a model. Almost all rule extraction techniques substantiate their approach on the search for a simpler understanding of what the model internally does, stating that the knowledge (information) can be expressed in these simpler proxies that they consider explaining the antecedent. This is the most used argument found among the reviewed papers to back up what they expect from reaching explainable models. \u2022Con?dence: as a generalization of robustness and stability, con?dence should always be assessed on a model in which reliability is expected. The methods to maintain con?dence under control are different depending on the model. As stated in [ 165,166,167], stability is a must-have when drawing interpretations from a certain model. Trustworthy interpretations should not be produced by models that are not stable. Hence, an explainable model should contain information about the con?dence of its working regime. \u2022Fairness: from a social standpoint, explainability can be considered as the capacity to reach and guarantee fairness in ML models. In a certain literature strand, an explainable ML model suggests a clear visualization of the relations affecting a result, allowing for a fairness or ethical analysis of the model at hand [ 3,100]. Likewise, a related objective of XAI is highlighting bias in the data a model was exposed to [ 168,169]. The support of algorithms and models is growing fast in ?elds that involve human lives, hence explainability should be considered as a bridge to avoid the unfair or unethical use of algorithm\u2019s outputs. \u2022Accessibility: a minor subset of the reviewed contributions argues for explainability as the property that allows end users to get more involved in the process of improving and developing a certain ML model [ 37,86] . It seems clear that explainable models will ease the burden felt by non-technical or non-expert users when having to deal with algorithms that seem incomprehensible at ?rst sight. This concept is expressed as the third most considered goal among the surveyed literature. \u2022Interactivity: some contributions [ 50,59] include the ability of a model to be interactive with the user as one of the goals targeted by an explainable ML model. Once again, this goal is related to ?elds in 9which the end users are of great importance, and their ability to tweak and interact with the models is what ensures success. \u2022Privacy awareness: almost forgotten in the reviewed literature, one of the byproducts enabled by ex- plainability in ML models is its ability to assess privacy. ML models may have complex representations of their learned patterns. Not being able to understand what has been captured by the model [ 4] and stored in its internal representation may entail a privacy breach. Contrarily, the ability to explain the inner relations of a trained model by non-authorized third parties may also compromise the differential privacy of the data origin. Due to its criticality in sectors where XAI is foreseen to play a crucial role, con?dentiality and privacy issues will be covered further in Subsections 5.4 and 6.3, respectively. This subsection has reviewed the goals encountered among the broad scope of the reviewed papers. All these goals are clearly under the surface of the concept of explainability introduced before in this section. To round up this prior analysis on the concept of explainability, the last subsection deals with different strategies followed by the community to address explainability in ML models. 2.5. How? The literature makes a clear distinction among models that are interpretable by design, and those that can be explained by means of external XAI techniques. This duality could also be regarded as the difference between interpretable models and model interpretability techniques; a more widely accepted classi?cation is that of transparent models and post-hoc explainability. This same duality also appears in the paper presented in [ 17] in which the distinction its authors make refers to the methods to solve the transparent box design problem against the problem of explaining the black-box problem. This work, further extends the distinction made among transparent models including the different levels of transparency considered. Within transparency, three levels are contemplated: algorithmic transparency, decomposability and simulatability1. Among post-hoc techniques we may distinguish among text explanations ,visualizations , local explanations ,explanations by example ,explanations by simpli?cation andfeature relevance . In this context, there is a broader distinction proposed by [ 24] discerning between 1) opaque systems, where the mappings from input to output are invisible to the user; 2) interpretable systems, in which users can mathematically analyze the mappings; and 3) comprehensible systems, in which the models should output symbols or rules along with their speci?c output to aid in the understanding process of the rationale behind the mappings being made. This last classi?cation criterion could be considered included within the one proposed earlier, hence this paper will attempt at following the more speci?c one. 2.5.1. Levels of Transparency in Machine Learning Models Transparent models convey some degree of interpretability by themselves. Models belonging to this category can be also approached in terms of the domain in which they are interpretable, namely, algorithmic transparency, decomposability and simulatability. As we elaborate next in connection to Figure 3, each of these classes contains its predecessors, e.g. a simulatable model is at the same time a model that is decomposable and algorithmically transparent: \u2022Simulatability denotes the ability of a model of being simulated or thought about strictly by a human, hence complexity takes a dominant place in this class. This being said, simple but extensive (i.e., with too large amount of rules) rule based systems fall out of this characteristic, whereas a single perceptron neural network falls within. This aspect aligns with the claim that sparse linear models are more interpretable than dense ones [ 170], and that an interpretable model is one that can be easily presented 1The alternative term simulability is also used in the literature to refer to the capacity of a system or process to be simulated. However, we note that this term does not appear in current English dictionaries. 10to a human by means of text and visualizations [32]. Again, endowing a decomposable model with simulatability requires that the model has to be self-contained enough for a human to think and reason about it as a whole. \u2022Decomposability stands for the ability to explain each of the parts of a model (input, parameter and calculation). It can be considered as intelligibility as stated in [ 171]. This characteristic might empower the ability to understand, interpret or explain the behavior of a model. However, as occurs with algorithmic transparency, not every model can ful?ll this property. Decomposability requires every input to be readily interpretable (e.g. cumbersome features will not ?t the premise). The added constraint for an algorithmically transparent model to become decomposable is that every part of the model must be understandable by a human without the need for additional tools. \u2022Algorithmic Transparency can be seen in different ways. It deals with the ability of the user to understand the process followed by the model to produce any given output from its input data. Put it differently, a linear model is deemed transparent because its error surface can be understood and reasoned about, allowing the user to understand how the model will act in every situation it may face [ 163]. Contrarily, it is not possible to understand it in deep architectures as the loss landscape might be opaque [ 172,173] since it cannot be fully observed and the solution has to be approximated through heuristic optimization (e.g. through stochastic gradient descent). The main constraint for algorithmically transparent models is that the model has to be fully explorable by means of mathematical analysis and methods. M? x1 x2 x3 y (b) Ifx2>180 then y= 1 Else if x1+x3>150 then y= 1 Elsey= 0 M? x1 x2 x3 y (a) Ifg(fA(x1), fB(x2))>5 then y= 1, else y= 0 fA(x1) = 1/x2 1,fB(x2) = log x2 g(f, g) = 1/(f+g) x1: weight, x2: height, x3: age M? x1 x2 x3 y (c) (c) 95% of the positive training samples have x2>180??Rule 1 90% of the positive training samples have x1+x3>150??Rule 2 ? ? ? Figure 3: Conceptual diagram exemplifying the different levels of transparency characterizing a ML model M?, with?denoting the parameter set of the model at hand: (a) simulatability; (b) decomposability; (c) algorithmic transparency. Without loss of generality, the example focuses on the ML model as the explanation target. However, other targets for explainability may include a given example, the output classes or the dataset itself. 2.5.2. Post-hoc Explainability Techniques for Machine Learning Models Post-hoc explainability targets models that are not readily interpretable by design by resorting to diverse means to enhance their interpretability, such as text explanations ,visual explanations ,local explanations ,explanations by example ,explanations by simpli?cation andfeature relevance explanations techniques. Each of these techniques covers one of the most common ways humans explain systems and processes by themselves. Further along this river, actual techniques, or better put, actual group of techniques are speci?ed to ease the future work of any researcher that intends to look up for an speci?c technique that suits its knowledge. Not ending there, the classi?cation also includes the type of data in which the techniques has been applied. Note that many techniques might be suitable for many different types of data, although the categorization only considers the type used by the authors that proposed such technique. Overall, post-hoc explainability techniques are divided ?rst by the intention of the author (explanation technique e.g. Explanation by simpli?cation), then, by the method utilized (actual technique e.g. sensitivity analysis) and ?nally by the type of data in which it was applied (e.g. images). 11\u2022Text explanations deal with the problem of bringing explainability for a model by means of learning to generate text explanations that help explaining the results from the model [ 169].Text explanations also include every method generating symbols that represent the functioning of the model. These symbols may portrait the rationale of the algorithm by means of a semantic mapping from model to symbols. \u2022Visual explanation techniques for post-hoc explainability aim at visualizing the model\u2019s behavior. Many of the visualization methods existing in the literature come along with dimensionality reduction techniques that allow for a human interpretable simple visualization. Visualizations may be coupled with other techniques to improve their understanding, and are considered as the most suitable way to introduce complex interactions within the variables involved in the model to users not acquainted to ML modeling. \u2022Local explanations tackle explainability by segmenting the solution space and giving explanations to less complex solution subspaces that are relevant for the whole model. These explanations can be formed by means of techniques with the differentiating property that these only explain part of the whole system\u2019s functioning. \u2022Explanations by example consider the extraction of data examples that relate to the result generated by a certain model, enabling to get a better understanding of the model itself. Similarly to how humans behave when attempting to explain a given process, explanations by example are mainly centered in extracting representative examples that grasp the inner relationships and correlations found by the model being analyzed. \u2022Explanations by simpli?cation collectively denote those techniques in which a whole new system is rebuilt based on the trained model to be explained. This new, simpli?ed model usually attempts at optimizing its resemblance to its antecedent functioning, while reducing its complexity, and keeping a similar performance score. An interesting byproduct of this family of post-hoc techniques is that the simpli?ed model is, in general, easier to be implemented due to its reduced complexity with respect to the model it represents. \u2022Finally, feature relevance explanation methods for post-hoc explainability clarify the inner functioning of a model by computing a relevance score for its managed variables. These scores quantify the affection (sensitivity) a feature has upon the output of the model. A comparison of the scores among different variables unveils the importance granted by the model to each of such variables when producing its output. Feature relevance methods can be thought to be an indirect method to explain a model. The above classi?cation (portrayed graphically in Figure 4) will be used when reviewing spe- ci?c/agnostic XAI techniques for ML models in the following sections (Table 2). For each ML model, a distinction of the propositions to each of these categories is presented in order to pose an overall image of the ?eld\u2019s trends. 3. Transparent Machine Learning Models The previous section introduced the concept of transparent models. A model is considered to be transparent if by itself it is understandable. The models surveyed in this section are a suit of transparent models that can fall in one or all of the levels of model transparency described previously (namely, simulatability, decomposability and algorithmic transparency). In what follows we provide reasons for this statement, with graphical support given in Figure 5. 12Black-box model x y M? x= (x1,...,xn) Feature relevance ... \u201cFeaturex2has a 90% importance in y\u201d ... Local explanations xi yi M? \u201cWhat happens with the prediction yiif we change slightly the features of xi?\u201d xi: input instance Visualization x y M? x1 x2 x3 x4 xn x1 x3 Model simpli?cation x y M? x1 x3 x7 x13 y' x F G Text explanations xi yi M? \u201cThe output for xiis yibecausex3>?\u201d by example Explanations xi yi M? \u201dExplanatory examples for the model:\u201d -xA??yA -xB??yB -xC??yCFigure 4: Conceptual diagram showing the different post-hoc explainability approaches available for a ML model M?. 3.1. Linear/Logistic Regression Logistic Regression (LR) is a classi?cation model to predict a dependent variable (category) that is dichotomous (binary). However, when the dependent variable is continuous, linear regression would be its homonym. This model takes the assumption of linear dependence between the predictors and the predicted variables, impeding a ?exible ?t to the data. This speci?c reason (stiffness of the model) is the one that maintains the model under the umbrella of transparent methods. However, as stated in Section 2, explainability is linked to a certain audience, which makes a model fall under both categories depending who is to interpret it. This way, logistic and linear regression, although clearly meeting the characteristics of transparent models (algorithmic transparency, decomposability and simulatability), may also demand post-hoc explainability techniques (mainly, visualization), particularly when the model is to be explained to non-expert audiences. The usage of this model has been largely applied within Social Sciences for quite a long time, which has pushed researchers to create ways of explaining the results of the models to non-expert users. Most authors agree on the different techniques used to analyze and express the soundness of LR [174,175,176,177], including the overall model evaluation, statistical tests of individual predictors, goodness-of-?t statistics and validation of the predicted probabilities. The overall model evaluation shows the improvement of the applied model over a baseline, showing if it is in fact improving the model without predictions. The statistical signi?cance of single predictors is shown by calculating the Wald chi-square statistic. The goodness-of-?t statistics show the quality of ?tness of the model to the data and how signi?cant this is. This can be achieved by resorting to different techniques e.g. the so-called Hosmer-Lemeshow (H-L) statistic. The validation of predicted probabilities involves testing whether the output of the model corresponds to what is shown by the data. These techniques show mathematical ways of representing the ?tness of the model and its behavior. Other techniques from other disciplines besides Statistics can be adopted for explaining these re- 13ModelTransparent ML ModelsPost-hoc analysis Simulatability Decomposability Algorithmic Transparency Linear/Logistic RegressionPredictors are human readable and interactions among them are kept to a minimumVariables are still readable, but the number of interactions and predictors involved in them have grown to force decompositionVariables and interactions are too complex to be analyzed without mathematical toolsNot needed Decision TreesA human can simulate and obtain the prediction of a decision tree on his/her own, without requiring any mathematical backgroundThe model comprises rules that do not alter data whatsoever, and preserves their readabilityHuman-readable rules that explain the knowledge learned from data and allows for a direct understanding of the prediction processNot needed K-Nearest NeighborsThe complexity of the model (number of variables, their understandability and the similarity measure under use) matches human naive capabilities for simulationThe amount of variables is too high and/or the similarity measure is too complex to be able to simulate the model completely, but the similarity measure and the set of variables can be decomposed and analyzed separatelyThe similarity measure cannot be decomposed and/or the number of variables is so high that the user has to rely on mathematical and statistical tools to analyze the modelNot needed Rule Based LearnersVariables included in rules are readable, and the size of the rule set is manageable by a human user without external helpThe size of the rule set becomes too large to be analyzed without decomposing it into small rule chunksRules have become so complicated (and the rule set size has grown so much) that mathematical tools are needed for inspecting the model behaviourNot needed General Additive ModelsVariables and the interaction among them as per the smooth functions involved in the model must be constrained within human capabilities for understandingInteractions become too complex to be simulated, so decomposition techniques are required for analyzing the modelDue to their complexity, variables and interactions cannot be analyzed without the application of mathematical and statistical toolsNot needed Bayesian ModelsStatistical relationships modeled among variables and the variables themselves should be directly understandable by the target audienceStatistical relationships involve so many variables that they must be decomposed in marginals so as to ease their analysisStatistical relationships cannot be interpreted even if already decomposed, and predictors are so complex that model can be only analyzed with mathematical toolsNot needed Tree Ensembles \u0017 \u0017 \u0017Needed: Usually Model simpli?cation or Feature relevance techniques Support Vector Machines \u0017 \u0017 \u0017Needed: Usually Model simpli?cation or Local explanations techniques Multi\u2013layer Neural Network \u0017 \u0017 \u0017Needed: Usually Model simpli?cation , Feature relevance orVisualization techniques Convolutional Neural Network \u0017 \u0017 \u0017Needed: Usually Feature relevance or Visualization techniques Recurrent Neural Network \u0017 \u0017 \u0017Needed: Usually Feature relevance techniques Table 2: Overall picture of the classi?cation of ML models attending to their level of explainability. gression models. Visualization techniques are very powerful when presenting statistical conclusions to users not well-versed in statistics. For instance, the work in [ 178] shows that the usage of probabilities to communicate the results, implied that the users where able to estimate the outcomes correctly in 10% of the cases, as opposed to 46% of the cases when using natural frequencies. Although logistic regression is among the simplest classi?cation models in supervised learning, there are concepts that must be taken care of. In this line of reasoning, the authors of [ 179] unveil some concerns with the interpretations derived from LR. They ?rst mention how dangerous it might be to interpret log odds ratios and odd ratios as substantive effects, since they also represent unobserved heterogeneity. Linked to this ?rst concern, [179] also states that a comparison between these ratios across models with different variables might be problematic, since the unobserved heterogeneity is likely to vary, thereby invalidating the comparison. Finally they also mention that the comparison of these odds across different samples, groups and time is also risky, since the variation of the heterogeneity is not known across samples, groups and time points. This last paper serves the purpose of visualizing the problems a model\u2019s interpretation might entail, even when its construction is as simple as that of LR. Also interesting is to note that, for a model such as logistic or linear regression to maintain decompos- ability and simulatability, its size must be limited, and the variables used must be understandable by their users. As stated in Section 2, if inputs to the model are highly engineered features that are complex or dif?cult to understand, the model at hand will be far from being decomposable . Similarly, if the model is so large that a human cannot think of the model as a whole, its simulatability will be put to question. 3.2. Decision Trees Decision trees are another example of a model that can easily ful?ll every constraint for transparency. Decision trees are hierarchical structures for decision making used to support regression and classi?cation problems [ 132,180]. In the simplest of their ?avors, decision trees are simulatable models. However, their properties can render them decomposable oralgorithmically transparent . 14x2 x1 x1=? x2=?' x2=?'' Yes No x1=?''' Yes No Yes No Class Support: 70% Impurity: 0.1 Straightforward what-if testing Simple univariate thresholds Simulatable, decomposable Direct support and impurity measures wi: increase in yifxi w0(intercept): yfor a test instance with average normalized features increases by one unit x1 x2 xtest 2 xtest 1 Yes Prediction by majority voting Ksimilar training instances Simulatable, decomposable Algorithmic transparency ( lazy training ) Linguistic rules: easy to interpret Training dataset -Ifx1ishigh theny= -Ifx1islowandx2is high theny= -Ifx2islowtheny= Simulatable if ruleset coverage and speci?ty are kept constrained Fuzziness improves interpretability y=w1x1+w2x2+w0 g(E(y)) =w1f1(x1) +w2f2(x2) Training dataset g(z) z fi(xi) xi E(y): expected value Simulatable, decomposable Interpretability depends on link functiong(z), the selected fi(xi) and the sparseness of [ w1,...,w N] y Training dataset Training dataset Training dataset Training dataset x1 x2 y p(y|x1, x2)?p(y|x1)p(y|x2) xi p(y|xi) to assess the contribution of each variable The independence assumption permits Simulatable, decomposable Algorithmic transparency ( distribution ?tting ) (a) (b) (c) (d) (e) (f) Class Class Class Class ? ? ? ? ? ?Figure 5: Graphical illustration of the levels of transparency of different ML models considered in this overview: (a) Linear regression; (b) Decision trees; (c) K-Nearest Neighbors; (d) Rule-based Learners; (e) Generalized Additive Models; (f) Bayesian Models. Decision trees have always lingered in between the different categories of transparent models. Their utilization has been closely linked to decision making contexts, being the reason why their complexity and understandability have always been considered a paramount matter. A proof of this relevance can be found in the upsurge of contributions to the literature dealing with decision tree simpli?cation and generation [ 132,180,181,182]. As noted above, although being capable of ?tting every category within transparent models, the individual characteristics of decision trees can push them toward the category of algorithmically transparent models. A simulatable decision tree is one that is manageable by a human user. This means its size is somewhat small and the amount of features and their meaning are easily understandable. An increment in size transforms the model into a decomposable one since its size impedes its full evaluation (simulation) by a human. Finally, further increasing its size and using complex feature relations will make the model algorithmically transparent loosing the previous characteristics. Decision trees have long been used in decision support contexts due to their off-the-shelf transparency. Many applications of these models fall out of the ?elds of computation and AI (even information technologies), meaning that experts from other ?elds usually feel comfortable interpreting the outputs of these models [ 183,184,185]. However, their poor generalization properties in comparison with other models make this model family less interesting for their application to scenarios where a balance between predictive performance is a design driver of utmost importance. Tree ensembles aim at overcoming such a poor performance by aggregating the predictions performed by trees learned on different subsets of training data. Unfortunately, the combination of decision trees looses every transparent property, calling for the adoption of post-hoc explainability techniques as the ones reviewed later in the manuscript. 153.3. K-Nearest Neighbors Another method that falls within transparent models is that of K-Nearest Neighbors (KNN), which deals with classi?cation problems in a methodologically simple way: it predicts the class of a test sample by voting the classes of its K nearest neighbors (where the neighborhood relation is induced by a measure of distance between samples). When used in the context of regression problems, the voting is replaced by an aggregation (e.g. average) of the target values associated with the nearest neighbors. In terms of model explainability, it is important to observe that predictions generated by KNN models rely on the notion of distance and similarity between examples, which can be tailored depending on the speci?c problem being tackled. Interestingly, this prediction approach resembles that of experience-based human decision making, which decides upon the result of past similar cases. There lies the rationale of why KNN has also been adopted widely in contexts in which model interpretability is a requirement [186,187,188,189]. Furthermore, aside from being simple to explain, the ability to inspect the reasons by which a new sample has been classi?ed inside a group and to examine how these predictions evolve when the number of neighbors K is increased or decreased empowers the interaction between the users and the model. One must keep in mind that as mentioned before, KNN\u2019s class of transparency depends on the features, the number of neighbors and the distance function used to measure the similarity between data instances. A very high K impedes a full simulation of the model performance by a human user. Similarly, the usage of complex features and/or distance functions would hinder the decomposability of the model, restricting its interpretability solely to the transparency of its algorithmic operations. 3.4. Rule-based Learning Rule-based learning refers to every model that generates rules to characterize the data it is intended to learn from. Rules can take the form of simple conditional if-then rules or more complex combinations of simple rules to form their knowledge. Also connected to this general family of models, fuzzy rule based systems are designed for a broader scope of action, allowing for the de?nition of verbally formulated rules over imprecise domains. Fuzzy systems improve two main axis relevant for this paper. First, they empower more understandable models since they operate in linguistic terms. Second, they perform better that classic rule systems in contexts with certain degrees of uncertainty. Rule based learners are clearly transparent models that have been often used to explain complex models by generating rules that explain their predictions [126, 127, 190, 191]. Rule learning approaches have been extensively used for knowledge representation in expert systems [192]. However, a central problem with rule generation approaches is the coverage (amount) and the speci?city (length) of the rules generated. This problem relates directly to the intention for their use in the ?rst place. When building a rule database, a typical design goal sought by the user is to be able to analyze and understand the model. The amount of rules in a model will clearly improve the performance of the model at the stake of compromising its intepretability. Similarly, the speci?city of the rules plays also against interpretability, since a rule with a high number of antecedents an/or consequences might become dif?cult to interpret. In this same line of reasoning, these two features of a rule based learner play along with the classes of transparent models presented in Section 2. The greater the coverage or the speci?city is, the closer the model will be to being just algorithmically transparent . Sometimes, the reason to transition from classical rules to fuzzy rules is to relax the constraints of rule sizes, since a greater range can be covered with less stress on interpretability. Rule based learners are great models in terms of interpretability across ?elds. Their natural and seamless relation to human behaviour makes them very suitable to understand and explain other models. If a certain threshold of coverage is acquired, a rule wrapper can be thought to contain enough information about a model to explain its behavior to a non-expert user, without forfeiting the possibility of using the generated rules as an standalone prediction model. 163.5. General Additive Models In statistics, a Generalized Additive Model (GAM) is a linear model in which the value of the variable to be predicted is given by the aggregation of a number of unknown smooth functions de?ned for the predictor variables. The purpose of such model is to infer the smooth functions whose aggregate composition approximates the predicted variable. This structure is easily interpretable, since it allows the user to verify the importance of each variable, namely, how it affects (through its corresponding function) the predicted output. Similarly to every other transparent model, the literature is replete with case studies where GAMs are in use, specially in ?elds related to risk assessment. When compared to other models, these are understandable enough to make users feel con?dent on using them for practical applications in ?nance [193,194,195], environmental studies [ 196], geology [ 197], healthcare [ 44], biology [ 198,199] and energy [ 200]. Most of these contributions use visualization methods to further ease the interpretation of the model. GAMs might be also considered as simulatable anddecomposable models if the properties mentioned in its de?nitions are ful?lled, but to an extent that depends roughly on eventual modi?cations to the baseline GAM model, such as the introduction of link functions to relate the aggregation with the predicted output, or the consideration of interactions between predictors. All in all, applications of GAMs like the ones exempli?ed above share one common factor: under- standability. The main driver for conducting these studies with GAMs is to understand the underlying relationships that build up the cases for scrutiny. In those cases the research goal is not accuracy for its own sake, but rather the need for understanding the problem behind and the relationship underneath the variables involved in data. This is why GAMs have been accepted in certain communities as their de facto modeling choice, despite their acknowledged misperforming behavior when compared to more complex counterparts. 3.6. Bayesian Models A Bayesian model usually takes the form of a probabilistic directed acyclic graphical model whose links represent the conditional dependencies between a set of variables. For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Similar to GAMs, these models also convey a clear representation of the relationships between features and the target, which in this case are given explicitly by the connections linking variables to each other. Once again, Bayesian models fall below the ceiling of Transparent models. Its categorization leaves it under simulatable ,decomposable andalgorithmically transparent . However, it is worth noting that under certain circumstances (overly complex or cumbersome variables), a model may loose these ?rst two properties. Bayesian models have been shown to lead to great insights in assorted applications such as cognitive modeling [ 201,202], ?shery [ 196,203], gaming [ 204], climate [ 205], econometrics [ 206] or robotics [ 207]. Furthermore, they have also been utilized to explain other models, such as averaging tree ensembles [208]. 4. Post-hoc Explainability Techniques for Machile Learning Models: Taxonomy, Shallow Models and Deep Learning When ML models do not meet any of the criteria imposed to declare them transparent, a separate method must be devised and applied to the model to explain its decisions. This is the purpose of post-hoc explainability techniques (also referred to as post-modeling explainability), which aim at communicating understandable information about how an already developed model produces its predictions for any given input. In this section we categorize and review different algorithmic approaches for post-hoc explainability, discriminating among 1) those that are designed for their application to ML models of any kind; and 2) those that are designed for a speci?c ML model and thus, can not be directly extrapolated to any other 17learner. We now elaborate on the trends identi?ed around post-hoc explainability for different ML models, which are illustrated in Figure 6 in the form of hierarchical bibliographic categories and summarized next: \u2022Model-agnostic techniques for post-hoc explainability (Subsection 4.1), which can be applied seam- lessly to any ML model disregarding its inner processing or internal representations. \u2022Post-hoc explainability that are tailored or speci?cally designed to explain certain ML models. We divide our literature analysis into two main branches: contributions dealing with post-hoc explainability ofshallow ML models, which collectively refers to all ML models that do not hinge on layered structures of neural processing units (Subsection 4.2); and techniques devised for deep learning models, which correspondingly denote the family of neural networks and related variants, such as convolutional neural networks, recurrent neural networks (Subsection 4.3) and hybrid schemes encompassing deep neural networks and transparent models. For each model we perform a thorough review of the latest post-hoc methods proposed by the research community, along with a identi?cation of trends followed by such contributions. \u2022We end our literature analysis with Subsection 4.4, where we present a second taxonomy that com- plements the more general one in Figure 6 by classifying contributions dealing with the post-hoc explanation of Deep Learning models. To this end we focus on particular aspects related to this family of black-box ML methods, and expose how they link to the classi?cation criteria used in the ?rst taxonomy. 4.1. Model-agnostic Techniques for Post-hoc Explainability Model-agnostic techniques for post-hoc explainability are designed to be plugged to any model with the intent of extracting some information from its prediction procedure. Sometimes, simpli?cation techniques are used to generate proxies that mimic their antecedents with the purpose of having something tractable and of reduced complexity. Other times, the intent focuses on extracting knowledge directly from the models or simply visualizing them to ease the interpretation of their behavior. Following the taxonomy introduced in Section 2, model-agnostic techniques may rely on model simpli?cation ,feature relevance estimation and visualization techniques: \u2022Explanation by simpli?cation . They are arguably the broadest technique under the category of model agnostic post-hoc methods. Local explanations are also present within this category, since sometimes, simpli?ed models are only representative of certain sections of a model. Almost all techniques taking this path for model simpli?cation are based on rule extraction techniques. Among the most known contributions to this approach we encounter the technique of Local Interpretable Model-Agnostic Explanations (LIME) [ 32] and all its variations [ 214,216]. LIME builds locally linear models around the predictions of an opaque model to explain it. These contributions fall under explanations by simpli?cation as well as under local explanations . Besides LIME and related ?avors, another approach to rule extraction is G-REX [ 212]. Although it was not originally intended for extracting rules from opaque models, the generic proposition of G-REX has been extended to also account for model explainability purposes [ 190,211]. In line with rule extraction methods, the work in [ 215] presents a novel approach to learn rules in CNF (Conjunctive Normal Form) or DNF (Disjunctive Normal Form) to bridge from a complex model to a human-interpretable model. Another contribution that falls off the same branch is that in [ 218], where the authors formulate model simpli?cation as a model extraction process by approximating a transparent model to the complex one. Simpli?cation is approached from a different perspective in [ 120], where an approach to distill and audit black box models is presented. In it, two main ideas are exposed: a method for model distillation and comparison to audit black-box risk scoring models; and an statistical test to check if the auditing data is missing key features it was trained with. The popularity of model simpli?cation is evident, given it temporally coincides with the most 18XAI in MLTransparent ModelsLogistic / Linear Regression Decision Trees K-Nearest Neighbors Rule-base Learners General Additive Models: [44] Bayesian Models: [31, 49, 209, 210] Post-Hoc ExplainabilityModel-AgnosticExplanation by simpli?cationRule-based learner: [32, 51, 120, 190, 211, 212, 213, 214, 215, 216] Decision Tree: [21, 119, 133, 135, 149, 217, 218] Others: [56, 219] Feature relevance explanationIn?uence functions: [173, 220, 221] Sensitivity: [222, 223] Game theory inspired: [224, 225] [226] Saliency: [85, 227] Interaction based: [123, 228] Others: [140, 141, 229, 230, 231] Local ExplanationsRule-based learner: [32, 216] Decision Tree: [232, 233] Others: [67, 224, 230, 234, 235, 236, 237] Visual explanationConditional / Dependence / Shapley plots: [56, 224, 238, 239] Sensitivity / Saliency: [85, 227] [222, 223] Others: [117, 123, 140, 178, 234] Model-Speci?cEnsembles and Multiple Classi?er SystemsExplanation by simpli?cation Decision Tree/Prototype: [84, 118, 122] Feature relevance explanation Feature importance / contribution: [103, 104, 240, 241] Visual explanation Variable importance / attribution: [104, 241] [242, 243] Support Vector MachinesExplanation by simpli?cationRule-based learner: [57, 93, 94, 98, 106, 134, 244, 245, 246] Probabilistic: [247, 248] Others: [102] Feature relevance explanation Feature Contribution / Statistics: [249] [116, 249] Visual explanation Internal visualization: [68, 77, 250] Multi-Layer Neural NetworksExplanation by simpli?cationRule-based learner: [82, 83, 147, 148, 251, 252, 253, 254, 255, 256] Decision Tree: [21, 56, 79, 81, 97, 135, 257, 258, 259] Others: [80] Feature relevance explanationImportance/Contribution: [60, 61, 110, 260, 261] Sensitivity / Saliency: [260] [262] Local explanation Decision Tree / Sensitivity: [233] [263] Explanation by Example Activation clusters: [264, 144] Text explanation Caption generation: [111] [150] Visual explanation Saliency / Weights: [265] Architecture modi?cation Others: [264] [266] [267] Convolutional Neural NetworksExplanation by simpli?cation Decision Tree: [78] Feature relevance explanationActivations: [72, 268] [46] Feature Extraction: [72, 268] Visual explanationFilter / Activation: [63, 136, 137, 142, 152, 269, 270, 271] Sensitivity / Saliency: [131, 272] [46] Others: [273] Architecture modi?cationLayer modi?cation: [143, 274, 275] Model combination: [91, 274, 276] Attention networks: [107, 114, 277, 278] [91] Loss modi?cation: [276] [113] Others: [279] Recurrent Neural NetworksExplanation by simpli?cation Rule-based learner: [146] Feature relevance explanation Activation propagation: [280] Visual explanation Activations: [281] Arquitecture modi?cationLoss / Layer modi?cation: [276, 282] [274] Others: [151, 283, 284] [285] Figure 6: Taxonomy of the reviewed literature and trends identi?ed for explainability techniques related to different ML models. References boxed in blue, green and red correspond to XAI techniques using image, text or tabular data, respectively. In order to build this taxonomy, the literature has been analyzed in depth to discriminate whether a post-hoc technique can be seamlessly applied to any ML model, even if, e.g., explicitly mentions Deep Learning in its title and/or abstract. recent literature on XAI, including techniques such as LIME or G-REX. This symptomatically reveals that this post-hoc explainability approach is envisaged to continue playing a central role on XAI. \u2022Feature relevance explanation techniques aim to describe the functioning of an opaque model by 19ranking or measuring the in?uence, relevance or importance each feature has in the prediction output by the model to be explained. An amalgam of propositions are found within this category, each resorting to different algorithmic approaches with the same targeted goal. One fruitful contribution to this path is that of [ 224] called SHAP (SHapley Additive exPlanations). Its authors presented a method to calculate an additive feature importance score for each particular prediction with a set of desirable properties (local accuracy, missingness and consistency) that its antecedents lacked. Another approach to tackle the contribution of each feature to predictions has been coalitional Game Theory [ 225] and local gradients [ 234]. Similarly, by means of local gradients [ 230] test the changes needed in each feature to produce a change in the output of the model. In [ 228] the authors analyze the relations and dependencies found in the model by grouping features, that combined, bring insights about the data. The work in [ 173] presents a broad variety of measures to tackle the quanti?cation of the degree of in?uence of inputs on outputs of systems. Their QII (Quantitative Input In?uence) measures account for correlated inputs while measuring in?uence. In contrast, in [ 222] the authors build upon the existing SA (Sensitivity Analysis) to construct a Global SA which extends the applicability of the existing methods. In [ 227] a real-time image saliency method is proposed, which is applicable to differentiable image classi?ers. The study in [ 123] presents the so-called Automatic STRucture IDenti?cation method (ASTRID) to inspect which attributes are exploited by a classi?er to generate a prediction. This method ?nds the largest subset of features such that the accuracy of a classi?er trained with this subset of features cannot be distinguished in terms of accuracy from a classi?er built on the original feature set. In [221] the authors use in?uence functions to trace a model\u2019s prediction back to the training data, by only requiring an oracle version of the model with access to gradients and Hessian-vector products. Heuristics for creating counterfactual examples by modifying the input of the model have been also found to contribute to its explainability [ 236,237]. Compared to those attempting explanations by simpli?cation, a similar amount of publications were found tackling explainability by means of feature relevance techniques. Many of the contributions date from 2017 and some from 2018, implying that as with model simpli?cation techniques, feature relevance has also become a vibrant subject study in the current XAI landscape. \u2022Visual explanation techniques are a vehicle to achieve model-agnostic explanations. Representative works in this area can be found in [ 222], which present a portfolio of visualization techniques to help in the explanation of a black-box ML model built upon the set of extended techniques mentioned earlier (Global SA). Another set of visualization techniques is presented in [ 223]. The authors present three novel SA methods (data based SA, Monte-Carlo SA, cluster-based SA) and one novel input importance measure (Average Absolute Deviation). Finally, [ 238] presents ICE (Individual Conditional Expecta- tion) plots as a tool for visualizing the model estimated by any supervised learning algorithm. Visual explanations are less common in the ?eld of model-agnostic techniques for post-hoc explainability. Since the design of these methods must ensure that they can be seamlessly applied to any ML model disregarding its inner structure, creating visualizations from just inputs and outputs from an opaque model is a complex task. This is why almost all visualization methods falling in this category work along with feature relevance techniques, which provide the information that is eventually displayed to the end user. Several trends emerge from our literature analysis. To begin with, rule extraction techniques prevail in model-agnostic contributions under the umbrella of post-hoc explainability. This could have been intuitively expected if we bear in mind the wide use of rule based learning as explainability wrappers anticipated in Section 3.4, and the complexity imposed by not being able to get into the model itself. Similarly, another large group of contributions deals with feature relevance . Lately these techniques are gathering much attention by the community when dealing with DL models, with hybrid approaches that utilize particular aspects of this class of models and therefore, compromise the independence of the feature relevance method on the model being explained. Finally, visualization techniques propose interesting 20ways for visualizing the output of feature relevance techniques to ease the task of model\u2019s interpretation. By contrast, visualization techniques for other aspects of the trained model (e.g. its structure, operations, etc) are tightly linked to the speci?c model to be explained. 4.2. Post-hoc Explainability in Shallow ML Models Shallow ML covers a diversity of supervised learning models. Within these models, there are strictly interpretable (transparent) approaches (e.g. KNN and Decision Trees, already discussed in Section 3). However, other shallow ML models rely on more sophisticated learning algorithms that require additional layers of explanation. Given their prominence and notable performance in predictive tasks, this section concentrates on two popular shallow ML models (tree ensembles and Support Vector Machines, SVMs) that require the adoption of post-hoc explainability techniques for explaining their decisions. 4.2.1. Tree Ensembles, Random Forests and Multiple Classi?er Systems Tree ensembles are arguably among the most accurate ML models in use nowadays. Their advent came as an ef?cient means to improve the generalization capability of single decision trees, which are usually prone to over?tting. To circumvent this issue, tree ensembles combine different trees to obtain an aggregated prediction/regression. While it results to be effective against over?tting, the combination of models makes the interpretation of the overall ensemble more complex than each of its compounding tree learners, forcing the user to draw from post-hoc explainability techniques. For tree ensembles, techniques found in the literature are explanation by simpli?cation and feature relevance techniques; we next examine recent advances in these techniques. To begin with, many contributions have been presented to simplify tree ensembles while maintaining part of the accuracy accounted for the added complexity. The author from [ 119] poses the idea of training a single albeit less complex model from a set of random samples from the data (ideally following the real data distribution) labeled by the ensemble model. Another approach for simpli?cation is that in [ 118], in which authors create a Simpli?ed Tree Ensemble Learner (STEL). Likewise, [ 122] presents the usage of two models (simple and complex) being the former the one in charge of interpretation and the latter of prediction by means of Expectation-Maximization and Kullback-Leibler divergence. As opposed to what was seen in model-agnostic techniques, not that many techniques to board explainability in tree ensembles by means of model simpli?cation . It derives from this that either the proposed techniques are good enough, or model-agnostic techniques do cover the scope of simpli?cation already. Following simpli?cation procedures, feature relevance techniques are also used in the ?eld of tree ensembles. Breiman [ 286] was the ?rst to analyze the variable importance within Random Forests. His method is based on measuring MDA (Mean Decrease Accuracy) or MIE (Mean Increase Error) of the forest when a certain variable is randomly permuted in the out-of-bag samples. Following this contribution [241] shows, in an real setting, how the usage of variable importance re?ects the underlying relationships of a complex system modeled by a Random Forest. Finally, a crosswise technique among post-hoc explainability, [ 240] proposes a framework that poses recommendations that, if taken, would convert an example from one class to another. This idea attempts to disentangle the variables importance in a way that is further descriptive. In the article, the authors show how these methods can be used to elevate recommendations to improve malicious online ads to make them rank higher in paying rates. Similar to the trend shown in model-agnostic techniques, for tree ensembles again, simpli?cation and feature relevance techniques seem to be the most used schemes. However, contrarily to what was observed before, most papers date back from 2017 and place their focus mostly on bagging ensembles. When shifting the focus towards other ensemble strategies, scarce activity has been recently noted around the explainability of boosting and stacking classi?ers. Among the latter, it is worth highlighting the connection between the reason why a compounding learner of the ensemble produces an speci?c prediction on a given data, and its contribution to the output of the ensemble. The so-called Stacking With Auxiliary Features (SWAF) approach proposed in [ 242] points in this direction by harnessing and integrating explanations in 21stacking ensembles to improve their generalization. This strategy allows not only relying on the output of the compounding learners, but also on the origin of that output and its consensus across the entire ensemble. Other interesting studies on the explainability of ensemble techniques include model-agnostic schemes such as DeepSHAP [ 226], put into practice with stacking ensembles and multiple classi?er systems in addition to Deep Learning models; the combination of explanation maps of multiple classi?ers to produce improved explanations of the ensemble to which they belong [ 243]; and recent insights dealing with traditional and gradient boosting ensembles [287, 288]. 4.2.2. Support Vector Machines Another shallow ML model with historical presence in the literature is the SVM. SVM models are more complex than tree ensembles, with a much opaquer structure. Many implementations of post-hoc explainability techniques have been proposed to relate what is mathematically described internally in these models, to what different authors considered explanations about the problem at hand. Technically, an SVM constructs a hyper-plane or set of hyper-planes in a high or in?nite-dimensional space, which can be used for classi?cation, regression, or other tasks such as outlier detection. Intuitively, a good separation is achieved by the hyperplane that has the largest distance (so-called functional margin) to the nearest training-data point of any class, since in general, the larger the margin, the lower the generalization error of the classi?er. SVMs are among the most used ML models due to their excellent prediction and generalization capabilities. From the techniques stated in Section 2, post-hoc explainability applied to SVMs covers explanation by simpli?cation ,local explanations ,visualizations andexplanations by example . Among explanation by simpli?cation, four classes of simpli?cations are made. Each of them dif- ferentiates from the other by how deep they go into the algorithm inner structure. First, some authors propose techniques to build rule based models only from the support vectors of a trained model. This is the approach of [ 93], which proposes a method that extracts rules directly from the support vectors of a trained SVM using a modi?ed sequential covering algorithm. In [ 57] the same authors propose eclectic rule extraction, still considering only the support vectors of a trained model. The work in [94] generates fuzzy rules instead of classical propositional rules. Here, the authors argue that long antecedents reduce comprehensibility, hence, a fuzzy approach allows for a more linguistically understandable result. The second class of simpli?cations can be exempli?ed by [ 98], which proposed the addition of the SVM\u2019s hyperplane, along with the support vectors, to the components in charge of creating the rules. His method relies on the creation of hyper-rectangles from the intersections between the support vectors and the hyper-plane. In a third approach to model simpli?cation , another group of authors considered adding the actual training data as a component for building the rules. In [ 126,244,246] the authors proposed a clustering method to group prototype vectors for each class. By combining them with the support vectors, it allowed de?ning ellipsoids and hyper-rectangles in the input space. Similarly in [ 106], the authors proposed the so-called Hyper-rectangle Rule Extraction, an algorithm based on SVC (Support Vector Clustering) to ?nd prototype vectors for each class and then de?ne small hyper-rectangles around. In [105], the authors formulate the rule extraction problem as a multi-constrained optimization to create a set of non-overlapping rules. Each rule conveys a non-empty hyper-cube with a shared edge with the hyper-plane. In a similar study conducted in [ 245], extracting rules for gene expression data, the authors presented a novel technique as a component of a multi-kernel SVM. This multi-kernel method consists of feature selection, prediction modeling and rule extraction. Finally, the study in [ 134] makes use of a growing SVC to give an interpretation to SVM decisions in terms of linear rules that de?ne the space in V oronoi sections from the extracted prototypes. Leaving aside rule extraction, the literature has also contemplated some other techniques to contribute to the interpretation of SVMs. Three of them (visualization techniques) are clearly used toward explaining SVM models when used for concrete applications. For instance, [ 77] presents an innovative approach to visualize trained SVM to extract the information content from the kernel matrix. They center the study 22on Support Vector Regression models. They show the ability of the algorithm to visualize which of the input variables are actually related with the associated output data. In [ 68] a visual way combines the output of the SVM with heatmaps to guide the modi?cation of compounds in late stages of drug discovery. They assign colors to atoms based on the weights of a trained linear SVM that allows for a much more comprehensive way of debugging the process. In [ 116] the authors argue that many of the presented studies for interpreting SVMs only account for the weight vectors, leaving the margin aside. In their study they show how this margin is important, and they create an statistic that explicitly accounts for the SVM margin. The authors show how this statistic is speci?c enough to explain the multivariate patterns shown in neuroimaging. Noteworthy is also the intersection between SVMs and Bayesian systems, the latter being adopted as a post-hoc technique to explain decisions made by the SVM model. This is the case of [ 248] and [247], which are studies where SVMs are interpreted as MAP (Maximum A Posteriori) solutions to inference problems with Gaussian Process priors. This framework makes tuning the hyper-parameters comprehensible and gives the capability of predicting class probabilities instead of the classical binary classi?cation of SVMs. Interpretability of SVM models becomes even more involved when dealing with non-CPD (Conditional Positive De?nite) kernels that are usually harder to interpret due to missing geometrical and theoretical understanding. The work in [ 102] revolves around this issue with a geometrical interpretation of inde?nite kernel SVMs, showing that these do not classify by hyper-plane margin optimization. Instead, they minimize the distance between convex hulls in pseudo-Euclidean spaces. A difference might be appreciated between the post-hoc techniques applied to other models and those noted for SVMs. In previous models, model simpli?cation in a broad sense was the prominent method for post-hoc explainability. In SVMs, local explanations have started to take some weight among the propositions. However, simpli?cation based methods are, on average, much older than local explanations. As a ?nal remark, none of the reviewed methods treating SVM explainability are dated beyond 2017, which might be due to the progressive proliferation of DL models in almost all disciplines. Another plausible reason is that these models are already understood, so it is hard to improve upon what has already been done. 4.3. Explainability in Deep Learning Post-hoc local explanations andfeature relevance techniques are increasingly the most adopted methods for explaining DNNs. This section reviews explainability studies proposed for the most used DL models, namely multi-layer neural networks, Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN). 4.3.1. Multi-layer Neural Networks From their inception, multi-layer neural networks (also known as multi-layer perceptrons) have been warmly welcomed by the academic community due to their huge ability to infer complex relations among variables. However, as stated in the introduction, developers and engineers in charge of deploying these models in real-life production ?nd in their questionable explainability a common reason for reluctance. That is why neural networks have been always considered as black-box models. The fact that explainability is often a must for the model to be of practical value, forced the community to generate multiple explainability techniques for multi-layer neural networks, including model simpli?cation approaches, feature relevance estimators, text explanations ,local explanations and model visualizations . Several model simpli?cation techniques have been proposed for neural networks with one single hidden layer, however very few works have been presented for neural networks with multiple hidden layers. One of these few works is DeepRED algorithm [ 257], which extends the decompositional approach to rule extraction (splitting at neuron level) presented in [ 259] for multi-layer neural network by adding more decision trees and rules. Some other works use model simpli?cation as a post-hoc explainability approach. For instance, [ 56] presents a simple distillation method called Interpretable Mimic Learning to extract an interpretable model 23by means of gradient boosting trees. In the same direction, the authors in [ 135] propose a hierarchical partitioning of the feature space that reveals the iterative rejection of unlikely class labels, until association is predicted. In addition, several works addressed the distillation of knowledge from an ensemble of models into a single model [80, 289, 290] . Given the fact that the simpli?cation of multi-layer neural networks is more complex as the number of layers increases, explaining these models by feature relevance methods has become progressively more popular. One of the representative works in this area is [ 60], which presents a method to decompose the network classi?cation decision into contributions of its input elements. They consider each neuron as an object that can be decomposed and expanded then aggregate and back-propagate these decompositions through the network, resulting in a deep Taylor decomposition. In the same direction, the authors in [ 110] proposed DeepLIFT, an approach for computing importance scores in a multi-layer neural network. Their method compares the activation of a neuron to the reference activation and assigns the score according to the difference. On the other hand, some works try to verify the theoretical soundness of current explainability methods. For example, the authors in [ 262], bring up a fundamental problem of most feature relevance techniques, designed for multi-layer networks. They showed that two axioms that such techniques ought to ful?ll namely, sensitivity andimplementation invariance , are violated in practice by most approaches. Following these axioms, the authors of [ 262] created integrated gradients , a new feature relevance method proven to meet the aforementioned axioms. Similarly, the authors in [ 61] analyzed the correctness of current feature relevance explanation approaches designed for Deep Neural Networks, e,g., DeConvNet, Guided BackProp and LRP, on simple linear neural networks. Their analysis showed that these methods do not produce the theoretically correct explanation and presented two new explanation methods PatternNet and PatternAttribution that are more theoretically sound for both, simple and deep neural networks. 4.3.2. Convolutional Neural Networks Currently, CNNs constitute the state-of-art models in all fundamental computer vision tasks, from image classi?cation and object detection to instance segmentation. Typically, these models are built as a sequence of convolutional layers and pooling layers to automatically learn increasingly higher level features. At the end of the sequence, one or multiple fully connected layers are used to map the output features map into scores. This structure entails extremely complex internal relations that are very dif?cult to explain. Fortunately, the road to explainability for CNNs is easier than for other types of models, as the human cognitive skills favors the understanding of visual data. Existing works that aim at understanding what CNNs learn can be divided into two broad categories: 1) those that try to understand the decision process by mapping back the output in the input space to see which parts of the input were discriminative for the output; and 2) those that try to delve inside the network and interpret how the intermediate layers see the external world, not necessarily related to any speci?c input, but in general. One of the seminal works in the ?rst category was [ 291]. When an input image runs feed-forward through a CNN, each layer outputs a number of feature maps with strong and soft activations. The authors in [291] used Deconvnet, a network designed previously by the same authors [ 142] that, when fed with a feature map from a selected layer, reconstructs the maximum activations. These reconstructions can give an idea about the parts of the image that produced that effect. To visualize these strongest activations in the input image, the same authors used the occlusion sensitivity method to generate a saliency map [ 136], which consists of iteratively forwarding the same image through the network occluding a different region at a time. To improve the quality of the mapping on the input space, several subsequent papers proposed simplifying both the CNN architecture and the visualization method. In particular, [ 96] included a global average pooling layer between the last convolutional layer of the CNN and the fully-connected layer that predicts the object class. With this simple architectural modi?cation of the CNN, the authors built a class 24activation map that helps identify the image regions that were particularly important for a speci?c object class by projecting back the weights of the output layer on the convolutional feature maps. Later, in [ 143], the authors showed that max-pooling layers can be used to replace convolutional layers with a large stride without loss in accuracy on several image recognition benchmarks. They obtained a cleaner visualization than Deconvnet by using a guided backpropagation method. To increase the interpretability of classical CNNs, the authors in [ 113] used a loss for each ?lter in high level convolutional layers to force each ?lter to learn very speci?c object components. The obtained activation patterns are much more interpretable for their exclusiveness with respect to the different labels to be predicted. The authors in [ 72] proposed visualizing the contribution to the prediction of each single pixel of the input image in the form of a heatmap. They used a Layer-wise Relevance Propagation (LRP) technique, which relies on a Taylor series close to the prediction point rather than partial derivatives at the prediction point itself. To further improve the quality of the visualization, attribution methods such as heatmaps, saliency maps or class activation methods ( GradCAM [292]) are used (see Figure 7). In particular, the authors in [ 292] proposed a Gradient-weighted Class Activation Mapping (Grad-CAM), which uses the gradients of any target concept, ?owing into the ?nal convolutional layer to produce a coarse localization map, highlighting the important regions in the image for predicting the concept. (a) Heatmap [168] (b) Attribution [293] (c) Grad-CAM [292] Figure 7: Examples of rendering for different XAI visualization techniques on images. In addition to the aforementioned feature relevance andvisual explanation methods, some works proposed generating text explanations of the visual content of the image. For example, the authors in [ 91] combined a CNN feature extractor with an RNN attention model to automatically learn to describe the content of images. In the same line, [ 278] presented a three-level attention model to perform a ?ne-grained classi?cation task. The general model is a pipeline that integrates three types of attention: the object level attention model proposes candidate image regions or patches from the input image, the part-level attention model ?lters out non-relevant patches to a certain object, and the last attention model localizes discriminative patches. In the task of video captioning, the authors in [ 111] use a CNN model combined with a bi-directional LSTM model as encoder to extract video features and then feed these features to an LSTM decoder to generate textual descriptions. One of the seminal works in the second category is [ 137]. In order to analyse the visual information contained inside the CNN, the authors proposed a general framework that reconstruct an image from the CNN internal representations and showed that several layers retain photographically accurate information about the image, with different degrees of geometric and photometric invariance. To visualize the notion of a class captured by a CNN, the same authors created an image that maximizes the class score based on computing the gradient of the class score with respect to the input image [ 272]. In the same direction, the authors in [ 268] introduced a Deep Generator Network (DGN) that generates the most representative image for a given output neuron in a CNN. For quantifying the interpretability of the latent representations of CNNs, the authors in [ 125] used a different approach called network dissection. They run a large number of images through a CNN and then analyze the top activated images by considering each unit as a concept detector to further evaluate each 25unit for semantic segmentation. This paper also examines the effects of classical training techniques on the interpretability of the learned model. Although many of the techniques examined above utilize local explanations to achieve an overall explanation of a CNN model, others explicitly focus on building global explanations based on locally found prototypes. In [ 263,294], the authors empirically showed how local explanations in deep networks are strongly dominated by their lower level features. They demonstrated that deep architectures provide strong priors that prevent the altering of how these low-level representations are captured. All in all, visualization mixed with feature relevance methods are arguably the most adopted approach to explainability in CNNs. Instead of using one single interpretability technique, the framework proposed in [ 295] combines several methods to provide much more information about the network. For example, combining feature visualization ( what is a neuron looking for? ) with attribution ( how does it affect the output? ) allows exploring how the network decides between labels. This visual interpretability interface displays different blocks such as feature visualization and attribution depending on the visualization goal. This interface can be thought of as a union of individual elements that belong to layers (input, hidden, output), atoms (a neuron, channel, spatial or neuron group), content (activations \u2013 the amount a neuron ?res, attribution \u2013 which classes a spatial position most contributes to, which tends to be more meaningful in later layers), and presentation (information visualization, feature visualization). Figure 8 shows some examples. Attribution methods normally rely on pixel association, displaying what part of an input example is responsible for the network activating in a particular way [293]. (a) Neuron (b) Channel (c) Layer Figure 8: Feature visualization at different levels of a certain network [293]. (a) Original image (b) Explaining electric guitar (c) Explaining acoustic guitar Figure 9: Examples of explanation when using LIME on images [71]. A much simpler approach to all the previously cited methods was proposed in LIME framework [71], as was described in Subsection 4.1 LIME perturbs the input and sees how the predictions change. In image classi?cation, LIME creates a set of perturbed instances by dividing the input image into interpretable components (contiguous superpixels ), and runs each perturbed instance through the model 26to get a probability. A simple linear model learns on this data set, which is locally weighted. At the end of the process, LIME presents the superpixels with highest positive weights as an explanation (see Figure 9). A completely different explainability approach is proposed in adversarial detection. To understand model failures in detecting adversarial examples, the authors in [ 264] apply the k-nearest neighbors algorithm on the representations of the data learned by each layer of the CNN. A test input image is considered as adversarial if its representations are far from the representations of the training images. 4.3.3. Recurrent Neural Networks As occurs with CNNs in the visual domain, RNNs have lately been used extensively for predictive problems de?ned over inherently sequential data, with a notable presence in natural language processing and time series analysis. These types of data exhibit long-term dependencies that are complex to be captured by a ML model. RNNs are able to retrieve such time-dependent relationships by formulating the retention of knowledge in the neuron as another parametric characteristic that can be learned from data. Few contributions have been made for explaining RNN models. These studies can be divided into two groups: 1) explainability by understanding what a RNN model has learned (mainly via feature relevance methods); and 2) explainability by modifying RNN architectures to provide insights about the decisions they make ( local explanations ). In the ?rst group, the authors in [ 280] extend the usage of LRP to RNNs. They propose a speci?c propagation rule that works with multiplicative connections as those in LSTMs (Long Short Term Memory) units and GRUs (Gated Recurrent Units). The authors in [ 281] propose a visualization technique based on ?nite horizon n-grams that discriminates interpretable cells within LSTM and GRU networks. Following the premise of not altering the architecture, [ 296] extends the interpretable mimic learning distillation method used for CNN models to LSTM networks, so that interpretable features are learned by ?tting Gradient Boosting Trees to the trained LSTM network under focus. Aside from the approaches that do not change the inner workings of the RNNs, [ 285] presents RETAIN (REverse Time AttentIoN) model, which detects in?uential past patterns by means of a two-level neural attention model. To create an interpretable RNN, the authors in [ 283] propose an RNN based on SISTA (Sequential Iterative Soft-Thresholding Algorithm) that models a sequence of correlated observations with a sequence of sparse latent vectors, making its weights interpretable as the parameters of a principled statistical model. Finally, [ 284] constructs a combination of an HMM (Hidden Markov Model) and an RNN, so that the overall model approach harnesses the interpretability of the HMM and the accuracy of the RNN model. 4.3.4. Hybrid Transparent and Black-box Methods The use of background knowledge in the form of logical statements or constraints in Knowledge Bases (KBs) has shown to not only improve explainability but also performance with respect to purely data-driven approaches [ 297,298,299]. A positive side effect shown is that this hybrid approach provides robustness to the learning system when errors are present in the training data labels. Other approaches have shown to be able to jointly learn and reason with both symbolic and sub-symbolic representations and inference. The interesting aspect is that this blend allows for expressive probabilistic-logical reasoning in an end-to-end fashion [ 300]. A successful use case is on dietary recommendations, where explanations are extracted from the reasoning behind (non-deep but KB-based) models [301]. Future data fusion approaches may thus consider endowing DL models with explainability by external- izing other domain information sources. Deep formulation of classical ML models has been done, e.g. in Deep Kalman ?lters (DKFs) [ 302], Deep Variational Bayes Filters (DVBFs) [ 303], Structural Variational Autoencoders (SV AE) [ 304], or conditional random ?elds as RNNs [ 305]. These approaches provide deep models with the interpretability inherent to probabilistic graphical models. For instance, SV AE combines probabilistic graphical models in the embedding space with neural networks to enhance the interpretability of DKFs. A particular example of classical ML model enhanced with its DL counterpart is 27Deep Nearest Neighbors DkNN [ 264], where the neighbors constitute human-interpretable explanations of predictions. The intuition is based on the rationalization of a DNN prediction based on evidence. This evidence consists of a characterization of con?dence termed credibility that spans the hierarchy of representations within a DNN, that must be supported by the training data [264]. M? Black-box ML model x y Transparent design methods \u2022Decision Tree \u2022(Fuzzy) rule-based learning \u2022KNN Prediction Explanation Figure 10: Pictorial representation of a hybrid model. A neural network considered as a black-box can be explained by associating it to a more interpretable model such as a Decision Tree [306], a (fuzzy) rule-based system [19] or KNN [264]. A different perspective on hybrid XAI models consists of enriching black-box models knowledge with that one of transparent ones, as proposed in [ 24] and further re?ned in [ 169] and [ 307]. In particular, this can be done by constraining the neural network thanks to a semantic KB and bias-prone concepts [169], or by stacking ensembles jointly encompassing white- and black-box models [307]. Other examples of hybrid symbolic and sub-symbolic methods where a knowledge-base tool or graph-perspective enhances the neural (e.g., language [ 308]) model are in [ 309,310]. In reinforcement learning, very few examples of symbolic (graphical [ 311] or relational [ 75,312]) hybrid models exist, while in recommendation systems, for instance, explainable autoencoders are proposed [ 313]. A speci?c transformer architecture symbolic visualization method (applied to music) pictorially shows how soft-max attention works [ 314]. By visualizing self-reference, i.e., the last layer of attention weights, arcs show which notes in the past are informing the future and how attention is skip over less relevant sections. Transformers can also help explain image captions visually [315]. Another hybrid approach consists of mapping an uninterpretable black-box system to a white-box twin that is more interpretable. For example, an opaque neural network can be combined with a transparent Case Based Reasoning (CBR) system [ 316,317]. In [ 318], the DNN and the CBR (in this case a kNN) are paired in order to improve interpretability while keeping the same accuracy. The explanation by example consists of analyzing the feature weights of the DNN which are then used in the CBR, in order to retrieve nearest-neighbor cases to explain the DNNs prediction. 4.4. Alternative Taxonomy of Post-hoc Explainability Techniques for Deep Learning DL is the model family where most research has been concentrated in recent times and they have become central for most of the recent literature on XAI. While the division between model-agnostic and model-speci?c is the most common distinction made, the community has not only relied on this criteria to classify XAI methods. For instance, some model-agnostic methods such as SHAP [224] are widely used to explain DL models. That is why several XAI methods can be easily categorized in different taxonomy branches depending on the angle the method is looked at. An example is LIME which can also be used over CNNs, despite not being exclusive to deal with images. Searching within the alternative DL taxonomy shows us that LIME can explicitly be used for Explaining a Deep Network Processing , as a kind of Linear Proxy Model . Another type of classi?cation is indeed proposed in [ 13] with a segmentation based on 3 categories. The ?rst category groups methods explaining the processing of data by the network, thus answering to the question \u201cwhy does this particular input leads to this particular output?\u201d . The second one concerns methods explaining the representation of data inside the network, i.e., answering to the question \u201cwhat information does the network contain?\u201d . The third approach concerns 28models speci?cally designed to simplify the interpretation of their own behavior. Such a multiplicity of classi?cation possibilities leads to different ways of constructing XAI taxonomies. XAI in DLExplanation of Deep Network ProcessingLinear Proxy Models [32] Decision Trees [82, 257, 258, 259] Automatic-Rule Extraction [217, 251, 252, 253, 254, 255, 256, 319, 320, 321] Salience Mapping [96, 136, 261, 262, 272, 280, 322, 323] Explanation of Deep Network RepresentationRole of Layers [324, 325] Role of IndividualUnits [125, 326, 327, 328, 329] Role of RepresentationVectors [144] Explanation Producing SystemsAttention Networks [267, 278, 330, 331, 332, 333, 334] Representation Disentanglement [113, 279, 335, 336, 337, 338, 339, 340, 341, 342] Explanation Generation [276, 343, 344, 345] Hybrid Transparent and Black-box MethodsNeural-symbolic Systems [297, 298, 299, 300] KB-enhanced Systems [24, 169, 301, 308, 309, 310] Deep Formulation [264, 302, 303, 304, 305] Relational Reasoning [75, 312, 313, 314] Case-base Reasoning [316, 317, 318] Explanation of Deep Explanation Producing Learning Representation Explanation of Deep Network Processing Systems Simpli?cation Local Explanation Text Explanation Feature Relevance Architecture Modi?cation Visual explanation XAI in DL XAI in ML Hybrid Transparent and Black-box Methods Transparent Models (Fig. 11.a) (Fig. 6) Explanation by Example (a) (b) Figure 11: (a) Alternative Deep Learning speci?c taxonomy extended from the categorization from [ 13]; and (b) its connection to the taxonomy in Figure 6. Figure 11 shows the alternative Deep Learning taxonomy inferred from [ 13]. From the latter, it can be deduced the complementarity and overlapping of this taxonomy to Figure 6 as: \u2022Some methods [ 272,280] classi?ed in distinct categories (namely feature relevance for CNN and feature relevance for RNN ) in Figure 6 are included in a single category ( Explanation of Deep Network Processing with Salience Mapping ) when considering the classi?cation from [13]. \u2022Some methods [ 82,144] are classi?ed on a single category ( Explanation by simpli?cation for Multi- Layer Neural Network ) in Figure 6 while being in 2 different categories (namely, Explanation of Deep Network Processing with Decision Trees andExplanation of Deep Network Representation with the Role of Representation Vectors ) in [13], as shown in Figure 11. A classi?cation based on explanations of model processing and explanations of model representation is relevant, as it leads to a differentiation between the execution trace of the model and its internal data structure. This means that depending of the failure reasons of a complex model, it would be possible to pick-up the right XAI method according to the information needed: the execution trace or the data structure. This idea is analogous to testing and debugging methods used in regular programming paradigms [346]. 5. XAI: Opportunities, Challenges and Future Research Needs We now capitalize on the performed literature review to put forward a critique of the achievements, trends and challenges that are still to be addressed in the ?eld of explainability of ML and data fusion models. Actually our discussion on the advances taken so far in this ?eld has already anticipated some of these challenges. In this section we revisit them and explore new research opportunities for XAI, identifying possible research paths that can be followed to address them effectively in years to come: 29\u2022When introducing the overview in Section 1 we already mentioned the existence of a tradeoff between model interpretability and performance, in the sense that making a ML model more understandable could eventually degrade the quality of its produced decisions. In Subsection 5.1 we will stress on the potential of XAI developments to effectively achieve an optimal balance between the interpretability and performance of ML models. \u2022In Subsection 2.2 we stressed on the imperative need for reaching a consensus on what explainability entails within the AI realm. Reasons for pursuing explainability are also assorted and, under our own assessment of the literature so far, not unambiguously mentioned throughout related works. In Subsection 5.2 we will further delve into this important issue. \u2022Given its notable prevalence in the XAI literature, Subsections 4.3 and 4.4 revolved on the explainability of Deep Learning models, examining advances reported so far around a speci?c bibliographic taxonomy. We go in this same direction with Subsection 5.3, which exposes several challenges that hold in regards to the explainability of this family of models. \u2022Finally, we close up this prospective discussion with Subsections 5.4 to 5.8, which place on the table several research niches that despite its connection to model explainability, remain insuf?ciently studied by the community. Before delving into these identi?ed challenges, it is important to bear in mind that this prospective section is complemented by Section 6, which enumerates research needs and open questions related to XAI within a broader context: the need for responsible AI. 5.1. On the Tradeoff between Interpretability and Performance The matter of interpretability versus performance is one that repeats itself through time, but as any other big statement, has its surroundings ?lled with myths and misconceptions. As perfectly stated in [ 347], it is not necessarily true that models that are more complex are inherently more accurate. This statement is false in cases in which the data is well structured and features at our disposal are of great quality and value. This case is somewhat common in some industry environments, since features being analyzed are constrained within very controlled physical problems, in which all of the features are highly correlated, and not much of the possible landscape of values can be explored in the data [ 348]. What can be hold as true, is that more complex models enjoy much more ?exibility than their simpler counterparts, allowing for more complex functions to be approximated. Now, returning to the statement \u201cmodels that are more complex are more accurate\u201d , given the premise that the function to be approximated entails certain complexity, that the data available for study is greatly widespread among the world of suitable values for each variable and that there is enough data to harness a complex model, the statement presents itself as a true statement. It is in this situation that the trade-off between performance and interpretability can be observed. It should be noted that the attempt at solving problems that do not respect the aforementioned premises will fall on the trap of attempting to solve a problem that does not provide enough data diversity (variance). Hence, the added complexity of the model will only ?ght against the task of accurately solving the problem. In this path toward performance, when the performance comes hand in hand with complexity, in- terpretability encounters itself on a downwards slope that until now appeared unavoidable. However, the apparition of more sophisticated methods for explainability could invert or at least cancel that slope. Figure 12 shows a tentative representation inspired by previous works [ 7], in which XAI shows its power to improve the common trade-off between model interpretability and performance. Another aspect worth mentioning at this point due to its close link to model interpretability and performance is the approximation dilemma : explanations made for a ML model must be made drastic and approximate enough to match the requirements of the audience for which they are sought, ensuring that explanations are representative of the studied model and do not oversimplify its essential features. 30Model interpretability Model SVM Ensembles Bayesian Models Decision Trees Generalized Models Linear/Logistic kNN Additive Regression Rule-based learning Learning Deep Model accuracy Post-hoc explainability techniques Interpretability-driven model designs Hybrid modelling approaches New explainability-preserving modelling approaches Interpretable feature engineering XAI\u2019s future research arena Low High Low HighFigure 12: Trade-off between model interpretability and performance, and a representation of the area of improvement where the potential of XAI techniques and tools resides. 5.2. On the Concept and Metrics The literature clearly asks for an uni?ed concept of explainability. In order for the ?eld to thrive, it is imperative to place a common ground upon which the community is enabled to contribute new techniques and methods. A common concept must convey the needs expressed in the ?eld. It should propose a common structure for every XAI system. This paper attempted a new proposition of a concept of explainability that is built upon that from Gunning [ 7]. In that proposition and the following strokes to complete it (Subsection 2.2), explainability is de?ned as the ability a model has to make its functioning clearer to an audience. To address it, post-hoc type methods exist. The concept portrayed in this survey might not be complete but as it stands, allows for a ?rst common ground and reference point to sustain a pro?table discussion in this matter. It is paramount that the ?eld of XAI reaches an agreement in this respect combining the shattered efforts of a widespread ?eld behind the same banner. Another key feature needed to relate a certain model to this concrete concept is the existence of a metric. A metric, or group of them should allow for a meaningful comparison of how well a model ?ts the de?nition of explainable. Without such tool, any claim in this respect dilutes among the literature, not providing a solid ground on which to stand. These metrics, as the classic ones (accuracy, F1, sensitivity...), should express how well the model performs in a certain aspect of explainability. Some attempts have been done recently around the measurement of XAI, as reviewed thoroughly in [ 349,350]. In general, XAI measurements should evaluate the goodness, usefulness and satisfaction of explanations, the improvement of the mental model of the audience induced by model explanations, and the impact of explanations on the performance of the model and on the trust and reliance of the audience. Measurement techniques surveyed in [349] and [ 350] (e.g., goodness checklist, explanation satisfaction scale, elicitation methods for mental models, computational measures for explainer ?delity, explanation trustworthiness and model reliability) seem to be a good push in the direction of evaluating XAI techniques. Unfortunately, conclusions drawn from these overviews are aligned with our prospects on the ?eld: more quanti?able, general XAI metrics are really needed to support the existing measurement procedures and tools proposed by the community. This survey does not tackle the problem of designing such a suite of metrics, since such a task should be approached by the community as a whole prior acceptance of the broader concept of explainabil- ity, which on the other hand, is one of the aims of the current work. Nevertheless, we advocate for further efforts towards new proposals to evaluate the performance of XAI techniques, as well as compar- ison methodologies among XAI approaches that allow contrasting them quantitatively under different 31application context, models and purposes. 5.3. Challenges to achieve Explainable Deep Learning While many efforts are currently being made in the area of XAI, there are still many challenges to be faced before being able to obtain explainability in DL models. First, as explained in Subsection 2.2, there is a lack of agreement on the vocabulary and the different de?nitions surrounding XAI. As an example, we often see the terms feature importance andfeature relevance referring to the same concept. This is even more obvious for visualization methods, where there is absolutely no consistency behind what is known as saliency maps, salient masks, heatmaps, neuron activations, attribution, and other approaches alike. As XAI is a relatively young ?eld, the community does not have a standardized terminology yet. As it has been commented in Subsection 5.1, there is a trade-off between interpretability and accuracy [13], i.e., between the simplicity of the information given by the system on its internal functioning, and the exhaustiveness of this description. Whether the observer is an expert in the ?eld, a policy-maker or a user without machine learning knowledge, intelligibility does not have to be at the same level in order to provide the audience an understanding [ 6]. This is one of the reasons why, as mentioned above, a challenge in XAI is establishing objective metrics on what constitutes a good explanation. A possibility to reduce this subjectivity is taking inspiration from experiments on human psychology, sociology or cognitive sciences to create objectively convincing explanations. Relevant ?ndings to be considered when creating an explainable AI model are highlighted in [ 12]: First, explanations are better when constrictive , meaning that a prerequisite for a good explanation is that it does not only indicate why the model made a decision X, but also why it made decision X rather than decision Y . It is also explained that probabilities are not as important as causal links in order to provide a satisfying explanation. Considering that black box models tend to process data in a quantitative manner, it would be necessary to translate the probabilistic results into qualitative notions containing causal links. In addition, they state that explanations are selective , meaning that focusing solely on the main causes of a decision-making process is suf?cient. It was also shown that the use of counterfactual explanations can help the user to understand the decision of a model [40, 42, 351]. Combining connectionist and symbolic paradigms seems a favourable way to address this challenge [169,299,312,352,353]. On one hand, connectionist methods are more precise but opaque. On the other hand, symbolic methods are popularly considered less ef?cient, while they offer a greater explainability thus respecting the conditions mentioned above: \u2022The ability to refer to established reasoning rules allows symbolic methods to be constrictive. \u2022The use of a KB formalized e.g. by an ontology can allow data to be processed directly in a qualitative way. \u2022Being selective is less straightforward for connectionist models than for symbolic ones. Recalling that a good explanation needs to in?uence the mental model of the user, i.e. the repre- sentation of the external reality using, among other things, symbols, it seems obvious that the use of the symbolic learning paradigm is appropriate to produce an explanation. Therefore, neural-symbolic interpretability could provide convincing explanations while keeping or improving generic performance [297]. As stated in [ 24], a truly explainable model should not leave explanation generation to the users as different explanations may be deduced depending on their background knowledge. Having a semantic representation of the knowledge can help a model to have the ability to produce explanations (e.g., in natural language [169]) combining common sense reasoning and human-understandable features. Furthermore, until an objective metric has been adopted, it appears necessary to make an effort to rigorously formalize evaluation methods. One way may be drawing inspiration from the social sciences, e.g., by being consistent when choosing the evaluation questions and the population sample used [354]. 32A ?nal challenge XAI methods for DL need to address is providing explanations that are accessible for society, policy makers and the law as a whole. In particular, conveying explanations that require non-technical expertise will be paramount to both handle ambiguities, and to develop the social right to the (not-yet available) right for explanation in the EU General Data Protection Regulation (GDPR) [ 355]. 5.4. Explanations for AI Security: XAI and Adversarial Machine Learning Nothing has been said about con?dentiality concerns linked to XAI. One of the last surveys very brie?y introduced the idea of algorithm property and trade secrets [ 14]. However, not much attention has been payed to these concepts. If con?dential is the property that makes something secret , in the AI context many aspects involved in a model may hold this property. For example, imagine a model that some company has developed through many years of research in a speci?c ?eld. The knowledge synthesized in the model built might be considered to be con?dential, and it may be compromised even by providing only input and output access [ 356]. The latter shows that, under minimal assumptions, data model functionality stealing is possible. An approach that has served to make DL models more robust against intellectual property exposure based on a sequence of non accessible queries is in [ 357]. This recent work exposes the need for further research toward the development of XAI tools capable of explaining ML models while keeping the model\u2019s con?dentiality in mind. Ideally, XAI should be able to explain the knowledge within an AI model and it should be able to reason about what the model acts upon. However, the information revealed by XAI techniques can be used both to generate more effective attacks in adversarial contexts aimed at confusing the model, at the same time as to develop techniques to better protect against private content exposure by using such information. Adversarial attacks [ 358] try to manipulate a ML algorithm after learning what is the speci?c information that should be fed to the system so as to lead it to a speci?c output. For instance, regarding a supervised ML classi?cation model, adversarial attacks try to discover the minimum changes that should be applied to the input data in order to cause a different classi?cation. This has happened regarding computer vision systems of autonomous vehicles; a minimal change in a stop signal, imperceptible to the human eye, led vehicles to detect it as a 45 mph signal [ 359]. For the particular case of DL models, available solutions such as Cleverhans [ 360] seek to detect adversarial vulnerabilities, and provide different approaches to harden the model against them. Other examples include AlfaSVMLib [ 361] for SVM models, and AdversarialLib [ 362] for evasion attacks. There are even available solutions for unsupervised ML, like clustering algorithms [363]. While XAI techniques can be used to furnish more effective adversarial attacks or to reveal con?dential aspects of the model itself, some recent contributions have capitalized on the possibilities of Generative Adversarial Networks (GANs [ 364]), Variational Autoencoders [ 365] and other generative models towards explaining data-based decisions. Once trained, generative models can generate instances of what they have learned based on a noise input vector that can be interpreted as a latent representation of the data at hand. By manipulating this latent representation and examining its impact on the output of the generative model, it is possible to draw insights and discover speci?c patterns related to the class to be predicted. This generative framework has been adopted by several recent studies [ 366,367] mainly as an attribution method to relate a particular output of a Deep Learning model to their input variables. Another interesting research direction is the use of generative models for the creation of counterfactuals, i.e., modi?cations to the input data that could eventually alter the original prediction of the model [ 368]. Counterfactual prototypes help the user understand the performance boundaries of the model under consideration for his/her improved trust and informed criticism. In light of this recent trend, we de?nitely believe that there is road ahead for generative ML models to take their part in scenarios demanding understandable machine decisions. 5.5. XAI and Output Con?dence Safety issues have also been studied in regards to processes that depend on the output of AI models, such as vehicular perception and self-driving in autonomous vehicles, automated surgery, data-based 33support for medical diagnosis, insurance risk assessment and cyber-physical systems in manufacturing, among others [ 369]. In all these scenarios erroneous model outputs can lead to harmful consequences, which has yielded comprehensive regulatory efforts aimed at ensuring that no decision is made solely on the basis of data processing [3]. In parallel, research has been conducted towards minimizing both risk and uncertainty of harms derived from decisions made on the output of a ML model. As a result, many techniques have been reported to reduce such a risk, among which we pause at the evaluation of the model\u2019s output con?dence to decide upon. In this case, the inspection of the share of epistemic uncertainty (namely, the uncertainty due to lack of knowledge) of the input data and its correspondence with the model\u2019s output con?dence can inform the user and eventually trigger his/her rejection of the model\u2019s output [ 370,371]. To this end, explaining via XAI techniques which region of the input data the model is focused on when producing a given output can discriminate possible sources of epistemic uncertainty within the input domain. 5.6. XAI, Rationale Explanation, and Critical Data Studies When shifting the focus to the research practices seen in Data Science, it has been noted that reproducibility is stringently subject not only to the mere sharing of data, models and results to the community, but also to the availability of information about the full discourse around data collection, understanding, assumptions held and insights drawn from model construction and results\u2019 analyses [ 372]. In other words, in order to transform data into a valuable actionable asset, individuals must engage in collaborative sense-making by sharing the context producing their ?ndings, wherein context refers to sets of narrative stories around how data were processed, cleaned, modeled and analyzed. In this discourse we ?nd also an interesting space for the adoption of XAI techniques due to their powerful ability to describe black-box models in an understandable, hence conveyable fashion towards colleagues from Social Science, Politics, Humanities and Legal ?elds. XAI can effectively ease the process of explaining the reasons why a model reached a decision in an accessible way to non-expert users, i.e. the rationale explanation . This con?uence of multi-disciplinary teams in projects related to Data Science and the search for methodologies to make them appraise the ethical implications of their data-based choices has been lately coined as Critical Data studies [ 373]. It is in this ?eld where XAI can signi?cantly boost the exchange of information among heterogeneous audiences about the knowledge learned by models. 5.7. XAI and Theory-guided Data Science We envision an exciting synergy between the XAI realm and Theory-guided Data Science , a paradigm exposed in [ 374] that merges both Data Science and the classic theoretical principles underlying the application/context where data are produced. The rationale behind this rising paradigm is the need for data- based models to generate knowledge that is the prior knowledge brought by the ?eld in which it operates. This means that the model type should be chosen according to the type of relations we intend to encounter. The structure should also follow what is previously known. Similarly, the training approach should not allow for the optimization process to enter regions that are not plausible. Accordingly, regularization terms should stand the prior premises of the ?eld, avoiding the elimination of badly represented true relations for spurious and deceptive false relations. Finally, the output of the model should inform about everything the model has come to learn, allowing to reason and merge the new knowledge with what was already known in the ?eld. Many examples of the implementation of this approach are currently available with promising results. The studies in [ 375]-[382] were carried out in diverse ?elds, showcasing the potential of this new paradigm for data science. Above all, it is relevant to notice the resemblance that all concepts and requirements of Theory-guided Data Science share with XAI. All the additions presented in [ 374] push toward techniques that would eventually render a model explainable, and furthermore, knowledge consistent. The concept ofknowledge from the beginning , central to Theory-guided Data Science, must also consider how 34the knowledge captured by a model should be explained for assessing its compliance with theoretical principles known beforehand. This, again, opens a magni?cent window of opportunity for XAI. 5.8. Guidelines for ensuring Interpretable AI Models Recent surveys have emphasized on the multidisciplinary, inclusive nature of the process of making an AI-based model interpretable. Along this process, it is of utmost importance to scrutinize and take into proper account the interests, demands and requirements of all stakeholders interacting with the system to be explained, from the designers of the system to the decision makers consuming its produced outputs and users undergoing the consequences of decisions made therefrom. Given the con?uence of multiple criteria and the need for having the human in the loop, some attempts at establishing the procedural guidelines to implement and explain AI systems have been recently contributed. Among them, we pause at the thorough study in [ 383], which suggests that the incorporation and consideration of explainability in practical AI design and deployment work?ows should comprise four major methodological steps: 1.Contextual factors, potential impacts and domain-speci?c needs must be taken into account when devising an approach to interpretability: These include a thorough understanding of the purpose for which the AI model is built, the complexity of explanations that are required by the audience, and the performance and interpretability levels of existing technology, models and methods. The latter pose a reference point for the AI system to be deployed in lieu thereof. 2.Interpretable techniques should be preferred when possible: when considering explainability in the development of an AI system, the decision of which XAI approach should be chosen should gauge domain-speci?c risks and needs, the available data resources and existing domain knowledge, and the suitability of the ML model to meet the requirements of the computational task to be addressed. It is in the con?uence of these three design drivers where the guidelines postulated in [ 383] (and other studies in this same line of thinking [ 384]) recommend ?rst the consideration of standard interpretable models rather than sophisticated yet opaque modeling methods. In practice, the aforementioned aspects (contextual factors, impacts and domain-speci?c needs) can make transparent models preferable over complex modeling alternatives whose interpretability require the application of post-hoc XAI techniques. By contrast, black-box models such as those reviewed in this work (namely, support vector machines, ensemble methods and neural networks) should be selected only when their superior modeling capabilities ?t best the characteristics of the problem at hand. 3.If a black-box model has been chosen, the third guideline establishes that ethics-, fairness- and safety- related impacts should be weighed. Speci?cally, responsibility in the design and implementation of the AI system should be ensured by checking whether such identi?ed impacts can be mitigated and counteracted by supplementing the system with XAI tools that provide the level of explainability required by the domain in which it is deployed. To this end, the third guideline suggests 1) a detailed articulation, examination and evaluation of the applicable explanatory strategies, 2) the analysis of whether the coverage and scope of the available explanatory approaches match the requirements of the domain and application context where the model is to be deployed; and 3) the formulation of an interpretability action plan that sets forth the explanation delivery strategy, including a detailed time frame for the execution of the plan, and a clearance of the roles and responsibilities of the team involved in the work?ow. 4.Finally, the fourth guideline encourages to rethink interpretability in terms of the cognitive skills, capacities and limitations of the individual human. This is an important question on which studies on measures of explainability are intensively revolving by considering human mental models, the accessibility of the audience to vocabularies of explanatory outcomes, and other means to involve the expertise of the audience into the decision of what explanations should provide. 35We foresee that the set of guidelines proposed in [ 383] and summarized above will be complemented and enriched further by future methodological studies, ultimately heading to a more responsible use of AI. Methodological principles ensure that the purpose for which explainability is pursued is met by bringing the manifold of requirements of all participants into the process, along with other universal aspects of equal relevance such as no discrimination, sustainability, privacy or accountability. A challenge remains in harnessing the potential of XAI to realize a Responsible AI , as we discuss in the next section. 6. Toward Responsible AI: Principles of Arti?cial Intelligence, Fairness, Privacy and Data Fusion Over the years many organizations, both private and public, have published guidelines to indicate how AI should be developed and used. These guidelines are commonly referred to as AI principles , and they tackle issues related to potential AI threats to both individuals and to the society as a whole. This section presents some of the most important and widely recognized principles in order to link XAI \u2013 which normally appears inside its own principle \u2013 to all of them. Should a responsible implementation and use of AI models be sought in practice, it is our ?rm claim that XAI does not suf?ce on its own. Other important principles of Arti?cial Intelligence such as privacy and fairness must be carefully addressed in practice. In the following sections we elaborate on the concept of Responsible AI, along with the implications of XAI and data fusion in the ful?llment of its postulated principles. 6.1. Principles of Arti?cial Intelligence A recent review of some of the main AI principles published since 2016 appears in [ 385]. In this work, the authors show a visual framework where different organizations are classi?ed according to the following parameters: \u2022Nature, which could be private sector, government, inter-governmental organization, civil society or multistakeholder. \u2022Content of the principles: eight possible principles such as privacy, explainability, or fairness. They also consider the coverage that the document grants for each of the considered principles. \u2022Target audience: to whom the principles are aimed. They are normally for the organization that developed them, but they could also be destined for another audience (see Figure 2). \u2022Whether or not they are rooted on the International Human Rights, as well as whether they explicitly talk about them. For instance, [ 386] is an illustrative example of a document of AI principles for the purpose of this overview, since it accounts for some of the most common principles, and deals explicitly with explainability. Here, the authors propose ?ve principles mainly to guide the development of AI within their company, while also indicating that they could also be used within other organizations and businesses. The authors of those principles aim to develop AI in a way that it directly reinforces inclusion, gives equal opportunities for everyone, and contributes to the common good. To this end, the following aspects should be considered: \u2022The outputs after using AI systems should not lead to any kind of discrimination against individuals or collectives in relation to race, religion, gender, sexual orientation, disability, ethnic, origin or any other personal condition. Thus, a fundamental criteria to consider while optimizing the results of an AI system is not only their outputs in terms of error optimization, but also how the system deals with those groups. This de?nes the principle of Fair AI . 36\u2022People should always know when they are communicating with a person, and when they are commu- nicating with an AI system. People should also be aware if their personal information is being used by the AI system and for what purpose. It is crucial to ensure a certain level of understanding about the decisions taken by an AI system. This can be achieved through the usage of XAI techniques. It is important that the generated explanations consider the pro?le of the user that will receive those explanations (the so-called audience as per the de?nition given in Subsection 2.2) in order to adjust the transparency level, as indicated in [45]. This de?nes the principle of Transparent and Explainable AI . \u2022AI products and services should always be aligned with the United Nation\u2019s Sustainable Development Goals [ 387] and contribute to them in a positive and tangible way. Thus, AI should always generate a bene?t for humanity and the common good. This de?nes the principle of Human-centric AI (also referred to as AI for Social Good [388]). \u2022AI systems, specially when they are fed by data, should always consider privacy and security standards during all of its life cycle. This principle is not exclusive of AI systems since it is shared with many other software products. Thus, it can be inherited from processes that already exist within a company. This de?nes the principle of Privacy and Security by Design , which was also identi?ed as one of the core ethical and societal challenges faced by Smart Information Systems under the Responsible Research and Innovation paradigm (RRI, [ 389]). RRI refers to a package of methodological guidelines and recommendations aimed at considering a wider context for scienti?c research, from the perspective of the lab to global societal challenges such as sustainability, public engagement, ethics, science education, gender equality, open access, and governance. Interestingly, RRI also requires openness and transparency to be ensured in projects embracing its principles, which links directly to the principle of Transparent and Explainable AI mentioned previously. \u2022The authors emphasize that all these principles should always be extended to any third-party (providers, consultants, partners...). Going beyond the scope of these ?ve AI principles, the European Commission (EC) has recently published ethical guidelines for Trustworthy AI [ 390] through an assessment checklist that can be completed by different pro?les related to AI systems (namely, product managers, developers and other roles). The assessment is based in a series of principles: 1) human agency and oversight; 2) technical robustness and safety; 3) privacy and data governance; 4) transparency, diversity, non-discrimination and fairness; 5) societal and environmental well-being; 6) accountability. These principles are aligned with the ones detailed in this section, though the scope for the EC principles is more general, including any type of organization involved in the development of AI. It is worth mentioning that most of these AI principles guides directly approach XAI as a key aspect to consider and include in AI systems. In fact, the overview for these principles introduced before [ 385], indicates that 28 out of the 32 AI principles guides covered in the analysis, explicitly include XAI as a crucial component. Thus, the work and scope of this article deals directly with one of the most important aspects regarding AI at a worldwide level. 6.2. Fairness and Accountability As mentioned in the previous section, there are many critical aspects, beyond XAI, included within the different AI principles guidelines published during the last decade. However, those aspects are not completely detached from XAI; in fact, they are intertwined. This section presents two key components with a huge relevance within the AI principles guides, Fairness and Accountability. It also highlights how they are connected to XAI. 376.2.1. Fairness and Discrimination It is in the identi?cation of implicit correlations between protected and unprotected features where XAI techniques ?nd their place within discrimination-aware data mining methods. By analyzing how the output of the model behaves with respect to the input feature, the model designer may unveil hidden correlations between the input variables amenable to cause discrimination. XAI techniques such as SHAP [224] could be used to generate counterfactual outcomes explaining the decisions of a ML model when fed with protected and unprotected variables. Recalling the Fair AI principle introduced in the previous section, [ 386] reminds that fairness is a discipline that generally includes proposals for bias detection within datasets regarding sensitive data that affect protected groups (through variables like gender, race...). Indeed, ethical concerns with black-box models arise from their tendency to unintentionally create unfair decisions by considering sensitive factors such as the individual\u2019s race, age or gender [ 391]. Unfortunately, such unfair decisions can give rise to discriminatory issues, either by explicitly considering sensitive attributes or implicitly by using factors that correlate with sensitive data. In fact, an attribute may implicitly encode a protected factor, as occurs with postal code in credit rating [ 392]. The aforementioned proposals centered on fairness aspects permit to discover correlations between non-sensitive variables and sensitive ones, detect imbalanced outcomes from the algorithms that penalize a speci?c subgroup of people ( discrimination ), and mitigate the effect of bias on the model\u2019s decisions. These approaches can deal with: \u2022Individual fairness: here, fairness is analyzed by modeling the differences between each subject and the rest of the population. \u2022Group fairness: it deals with fairness from the perspective of all individuals. \u2022Counterfactual fairness: it tries to interpret the causes of bias using, for example, causal graphs. The sources for bias, as indicated in [392], can be traced to: \u2022Skewed data: bias within the data acquisition process. \u2022Tainted data: errors in the data modelling de?nition, wrong feature labelling, and other possible causes. \u2022Limited features: using too few features could lead to an inference of false feature relationships that can lead to bias. \u2022Sample size disparities: when using sensitive features, disparities between different subgroups can induce bias. \u2022Proxy features: there may be correlated features with sensitive ones that can induce bias even when the sensitive features are not present in the dataset. The next question that can be asked is what criteria could be used to de?ne when AI is not biased. For supervised ML, [ 393] presents a framework that uses three criteria to evaluate group fairness when there is a sensitive feature present within the dataset: \u2022Independence: this criterion is ful?lled when the model predictions are independent of the sensitive feature. Thus, the proportion of positive samples (namely, those ones belonging to the class of interest) given by the model is the same for all the subgroups within the sensitive feature. \u2022Separation: it is met when the model predictions are independent of the sensitive feature given the target variable. For instance, in classi?cation models, the True Positive (TP) rate and the False Positive (FP) rate are the same in all the subgroups within the sensitive feature. This criteria is also known as Equalized Odds . 38\u2022Suf?ciency: it is accomplished when the target variable is independent of the sensitive feature given the model output. Thus, the Positive Predictive Value is the same for all subgroups within the sensitive feature. This criteria is also known as Predictive Rate Parity. Although not all of the criteria can be ful?lled at the same time, they can be optimized together in order to minimize the bias within the ML model. There are two possible actions that could be used in order to achieve those criteria. On one hand, evaluation includes measuring the amount of bias present within the model (regarding one of the criteria aforementioned). There are many different metrics that can be used, depending on the criteria considered. Regarding independence criterion, possible metrics are statistical parity difference ordisparate impact . In case of the separation criterion, possible metrics are equal opportunity difference andaverage odds difference [393]. Another possible metric is the Theil index [394], which measures inequality both in terms of individual and group fairness. On the other hand, mitigation refers to the process of ?xing some aspects in the model in order to remove the effect of the bias in terms of one or several sensitive features. Several techniques exist within the literature, classi?ed in the following categories: \u2022Pre-processing: these groups of techniques are applied before the ML model is trained, looking to remove the bias at the ?rst step of the learning process. An example is Reweighing [ 395], which modi?es the weights of the features in order to remove discrimination in sensitive attributes. Another example is [ 396], which hinges on transforming the input data in order to ?nd a good representation that obfuscates information about membership in sensitive features. \u2022In-processing: these techniques are applied during the training process of the ML model. Normally, they include Fairness optimization constraints along with cost functions of the ML model. An example is Adversarial Debiasing, [ 397]. This technique optimizes jointly the ability of predicting the target variable while minimizing the ability of predicting sensitive features using a GAN. \u2022Post-processing: these techniques are applied after the ML model is trained. They are less intrusive because they do not modify the input data or the ML model. An example is Equalized Odds [ 393]. This techniques allows to adjust the thresholds in the classi?cation model in order to reduce the differences between the TP rate and the FP rate for each sensitive subgroup. Even though these references apparently address an AI principle that appears to be independent of XAI, the literature shows that they are intertwined. For instance, the survey in [ 385] evinces that 26 out of the 28 AI principles that deal with XAI, also talk about fairness explicitly. This fact elucidates that organizations usually consider both aspects together when implementing Responsible AI. The literature also exploses that XAI proposals can be used for bias detection. For example, [ 398] proposes a framework to visually analyze the bias present in a model (both for individual and group fairness). Thus, the fairness report is shown just like the visual summaries used within XAI. This explainability approach eases the understanding and measurement of bias. The system must report that there is bias, justify it quantitatively, indicate the degree of fairness, and explain why a user or group would be treated unfairly with the available data. Similarly, XAI techniques such as SHAP [ 224] could be used to generate counterfactual outcomes explaining the decisions of a ML model when fed with protected and unprotected variables. By identifying implicit correlations between protected and unprotected features through XAI techniques, the model designer may unveil hidden correlations between the input variables amenable to cause discrimination. Another example is [ 399], where the authors propose a fair-by-design approach in order to develop ML models that jointly have less bias and include as explanations human comprehensible rules. The proposal is based in self-learning locally generative models that use only a small part of the whole dataset available (weak supervision). It ?rst ?nds recursively relevant prototypes within the dataset, and 39extracts the empirical distribution and density of the points around them. Then it generates rules in an IF/THEN format that explain that a data point is classi?ed within a speci?c category because it is similar to some prototypes. The proposal then includes an algorithm that both generates explanations and reduces bias, as it is demonstrated for the use case of recidivism using the Correctional Offender Management Pro?ling for Alternative Sanctions (COMPAS) dataset [ 400]. The same goal has been recently pursued in [401], showing that post-hoc XAI techniques can forge fairer explanations from truly unfair black-box models. Finally, CERTIFAI (Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Arti?cial Intelligence models) [ 402] uses a customized genetic algorithm to generate counterfactuals that can help to see the robustness of a ML model, generate explanations, and examine fairness (both at the individual level and at the group level) at the same time. Strongly linked to the concept of fairness, much attention has been lately devoted to the concept of data diversity , which essentially refers to the capability of an algorithmic model to ensure that all different types of objects are represented in its output [ 403]. Therefore, diversity can be thought to be an indicator of the quality of a collection of items that, when taking the form of a model\u2019s output, can quantify the proneness of the model to produce diverse results rather than highly accurate predictions. Diversity comes into play in human-centered applications with ethical restrictions that permeate to the AI modeling phase [404]. Likewise, certain AI problems (such as content recommendation or information retrieval) also aim at producing diverse recommendations rather than highly-scoring yet similar results [ 405,406]. In these scenarios, dissecting the internals of a black-box model via XAI techniques can help identifying the capability of the model to maintain the input data diversity at its output. Learning strategies to endow a model with diversity keeping capabilities could be complemented with XAI techniques in order to shed transparency over the model internals, and assess the effectiveness of such strategies with respect to the diversity of the data from which the model was trained. Conversely, XAI could help to discriminate which parts of the model are compromising its overall ability to preserve diversity. 6.2.2. Accountability Regarding accountability, the EC [390] de?nes the following aspects to consider: \u2022Auditability: it includes the assessment of algorithms, data and design processes, but preserving the intellectual property related to the AI systems. Performing the assessment by both internal and external auditors, and making the reports available, could contribute to the trustworthiness of the technology. When the AI system affects fundamental rights, including safety-critical applications, it should always be audited by an external third party. \u2022Minimization and reporting of negative impacts: it consists of reporting actions or decisions that yield a certain outcome by the system. It also comprises the assessment of those outcomes and how to respond to them. To address that, the development of AI systems should also consider the identi?cation, assessment, documentation and minimization of their potential negative impacts. In order to minimize the potential negative impact, impact assessments should be carried out both prior to and during the development, deployment and use of AI systems. It is also important to guarantee protection for anyone who raises concerns about an AI system (e.g., whistle-blowers ). All assessments must be proportionate to the risk that the AI systems pose. \u2022Trade-offs: in case any tension arises due to the implementation of the above requirements, trade-offs could be considered but only if they are ethically acceptable. Such trade-offs should be reasoned, explicitly acknowledged and documented, and they must be evaluated in terms of their risk to ethical principles. The decision maker must be accountable for the manner in which the appropriate trade-off is being made, and the trade-off decided should be continually reviewed to ensure the appropriateness of the decision. If there is no ethically acceptable trade-off, the development, deployment and use of the AI system should not proceed in that form. 40\u2022Redress: it includes mechanisms that ensure an adequate redress for situations when unforeseen unjust adverse impacts take place. Guaranteeing a redress for those non-predicted scenarios is a key to ensure trust. Special attention should be paid to vulnerable persons or groups. These aspects addressed by the EC highlight different connections of XAI with accountability. First, XAI contributes to auditability as it can help explaining AI systems for different pro?les, including regulatory ones. Also, since there is a connection between fairness and XAI as stated before, XAI can also contribute to the minimization and report of negative impacts. 6.3. Privacy and Data Fusion The ever-growing number of information sources that nowadays coexist in almost all domains of activity calls for data fusion approaches aimed at exploiting them simultaneously toward solving a learning task. By merging heterogeneous information, data fusion has been proven to improve the performance of ML models in many applications, such as industrial prognosis [ 348], cyber-physical social systems [ 407] or the Internet of Things [ 408], among others. This section speculates with the potential of data fusion techniques to enrich the explainability of ML models, and to compromise the privacy of the data from which ML models are learned. To this end, we brie?y overview different data fusion paradigms, and later analyze them from the perspective of data privacy. As we will later, despite its relevance in the context of Responsible AI, the con?uence between XAI and data fusion is an uncharted research area in the current research mainstream. 6.3.1. Basic Levels of Data Fusion We depart from the different levels of data fusion that have been identi?ed in comprehensive surveys on the matter [ 409,410,411,412]. In the context of this subsection, we will distinguish among fusion at data level, fusion at model level and fusion at knowledge level. Furthermore, a parallel categorization can be established depending on where such data is processed and fused, yielding centralized and distributed methods for data fusion. In a centralized approach, nodes deliver their locally captured data to a centralized processing system to merge them together. In contrast, in a distributed approach, each of the nodes merges its locally captured information, eventually sharing the result of the local fusion with its counterparts. Fusion through the information generation process has properties and peculiarities depending on the level at which the fusion is performed. At the so-called data level , fusion deals with raw data. As schematically shown in Figure 13, a fusion model at this stage receives raw data from different information sources, and combines them to create a more coherent, compliant, robust or simply representative data ?ow. On the other hand, fusion at the model level aggregates models, each learned from a subset of the data sets that were to be fused. Finally, at the knowledge level the fusion approach deals with knowledge in the form of rules, ontologies or other knowledge representation techniques with the intention of merging them to create new, better or more complete knowledge from what was originally provided. Structured knowledge information is extracted from each data source and for every item in the data set using multiple knowledge extractors (e.g. a reasoning engine operating on an open semantic database). All produced information is then fused to further ensure the quality, correctness and manageability of the produced knowledge about the items in the data set. Other data fusion approaches exist beyonds the ones represented in Figure 13. As such, data-level fusion can be performed either by a technique speci?cally devoted to this end (as depicted in Figure 13.b) or, instead, performed along the learning process of the ML model (as done in e.g. DL models). Similarly, model-level data fusion can be made by combining the decisions of different models (as done in tree ensembles). 6.3.2. Emerging Data Fusion Approaches In the next subsection we examine other data fusion approaches that have recently come into scene due to their implications in terms of data privacy: 41D1 D2 DN ... D1 D2 DN ... (d) (e) (f) ... ... W1 Split W2 W3 WN Map Reduce R ~ML ML1 ML2 MLN ... Aggregation Secure Client-server delivery : encrypted model : model update information (e.g. Server side Remote clients gradients) Wn:n-th worker node R: reducer node ... D1 D2 DN ... MLN ... View 1 View 2 View 3 View V ... ML1 ML2 ML3 MLV ... Joint optimization + Fusion D1 D2 DN DF D1 D2 DN ML ML ML ML Data Fusion technique Model Fusion ... ... ... D1 D2 DN ... Knowledge extractor Knowledge extractor Knowledge extractor Knowledge Fusion KB ... ML KB Di DF ... (a) (b) (c) : Predictions : Knowledge Base : Fused data :i-th datasetFigure 13: Diagrams showing different levels at which data fusion can be performed: (a) data level; (b) model level; (c) knowledge level; (d) Big Data fusion; (e) Federated Learning and (f) Multiview Learning. \u2022In Big Data fusion (Figure 13.d), local models are learned on a split of the original data sources, each submitted to a Worker node in charge of performing this learning process ( Map task). Then, a Reduce node (or several Reduce nodes, depending on the application) combines the outputs produced by each Map task. Therefore, Big Data fusion can be conceived as a means to distribute the complexity of learn- ing a ML model over a pool of Worker nodes, wherein the strategy to design how information/models are fused together between the Map and the Reduce tasks is what de?nes the quality of the ?nally generated outcome [413]. \u2022By contrast, in Federated Learning [ 414,415,416], the computation of ML models is made on data captured locally by remote client devices (Figure 13.e). Upon local model training, clients transmit encrypted information about their learned knowledge to a central server, which can take the form of layer-wise gradients (in the case of neural ML models) or any other model-dependent content alike. The central server aggregates (fuses) the knowledge contributions received from all clients to yield a shared model harnessing the collected information from the pool of clients. It is important to observe that no client data is delivered to the central server, which elicits the privacy-preserving nature of Federated Learning. Furthermore, computation is set closer to the collected data, which reduces the processing latency and alleviates the computational burden of the central server. \u2022Finally, Multiview Learning [ 417] constructs different views of the object as per the information contained in the different data sources (Figure 13.f). These views can be produced from multiple sources of information and/or different feature subsets [ 418]. Multiview Learning devises strategies to jointly optimize ML models learned from the aforementioned views to enhance the generalization performance, specially in those applications with weak data supervision and hence, prone to model over?tting. This joint optimization resorts to different algorithmic means, from co-training to co- regularization [419]. 6.3.3. Opportunities and Challenges in Privacy and Data Fusion under the Responsible AI Paradigm AI systems, specially when dealing with multiple data sources, need to explicitly include privacy considerations during the system\u2019s life cycle. This is specially critical when working with personal data, 42because respecting people\u2019s right to privacy should always be addressed. The EC highlights that privacy should also address data governance, covering the quality and integrity of the used data [ 390]. It should also include the de?nition of access protocols and the capability to process data in a way that ensures privacy. The EC guide breaks down the privacy principle into three aspects: \u2022Privacy and data protection: they should be guaranteed in AI systems throughout its entire lifecycle. It includes both information provided by users and information generated about those users derived from their interactions with the system. Since digital information about a user could be used in a negative way against them (discrimination due to sensitive features, unfair treatment...), it is crucial to ensure proper usage of all the data collected. \u2022Quality and integrity of data: quality of data sets is fundamental to reach good performance with AI systems that are fueled with data, like ML. However, sometimes the data collected contains socially constructed biases, inaccuracies, errors and mistakes. This should be tackled before training any model with the data collected. Additionally, the integrity of the data sets should be ensured. \u2022Access to data: if there is individual personal data, there should always be data protocols for data governance. These protocols should indicate who may access data and under which circumstances. The aforementioned examples from the EC shows how data fusion is directly intertwined with privacy and with fairness, regardless of the technique employed for it. Notwithstanding this explicit concern from regulatory bodies, loss of privacy has been compromised by DL methods in scenarios where no data fusion is performed. For instance, a few images are enough to threaten users\u2019 privacy even in the presence of image obfuscation [ 420], and the model parameters of a DNN can be exposed by simply performing input queries on the model [ 356,357]. An approach to explain loss of privacy is by using privacy loss andintent loss subjective scores. The former provides a subjective measure of the severity of the privacy violation depending on the role of a face in the image, while the latter captures the intent of the bystanders to appear in the picture. These kind of explanations have motivated, for instance, secure matching cryptographic protocols for photographer and bystanders to preserve privacy [ 356,421,422]. We de?nite advocate for more efforts invested in this direction, namely, in ensuring that XAI methods do not pose a threat in regards to the privacy of the data used for training the ML model under target. When data fusion enters the picture, different implications arise with the context of explainability covered in this survey. To begin with, classical techniques for fusion at the data level only deal with data and have no connection to the ML model, so they have little to do with explainability. However, the advent of DL models has blurred the distinction between information fusion and predictive modeling. The ?rst layers of DL architectures are in charge of learning high-level features from raw data that possess relevance for the task at hand. This learning process can be thought to aim at solving a data level fusion problem, yet in a directed learning fashion that makes the fusion process tightly coupled to the task to be solved. In this context, many techniques in the ?eld of XAI have been proposed to deal with the analysis of correlation between features. This paves the way to explaining how data sources are actually fused through the DL model, which can yield interesting insights on how the predictive task at hand induces correlations among the data sources over the spatial and/or time domain. Ultimately, this gained information on the fusion could not only improve the usability of the model as a result of its enhanced understanding by the user, but could also help identifying other data sources of potential interest that could be incorporated to the model, or even contribute to a more ef?cient data fusion in other contexts. Unfortunately, this previously mentioned concept of fusion at data level contemplates data under certain constraints of known form and source origin. As presented in [ 423], the Big Data era presents an environment in which these premises cannot be taken for granted, and methods to board Big Data fusion (as that illustrated in Figure 13.d) have to be thought. Conversely, a concern with model fusion 43context emerges in the possibility that XAI techniques could be explanatory enough to compromise the con?dentiality of private data. This could eventually occur if sensitive information (e.g. ownership) could be inferred from the explained fusion among protected and unprotected features. When turning our prospects to data fusion at model level, we have already argued that the fusion of the outputs of several transparent models (as in tree ensembles) could make the overall model opaque, thereby making it necessary to resort to post-hoc explainability solutions. However, model fusion may entail other drawbacks when endowed with powerful post-hoc XAI techniques. Let us imagine that relationships of a model\u2019s input features have been discovered by means of a post-hoc technique) and that one of those features is hidden or unknown. Will it be possible to infer another model\u2019s features if that previous feature was known to be used in that model? Would this possibility uncover a problem as privacy breaches in cases in which related protected input variables are not even shared in the ?rst place? To get the example clearer, in [ 424] a multiview perspective is utilized in which different single views (representing the sources they attend to) models are fused. These models contain among others, cell-phone data, transportation data, etc. which might introduce the problem that information that is not even shared can be discovered through other sources that are actually shared. In the example above, what if instead of features, a model shares with another a layer or part of its architecture as in Federated Learning? Would this sharing make possible to infer information from that exchanged part of its model, to the extent of allowing for the design of adversarial attacks with better success rate upon the antecedent model? If focused at knowledge level fusion, a similar reasoning holds: XAI comprises techniques that extract knowledge from ML model(s). This ability to explain models could have an impact on the necessity of discovering new knowledge through the complex interactions formed within ML models. If so, XAI might enrich knowledge fusion paradigms, bringing the possibility of discovering new knowledge extractors of relevance for the task at hand. For this purpose, it is of paramount importance that the knowledge extracted from a model by means of XAI techniques can be understood and extrapolated to the domain in which knowledge extractors operate. The concept matches with ease with that of transfer learning portrayed in [ 425]. Although XAI is not contemplated in the surveyed processes of extracting knowledge from models trained in certain feature spaces and distributions, to then be utilized in environments where previous conditions do not hold, when deployed, XAI can pose a threat if the explanations given about the model can be reversely engineered through the knowledge fusion paradigm to eventually compromise, for instance, the differential privacy of the overall model. The distinction between centralized and distributed data fusion also spurs further challenges in regards to privacy and explainability. The centralized approach does not bring any further concerns that those presented above. However, distributed fusion does arise new problems. Distributed fusion might be applied for different reasons, mainly due to environmental constraints or due to security or privacy issues. The latter context may indulge some dangers. Among other goals (e.g. computational ef?ciency), model-level data fusion is performed in a distributed fashion to ensure that no actual data is actually shared, but rather parts of an ML model trained on local data. This rationale lies at the heart of Federated Learning, where models exchange locally learned information among nodes. Since data do not leave the local device, only the transmission of model updates is required across distributed devices. This lightens the training process for network-compromised settings and guarantees data privacy [416]. Upon the use of post-hoc explainability techniques, a node could disguise sensitive information about the local context in which the received ML model part was trained. In fact, it was shown that a black-box model based on a DNN from which an input/output query interface is given can be used to accurately predict every single hyperparameter value used for training, allowing for potential privacy- related consequences [ 357,420,421]. This relates to studies showing that blurring images does not guarantee privacy preservation. Data fusion, privacy and model explainability are concepts that have not been analysed together so far. From the above discussion it is clear that there are unsolved concerns and caveats that demand further study by the community in forthcoming times. 446.4. Implementing Responsible AI Principles in an Organization While increasingly more organizations are publishing AI principles to declare that they care about avoiding unintended negative consequences, there is much less experience on how to actually implement the principles into an organization. Looking at several examples of principles declared by different organizations [385], we can divide them into two groups: \u2022AI-speci?c principles that focus on aspects that are speci?c to AI, such as explainability, fairness and human agency. \u2022End-to-end principles that cover all aspects involved in AI, including also privacy, security and safety. The EC Guidelines for Trustworthy AI are an example of end-to-end principles [ 390], while those of Telefonica (a large Spanish ICT company operating worldwide) are more AI-speci?c [ 386]. For example, safety and security are relevant for any connected IT system, and therefore also for AI systems. The same holds for privacy, but it is probably true that privacy in the context of AI systems is even more important than for general IT systems, due to the fact that ML models need huge amounts of data and most importantly, because XAI tools and data fusion techniques pose new challenges to preserve the privacy of protected records. When it comes to implement the AI Principles into an organization, it is important to operationalize the AI-speci?c parts and, at the same time, leverage the processes already existing for the more generic principles. Indeed, in many organizations there already exist norms and procedures for privacy, security and safety. Implementing AI principles requires a methodology such as that presented in [ 386] that breaks down the process into different parts. The ingredients of such a methodology should include, at least: \u2022AI principles (already discussed earlier), which set the values and boundaries. \u2022Awareness and training about the potential issues, both technical and non-technical. \u2022A questionnaire that forces people to think about certain impacts of the AI system ( impact explanation ). This questionnaire should give concrete guidance on what to do if certain undesired impacts are detected. \u2022Tools that help answering some of the questions, and help mitigating any problems identi?ed. XAI tools and fairness tools fall in this category, as well as other recent proposals such as model cards [426]. \u2022A governance model assigning responsibilities and accountabilities ( responsibility explanation ). There are two philosophies for governance: 1) based on committees that review and approve AI developments, and 2) based on the self-responsibility of the employees. While both are possible, given the fact that agility is key for being successful in the digital world, it seems wiser to focus on awareness and employee responsibility, and only use committees when there are speci?c, but important issues. From the above elaborations, it is clear that the implementation of Responsible AI principles in companies should balance between two requirements: 1) major cultural and organizational changes needed to enforce such principles over processes endowed with AI functionalities; and 2) the feasibility and compliance of the implementation of such principles with the IT assets, policies and resources already available at the company. It is in the gradual process of rising corporate awareness around the principles and values of Responsible AI where we envision that XAI will make its place and create huge impact. 7. Conclusions and Outlook This overview has revolved around eXplainable Arti?cial Intelligence (XAI), which has been identi?ed in recent times as an utmost need for the adoption of ML methods in real-life applications. Our study 45has elaborated on this topic by ?rst clarifying different concepts underlying model explainability, as well as by showing the diverse purposes that motivate the search for more interpretable ML methods. These conceptual remarks have served as a solid baseline for a systematic review of recent literature dealing with explainability, which has been approached from two different perspectives: 1) ML models that feature some degree of transparency, thereby interpretable to an extent by themselves; and 2) post-hoc XAI techniques devised to make ML models more interpretable. This literature analysis has yielded a global taxonomy of different proposals reported by the community, classifying them under uniform criteria. Given the prevalence of contributions dealing with the explainability of Deep Learning models, we have inspected in depth the literature dealing with this family of models, giving rise to an alternative taxonomy that connects more closely with the speci?c domains in which explainability can be realized for Deep Learning models. We have moved our discussions beyond what has been made so far in the XAI realm toward the concept of Responsible AI, a paradigm that imposes a series of AI principles to be met when implementing AI models in practice, including fairness, transparency, and privacy. We have also discussed the implications of adopting XAI techniques in the context of data fusion, unveiling the potential of XAI to compromise the privacy of protected data involved in the fusion process. Implications of XAI in fairness have also been discussed in detail. This vision of XAI as a core concept to ensure the aforementioned principles for Responsible AI is summarized graphically in Figure 14. XAIInterpretability versus  Performance XAI  Concepts and Metrics Achieving Explainability  in Deep  Learning XAI &  Security:  Adversarial  ML Rationale Explanation & Critical Data  StudiesTheory guided Data  ScienceImplementation & GuidelinesXAI and  Output  ConfidenceXAI & Data  Fusion  Fairness Privacy Accountability Ethics TransparencySecurity &  SafetyResponsible AI Figure 14: Summary of XAI challenges discussed in this overview and its impact on the principles for Responsible AI. Our re?ections about the future of XAI, conveyed in the discussions held throughout this work, agree on the compelling need for a proper understanding of the potentiality and caveats opened up by XAI techniques. It is our vision that model interpretability must be addressed jointly with requirements and constraints related to data privacy, model con?dentiality, fairness and accountability. A responsible implementation and use of AI methods in organizations and institutions worldwide will be only guaranteed if all these AI principles are studied jointly. Acknowledgments Alejandro Barredo-Arrieta, Javier Del Ser and Sergio Gil-Lopez would like to thank the Basque Government for the funding support received through the EMAITEK and ELKARTEK programs. Javier Del Ser also acknowledges funding support from the Consolidated Research Group MATHMODE (IT1294-19) granted by the Department of Education of the Basque Government. Siham Tabik, Salvador Garcia, Daniel Molina and Francisco Herrera would like to thank the Spanish Government for its funding support (SMART-DaSCI project, TIN2017-89517-P), as well as the BBV A Foundation through its Ayudas 46Fundaci \u00b4on BBVA a Equipos de Investigaci \u00b4on Cient \u00b4i?ca 2018 call (DeepSCOP project). This work was also funded in part by the European Union\u2019s Horizon 2020 research and innovation programme AI4EU under grant agreement 825619. We also thank Chris Olah, Alexander Mordvintsev and Ludwig Schubert for borrowing images for illustration purposes. Part of this overview is inspired by a preliminary work of the concept of Responsible AI: R. Benjamins, A. Barbado, D. Sierra, \u201cResponsible AI by Design\u201d , to appear in the Proceedings of the Human-Centered AI: Trustworthiness of AI Models & Data (HAI) track at AAAI Fall Symposium, DC, November 7-9, 2019 [386]. References [1]S. J. Russell, P. Norvig, Arti?cial intelligence: a modern approach, Malaysia; Pearson Education Limited,, 2016. [2] D. M. West, The future of work: robots, AI, and automation, Brookings Institution Press, 2018. [3]B. Goodman, S. Flaxman, European union regulations on algorithmic decision-making and a right to explanation, AI Magazine 38 (3) (2017) 50\u201357. [4] D. Castelvecchi, Can we open the black box of AI?, Nature News 538 (7623) (2016) 20. [5] Z. C. Lipton, The mythos of model interpretability, Queue 16 (3) (2018) 30:31\u201330:57. [6]A. Preece, D. Harborne, D. Braines, R. Tomsett, S. Chakraborty, Stakeholders in Explainable AI (2018). arXiv:1810.00184 . [7]D. Gunning, Explainable arti?cial intelligence (xAI), Tech. rep., Defense Advanced Research Projects Agency (DARPA) (2017). [8]E. Tjoa, C. Guan, A survey on explainable arti?cial intelligence (XAI): Towards medical XAI (2019). arXiv:1907.07374 . [9]J. Zhu, A. Liapis, S. Risi, R. Bidarra, G. M. Youngblood, Explainable AI for designers: A human- centered perspective on mixed-initiative co-creation, 2018 IEEE Conference on Computational Intelligence and Games (CIG) (2018) 1\u20138. [10] F. K. Do \u02dcsilovi \u00b4c, M. Br \u02dcci\u00b4c, N. Hlupi \u00b4c, Explainable arti?cial intelligence: A survey, in: 41st International Convention on Information and Communication Technology, Electronics and Micro- electronics (MIPRO), 2018, pp. 210\u2013215. [11] P. Hall, On the Art and Science of Machine Learning Explanations (2018). arXiv:1810. 02909 . [12] T. Miller, Explanation in arti?cial intelligence: Insights from the social sciences, Artif. Intell. 267 (2019) 1\u201338. [13] L. H. Gilpin, D. Bau, B. Z. Yuan, A. Bajwa, M. Specter, L. Kagal, Explaining Explanations: An Overview of Interpretability of Machine Learning (2018). arXiv:1806.00069 . [14] A. Adadi, M. Berrada, Peeking inside the black-box: A survey on explainable arti?cial intelligence (XAI), IEEE Access 6 (2018) 52138\u201352160. [15] O. Biran, C. Cotton, Explanation and justi?cation in machine learning: A survey, in: IJCAI-17 workshop on explainable AI (XAI), V ol. 8, 2017, p. 1. 47[16] S. T. Shane T. Mueller, R. R. Hoffman, W. Clancey, G. Klein, Explanation in Human-AI Systems: A Literature Meta-Review Synopsis of Key Ideas and Publications and Bibliography for Explainable AI, Tech. rep., Defense Advanced Research Projects Agency (DARPA) XAI Program (2019). [17] R. Guidotti, A. Monreale, S. Ruggieri, F. Turini, F. Giannotti, D. Pedreschi, A survey of methods for explaining black box models, ACM Computing Surveys 51 (5) (2018) 93:1\u201393:42. [18] G. Montavon, W. Samek, K.-R. Mller, Methods for interpreting and understanding deep neural networks, Digital Signal Processing 73 (2018) 1\u201315. doi:10.1016/j.dsp.2017.10.011 . [19] A. Fernandez, F. Herrera, O. Cordon, M. Jose del Jesus, F. Marcelloni, Evolutionary fuzzy systems for explainable arti?cial intelligence: Why, when, what for, and where to?, IEEE Computational Intelligence Magazine 14 (1) (2019) 69\u201381. [20] M. Gleicher, A framework for considering comprehensibility in modeling, Big data 4 (2) (2016) 75\u201388. [21] M. W. Craven, Extracting comprehensible models from trained neural networks, Tech. rep., Univer- sity of Wisconsin-Madison Department of Computer Sciences (1996). [22] R. S. Michalski, A theory and methodology of inductive learning, in: Machine learning, Springer, 1983, pp. 83\u2013134. [23] J. D\u00b4iez, K. Khalifa, B. Leuridan, General theories of explanation: buyer beware, Synthese 190 (3) (2013) 379\u2013396. [24] D. Doran, S. Schulz, T. R. Besold, What does explainable AI really mean? a new conceptualization of perspectives (2017). arXiv:1710.00794 . [25] F. Doshi-Velez, B. Kim, Towards a rigorous science of interpretable machine learning (2017). arXiv:1702.08608 . [26] A. Vellido, J. D. Mart \u00b4in-Guerrero, P. J. Lisboa, Making machine learning models interpretable., in: European Symposium on Arti?cial Neural Networks, Computational Intelligence and Machine Learning (ESANN), V ol. 12, Citeseer, 2012, pp. 163\u2013172. [27] E. Walter, Cambridge advanced learner\u2019s dictionary, Cambridge University Press, 2008. [28] P. Besnard, A. Hunter, Elements of Argumentation, The MIT Press, 2008. [29] F. Rossi, AI Ethics for Enterprise AI (2019). URL https://economics.harvard.edu/files/economics/files/rossi- francesca_4-22-19_ai-ethics-for-enterprise-ai_ec3118-hbs.pdf [30] A. Holzinger, C. Biemann, C. S. Pattichis, D. B. Kell, What do we need to build explainable Ai systems for the medical domain? (2017). arXiv:1712.09923 . [31] B. Kim, E. Glassman, B. Johnson, J. Shah, iBCM: Interactive bayesian case model empowering humans via intuitive interaction, Tech. rep., MIT-CSAIL-TR-2015-010 (2015). [32] M. T. Ribeiro, S. Singh, C. Guestrin, Why should I trust you?: Explaining the predictions of any classi?er, in: ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM, 2016, pp. 1135\u20131144. [33] M. Fox, D. Long, D. Magazzeni, Explainable planning (2017). arXiv:1709.10256 . 48[34] H. C. Lane, M. G. Core, M. Van Lent, S. Solomon, D. Gomboc, Explainable arti?cial intelligence for training and tutoring, Tech. rep., University of Southern California (2005). [35] W. J. Murdoch, C. Singh, K. Kumbier, R. Abbasi-Asl, B. Yu, Interpretable machine learning: de?nitions, methods, and applications (2019). arXiv:1901.04592 . [36] J. Haspiel, N. Du, J. Meyerson, L. P. Robert Jr, D. Tilbury, X. J. Yang, A. K. Pradhan, Explana- tions and expectations: Trust building in automated vehicles, in: Companion of the ACM/IEEE International Conference on Human-Robot Interaction, ACM, 2018, pp. 119\u2013120. [37] A. Chander, R. Srinivasan, S. Chelian, J. Wang, K. Uchino, Working with beliefs: AI transparency in the enterprise., in: Workshops of the ACM Conference on Intelligent User Interfaces, 2018. [38] A. B. Tickle, R. Andrews, M. Golea, J. Diederich, The truth will come to light: Directions and challenges in extracting the knowledge embedded within trained arti?cial neural networks, IEEE Transactions on Neural Networks 9 (6) (1998) 1057\u20131068. [39] C. Louizos, U. Shalit, J. M. Mooij, D. Sontag, R. Zemel, M. Welling, Causal effect inference with deep latent-variable models, in: Advances in Neural Information Processing Systems, 2017, pp. 6446\u20136456. [40] O. Goudet, D. Kalainathan, P. Caillou, I. Guyon, D. Lopez-Paz, M. Sebag, Learning functional causal models with generative neural networks, in: Explainable and Interpretable Models in Computer Vision and Machine Learning, Springer, 2018, pp. 39\u201380. [41] S. Athey, G. W. Imbens, Machine learning methods for estimating heterogeneous causal effects, stat 1050 (5) (2015). [42] D. Lopez-Paz, R. Nishihara, S. Chintala, B. Scholkopf, L. Bottou, Discovering causal signals in images, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 6979\u20136987. [43] C. Barabas, K. Dinakar, J. Ito, M. Virza, J. Zittrain, Interventions over predictions: Reframing the ethical debate for actuarial risk assessment (2017). arXiv:1712.08238 . [44] R. Caruana, Y . Lou, J. Gehrke, P. Koch, M. Sturm, N. Elhadad, Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission, in: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201915, 2015, pp. 1721\u20131730. [45] A. Theodorou, R. H. Wortham, J. J. Bryson, Designing and implementing transparency for real time inspection of autonomous robots, Connection Science 29 (3) (2017) 230\u2013241. [46] W. Samek, T. Wiegand, K.-R. M \u00a8uller, Explainable arti?cial intelligence: Understanding, visualizing and interpreting deep learning models (2017). arXiv:1708.08296 . [47] C. Wadsworth, F. Vera, C. Piech, Achieving fairness through adversarial learning: an application to recidivism prediction (2018). arXiv:1807.00199 . [48] X. Yuan, P. He, Q. Zhu, X. Li, Adversarial examples: Attacks and defenses for deep learning, IEEE Transactions on Neural Networks and Learning Systems 30 (9) (2019) 2805\u20132824. [49] B. Letham, C. Rudin, T. H. McCormick, D. Madigan, et al., Interpretable classi?ers using rules and bayesian analysis: Building a better stroke prediction model, The Annals of Applied Statistics 9 (3) (2015) 1350\u20131371. 49[50] M. Harbers, K. van den Bosch, J.-J. Meyer, Design and evaluation of explainable BDI agents, in: IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology, V ol. 2, IEEE, 2010, pp. 125\u2013132. [51] M. H. Aung, P. G. Lisboa, T. A. Etchells, A. C. Testa, B. Van Calster, S. Van Huffel, L. Valentin, D. Timmerman, Comparing analytical decision support models through boolean rule extraction: A case study of ovarian tumour malignancy, in: International Symposium on Neural Networks, Springer, 2007, pp. 1177\u20131186. [52] A. Weller, Challenges for transparency (2017). arXiv:1708.01870 . [53] A. A. Freitas, Comprehensible classi?cation models: a position paper, ACM SIGKDD explorations newsletter 15 (1) (2014) 1\u201310. [54] V . Schetinin, J. E. Fieldsend, D. Partridge, T. J. Coats, W. J. Krzanowski, R. M. Everson, T. C. Bailey, A. Hernandez, Con?dent interpretation of bayesian decision tree ensembles for clinical applications, IEEE Transactions on Information Technology in Biomedicine 11 (3) (2007) 312\u2013319. [55] D. Martens, J. Vanthienen, W. Verbeke, B. Baesens, Performance of classi?cation models from a user perspective, Decision Support Systems 51 (4) (2011) 782\u2013793. [56] Z. Che, S. Purushotham, R. Khemani, Y . Liu, Interpretable deep models for ICU outcome prediction, in: AMIA Annual Symposium Proceedings, V ol. 2016, American Medical Informatics Association, 2016, p. 371. [57] N. Barakat, J. Diederich, Eclectic rule-extraction from support vector machines, International Journal of Computer, Electrical, Automation, Control and Information Engineering 2 (5) (2008) 1672\u20131675. [58] F. J. C. Garcia, D. A. Robb, X. Liu, A. Laskov, P. Patron, H. Hastie, Explain yourself: A natural language interface for scrutable autonomous robots (2018). arXiv:1803.02088 . [59] P. Langley, B. Meadows, M. Sridharan, D. Choi, Explainable agency for intelligent autonomous systems, in: AAAI Conference on Arti?cial Intelligence, 2017, pp. 4762\u20134763. [60] G. Montavon, S. Lapuschkin, A. Binder, W. Samek, K.-R. M \u00a8uller, Explaining nonlinear classi?ca- tion decisions with deep taylor decomposition, Pattern Recognition 65 (2017) 211\u2013222. [61] P.-J. Kindermans, K. T. Sch \u00a8utt, M. Alber, K.-R. M \u00a8uller, D. Erhan, B. Kim, S. D \u00a8ahne, Learning how to explain neural networks: Patternnet and patternattribution (2017). arXiv:1705.05598 . [62] G. Ras, M. van Gerven, P. Haselager, Explanation methods in deep learning: Users, values, concerns and challenges, in: Explainable and Interpretable Models in Computer Vision and Machine Learning, Springer, 2018, pp. 19\u201336. [63] S. Bach, A. Binder, K.-R. M \u00a8uller, W. Samek, Controlling explanatory heatmap resolution and semantics via decomposition depth, in: IEEE International Conference on Image Processing (ICIP), IEEE, 2016, pp. 2271\u20132275. [64] G. J. Katuwal, R. Chen, Machine learning model interpretability for precision medicine (2016). arXiv:1610.09045 . [65] M. A. Neerincx, J. van der Waa, F. Kaptein, J. van Diggelen, Using perceptual and cognitive expla- nations for enhanced human-agent team performance, in: International Conference on Engineering Psychology and Cognitive Ergonomics, Springer, 2018, pp. 204\u2013214. 50[66] J. D. Olden, D. A. Jackson, Illuminating the black box: a randomization approach for understanding variable contributions in arti?cial neural networks, Ecological modelling 154 (1-2) (2002) 135\u2013150. [67] J. Krause, A. Perer, K. Ng, Interacting with predictions: Visual inspection of black-box machine learning models, in: CHI Conference on Human Factors in Computing Systems, ACM, 2016, pp. 5686\u20135697. [68] L. Rosenbaum, G. Hinselmann, A. Jahn, A. Zell, Interpreting linear support vector machine models with heat map molecule coloring, Journal of Cheminformatics 3 (1) (2011) 11. [69] J. Tan, M. Ung, C. Cheng, C. S. Greene, Unsupervised feature construction and knowledge extraction from genome-wide assays of breast cancer with denoising autoencoders, in: Paci?c Symposium on Biocomputing Co-Chairs, World Scienti?c, 2014, pp. 132\u2013143. [70] S. Krening, B. Harrison, K. M. Feigh, C. L. Isabell, M. Riedl, A. Thomaz, Learning from expla- nations using sentiment and advice in RL, IEEE Transactions on Cognitive and Developmental Systems 9 (1) (2017) 44\u201355. [71] M. T. Ribeiro, S. Singh, C. Guestrin, Model-agnostic interpretability of machine learning (2016). arXiv:1606.05386 . [72] S. Bach, A. Binder, G. Montavon, F. Klauschen, K.-R. M \u00a8uller, W. Samek, On pixel-wise expla- nations for non-linear classi?er decisions by layer-wise relevance propagation, PloS one 10 (7) (2015) e0130140. [73] T. A. Etchells, P. J. Lisboa, Orthogonal search-based rule extraction (OSRE) for trained neural networks: a practical and ef?cient approach, IEEE Transactions on Neural Networks 17 (2) (2006) 374\u2013384. [74] Y . Zhang, S. Sreedharan, A. Kulkarni, T. Chakraborti, H. H. Zhuo, S. Kambhampati, Plan expli- cability and predictability for robot task planning, in: 2017 IEEE International Conference on Robotics and Automation (ICRA), IEEE, 2017, pp. 1313\u20131320. [75] A. Santoro, D. Raposo, D. G. Barrett, M. Malinowski, R. Pascanu, P. Battaglia, T. Lillicrap, A simple neural network module for relational reasoning, in: Advances in Neural Information Processing Systems, 2017, pp. 4967\u20134976. [76] C.-Y . J. Peng, T.-S. H. So, F. K. Stage, E. P. S. John, The use and interpretation of logistic regression in higher education journals: 1988\u20131999, Research in Higher Education 43 (3) (2002) 259\u2013293. [77] B.\u00a8Ust\u00a8un, W. Melssen, L. Buydens, Visualisation and interpretation of support vector regression models, Analytica Chimica Acta 595 (1-2) (2007) 299\u2013309. [78] Q. Zhang, Y . Yang, H. Ma, Y . N. Wu, Interpreting CNNs via decision trees, in: IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 6261\u20136270. [79] M. Wu, M. C. Hughes, S. Parbhoo, M. Zazzi, V . Roth, F. Doshi-Velez, Beyond sparsity: Tree regularization of deep models for interpretability, in: AAAI Conference on Arti?cial Intelligence, 2018, pp. 1670\u20131678. [80] G. Hinton, O. Vinyals, J. Dean, Distilling the knowledge in a neural network (2015). arXiv: 1503.02531 . [81] N. Frosst, G. Hinton, Distilling a neural network into a soft decision tree (2017). arXiv: 1711.09784 . 51[82] M. G. Augasta, T. Kathirvalavakumar, Reverse engineering the neural networks for rule extraction in classi?cation problems, Neural Processing Letters 35 (2) (2012) 131\u2013150. [83] Z.-H. Zhou, Y . Jiang, S.-F. Chen, Extracting symbolic rules from trained neural network ensembles, AI Communications 16 (1) (2003) 3\u201315. [84] H. F. Tan, G. Hooker, M. T. Wells, Tree space prototypes: Another look at making tree ensembles interpretable (2016). arXiv:1611.07115 . [85] R. C. Fong, A. Vedaldi, Interpretable explanations of black boxes by meaningful perturbation, in: IEEE International Conference on Computer Vision, 2017, pp. 3429\u20133437. [86] T. Miller, P. Howe, L. Sonenberg, Explainable AI: Beware of inmates running the asylum, in: International Joint Conference on Arti?cial Intelligence, Workshop on Explainable AI (XAI), V ol. 36, 2017, pp. 36\u201340. [87] R. Goebel, A. Chander, K. Holzinger, F. Lecue, Z. Akata, S. Stumpf, P. Kieseberg, A. Holzinger, Explainable AI: the new 42?, in: International Cross-Domain Conference for Machine Learning and Knowledge Extraction, Springer, 2018, pp. 295\u2013303. [88] V . Belle, Logic meets probability: Towards explainable AI systems for uncertain worlds, in: International Joint Conference on Arti?cial Intelligence, 2017, pp. 5116\u20135120. [89] L. Edwards, M. Veale, Slave to the algorithm: Why a right to an explanation is probably not the remedy you are looking for, Duke L. & Tech. Rev. 16 (2017) 18. [90] Y . Lou, R. Caruana, J. Gehrke, G. Hooker, Accurate intelligible models with pairwise interactions, in: ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM, 2013, pp. 623\u2013631. [91] K. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhudinov, R. Zemel, Y . Bengio, Show, attend and tell: Neural image caption generation with visual attention, in: International Conference on Machine Learning, 2015, pp. 2048\u20132057. [92] J. Huysmans, K. Dejaeger, C. Mues, J. Vanthienen, B. Baesens, An empirical evaluation of the comprehensibility of decision table, tree and rule based predictive models, Decision Support Systems 51 (1) (2011) 141\u2013154. [93] N. H. Barakat, A. P. Bradley, Rule extraction from support vector machines: A sequential covering approach, IEEE Transactions on Knowledge and Data Engineering 19 (6) (2007) 729\u2013741. [94] F. C. Adriana da Costa, M. M. B. Vellasco, R. Tanscheit, Fuzzy rule extraction from support vector machines, in: International Conference on Hybrid Intelligent Systems, IEEE, 2005, pp. 335\u2013340. [95] D. Martens, B. Baesens, T. Van Gestel, J. Vanthienen, Comprehensible credit scoring models using rule extraction from support vector machines, European Journal of Operational Research 183 (3) (2007) 1466\u20131476. [96] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, A. Torralba, Learning deep features for discriminative localization, in: IEEE Conference on Computer Vision and Pattern Recognition, 2016, pp. 2921\u2013 2929. [97] R. Krishnan, G. Sivakumar, P. Bhattacharya, Extracting decision trees from trained neural networks, Pattern Recognition 32 (12) (1999) 1999\u20132009. 52[98] X. Fu, C. Ong, S. Keerthi, G. G. Hung, L. Goh, Extracting the knowledge embedded in support vector machines, in: IEEE International Joint Conference on Neural Networks, V ol. 1, IEEE, 2004, pp. 291\u2013296. [99] B. Green, \u201cFair\u201d risk assessments: A precarious approach for criminal justice reform, in: 5th Workshop on Fairness, Accountability, and Transparency in Machine Learning, 2018. [100] A. Chouldechova, Fair prediction with disparate impact: A study of bias in recidivism prediction instruments, Big Data 5 (2) (2017) 153\u2013163. [101] M. Kim, O. Reingold, G. Rothblum, Fairness through computationally-bounded awareness, in: Advances in Neural Information Processing Systems, 2018, pp. 4842\u20134852. [102] B. Haasdonk, Feature space interpretation of SVMs with inde?nite kernels, IEEE Transactions on Pattern Analysis and Machine Intelligence 27 (4) (2005) 482\u2013492. [103] A. Palczewska, J. Palczewski, R. M. Robinson, D. Neagu, Interpreting random forest classi?cation models using a feature contribution method, in: Integration of Reusable Systems, Springer, 2014, pp. 193\u2013218. [104] S. H. Welling, H. H. Refsgaard, P. B. Brockhoff, L. H. Clemmensen, Forest ?oor visualizations of random forests (2016). arXiv:1605.09196 . [105] G. Fung, S. Sandilya, R. B. Rao, Rule extraction from linear support vector machines, in: ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, ACM, 2005, pp. 32\u201340. [106] Y . Zhang, H. Su, T. Jia, J. Chu, Rule extraction from trained support vector machines, in: Paci?c- Asia Conference on Knowledge Discovery and Data Mining, Springer, 2005, pp. 61\u201370. [107] D. Linsley, D. Shiebler, S. Eberhardt, T. Serre, Global-and-local attention networks for visual recognition (2018). arXiv:1805.08819 . [108] S.-M. Zhou, J. Q. Gan, Low-level interpretability and high-level interpretability: a uni?ed view of data-driven interpretable fuzzy system modelling, Fuzzy Sets and Systems 159 (23) (2008) 3091\u20133131. [109] J. Burrell, How the machine \u2018thinks\u2019: Understanding opacity in machine learning algorithms, Big Data & Society 3 (1) (2016) 1\u201312. [110] A. Shrikumar, P. Greenside, A. Shcherbina, A. Kundaje, Not just a black box: Learning important features through propagating activation differences (2016). arXiv:1605.01713 . [111] Y . Dong, H. Su, J. Zhu, B. Zhang, Improving interpretability of deep neural networks with semantic information, in: IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 4306\u20134314. [112] G. Ridgeway, D. Madigan, T. Richardson, J. O\u2019Kane, Interpretable boosted na \u00a8ive bayes classi- ?cation., in: ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 1998, pp. 101\u2013104. [113] Q. Zhang, Y . Nian Wu, S.-C. Zhu, Interpretable convolutional neural networks, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 8827\u20138836. 53[114] S. Seo, J. Huang, H. Yang, Y . Liu, Interpretable convolutional neural networks with dual local and global attention for review rating prediction, in: Proceedings of the Eleventh ACM Conference on Recommender Systems, ACM, 2017, pp. 297\u2013305. [115] K. Larsen, J. H. Petersen, E. Budtz-J\u00f8rgensen, L. Endahl, Interpreting parameters in the logistic regression model with random effects, Biometrics 56 (3) (2000) 909\u2013914. [116] B. Gaonkar, R. T. Shinohara, C. Davatzikos, A. D. N. Initiative, et al., Interpreting support vector machine models for multivariate group wise analysis in neuroimaging, Medical image analysis 24 (1) (2015) 190\u2013204. [117] K. Xu, D. H. Park, C. Yi, C. Sutton, Interpreting deep classi?er by visual distillation of dark knowledge (2018). arXiv:1803.04042 . [118] H. Deng, Interpreting tree ensembles with intrees (2014). arXiv:1408.5456 . [119] P. Domingos, Knowledge discovery via multiple models, Intelligent Data Analysis 2 (1-4) (1998) 187\u2013202. [120] S. Tan, R. Caruana, G. Hooker, Y . Lou, Distill-and-compare: Auditing black-box models using transparent model distillation, in: AAAI/ACM Conference on AI, Ethics, and Society, ACM, 2018, pp. 303\u2013310. [121] R. A. Berk, J. Bleich, Statistical procedures for forecasting criminal behavior: A comparative assessment, Criminology & Public Policy 12 (3) (2013) 513\u2013544. [122] S. Hara, K. Hayashi, Making tree ensembles interpretable (2016). arXiv:1606.05390 . [123] A. Henelius, K. Puolam \u00a8aki, A. Ukkonen, Interpreting classi?ers through attribute interactions in datasets (2017). arXiv:1707.07576 . [124] H. Hastie, F. J. C. Garcia, D. A. Robb, P. Patron, A. Laskov, MIRIAM: a multimodal chat-based interface for autonomous systems, in: ACM International Conference on Multimodal Interaction, ACM, 2017, pp. 495\u2013496. [125] D. Bau, B. Zhou, A. Khosla, A. Oliva, A. Torralba, Network dissection: Quantifying interpretability of deep visual representations, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 6541\u20136549. [126] H. N \u00b4u\u02dcnez, C. Angulo, A. Catal `a, Rule extraction from support vector machines., in: European Symposium on Arti?cial Neural Networks, Computational Intelligence and Machine Learning (ESANN), 2002, pp. 107\u2013112. [127] H. N \u00b4u\u02dcnez, C. Angulo, A. Catal `a, Rule-based learning systems for support vector machines, Neural Processing Letters 24 (1) (2006) 1\u201318. [128] M. Kearns, S. Neel, A. Roth, Z. S. Wu, Preventing fairness gerrymandering: Auditing and learning for subgroup fairness (2017). arXiv:1711.05144 . [129] E. Akyol, C. Langbort, T. Basar, Price of transparency in strategic machine learning (2016). arXiv:1610.08210 . [130] D. Erhan, A. Courville, Y . Bengio, Understanding representations learned in deep architectures, Department dInformatique et Recherche Operationnelle, University of Montreal, QC, Canada, Tech. Rep 1355 (2010) 1. 54[131] Y . Zhang, B. Wallace, A sensitivity analysis of (and practitioners\u2019 guide to) convolutional neural networks for sentence classi?cation (2015). arXiv:1510.03820 . [132] J. R. Quinlan, Simplifying decision trees, International journal of man-machine studies 27 (3) (1987) 221\u2013234. [133] Y . Zhou, G. Hooker, Interpreting models via single tree approximation (2016). arXiv:1610. 09036 . [134] A. Navia-V \u00b4azquez, E. Parrado-Hern \u00b4andez, Support vector machine interpretation, Neurocomputing 69 (13-15) (2006) 1754\u20131759. [135] J. J. Thiagarajan, B. Kailkhura, P. Sattigeri, K. N. Ramamurthy, Treeview: Peeking into deep neural networks via feature-space partitioning (2016). arXiv:1611.07429 . [136] M. D. Zeiler, R. Fergus, Visualizing and understanding convolutional networks, in: European conference on computer vision, Springer, 2014, pp. 818\u2013833. [137] A. Mahendran, A. Vedaldi, Understanding deep image representations by inverting them, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 5188\u2013 5196. [138] J. Wagner, J. M. Kohler, T. Gindele, L. Hetzel, J. T. Wiedemer, S. Behnke, Interpretable and ?ne-grained visual explanations for convolutional neural networks, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 9097\u20139107. [139] A. Kanehira, T. Harada, Learning to explain with complemental examples, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 8603\u20138611. [140] D. W. Apley, Visualizing the effects of predictor variables in black box supervised learning models (2016). arXiv:1612.08468 . [141] M. Staniak, P. Biecek, Explanations of Model Predictions with live and breakDown Packages, The R Journal 10 (2) (2018) 395\u2013409. [142] M. D. Zeiler, D. Krishnan, G. W. Taylor, R. Fergus, Deconvolutional networks., in: CVPR, V ol. 10, 2010, p. 7. [143] J. T. Springenberg, A. Dosovitskiy, T. Brox, M. Riedmiller, Striving for simplicity: The all convolutional net (2014). arXiv:1412.6806 . [144] B. Kim, M. Wattenberg, J. Gilmer, C. Cai, J. Wexler, F. Viegas, R. Sayres, Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (TCA V) (2017). arXiv: 1711.11279 . [145] A. Polino, R. Pascanu, D. Alistarh, Model compression via distillation and quantization (2018). arXiv:1802.05668 . [146] W. J. Murdoch, A. Szlam, Automatic rule extraction from long short term memory networks (2017). arXiv:1702.02540 . [147] M. W. Craven, J. W. Shavlik, Using sampling and queries to extract rules from trained neural networks, in: Machine learning proceedings 1994, Elsevier, 1994, pp. 37\u201345. [148] A. D. Arbatli, H. L. Akin, Rule extraction from trained neural networks using genetic algorithms, Nonlinear Analysis: Theory, Methods & Applications 30 (3) (1997) 1639\u20131648. 55[149] U. Johansson, L. Niklasson, Evolving decision trees using oracle guides, in: 2009 IEEE Symposium on Computational Intelligence and Data Mining, IEEE, 2009, pp. 238\u2013244. [150] T. Lei, R. Barzilay, T. Jaakkola, Rationalizing neural predictions (2016). arXiv:1606.04155 . [151] A. Radford, R. Jozefowicz, I. Sutskever, Learning to generate reviews and discovering sentiment (2017). arXiv:1704.01444 . [152] R. R. Selvaraju, A. Das, R. Vedantam, M. Cogswell, D. Parikh, D. Batra, Grad-CAM: Why did you say that? (2016). [153] R. Shwartz-Ziv, N. Tishby, Opening the black box of deep neural networks via information (2017). arXiv:1703.00810 . [154] J. Yosinski, J. Clune, A. Nguyen, T. Fuchs, H. Lipson, Understanding neural networks through deep visualization (2015). arXiv:1506.06579 . [155] P. E. Pope, S. Kolouri, M. Rostami, C. E. Martin, H. Hoffmann, Explainability methods for graph convolutional neural networks, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 10772\u201310781. [156] P. Gajane, M. Pechenizkiy, On formalizing fairness in prediction with machine learning (2017). arXiv:1710.03184 . [157] C. Dwork, C. Ilvento, Composition of fairsystems (2018). arXiv:1806.06122 . [158] S. Barocas, M. Hardt, A. Narayanan, Fairness and Machine Learning, fairmlbook.org, 2019, http://www.fairmlbook.org . [159] H.-X. Wang, L. Fratiglioni, G. B. Frisoni, M. Viitanen, B. Winblad, Smoking and the occurence of alzheimer\u2019s disease: Cross-sectional and longitudinal data in a population-based study, American journal of epidemiology 149 (7) (1999) 640\u2013644. [160] P. Rani, C. Liu, N. Sarkar, E. Vanman, An empirical study of machine learning techniques for affect recognition in human\u2013robot interaction, Pattern Analysis and Applications 9 (1) (2006) 58\u201369. [161] J. Pearl, Causality, Cambridge university press, 2009. [162] M. Kuhn, K. Johnson, Applied predictive modeling, V ol. 26, Springer, 2013. [163] G. James, D. Witten, T. Hastie, R. Tibshirani, An introduction to statistical learning, V ol. 112, Springer, 2013. [164] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, R. Fergus, Intriguing properties of neural networks (2013). arXiv:1312.6199 . [165] D. Ruppert, Robust statistics: The approach based on in?uence functions, Taylor & Francis, 1987. [166] S. Basu, K. Kumbier, J. B. Brown, B. Yu, Iterative random forests to discover predictive and stable high-order interactions, Proceedings of the National Academy of Sciences 115 (8) (2018) 1943\u20131948. [167] B. Yu, et al., Stability, Bernoulli 19 (4) (2013) 1484\u20131500. [168] K. Burns, L. A. Hendricks, K. Saenko, T. Darrell, A. Rohrbach, Women also Snowboard: Over- coming Bias in Captioning Models (2018). arXiv:1803.09797 . 56[169] A. Bennetot, J.-L. Laurent, R. Chatila, N. D \u00b4iaz-Rodr \u00b4iguez, Towards explainable neural-symbolic visual reasoning, in: NeSy Workshop IJCAI 2019, Macau, China, 2019. [170] R. Tibshirani, Regression shrinkage and selection via the lasso, Journal of the Royal Statistical Society: Series B (Methodological) 58 (1) (1996) 267\u2013288. [171] Y . Lou, R. Caruana, J. Gehrke, Intelligible models for classi?cation and regression, in: ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM, 2012, pp. 150\u2013158. [172] K. Kawaguchi, Deep learning without poor local minima, in: Advances in neural information processing systems, 2016, pp. 586\u2013594. [173] A. Datta, S. Sen, Y . Zick, Algorithmic transparency via quantitative input in?uence: Theory and experiments with learning systems, in: 2016 IEEE symposium on security and privacy (SP), IEEE, 2016, pp. 598\u2013617. [174] Z. Bursac, C. H. Gauss, D. K. Williams, D. W. Hosmer, Purposeful selection of variables in logistic regression, Source code for biology and medicine 3 (1) (2008) 17. [175] J. Jaccard, Interaction effects in logistic regression: Quantitative applications in the social sciences, Sage Thousand Oaks, CA, 2001. [176] D. W. Hosmer Jr, S. Lemeshow, R. X. Sturdivant, Applied logistic regression, V ol. 398, John Wiley & Sons, 2013. [177] C.-Y . J. Peng, K. L. Lee, G. M. Ingersoll, An introduction to logistic regression analysis and reporting, The journal of educational research 96 (1) (2002) 3\u201314. [178] U. Hoffrage, G. Gigerenzer, Using natural frequencies to improve diagnostic inferences, Academic medicine 73 (5) (1998) 538\u2013540. [179] C. Mood, Logistic regression: Why we cannot do what we think we can do, and what we can do about it, European sociological review 26 (1) (2010) 67\u201382. [180] H. Laurent, R. L. Rivest, Constructing optimal binary decision trees is Np-complete, Information processing letters 5 (1) (1976) 15\u201317. [181] P. E. Utgoff, Incremental induction of decision trees, Machine learning 4 (2) (1989) 161\u2013186. [182] J. R. Quinlan, Induction of decision trees, Machine learning 1 (1) (1986) 81\u2013106. [183] L. Rokach, O. Z. Maimon, Data mining with decision trees: theory and applications, V ol. 69, World scienti?c, 2014. [184] S. Rovnyak, S. Kretsinger, J. Thorp, D. Brown, Decision trees for real-time transient stability prediction, IEEE Transactions on Power Systems 9 (3) (1994) 1417\u20131426. [185] H. Nefeslioglu, E. Sezer, C. Gokceoglu, A. Bozkir, T. Duman, Assessment of landslide suscep- tibility by decision trees in the metropolitan area of istanbul, turkey, Mathematical Problems in Engineering 2010 (2010) Article ID 901095. [186] S. B. Imandoust, M. Bolandraftar, Application of k-nearest neighbor (knn) approach for predicting economic events: Theoretical background, International Journal of Engineering Research and Applications 3 (5) (2013) 605\u2013610. 57[187] L. Li, D. M. Umbach, P. Terry, J. A. Taylor, Application of the GA/KNN method to SELDI proteomics data, Bioinformatics 20 (10) (2004) 1638\u20131640. [188] G. Guo, H. Wang, D. Bell, Y . Bi, K. Greer, An KNN model-based approach and its application in text categorization, in: International Conference on Intelligent Text Processing and Computational Linguistics, Springer, 2004, pp. 559\u2013570. [189] S. Jiang, G. Pang, M. Wu, L. Kuang, An improved k-nearest-neighbor algorithm for text catego- rization, Expert Systems with Applications 39 (1) (2012) 1503\u20131509. [190] U. Johansson, R. K \u00a8onig, L. Niklasson, The truth is in there-rule extraction from opaque models using genetic programming., in: FLAIRS Conference, Miami Beach, FL, 2004, pp. 658\u2013663. [191] J. R. Quinlan, Generating production rules from decision trees., in: ijcai, V ol. 87, Citeseer, 1987, pp. 304\u2013307. [192] P. Langley, H. A. Simon, Applications of machine learning and rule induction, Communications of the ACM 38 (11) (1995) 54\u201364. [193] D. Berg, Bankruptcy prediction by generalized additive models, Applied Stochastic Models in Business and Industry 23 (2) (2007) 129\u2013143. [194] R. Calabrese, et al., Estimating bank loans loss given default by generalized additive models, UCD Geary Institute Discussion Paper Series, WP2012/24 (2012). [195] P. Taylan, G.-W. Weber, A. Beck, New approaches to regression by generalized additive models and continuous optimization for modern applications in ?nance, science and technology, Optimization 56 (5-6) (2007) 675\u2013698. [196] H. Murase, H. Nagashima, S. Yonezaki, R. Matsukura, T. Kitakado, Application of a generalized additive model (GAM) to reveal relationships between environmental factors and distributions of pelagic ?sh and krill: a case study in sendai bay, Japan, ICES Journal of Marine Science 66 (6) (2009) 1417\u20131424. [197] N. Tomi \u00b4c, S. Bo ?zi\u00b4c, A modi?ed geosite assessment model (M-GAM) and its application on the lazar canyon area (serbia), International journal of environmental research 8 (4) (2014) 1041\u20131052. [198] A. Guisan, T. C. Edwards Jr, T. Hastie, Generalized linear and generalized additive models in studies of species distributions: setting the scene, Ecological Modelling 157 (2-3) (2002) 89\u2013100. [199] P. Rothery, D. B. Roy, Application of generalized additive models to butter?y transect count data, Journal of Applied Statistics 28 (7) (2001) 897\u2013909. [200] A. Pierrot, Y . Goude, Short-term electricity load forecasting with generalized additive models, in: 16th Intelligent System Applications to Power Systems Conference, ISAP 2011, IEEE, 2011, pp. 410\u2013415. [201] T. L. Grif?ths, C. Kemp, J. B. Tenenbaum, Bayesian models of cognition. (4 2008). doi:10.1184/R1/6613682.v1 . URL https://kilthub.cmu.edu/articles/Bayesian_models_of_ cognition/6613682 [202] B. H. Neelon, A. J. OMalley, S.-L. T. Normand, A bayesian model for repeated measures zero- in?ated count data with application to outpatient psychiatric service use, Statistical modelling 10 (4) (2010) 421\u2013439. 58[203] M. McAllister, G. Kirkwood, Bayesian stock assessment: a review and example application using the logistic model, ICES Journal of Marine Science 55 (6) (1998) 1031\u20131060. [204] G. Synnaeve, P. Bessiere, A bayesian model for opening prediction in RTS games with application to starcraft, in: Computational Intelligence and Games (CIG), 2011 IEEE Conference on, IEEE, 2011, pp. 281\u2013288. [205] S.-K. Min, D. Simonis, A. Hense, Probabilistic climate change predictions applying bayesian model averaging, Philosophical transactions of the royal society of london a: mathematical, physical and engineering sciences 365 (1857) (2007) 2103\u20132116. [206] G. Koop, D. J. Poirier, J. L. Tobias, Bayesian econometric methods, Cambridge University Press, 2007. [207] A. R. Cassandra, L. P. Kaelbling, J. A. Kurien, Acting under uncertainty: Discrete bayesian models for mobile-robot navigation, in: Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems. IROS\u201996, V ol. 2, IEEE, 1996, pp. 963\u2013972. [208] H. A. Chipman, E. I. George, R. E. McCulloch, Bayesian cart model search, Journal of the American Statistical Association 93 (443) (1998) 935\u2013948. [209] B. Kim, C. Rudin, J. A. Shah, The bayesian case model: A generative approach for case-based reasoning and prototype classi?cation, in: Advances in Neural Information Processing Systems, 2014, pp. 1952\u20131960. [210] B. Kim, R. Khanna, O. O. Koyejo, Examples are not enough, learn to criticize! criticism for interpretability, in: Advances in Neural Information Processing Systems, 2016, pp. 2280\u20132288. [211] U. Johansson, L. Niklasson, R. K \u00a8onig, Accuracy vs. comprehensibility in data mining models, in: Proceedings of the seventh international conference on information fusion, V ol. 1, 2004, pp. 295\u2013300. [212] R. Konig, U. Johansson, L. Niklasson, G-rex: A versatile framework for evolutionary data mining, in: 2008 IEEE International Conference on Data Mining Workshops, IEEE, 2008, pp. 971\u2013974. [213] H. Lakkaraju, E. Kamar, R. Caruana, J. Leskovec, Interpretable & explorable approximations of black box models (2017). arXiv:1707.01154 . [214] S. Mishra, B. L. Sturm, S. Dixon, Local interpretable model-agnostic explanations for music content analysis., in: ISMIR, 2017, pp. 537\u2013543. [215] G. Su, D. Wei, K. R. Varshney, D. M. Malioutov, Interpretable two-level boolean rule learning for classi?cation (2015). arXiv:1511.07361 . [216] M. T. Ribeiro, S. Singh, C. Guestrin, Nothing else matters: Model-agnostic explanations by identifying prediction invariance (2016). arXiv:1611.05817 . [217] M. W. Craven, Extracting comprehensible models from trained neural networks, Ph.D. thesis, aAI9700774 (1996). [218] O. Bastani, C. Kim, H. Bastani, Interpretability via model extraction (2017). arXiv:1706. 09773 . [219] G. Hooker, Discovering additive structure in black box functions, in: Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, ACM, 2004, pp. 575\u2013580. 59[220] P. Adler, C. Falk, S. A. Friedler, T. Nix, G. Rybeck, C. Scheidegger, B. Smith, S. Venkatasubra- manian, Auditing black-box models for indirect in?uence, Knowledge and Information Systems 54 (1) (2018) 95\u2013122. [221] P. W. Koh, P. Liang, Understanding black-box predictions via in?uence functions, in: Proceedings of the 34th International Conference on Machine Learning-V olume 70, JMLR. org, 2017, pp. 1885\u20131894. [222] P. Cortez, M. J. Embrechts, Opening black box data mining models using sensitivity analysis, in: 2011 IEEE Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2011, pp. 341\u2013348. [223] P. Cortez, M. J. Embrechts, Using sensitivity analysis and visualization techniques to open black box data mining models, Information Sciences 225 (2013) 1\u201317. [224] S. M. Lundberg, S.-I. Lee, A uni?ed approach to interpreting model predictions, in: Advances in Neural Information Processing Systems, 2017, pp. 4765\u20134774. [225] I. Kononenko, et al., An ef?cient explanation of individual classi?cations using game theory, Journal of Machine Learning Research 11 (Jan) (2010) 1\u201318. [226] H. Chen, S. Lundberg, S.-I. Lee, Explaining models by propagating shapley values of local components (2019). arXiv:arXiv:1911.11888 . [227] P. Dabkowski, Y . Gal, Real time image saliency for black box classi?ers, in: Advances in Neural Information Processing Systems, 2017, pp. 6967\u20136976. [228] A. Henelius, K. Puolam \u00a8aki, H. Bostr \u00a8om, L. Asker, P. Papapetrou, A peek into the black box: exploring classi?ers by randomization, Data mining and knowledge discovery 28 (5-6) (2014) 1503\u20131529. [229] J. Moeyersoms, B. d\u2019Alessandro, F. Provost, D. Martens, Explaining classi?cation models built on high-dimensional sparse data (2016). arXiv:1607.06280 . [230] D. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M \u02dcA?zller, How to explain individual classi?cation decisions, Journal of Machine Learning Research 11 (Jun) (2010) 1803\u20131831. [231] J. Adebayo, L. Kagal, Iterative orthogonal feature projection for diagnosing bias in black-box models (2016). arXiv:1611.04967 . [232] R. Guidotti, A. Monreale, S. Ruggieri, D. Pedreschi, F. Turini, F. Giannotti, Local rule-based explanations of black box decision systems (2018). arXiv:1805.10820 . [233] S. Krishnan, E. Wu, Palm: Machine learning explanations for iterative debugging, in: Proceedings of the 2nd Workshop on Human-In-the-Loop Data Analytics, ACM, 2017, p. 4. [234] M. Robnik- ?Sikonja, I. Kononenko, Explaining classi?cations for individual instances, IEEE Transactions on Knowledge and Data Engineering 20 (5) (2008) 589\u2013600. [235] M. T. Ribeiro, S. Singh, C. Guestrin, Anchors: High-precision model-agnostic explanations, in: AAAI Conference on Arti?cial Intelligence, 2018, pp. 1527\u20131535. [236] D. Martens, F. Provost, Explaining data-driven document classi?cations, MIS Quarterly 38 (1) (2014) 73\u2013100. 60[237] D. Chen, S. P. Fraiberger, R. Moakler, F. Provost, Enhancing transparency and control when drawing data-driven inferences about individuals, Big data 5 (3) (2017) 197\u2013212. [238] A. Goldstein, A. Kapelner, J. Bleich, E. Pitkin, Peeking inside the black box: Visualizing statistical learning with plots of individual conditional expectation, Journal of Computational and Graphical Statistics 24 (1) (2015) 44\u201365. [239] G. Casalicchio, C. Molnar, B. Bischl, Visualizing the feature importance for black box models, in: Joint European Conference on Machine Learning and Knowledge Discovery in Databases, Springer, 2018, pp. 655\u2013670. [240] G. Tolomei, F. Silvestri, A. Haines, M. Lalmas, Interpretable predictions of tree-based ensembles via actionable feature tweaking, in: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM, 2017, pp. 465\u2013474. [241] L. Auret, C. Aldrich, Interpretation of nonlinear relationships between process variables by use of random forests, Minerals Engineering 35 (2012) 27\u201342. [242] N. F. Rajani, R. Mooney, Stacking with auxiliary features for visual question answering, in: Proceed- ings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, V olume 1 (Long Papers), 2018, pp. 2217\u20132226. [243] N. F. Rajani, R. J. Mooney, Ensembling visual explanations, in: Explainable and Interpretable Models in Computer Vision and Machine Learning, Springer, 2018, pp. 155\u2013172. [244] H. N \u00b4u\u02dcnez, C. Angulo, A. Catal `a, Rule-based learning systems for support vector machines, Neural Processing Letters 24 (1) (2006) 1\u201318. [245] Z. Chen, J. Li, L. Wei, A multiple kernel support vector machine scheme for feature selection and rule extraction from gene expression data of cancer tissue, Arti?cial Intelligence in Medicine 41 (2) (2007) 161\u2013175. [246] H. N \u00b4u\u02dcnez, C. Angulo, A. Catal `a, Support vector machines with symbolic interpretation, in: VII Brazilian Symposium on Neural Networks, 2002. SBRN 2002. Proceedings., IEEE, 2002, pp. 142\u2013147. [247] P. Sollich, Bayesian methods for support vector machines: Evidence and predictive class probabili- ties, Machine learning 46 (1-3) (2002) 21\u201352. [248] P. Sollich, Probabilistic methods for support vector machines, in: Advances in neural information processing systems, 2000, pp. 349\u2013355. [249] W. Landecker, M. D. Thomure, L. M. Bettencourt, M. Mitchell, G. T. Kenyon, S. P. Brumby, Interpreting individual classi?cations of hierarchical networks, in: 2013 IEEE Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2013, pp. 32\u201338. [250] A. Jakulin, M. Mo ?zina, J. Dem ?sar, I. Bratko, B. Zupan, Nomograms for visualizing support vector machines, in: Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining, ACM, 2005, pp. 108\u2013117. [251] L. Fu, Rule generation from neural networks, IEEE Transactions on Systems, Man, and Cybernetics 24 (8) (1994) 1114\u20131124. [252] G. G. Towell, J. W. Shavlik, Extracting re?ned rules from knowledge-based neural networks, Machine Learning 13 (1) (1993) 71\u2013101. 61[253] S. Thrun, Extracting rules from arti?cial neural networks with distributed representations, in: Proceedings of the 7th International Conference on Neural Information Processing Systems, NIPS\u201994, 1994, pp. 505\u2013512. [254] R. Setiono, W. K. Leow, FERNN: An algorithm for fast extraction of rules from neural networks, Applied Intelligence 12 (1) (2000) 15\u201325. [255] I. A. Taha, J. Ghosh, Symbolic interpretation of arti?cial neural networks, IEEE Transactions on Knowledge and Data Engineering 11 (3) (1999) 448\u2013463. [256] H. Tsukimoto, Extracting rules from trained neural networks, IEEE Transactions on Neural Networks 11 (2) (2000) 377\u2013389. [257] J. R. Zilke, E. L. Menc \u00b4ia, F. Janssen, Deepred\u2013rule extraction from deep neural networks, in: International Conference on Discovery Science, Springer, 2016, pp. 457\u2013473. [258] G. P. J. Schmitz, C. Aldrich, F. S. Gouws, ANN-DT: an algorithm for extraction of decision trees from arti?cial neural networks, IEEE Transactions on Neural Networks 10 (6) (1999) 1392\u20131401. [259] M. Sato, H. Tsukimoto, Rule extraction from neural networks via decision tree induction, in: IJCNN\u201901. International Joint Conference on Neural Networks. Proceedings (Cat. No. 01CH37222), V ol. 3, IEEE, 2001, pp. 1870\u20131875. [260] R. F\u00b4eraud, F. Cl \u00b4erot, A methodology to explain neural network classi?cation, Neural networks 15 (2) (2002) 237\u2013246. [261] A. Shrikumar, P. Greenside, A. Kundaje, Learning Important Features Through Propagating Activation Differences (2017). arXiv:1704.02685 . [262] M. Sundararajan, A. Taly, Q. Yan, Axiomatic attribution for deep networks, in: International Conference on Machine Learning, V ol. 70, JMLR. org, 2017, pp. 3319\u20133328. [263] J. Adebayo, J. Gilmer, I. Goodfellow, B. Kim, Local explanation methods for deep neural networks lack sensitivity to parameter values (2018). arXiv:1810.03307 . [264] N. Papernot, P. McDaniel, Deep k-nearest neighbors: Towards con?dent, interpretable and robust deep learning (2018). arXiv:1803.04765 . [265] J. Li, X. Chen, E. Hovy, D. Jurafsky, Visualizing and understanding neural models in NLP (2015). arXiv:1506.01066 . [266] S. Tan, K. C. Sim, M. Gales, Improving the interpretability of deep neural networks with stimulated learning, in: 2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), IEEE, 2015, pp. 617\u2013623. [267] L. Rieger, C. Singh, W. J. Murdoch, B. Yu, Interpretations are useful: penalizing explanations to align neural networks with prior knowledge (2019). arXiv:arXiv:1909.13584 . [268] A. Nguyen, A. Dosovitskiy, J. Yosinski, T. Brox, J. Clune, Synthesizing the preferred inputs for neurons in neural networks via deep generator networks, in: Advances in Neural Information Processing Systems, 2016, pp. 3387\u20133395. [269] Y . Li, J. Yosinski, J. Clune, H. Lipson, J. E. Hopcroft, Convergent learning: Do different neural networks learn the same representations?, in: ICLR, 2016. 62[270] M. Liu, J. Shi, Z. Li, C. Li, J. Zhu, S. Liu, Towards better analysis of deep convolutional neural networks, IEEE transactions on visualization and computer graphics 23 (1) (2016) 91\u2013100. [271] Y . Goyal, A. Mohapatra, D. Parikh, D. Batra, Towards transparent AI systems: Interpreting visual question answering models (2016). arXiv:1608.08974 . [272] K. Simonyan, A. Vedaldi, A. Zisserman, Deep inside convolutional networks: Visualising image classi?cation models and saliency maps (2013). arXiv:1312.6034 . [273] A. Nguyen, J. Yosinski, J. Clune, Deep neural networks are easily fooled: High con?dence predictions for unrecognizable images, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 427\u2013436. [274] J. Donahue, L. Anne Hendricks, S. Guadarrama, M. Rohrbach, S. Venugopalan, K. Saenko, T. Darrell, Long-term recurrent convolutional networks for visual recognition and description, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 2625\u20132634. [275] M. Lin, Q. Chen, S. Yan, Network in network (2013). arXiv:1312.4400 . [276] L. A. Hendricks, Z. Akata, M. Rohrbach, J. Donahue, B. Schiele, T. Darrell, Generating Visual Explanations (2016). arXiv:1603.08507 . [277] F. Wang, M. Jiang, C. Qian, S. Yang, C. Li, H. Zhang, X. Wang, X. Tang, Residual attention network for image classi?cation, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 3156\u20133164. [278] T. Xiao, Y . Xu, K. Yang, J. Zhang, Y . Peng, Z. Zhang, The application of two-level attention models in deep convolutional neural network for ?ne-grained image classi?cation, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2015, pp. 842\u2013850. [279] Q. Zhang, R. Cao, Y . Nian Wu, S.-C. Zhu, Growing Interpretable Part Graphs on ConvNets via Multi-Shot Learning (2016). arXiv:1611.04246 . [280] L. Arras, G. Montavon, K.-R. M \u00a8uller, W. Samek, Explaining recurrent neural network predictions in sentiment analysis (2017). arXiv:1706.07206 . [281] A. Karpathy, J. Johnson, L. Fei-Fei, Visualizing and understanding recurrent networks (2015). arXiv:1506.02078 . [282] J. Clos, N. Wiratunga, S. Massie, Towards explainable text classi?cation by jointly learning lexicon and modi?er terms, in: IJCAI-17 Workshop on Explainable AI (XAI), 2017, p. 19. [283] S. Wisdom, T. Powers, J. Pitton, L. Atlas, Interpretable recurrent neural networks using sequential sparse recovery (2016). arXiv:1611.07252 . [284] V . Krakovna, F. Doshi-Velez, Increasing the interpretability of recurrent neural networks using hidden markov models (2016). arXiv:1606.05320 . [285] E. Choi, M. T. Bahadori, J. Sun, J. Kulas, A. Schuetz, W. Stewart, Retain: An interpretable predictive model for healthcare using reverse time attention mechanism, in: Advances in Neural Information Processing Systems, 2016, pp. 3504\u20133512. [286] L. Breiman, Classi?cation and regression trees, Routledge, 2017. 63[287] A. Lucic, H. Haned, M. de Rijke, Explaining predictions from tree-based boosting ensembles (2019). arXiv:arXiv:1907.02582 . [288] S. M. Lundberg, G. G. Erion, S.-I. Lee, Consistent individualized feature attribution for tree ensembles (2018). arXiv:arXiv:1802.03888 . [289] C. Bucilu ?a, R. Caruana, A. Niculescu-Mizil, Model compression, in: ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM, 2006, pp. 535\u2013541. [290] R. Traor \u00b4e, H. Caselles-Dupr \u00b4e, T. Lesort, T. Sun, G. Cai, N. D. Rodr \u00b4iguez, D. Filliat, DisCoRL: Continual reinforcement learning via policy distillation (2019). arXiv:1907.05855 . [291] M. D. Zeiler, G. W. Taylor, R. Fergus, et al., Adaptive deconvolutional networks for mid and high level feature learning., in: ICCV , V ol. 1, 2011, p. 6. [292] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, D. Batra, Grad-cam: Visual explanations from deep networks via gradient-based localization, in: Proceedings of the IEEE International Conference on Computer Vision, 2017, pp. 618\u2013626. [293] C. Olah, A. Mordvintsev, L. Schubert, Feature visualization., DistillHttps://distill.pub/2017/feature- visualization (2017). doi:10.23915/distill.00007 . [294] J. Adebayo, J. Gilmer, M. Muelly, I. Goodfellow, M. Hardt, B. Kim, Sanity checks for saliency maps, in: Advances in Neural Information Processing Systems, 2018, pp. 9505\u20139515. [295] C. Olah, A. Satyanarayan, I. Johnson, S. Carter, L. Schubert, K. Ye, A. Mordvintsev, The building blocks of interpretability, Distill (2018). URL https://distill.pub/2018/building-blocks/ [296] Z. Che, S. Purushotham, R. Khemani, Y . Liu, Distilling knowledge from deep networks with applications to healthcare domain (2015). arXiv:1512.03542 . [297] I. Donadello, L. Sera?ni, A. D. Garcez, Logic tensor networks for semantic image interpretation, Proceedings of the Twenty-Sixth International Joint Conference on Arti?cial Intelligence, IJCAI (2017) 1596\u20131602. [298] I. Donadello, Semantic image interpretation-integration of numerical data and logical knowledge for cognitive vision, Ph.D. thesis, University of Trento (2018). [299] A. S. d\u2019Avila Garcez, M. Gori, L. C. Lamb, L. Sera?ni, M. Spranger, S. N. Tran, Neural-symbolic computing: An effective methodology for principled integration of machine learning and reasoning (2019). arXiv:1905.06088 . [300] R. Manhaeve, S. Dumancic, A. Kimmig, T. Demeester, L. De Raedt, DeepProbLog: Neural probabilistic logic programming, in: Advances in Neural Information Processing Systems 31, 2018, pp. 3749\u20133759. [301] I. Donadello, M. Dragoni, C. Eccher, Persuasive explanation of reasoning inferences on dietary data, in: First Workshop on Semantic Explainability @ ISWC 2019, 2019. [302] R. G. Krishnan, U. Shalit, D. Sontag, Deep Kalman Filters (2015). arXiv:1511.05121 . [303] M. Karl, M. Soelch, J. Bayer, P. van der Smagt, Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data (2016). arXiv:1605.06432 . 64[304] M. J. Johnson, D. K. Duvenaud, A. Wiltschko, R. P. Adams, S. R. Datta, Composing graphical models with neural networks for structured representations and fast inference, in: Advances in Neural Information Processing Systems 29, 2016, pp. 2946\u20132954. [305] S. Zheng, S. Jayasumana, B. Romera-Paredes, V . Vineet, Z. Su, D. Du, C. Huang, P. H. Torr, Conditional random ?elds as recurrent neural networks, in: Proceedings of the IEEE international conference on computer vision, 2015, pp. 1529\u20131537. [306] N. Narodytska, A. Ignatiev, F. Pereira, J. Marques-Silva, Learning optimal decision trees with SAT, in: Proceedings of the Twenty-Seventh International Joint Conference on Arti?cial Intelligence, IJCAI-18, 2018, pp. 1362\u20131368. [307] O. Loyola-Gonz \u00b4alez, Black-box vs. white-box: Understanding their advantages and weaknesses from a practical point of view, IEEE Access 7 (2019) 154096\u2013154113. [308] F. Petroni, T. Rocktschel, P. Lewis, A. Bakhtin, Y . Wu, A. H. Miller, S. Riedel, Language models as knowledge bases? (2019). arXiv:1909.01066 . [309] K. Bollacker, N. D \u00b4iaz-Rodr \u00b4iguez, X. Li, Extending knowledge graphs with subjective in?uence networks for personalized fashion, in: E. Portmann, M. E. Tabacchi, R. Seising, A. Habenstein (Eds.), Designing Cognitive Cities, Springer International Publishing, 2019, pp. 203\u2013233. [310] W. Shang, A. Trott, S. Zheng, C. Xiong, R. Socher, Learning world graphs to accelerate hierarchical reinforcement learning (2019). arXiv:1907.00664 . [311] M. Zolotas, Y . Demiris, Towards explainable shared control using augmented reality, 2019. [312] M. Garnelo, K. Arulkumaran, M. Shanahan, Towards deep symbolic reinforcement learning (2016). arXiv:1609.05518 . [313] V . Bellini, A. Schiavone, T. Di Noia, A. Ragone, E. Di Sciascio, Knowledge-aware autoencoders for explainable recommender systems, in: Proceedings of the 3rd Workshop on Deep Learning for Recommender Systems, DLRS 2018, 2018, pp. 24\u201331. [314] C.-Z. A. Huang, A. Vaswani, J. Uszkoreit, N. Shazeer, C. Hawthorne, A. M. Dai, M. D. Hoffman, D. Eck, Music transformer: Generating music with long-term structure (2018). arXiv:1809. 04281 . [315] M. Cornia, L. Baraldi, R. Cucchiara, Smart: Training shallow memory-aware transformers for robotic explainability (2019). arXiv:1910.02974 . [316] A. Aamodt, E. Plaza, Case-based reasoning: Foundational issues, Methodological Variations, and System Approaches 7 (1) (1994) 39\u201359. [317] R. Caruana, Case-based explanation for arti?cial neural nets, in: Arti?cial Neural Networks in Medicine and Biology, Proceedings of the ANNIMAB-1 Conference, 2000, pp. 303\u2013308. [318] M. T. Keane, E. M. Kenny, The Twin-System Approach as One Generic Solution for XAI: An Overview of ANN-CBR Twins for Explaining Deep Learning (2019). arXiv:1905.08069 . [319] T. Hailesilassie, Rule extraction algorithm for deep neural networks: A review (2016). arXiv: 1610.05267 . [320] J. M. Benitez, J. L. Castro, I. Requena, Are arti?cial neural networks black boxes?, IEEE Trans. Neural Networks 8 (5) (1997) 1156\u20131164. 65[321] U. Johansson, R. Knig, L. Niklasson, Automatically balancing accuracy and comprehensibility in predictive modeling, in: Proceedings of the 8th International Conference on Information Fusion, V ol. 2, 2005, p. 7 pp. [322] D. Smilkov, N. Thorat, B. Kim, F. Vi \u00b4egas, M. Wattenberg, SmoothGrad: removing noise by adding noise (2017). arXiv:1706.03825 . [323] M. Ancona, E. Ceolini, C. \u00a8Oztireli, M. Gross, Towards better understanding of gradient-based attribution methods for Deep Neural Networks (2017). arXiv:1711.06104 . [324] J. Yosinski, J. Clune, Y . Bengio, H. Lipson, How transferable are features in deep neural networks? (2014). arXiv:1411.1792 . [325] A. Sharif Razavian, H. Azizpour, J. Sullivan, S. Carlsson, CNN Features off-the-shelf: an Astound- ing Baseline for Recognition (2014). arXiv:1403.6382 . [326] S. Du, H. Guo, A. Simpson, Self-driving car steering angle prediction based on image recognition, Tech. rep., Technical Report, Stanford University (2017). [327] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, A. Torralba, Object Detectors Emerge in Deep Scene CNNs (2014). arXiv:1412.6856 . [328] Y . Zhang, X. Chen, Explainable Recommendation: A Survey and New Perspectives (2018). arXiv:1804.11192 . [329] J. Frankle, M. Carbin, The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks (2018). arXiv:1803.03635 . [330] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, I. Polosukhin, Attention Is All You Need (2017). arXiv:1706.03762 . [331] J. Lu, J. Yang, D. Batra, D. Parikh, Hierarchical question-image co-attention for visual question answering, in: Proceedings of the 30th International Conference on Neural Information Processing Systems, NIPS\u201916, 2016, pp. 289\u2013297. [332] A. Das, H. Agrawal, C. L. Zitnick, D. Parikh, D. Batra, Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions? (2016). arXiv: 1606.03556 . [333] D. Huk Park, L. A. Hendricks, Z. Akata, A. Rohrbach, B. Schiele, T. Darrell, M. Rohrbach, Multimodal Explanations: Justifying Decisions and Pointing to the Evidence (2018). arXiv: 1802.08129 . [334] A. Slavin Ross, M. C. Hughes, F. Doshi-Velez, Right for the Right Reasons: Training Differentiable Models by Constraining their Explanations (2017). arXiv:1703.03717 . [335] I. T. Jolliffe, Principal Component Analysis and Factor Analysis, Springer New York, 1986, pp. 115\u2013128. [336] A. Hyvrinen, E. Oja, Oja, e.: Independent component analysis: Algorithms and applications. neural networks 13(4-5), 411-430, Neural networks 13 (2000) 411\u2013430. [337] M. W. Berry, M. Browne, A. N. Langville, V . P. Pauca, R. J. Plemmons, Algorithms and applications for approximate nonnegative matrix factorization, Computational Statistics & Data Analysis 52 (2007) 155\u2013173. 66[338] D. P. Kingma, M. Welling, Auto-Encoding Variational Bayes (2013). arXiv:1312.6114 . [339] I. Higgins, L. Matthey, A. Pal, C. Burgess, X. Glorot, M. M. Botvinick, S. Mohamed, A. Lerchner, beta-vae: Learning basic visual concepts with a constrained variational framework, in: ICLR, 2017. [340] X. Chen, Y . Duan, R. Houthooft, J. Schulman, I. Sutskever, P. Abbeel, InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets (2016). arXiv: 1606.03657 . [341] Q. Zhang, Y . Yang, Y . Liu, Y . Nian Wu, S.-C. Zhu, Unsupervised Learning of Neural Networks to Explain Neural Networks (2018). arXiv:1805.07468 . [342] S. Sabour, N. Frosst, G. E Hinton, Dynamic Routing Between Capsules (2017). arXiv:1710. 09829 . [343] A. Agrawal, J. Lu, S. Antol, M. Mitchell, C. L. Zitnick, D. Batra, D. Parikh, VQA: Visual Question Answering (2015). arXiv:1505.00468 . [344] A. Fukui, D. Huk Park, D. Yang, A. Rohrbach, T. Darrell, M. Rohrbach, Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding (2016). arXiv:1606. 01847 . [345] D. Bouchacourt, L. Denoyer, EDUCE: explaining model decisions through unsupervised concepts extraction (2019). arXiv:1905.11852 . [346] C. Hofer, M. Denker, S. Ducasse, Design and Implementation of a Backward-In-Time Debugger, in: NODe 2006, V ol. P-88 of Lecture Notes in Informatics, 2006, pp. 17\u201332. [347] C. Rudin, Please stop explaining black box models for high stakes decisions (2018). arXiv: 1811.10154 . [348] A. Diez-Olivan, J. Del Ser, D. Galar, B. Sierra, Data fusion and machine learning for industrial prognosis: Trends and perspectives towards Industry 4.0, Information Fusion 50 (2019) 92\u2013111. [349] R. R. Hoffman, S. T. Mueller, G. Klein, J. Litman, Metrics for explainable ai: Challenges and prospects (2018). arXiv:arXiv:1812.04608 . [350] S. Mohseni, N. Zarei, E. D. Ragan, A multidisciplinary survey and framework for design and evaluation of explainable ai systems (2018). arXiv:arXiv:1811.11839 . [351] R. M. J. Byrne, Counterfactuals in explainable arti?cial intelligence (XAI): Evidence from human reasoning, in: Proceedings of the Twenty-Eighth International Joint Conference on Arti?cial Intelligence, IJCAI-19, 2019, pp. 6276\u20136282. [352] M. Garnelo, M. Shanahan, Reconciling deep learning with symbolic arti?cial intelligence: repre- senting objects and relations, Current Opinion in Behavioral Sciences 29 (2019) 17\u201323. [353] G. Marra, F. Giannini, M. Diligenti, M. Gori, Integrating learning and reasoning with deep logic models (2019). arXiv:1901.04195 . [354] K. Kelley, B. Clark, V . Brown, J. Sitzia, Good practice in the conduct and reporting of survey research, International Journal for Quality in Health Care 15 (3) (2003) 261\u2013266. [355] S. Wachter, B. Mittelstadt, L. Floridi, Why a right to explanation of automated decision-making does not exist in the general data protection regulation, International Data Privacy Law 7 (2) (2017) 76\u201399. 67[356] T. Orekondy, B. Schiele, M. Fritz, Knockoff nets: Stealing functionality of black-box models (2018). arXiv:1812.02766 . [357] S. J. Oh, B. Schiele, M. Fritz, Towards reverse-engineering black-box neural networks, in: Explain- able AI: Interpreting, Explaining and Visualizing Deep Learning, Springer, 2019, pp. 121\u2013144. [358] I. J. Goodfellow, J. Shlens, C. Szegedy, Explaining and harnessing adversarial examples (2014). arXiv:1412.6572 . [359] K. Eykholt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, C. Xiao, A. Prakash, T. Kohno, D. Song, Robust physical-world attacks on deep learning models (2017). arXiv:1707.08945 . [360] I. J. Goodfellow, N. Papernot, P. D. McDaniel, cleverhans v0.1: an adversarial machine learning library (2016). arXiv:1610.00768 . [361] H. Xiao, B. Biggio, B. Nelson, H. Xiao, C. Eckert, F. Roli, Support vector machines under adversarial label contamination, Neurocomputing 160 (C) (2015) 53\u201362. [362] B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. ?Srndi \u00b4c, P. Laskov, G. Giacinto, F. Roli, Evasion attacks against machine learning at test time, in: Proceedings of the 2013th European Conference on Machine Learning and Knowledge Discovery in Databases - V olume Part III, ECMLPKDD\u201913, 2013, pp. 387\u2013402. [363] B. Biggio, I. Pillai, S. R. Bul `o, D. Ariu, M. Pelillo, F. Roli, Is data clustering in adversarial settings secure? (2018). arXiv:1811.09982 . [364] Z. Pan, W. Yu, X. Yi, A. Khan, F. Yuan, Y . Zheng, Recent progress on generative adversarial networks (gans): A survey, IEEE Access 7 (2019) 36322\u201336333. [365] D. Charte, F. Charte, S. Garc \u00b4ia, M. J. del Jesus, F. Herrera, A practical tutorial on autoencoders for nonlinear feature fusion: Taxonomy, models, software and guidelines, Information Fusion 44 (2018) 78\u201396. [366] C. F. Baumgartner, L. M. Koch, K. Can Tezcan, J. Xi Ang, E. Konukoglu, Visual feature attribution using wasserstein gans, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 8309\u20138319. [367] C. Bif?, O. Oktay, G. Tarroni, W. Bai, A. De Marvao, G. Doumou, M. Rajchl, R. Bedair, S. Prasad, S. Cook, et al., Learning interpretable anatomical features through deep generative models: Ap- plication to cardiac remodeling, in: International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer, 2018, pp. 464\u2013471. [368] S. Liu, B. Kailkhura, D. Loveland, Y . Han, Generative counterfactual introspection for explainable deep learning (2019). arXiv:arXiv:1907.03077 . [369] K. R. Varshney, H. Alemzadeh, On the safety of machine learning: Cyber-physical systems, decision sciences, and data products, Big data 5 (3) (2017) 246\u2013255. [370] G. M. Weiss, Mining with rarity: a unifying framework, ACM Sigkdd Explorations Newsletter 6 (1) (2004) 7\u201319. [371] J. Attenberg, P. Ipeirotis, F. Provost, Beat the machine: Challenging humans to ?nd a predictive model\u2019s unknown unknowns, Journal of Data and Information Quality (JDIQ) 6 (1) (2015) 1. [372] G. Neff, A. Tanweer, B. Fiore-Gartland, L. Osburn, Critique and contribute: A practice-based framework for improving critical data studies and data science, Big data 5 (2) (2017) 85\u201397. 68[373] A. Iliadis, F. Russo, Critical data studies: An introduction, Big Data & Society 3 (2) (2016) 2053951716674238. [374] A. Karpatne, G. Atluri, J. H. Faghmous, M. Steinbach, A. Banerjee, A. Ganguly, S. Shekhar, N. Samatova, V . Kumar, Theory-guided data science: A new paradigm for scienti?c discovery from data, IEEE Transactions on Knowledge and Data Engineering 29 (10) (2017) 2318\u20132331. [375] G. Hautier, C. C. Fischer, A. Jain, T. Mueller, G. Ceder, Finding natures missing ternary oxide compounds using machine learning and density functional theory, Chemistry of Materials 22 (12) (2010) 3762\u20133767. [376] C. C. Fischer, K. J. Tibbetts, D. Morgan, G. Ceder, Predicting crystal structure by merging data mining with quantum mechanics, Nature materials 5 (8) (2006) 641. [377] S. Curtarolo, G. L. Hart, M. B. Nardelli, N. Mingo, S. Sanvito, O. Levy, The high-throughput highway to computational materials design, Nature materials 12 (3) (2013) 191. [378] K. C. Wong, L. Wang, P. Shi, Active model with orthotropic hyperelastic material for cardiac image analysis, in: International Conference on Functional Imaging and Modeling of the Heart, Springer, 2009, pp. 229\u2013238. [379] J. Xu, J. L. Sapp, A. R. Dehaghani, F. Gao, M. Horacek, L. Wang, Robust transmural electrophysi- ological imaging: Integrating sparse and dynamic physiological models into ecg-based inference, in: International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer, 2015, pp. 519\u2013527. [380] T. Lesort, M. Seurin, X. Li, N. Daz-Rodrguez, D. Filliat, Unsupervised state representation learning with robotic priors: a robustness benchmark (2017). arXiv:arXiv:1709.05185 . [381] J. Z. Leibo, Q. Liao, F. Anselmi, W. A. Freiwald, T. Poggio, View-tolerant face recognition and hebbian learning imply mirror-symmetric neural tuning to head orientation, Current Biology 27 (1) (2017) 62\u201367. [382] F. Schrodt, J. Kattge, H. Shan, F. Fazayeli, J. Joswig, A. Banerjee, M. Reichstein, G. B \u00a8onisch, S. D\u00b4iaz, J. Dickie, et al., Bhpmf\u2013a hierarchical bayesian approach to gap-?lling and trait prediction for macroecology and functional biogeography, Global Ecology and Biogeography 24 (12) (2015) 1510\u20131521. [383] D. Leslie, Understanding arti?cial intelligence ethics and safety (2019). arXiv:arXiv:1906. 05684 ,doi:10.5281/zenodo.3240529 . [384] C. Rudin, Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead (2018). arXiv:arXiv:1811.10154 . [385] J. Fjeld, H. Hilligoss, N. Achten, M. L. Daniel, J. Feldman, S. Kagay, Principled arti?cial intelli- gence: A map of ethical and rights-based approaches (2019). URL https://ai-hr.cyber.harvard.edu/images/primp-viz.pdf [386] R. Benjamins, A. Barbado, D. Sierra, Responsible AI by design (2019). arXiv:1909.12838 . [387] United-Nations, Transforming our world: the 2030 agenda for sustainable development, Tech. rep., eSocialSciences (2015). URL https://EconPapers.repec.org/RePEc:ess:wpaper:id:7559 69[388] G. D. Hager, A. Drobnis, F. Fang, R. Ghani, A. Greenwald, T. Lyons, D. C. Parkes, J. Schultz, S. Saria, S. F. Smith, M. Tambe, Arti?cial intelligence for social good (2019). arXiv:arXiv: 1901.05406 . [389] B. C. Stahl, D. Wright, Ethics and privacy in ai and big data: Implementing responsible research and innovation, IEEE Security & Privacy 16 (3) (2018) 26\u201333. [390] High Level Expert Group on Arti?cial Intelligence, Ethics guidelines for trustworthy ai, Tech. rep., European Commission (2019). [391] B. d\u2019Alessandro, C. O\u2019Neil, T. LaGatta, Conscientious classi?cation: A data scientist\u2019s guide to discrimination-aware classi?cation, Big data 5 (2) (2017) 120\u2013134. [392] S. Barocas, A. D. Selbst, Big data\u2019s disparate impact, Calif. L. Rev. 104 (2016) 671. [393] M. Hardt, E. Price, N. Srebro, et al., Equality of opportunity in supervised learning, in: Advances in neural information processing systems, 2016, pp. 3315\u20133323. [394] T. Speicher, H. Heidari, N. Grgic-Hlaca, K. P. Gummadi, A. Singla, A. Weller, M. B. Zafar, A uni?ed approach to quantifying algorithmic unfairness: Measuring individual group unfairness via inequality indices, in: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery Data Mining, ACM, 2018, pp. 2239\u20132248. [395] F. Kamiran, T. Calders, Data preprocessing techniques for classi?cation without discrimination, Knowledge and Information Systems 33 (1) (2012) 1\u201333. [396] R. Zemel, Y . Wu, K. Swersky, T. Pitassi, C. Dwork, Learning fair representations, in: International Conference on Machine Learning, 2013, pp. 325\u2013333. [397] B. H. Zhang, B. Lemoine, M. Mitchell, Mitigating unwanted biases with adversarial learning, in: Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society, ACM, 2018, pp. 335\u2013340. [398] Y . Ahn, Y .-R. Lin, Fairsight: Visual analytics for fairness in decision making, IEEE transactions on visualization and computer graphics (2019). [399] E. Soares, P. Angelov, Fair-by-design explainable models for prediction of recidivism, arXiv preprint arXiv:1910.02043 (2019). [400] J. Dressel, H. Farid, The accuracy, fairness, and limits of predicting recidivism, Science advances 4 (1) (2018) eaao5580. [401] U. Aivodji, H. Arai, O. Fortineau, S. Gambs, S. Hara, A. Tapp, Fairwashing: the risk of rationaliza- tion, in: International Conference on Machine Learning, 2019, pp. 161\u2013170. [402] S. Sharma, J. Henderson, J. Ghosh, Certifai: Counterfactual explanations for robustness, transparency, interpretability, and fairness of arti?cial intelligence models, arXiv preprint arXiv:1905.07857 (2019). [403] M. Drosou, H. Jagadish, E. Pitoura, J. Stoyanovich, Diversity in big data: A review, Big data 5 (2) (2017) 73\u201384. [404] J. Lerman, Big data and its exclusions, Stan. L. Rev. Online 66 (2013) 55. [405] R. Agrawal, S. Gollapudi, A. Halverson, S. Ieong, Diversifying search results, in: Proceedings of the second ACM international conference on web search and data mining, ACM, 2009, pp. 5\u201314. 70[406] B. Smyth, P. McClave, Similarity vs. diversity, in: International conference on case-based reasoning, Springer, 2001, pp. 347\u2013361. [407] P. Wang, L. T. Yang, J. Li, J. Chen, S. Hu, Data fusion in cyber-physical-social systems: State-of- the-art and perspectives, Information Fusion 51 (2019) 42\u201357. [408] W. Ding, X. Jing, Z. Yan, L. T. Yang, A survey on data fusion in internet of things: Towards secure and privacy-preserving fusion, Information Fusion 51 (2019) 129\u2013144. [409] A. Smirnov, T. Levashova, Knowledge fusion patterns: A survey, Information Fusion 52 (2019) 31\u201340. [410] W. Ding, X. Jing, Z. Yan, L. T. Yang, A survey on data fusion in internet of things: Towards secure and privacy-preserving fusion, Information Fusion 51 (2019) 129\u2013144. [411] P. Wang, L. T. Yang, J. Li, J. Chen, S. Hu, Data fusion in cyber-physical-social systems: State-of- the-art and perspectives, Information Fusion 51 (2019) 42\u201357. [412] B. P. L. Lau, S. H. Marakkalage, Y . Zhou, N. U. Hassan, C. Yuen, M. Zhang, U.-X. Tan, A survey of data fusion in smart city applications, Information Fusion 52 (2019) 357\u2013374. [413] S. Ram \u00b4irez-Gallego, A. Fern \u00b4andez, S. Garc \u00b4ia, M. Chen, F. Herrera, Big data: Tutorial and guidelines on information and process fusion for analytics algorithms with mapreduce, Information Fusion 42 (2018) 51\u201361. [414] J. Kone ?cn\u00b4y, H. B. McMahan, D. Ramage, P. Richtrik, Federated optimization: Distributed machine learning for on-device intelligence (2016). arXiv:1610.02527 . [415] B. McMahan, E. Moore, D. Ramage, S. Hampson, B. A. y Arcas, Communication-ef?cient learning of deep networks from decentralized data, in: Arti?cial Intelligence and Statistics, 2017, pp. 1273\u20131282. [416] J. Kone ?cn`y, H. B. McMahan, F. X. Yu, P. Richt \u00b4arik, A. T. Suresh, D. Bacon, Federated learning: Strategies for improving communication ef?ciency (2016). arXiv:1610.05492 . [417] S. Sun, A survey of multi-view machine learning, Neural computing and applications 23 (7-8) (2013) 2031\u20132038. [418] R. Zhang, F. Nie, X. Li, X. Wei, Feature selection with multi-view data: A survey, Information Fusion 50 (2019) 158\u2013167. [419] J. Zhao, X. Xie, X. Xu, S. Sun, Multi-view learning overview: Recent progress and new challenges, Information Fusion 38 (2017) 43\u201354. [420] S. J. Oh, R. Benenson, M. Fritz, B. Schiele, Faceless person recognition: Privacy implications in social media, in: Computer Vision - ECCV 2016 - 14th European Conference, Amsterdam, Proceedings, Part III, 2016, pp. 19\u201335. [421] P. Aditya, R. Sen, P. Druschel, S. Joon Oh, R. Benenson, M. Fritz, B. Schiele, B. Bhattacharjee, T. T. Wu, I-pic: A platform for privacy-compliant image capture, in: Proceedings of the 14th annual international conference on mobile systems, applications, and services, ACM, 2016, pp. 235\u2013248. [422] Q. Sun, A. Tewari, W. Xu, M. Fritz, C. Theobalt, B. Schiele, A hybrid model for identity obfuscation by face replacement, in: Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp. 553\u2013569. 71[423] X. L. Dong, D. Srivastava, Big data integration, in: 2013 IEEE 29th international conference on data engineering (ICDE), IEEE, 2013, pp. 1245\u20131248. [424] D. Zhang, J. Zhao, F. Zhang, T. He, comobile: Real-time human mobility modeling at urban scale using multi-view learning, in: Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM, 2015, p. 40. [425] S. J. Pan, Q. Yang, A survey on transfer learning, IEEE Transactions on knowledge and data engineering 22 (10) (2009) 1345\u20131359. [426] M. Mitchell, S. Wu, A. Zaldivar, P. Barnes, L. Vasserman, B. Hutchinson, E. Spitzer, I. D. Raji, T. Gebru, Model cards for model reporting, in: Proceedings of the Conference on Fairness, Accountability, and Transparency, ACM, 2019, pp. 220\u2013229. 72", "8": "11 https://e-heartfailure.orgABSTRACT The prevalence of heart failure (HF) is increasing, necessitating accurate diagnosis and tailored  treatment. The accumulation of clinical information from patients with HF generates big data,  which poses challenges for traditional analytical methods. To address this, big data approaches  and artificial intelligence (AI) have been developed that can effectively predict future observa - tions and outcomes, enabling precise diagnoses and personalized treatments of patients with  HF. Machine learning (ML) is a subfield of AI that allows computers to analyze data, find pat - terns, and make predictions without explicit instructions. ML can be supervised, unsupervised,  or semi-supervised. Deep learning is a branch of ML that uses artificial neural networks with  multiple layers to find complex patterns. These AI technologies have shown significant poten - tial in various aspects of HF research, including diagnosis, outcome prediction, classification of  HF phenotypes, and optimization of treatment strategies. In addition, integrating multiple data  sources, such as electrocardiography, electronic health records, and imaging data, can enhance  the diagnostic accuracy of AI algorithms. Currently, wearable devices and remote monitoring  aided by AI enable the earlier detection of HF and improved patient care. This review focuses on  the rationale behind utilizing AI in HF and explores its various applications. Keywords:  Heart failure; Artificial intelligence; Machine learning; Deep learning; Big data INTRODUCTION The prevalence of heart failure (HF) is increasing,1,2) along with the complexity of its treatment  and diagnosis. The accurate diagnosis of HF relies on various invasive and noninvasive tests,  and tailored treatment is based on the characteristics and type of HF.3-6) The diagnosis and  management of patients with HF require a substantial amount of clinical information, leading  to the accumulation of big data. However, traditional analytical methods are insufficient for  handling large datasets.7,8) Consequently, the significance of big data approaches and artificial intelligence (AI) in med - icine has grown.9) This review discusses the role of AI in HF. We focused on traditional risk  factors, electrocardiography (ECG), electronic health records (EHRs), and telemonitoring, Int J Heart Fail. 2024 Jan;6(1):11-19 https://doi.org/10.36628/ijhf.2023.0050 pISSN 2636-154X\u00b7eISSN 2636-1558 Review Article Received:  Sep 5, 2023 Revised:  Nov 24, 2023 Accepted:  Nov 26, 2023 Published online:  Nov 30, 2023 Correspondence to Dong-Ju Choi, MD, PhD Cardiovascular Center, Seoul National  University Bundang Hospital, Seoul National  University College of Medicine, 82 Gumi-ro  173-beon-gil, Bundang-gu, Seongnam 13620,  Korea. Email: djchoi@snubh.org *Minjae Yoon and Jin Joo Park contributed  equally to this work and share first authorship. Copyright \u00a9 2024. Korean Society of Heart  Failure This is an Open Access article distributed  under the terms of the Creative Commons  Attribution Non-Commercial License ( https:// creativecommons.org/licenses/by-nc/4.0 )  which permits unrestricted noncommercial  use, distribution, and reproduction in any  medium, provided the original work is properly  cited.Minjae Yoon , MD1,*, Jin Joo Park , MD, PhD1,*, Taeho Hur , PhD1,2,   Cam-Hao Hua , PhD2, Musarrat Hussain , PhD2, Sungyoung Lee , PhD2, and  Dong-Ju Choi , MD, PhD1 1 Division of Cardiology, Department of Internal Medicine, Seoul National University Bundang Hospital,  Seoul National University College of Medicine, Seongnam, Korea 2Department of Computer Science and Engineering, Kyung Hee University, Yongin, KoreaApplication and Potential of Artificial  Intelligence in Heart Failure: Past,  Present, and Futureand excluded each detailed imaging modality (cardiac magnetic  resonance image, echocardiography, nuclear imaging, etc.). IMPORTANCE OF BIG DATA  APPROACHES IN HF The era of big data is upon us, a term that refers to the explo - sion of available information. Enormous amounts of extremely  high-dimensional or unstructured data are being produced and  stored at a much lower cost than ever before, driving the big data  movement. The main goal of analyzing such high-dimensional  data is to develop effective methods for accurately predicting  future observations and results.10) However, the large sample size  and high dimensionality of big data introduce unique computa - tional and statistical challenges, necessitating the development  of new paradigms and analysis techniques.11) These innovations  aim to address issues such as data noise, erroneous correlations,  and computational power constraints.11) One common objective  of computational methods is feature or dimension reduction.12)  Statistical learning and modeling are frequently employed to  estimate populations (inference) or predict future experiments  after preprocessing and performing possible dimension reduc - tion. These analyses frequently rely on AI and machine learning  (ML), which are algorithms that can perform computational  tasks without specific user instructions.13) HF is an important target for big data research because of its  complex etiology, numerous comorbidities, and the prolonged  and progressive course of the disease.7,14) The 2 most popular big  data types used in HF research are clinical data and omics. Clini - cal data are collected using various means such as imaging meth - ods, echocardiography, ECG, wearables, and EHRs. In contrast,  the omics technologies, including genomics, transcriptomics,  proteomics, and metabolomics, are primarily used for analyzing  heart tissue or blood samples.7,15) However, the accuracy, struc - ture, and volume of omics and clinical data present challenges  for data analysis.16) To advance biological comprehension and  clinical care of patients with HF, both conventional statistical  methods and ML approaches are employed to gather critical in - sights from big data sources. APPLICATION OF AI IN HF Concept of AI, ML, and deep learning (DL) AI is defined as the intelligence of a computer or machine that en - ables it to imitate or mimic human capabilities.17,18) This technol - ogy can make decisions without requiring human intervention. ML is a subfield of AI that empowers computers to analyze data  beyond programmatic procedures, identify patterns within the  data, apply learned patterns to new data, and perform computa - tional tasks more effectively than humans.19) Traditional statistical methods and ML have several distinct and  overlapping characteristics.20) High-dimensional datasets with  numerous variables present a challenge for traditional statistical  techniques, such as regression, whereas ML methods are well  suited to handle such complex data. Moreover, ML can evaluate  intricate connections between predictors and handle correlated  or collinear data. To accommodate temporal changes in data,  ML can generate dynamic models that are continuously updated  using new training data. For instance, \u201cbaseline\u201d features, such  as vital signs, laboratory results, and comorbidities, may change  over time. Although the evolution of these traits may be crucial  for outcome prediction, conventional statistical tools are fre - quently ill-equipped to handle them.20) ML algorithms offer the  ability to calculate nonlinear relationships more effectively and  precisely; however, their higher accuracy comes at the expense  of interpretability.21) There are 3 primary/representative methods in ML: supervised,  unsupervised, and semi-supervised learning ( Figure 1 ).20,22) Su- pervised ML is characterized by the use of human-labeled data - sets that are intended to \u201csupervise\u201d or \u201ctrain\u201d algorithms to  correctly classify data or predict outcomes. In contrast, unsuper - vised ML is used to analyze and group unlabeled datasets, uncov - ering hidden patterns in the data without human intervention.  Semi-supervised is a method that combines both supervised and  unsupervised methods with limited labeled datasets and unla - beled datasets, where the unlabeled datasets are grouped with  labeled datasets based on their traits. In the field of cardiovascu - lar medicine, ML can uncover disease mechanisms and increase  the precision of diagnosis, management, and risk prediction by  identifying clinically relevant patterns or phenotypes that may  not be apparent to clinicians.23) In fact, algorithms such as re - gression, decision trees, random forest, support vector machine,  na\u00efve Bayes, K-Nearest neighbors, and extreme gradient boost - ing are commonly used to analyze medical data. DL is a subset of ML that uses multiple layers of artificial neural  networks to discover or predict patterns.24) It mimics the operation  of the human brain and was originally developed by Dr. Warren  McCulloch (neuroscientist) and Walter Pitts (computer scientist)  in 1943 as the \u201cMcCulloch-Pitts (MP) neuron.\u201d25) MP neurons are  structured similarly to brain neurons. Similar to the dendrites of  neurons, they receive external data, perform calculations in the  nucleus, and output the results as binary signals (1 or 0) that are  12Role of AI in Heart Failure https://doi.org/10.36628/ijhf.2023.0050 https://e-heartfailure.orgtransmitted through the axons. When these neurons are con - nected, they create a neural network structure that resembles  that of the human brain. Recently, the computational power of  MP neurons has advanced, and they are referred to as \u201cPercep - tron.\u201d With significant advancements in computing power, brain  neural networks have also become more complex, evolving into  widely used DL models, such as deep neural networks and CNN  (Figure 2 ).DL is especially helpful when handling big data sources, such as  EHRs, because it is less dependent on feature engineering or vari - able selection. Overall, DL is compelling in image recognition26)  and modeling disease onset27) using temporal relations among  events. DL models can predict incident HF by analyzing the tem - poral relationships among a large number of evolving variables  such as comorbidities, physiological measurements, laboratory  indices, medication prescriptions, and invasive procedures.28) 13Role of AI in Heart Failure https://doi.org/10.36628/ijhf.2023.0050 https://e-heartfailure.org Machine learning Supervised learning Classi?cation  Regression  Clustering Dimensionality reduction Classi?cation Na\u00efve Bayes  AdaBoost Gaussian mixture model Autoencoders  Co-training Nearest neighbor  Bayesian network Hidden markov model t-SNE  Multi-view learning Neural networks  Neural networks  Neural networks  UMAP  S/three.LPVM Regression Support vector machine Linear regression, GLM K-Means, K-Medoids, Fuzzy C-Means Principal component analysis Label propagation Multi-instance regression Discriminant analysis SVR, GPR  Hierarchical Linear discriminant analysis Self-training Transductive regression Unsupervised learning Semi-supervised learning Figure 1.  Classification of machine learning.   GLM = generalized linear model; SVR = support vector regression; GPR = ground penetrating radar; t-SNE = t-Distributed Stochastic Neighbor Embedding; UMAP  = Uniform Manifold Approximation and Projection; S3VM = Semi-Supervised Support Vector Machines. <Perceptron> <Neural network> <Deep neural network (DNN)>Input layer Hidden layer /one.LP Hidden layer /two.LPOutput layer Figure 2.  Evolution of deep learning.Recently, generative AI has emerged as a great innovation in the  domain of digital health ( Figure 3 ). Generative AI is an AI that can  generate novel content, such as creating unique and high-quality  images or original writing, rather than solving traditional regres - sion or classification problems.29) For example, ChatGPT, which  was released to the general public about a year ago, can efficiently  understand queries from humans and responds to complex ques - tions, and even create a script or a source code. Its versatile ap - plications have far-reaching implications for improving patient  care and advancing medical research. One of the key applications  of generative AI is in the medical imaging. Utilizing advanced al - gorithms such as Generative Adversarial Networks (GANs) and  Variational Autoencoders, these models excel in generating syn - thetic medical images, including X-ray, computed tomography,  and magnetic resonance images. As a result, they facilitate the  development of more accurate and robust medical imaging sys - tems.30) Research was conducted to find if an ML model could  correctly capture the characteristics of congestive heart failure  (CHF).31) Unlike other diseases, such as lung cancer, where the  characteristics can be found in the local area, CHF characteris - tics are widespread, making them difficult to detect. The authors  have created a synthesized image utilizing the Wasserstein GAN  model, by subtracting the features from the healthy image with  the diseased image, and adding them to the original image. Veri - fied by both ML model and radiologist, the model has well reflect - ed the features of CHF in the synthesized image, proving both  the performance of the model and the usability of generative AI  model. Additionally, the digitization of EHRs benefits from gen - erative AI, particularly in the context of natural language process - ing. These models proficiently generate and summarize patient  notes, extract structured information from unstructured clini - cal text, and automate data entry into EHR systems, ultimately  saving valuable time for healthcare professionals.32) Diagnosis of HF Even for HF specialists, correctly diagnosing HF can be challeng - ing because it is a complex syndrome caused by both structur - al and functional cardiac disorders rather than a single disease entity. A classic example is leg edema, a common symptom of  right-sided heart congestion. However, it can also develop in  numerous alternative conditions, such as chronic venous in - sufficiency, chronic kidney disease, and drug side effects. Con - sequently, in clinical practice, many patients are misdiagnosed  with HF and vice versa. In addition, contemporary physicians  face difficulties in keeping up with the rapidly evolving scientific  evidence, new medications, time constraints, and complexity of  HF management guidelines, particularly in outpatient clinics. AI  algorithms could help physicians identify HF in at-risk patients  early and develop an AI-Clinical Decision Support System (AI- CDSS) ( Figure 4 ).23,33-35) AI-CDSS is a scalable and flexible medical  assistant platform for different types of diseases. AI-CDSS con - sists of a total of 5 layers: Data Acquisition and Persistence Layer,  Context Recognition and Monitoring Layer, Knowledge Acquisi - tion and Inferencing Layer, Engineering Support Layer, and User  Interface Management Layer. The third layer, Knowledge Acquisi - tion and Inferencing Layer, creates hybrid knowledge models by  combining rule generated from data such as images and text, and  with rules created by experts and automatically evolve knowledge  over time. Choi et al.35) developed and evaluated the diagnostic ac - curacy of the AI-CDSS for HF. It demonstrated a remarkable diag - nostic accuracy of 98% for HF diagnosis, which was higher than  that of non-HF specialists (76%). This suggests that the AI-CDSS  could prove particularly useful for diagnosing HF, especially in  situations where access to HF specialists is limited. ECG is a non-invasive and simple diagnostic tool that is widely  used in health checkups. Previous studies have shown a signifi - cant association between HF and ECG.36-40) Attia et al.38) showed  that the application of AI to ECG can be a powerful screening tool  to identify left ventricular dysfunction in asymptomatic individu - als. To achieve high accuracy, Kwon et al.41) analyzed 55,163 ECGs  of 22,765 patients and developed a deep-learning algorithm for  ECG-based HF identification. Compared to logistic regression  and random forest ML algorithms, the DL algorithm showed  superior effectiveness in identifying HF with a reduced ejection  fraction (area under the curve, 0.843; 95% confidence interval,  14Role of AI in Heart Failure https://doi.org/10.36628/ijhf.2023.0050 https://e-heartfailure.org Stages of arti?cial intelligence for HF Pre-AI (Manual) Traditional ML  Deep learning  Generative AI \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7/one.LP/nine.LP/five.LP/zero.LP/endash.cap/one.LP/nine.LP/six.LP/zero.LP /one.LP/nine.LP/six.LP/zero.LP/endash.cap/two.LP/zero.LP/one.LP/zero.LP /two.LP/zero.LP/one.LP/zero.LP/endash.cap/two.LP/zero.LP/two.LP/zero.LP /two.LP/zero.LP/two.LP/zero.LP/endash.cap/periodcentered.cap/periodcentered.cap/periodcentered.cap Figure 3.  Stages of AI for HF.   AI = artificial intelligence; HF = heart failure; ML = machine learning.0.840\u20130.845). In addition, the DL model applied to ECG was  shown to have a high performance in the detection of HF with  preserved ejection fraction (HFpEF).39,42) Prediction of HF outcomes HF is the leading cause of hospitalization in people aged 65 years  and older.43) Moreover, patients with HF have a high risk of re - admission, especially immediately after discharge.44) Therefore,  risk stratification is important for HF, and ML can be particularly  valuable in predicting readmission for these patients. Golas et  al.45) showed that DL techniques outperformed traditional tech - niques in predicting 30-day readmission in patients with HF.  Furthermore, Kwon et al.46) showed that a DL-based algorithm  predicted in-hospital mortality and long-term mortality more  accurately than the existing scores, including the Get with the  Guidelines-Heart Failure Score (GWTG) and Meta-Analysis  Global Group for Heart Failure (MAGGIC) score. This might be  because DL algorithms do not restrict the number of input or fea - tures without limiting to those with established associations or  biologically plausible rationales. Cardiac monitoring data can be used to develop risk prediction al - gorithms. In a cohort study of 900 patients, data from implanted cardiac resynchronization therapy (CRT) were collected.47) The  alert algorithm used heart sounds, respiratory rate, tidal volume,  heart rate, and patient activity to provide a sensitive and timely  predictor of impending HF decompensation. Classification of HF phenotypes and treatment The present HF classification may be enhanced using ML. Phe - notype mapping was performed in a prospective trial with 397  ambulatory patients with HFpEF using ML algorithms and data  from EHRs.48) A novel classification method for HFpEF was cre - ated using this technique, which grouped study participants into  phenotypes based on their clinical traits, echocardiographic pa - rameters, ECG, invasive hemodynamics, and outcomes. Anoth - er unsupervised ML analysis of 1,693 hospitalized patients with  HF across the left ventricular ejection fraction (LVEF) spectrum  identified 6 distinct phenogroups based on the common comor - bidities: coronary artery disease, valvular heart disease, atrial  fibrillation, chronic obstructive pulmonary disease, obstructive  sleep apnea, or a few comorbidities.49) This grouping stratified  the cardiovascular risk more effectively than LVEF. ML algorithms can be used to improve HF treatment by assessing  the heterogeneity of the response to HF therapies. Ahmad et al.50)  15Role of AI in Heart Failure https://doi.org/10.36628/ijhf.2023.0050 https://e-heartfailure.org HF diagnosis services ? Disease diagnosis ? Follow-up & AnalyticsRisk prediction services ? Severity risk prediction ? Re-admission and mortality predictionHF monitoring services ? ECG monitoring ? Blood pressure monitoring? Glucose monitoring ? Delirium monitoring UI management layer UI development environment Feedback module Knowledge acquisition and inferencing layer Knowledge evolution and inferencingKnowledge hybridizationStructured knowledge acquisitionDescriptive knowledge acquisitionImage-based knowledge acquisitionEngineering support layer Knowledge engineering tool Evidence support Context recognition and monitoring layer High level context recognizer Low level context recognizer Patient monitoring module Data acquisition and persistence layer Big data storage processing Log repositoryMultimodal data acquisition and processingAI-CDSS platform Figure 4.  Hybrid AI-CDSS (expert system and machine learning) for diagnosis of heart failure.   AI-CDSS = Artificial Intelligence-Clinical Decision Support System; HF = heart failure; ECG = electrocardiography; UI = user interface.studied 44,886 patients with HF in the Swedish HF registry, and  utilized ML to classify patients into 4 subgroups based on their  response to therapeutics and 1-year survival rates. This stratifi - cation allowed the identification of those most likely to benefit  from guideline-directed medical therapy.51) ML can be used to  prioritize patients who are most likely to benefit from interven - tions to optimize evidence-based therapies.52) Moreover, ML  algorithms can assist clinicians in determining optimal sequenc - ing and dosing of evidence-based therapies.53) Furthermore, ML has a potential role in optimizing patient se - lection for HF device therapy. In general, one-third of patients  with HF are non-responders to CRT.54) A post-hoc analysis of the  Multicenter Automatic Defibrillator Implantation Trial with CRT  demonstrated that ML algorithms, by integrating clinical param - eters and cardiac cycle imaging data, could classify a phenotyp - ically heterogeneous HF cohort into 4 distinct phenotypes, thus  potentially optimizing the response rate to CRT.55) Implantable  cardioverter defibrillators (ICDs) reduce the risk of sudden cardiac  death in patients with HF. One study showed that unsupervised  ML-based phenomapping could identify distinct phenotype sub - groups in patients with clinically heterogeneous HF receiving sec - ondary prophylactic ICD therapy, thus aiding the implementation  of personalized medicine for these patients.56) Shakibfar et al.57) re- vealed that ML using daily summaries of ICD measurements in the  absence of clinical information could predict the short-term risk  of electrical storms. In addition, a DL model can assist in selecting  patients with HF that are eligible for subcutaneous ICD.58,59) Multiple data sources, remote monitoring, and  wearable devices AI serves as an essential tool to help physicians improve their clin - ical judgment and achieve precise diagnoses of diseases such as  HF.60) To detect and diagnose HF, multiple data sources (e.g., ECG,  EHRs, and imaging data [echocardiography and cardiac magnetic  resonance imaging]) are integrated, and further AI algorithms are  developed to improve the diagnostic accuracy. Ongoing research is  focused on areas such as ECG analysis, natural language process - ing for EHR data mining, and echocardiography image analysis.  Cho et al.61) showed that HF with a reduced ejection fraction could  be screened not only with a 12-lead ECG, but also with a single-lead  ECG performed by a wearable device using an AI algorithm. By in - corporating such algorithms, AI can be of great assistance in ana - lyzing raw imaging data from cardiac imaging techniques.60) With the increasing amount of data from remote monitoring  and wearable devices, the role of AI is expanding.62) Kwon et al.63)  showed that an AI-enabled smartwatch with a 2-lead ECG detected  HF with reduced ejection fraction with acceptable performance. The LINK-HF (Multisensor Non-invasive Remote Monitoring for  Prediction of Heart Failure Exacerbation) study evaluated the per - formance of a personalized analysis platform using continuous  data streams to predict rehospitalization after HF admission.64)  This study showed that physiological telemetry from a wearable  sensor could provide accurate early detection of impending rehos - pitalization. In the future, the use of wearable devices or remote  monitoring is expected to enable the earlier detection of HF. LIMITATIONS OF AI IN HF However, there are several limitations in the widespread use of  AI in cardiovascular medicine. Dichotomy and improper cali - bration are recognized issues in ML techniques based on AI.23)  The performance of ML models can be compromised by inaccu - rate or missing training data.65) This is especially true when ML  algorithms rely on continuous data inputs, such as EHRs. For  accurate predictions, data must be cleansed and validated by de - tecting out-of-range values and skewness.65) Missing data can be  filled in using ML algorithms and techniques while maintaining  the algorithm performance.66) In addition, an obvious situation in visual-based diagnosis and  predictive tasks (e.g., segmentation of the left ventricle endocar - dium, epicardium, and left atrium regions in echocardiography  for providing fine-grained cardiac information) is the limited  availability of well-annotated imaging data owing to expensive  labor costs and time consumption. Furthermore, ML and DL al - gorithms are vulnerable to domain shift issues, wherein diagnos - tic or predictive outcomes may be adversely affected by inherent  differences in distribution between the trained and applied data - sets (e.g., those collected and combined from various hospitals  with different configurations of data-capturing machines). Thus,  external validation is crucial in medical AI. Another drawback is the opaque reasoning and lack of explain - ability that underlie an ML model\u2019s output of a specific pre - diction, especially when using DL algorithms because many  physicians are skeptical of recommendations generated by a  \u201cblack box\u201d algorithm. False prediction due to wrong data based  training rises a critical problem in the medical field. In an im - age-based prediction, a slight manipulation of an image or noise  leads to a different conclusion,67-69) and in text-based prediction,  hallucination problem arises that the DL algorithm believes the  prediction is correct, which is misled by wrong input data.70,71) In  addition, the failure to evaluate the clinical impact of ML algo - rithms in prospective studies, which makes the benefits of ML  approaches hypothetical, is one of the biggest obstacles to their  16Role of AI in Heart Failure https://doi.org/10.36628/ijhf.2023.0050 https://e-heartfailure.orgadoption.9) There is an increasing need for prospective AI valida - tion studies to address these limitations. Lastly, there have been  recent issues with the use of patient data, particularly protected  health information. CONCLUSION Nowadays, big data approaches, AI, ML, and DL are widely used  in the field of HF. AI algorithms can help in the diagnosis and  classification of HF and predict the prognosis and therapeutic  response. Various data, including ECG, echocardiography, and  EHRs, are used in AI. In addition, the integration of data from  remote monitoring and wearable devices has expanded the po - tential applications of AI in HF. The incorporation of AI tools  is expected to revolutionize HF management and significantly  impact patient outcomes, thereby enabling more precise and  personalized care of patients with HF ( Figure 5 ). ORCID iDs Minjae Yoon  https://orcid.org/0000-0003-4209-655X Jin Joo Park  https://orcid.org/0000-0001-9611-1490 Taeho Hur  https://orcid.org/0000-0001-7458-3745 Cam-Hao Hua  https://orcid.org/0000-0002-2556-4991 Musarrat Hussain  https://orcid.org/0000-0003-4494-1593 Sungyoung Lee  https://orcid.org/0000-0002-5962-1587 Dong-Ju Choi  https://orcid.org/0000-0003-0146-2189 Funding This research was supported by a grant of the Korea Health Technology R&D Project  through the Korea Health Industry Development Institute (KHIDI), funded by the  Ministry of Health & Welfare, Republic of Korea (grant number: HI21C1074).Conflict of Interest Jin Joo Park, serves as an associate editor of the International Journal of Heart  Failure , but has no role in the decision to publish this article. Except for that, no  potential conflict of interest relevant to this article was reported. Author Contributions Conceptualization: Yoon M, Park JJ, Hur T, Hua CH, Hussain M, Lee S, Choi DJ; Data  curation: Yoon M, Park JJ, Hur T, Hua CH, Hussain M, Lee S, Choi DJ; Funding acquisi - tion: Choi DJ; Investigation: Yoon M, Park JJ, Hur T, Hua CH, Hussain M, Lee S, Choi DJ;  Methodology: Yoon M, Park JJ, Hur T, Hua CH, Hussain M, Lee S, Choi DJ; Project ad - ministration: Yoon M, Park JJ, Lee S, Choi DJ; Supervision: Lee S, Choi DJ; Visualization:  Yoon M, Park JJ, Hur T, Hua CH, Hussain M, Choi DJ; Writing - original draft: Yoon M;  Writing - review & editing: Yoon M, Park JJ, Hur T, Hua CH, Hussain M, Lee S, Choi DJ. REFERENCES  1. Conrad N, Judge A, Tran J, et al. Temporal trends and patterns in heart  failure incidence: a population-based study of 4 million individuals.  Lancet 2018;391:572-80.     PUBMED  | CROSSREF  2. Park JJ, Lee CJ, Park SJ, et al. Heart failure statistics in Korea, 2020:  a report from the Korean Society of Heart Failure. Int J Heart Fail  2021;3:224-36.     PUBMED  | CROSSREF  3. Heidenreich PA, Bozkurt B, Aguilar D, et al. 2022 AHA/ACC/HFSA  guideline for the management of heart failure: a report of the American  College of Cardiology/American Heart Association joint committee  on clinical practice guidelines. J Am Coll Cardiol 2022;79:e263-421.      PUBMED  | CROSSREF  4. McDonagh TA, Metra M, Adamo M, et al. Corrigendum to: 2021 ESC  guidelines for the diagnosis and treatment of acute and chronic heart  failure: developed by the task force for the diagnosis and treatment of  acute and chronic heart failure of the European Society of Cardiology  (ESC) with the special contribution of the Heart Failure Association  (HFA) of the ESC. Eur Heart J 2021;42:4901.     PUBMED  | CROSSREF  5. Cho JY, Cho DH, Youn JC, et al. Korean Society of Heart Failure  guidelines for the management of heart failure: definition and  diagnosis. Int J Heart Fail 2023;5:51-65.     PUBMED  | CROSSREF  6. Youn JC, Kim D, Cho JY, et al. Korean Society of Heart Failure  guidelines for the management of heart failure: treatment. Int J Heart  Fail 2023;5:66-81.     PUBMED  | CROSSREF  7. Lanzer JD, Leuschner F, Kramann R, Levinson RT, Saez-Rodriguez  J. Big data approaches in heart failure research. Curr Heart Fail Rep  2020;17:213-24.     PUBMED  | CROSSREF 17Role of AI in Heart Failure https://doi.org/10.36628/ijhf.2023.0050 https://e-heartfailure.orgApplication of AI in HF Current and future application \u00b7 Diagnosis \u00b7 Classi?cation and phenotype \u00b7 Prognosis and prediction \u00b7 Treatment \u00b7 Personalized medicine Data and imaging \u00b7 Multiple data sources: ECG, EHRs, and imaging data \u00b7 Remote monitoring \u00b7 Wearable devices Computational techniques \u00b7 Big data approach \u00b7 AI: traditional machine learning, deep learning, generative AI Figure 5.  Application of AI in HF.   AI = artificial intelligence; HF = heart failure; ECG = electrocardiography; EHR = electronic health record. 8. Docherty AB, Lone NI. Exploiting big data for critical care research.  Curr Opin Crit Care 2015;21:467- 72.     PUBMED  | CROSSREF  9. Averbuch T, Sullivan K, Sauer A, et al. Applications of artificial  intelligence and machine learning in heart failure. Eur Heart J Digit  Health 2022;3:311-22.     PUBMED  | CROSSREF  10. Fan J, Lv J. Sure independence screening for ultrahigh dimensional  feature space. J R Stat Soc Series B Stat Methodol 2008;70:849-911.      PUBMED  | CROSSREF  11. Fan J, Han F, Liu H. Challenges of big data analysis. Natl Sci Rev  2014;1:293-314.     PUBMED  | CROSSREF  12. Meng C, Zeleznik OA, Thallinger GG, Kuster B, Gholami AM, Culhane  AC. Dimension reduction techniques for the integrative analysis of  multi-omics data. Brief Bioinform 2016;17:628-41.     PUBMED  | CROSSREF  13. Choi RY, Coyner AS, Kalpathy-Cramer J, Chiang MF, Campbell JP.  Introduction to machine learning, neural networks, and deep learning.  Transl Vis Sci Technol 2020;9:14.    PUBMED  14. Park SM, Lee SY, Jung MH, et al. Korean Society of Heart Failure guidelines  for the management of heart failure: management of the underlying  etiologies and comorbidities of heart failure. Korean Circ J 2023;53:425-51.      PUBMED  | CROSSREF  15. Fu Y, Eisen HJ. Genetics of dilated cardiomyopathy. Curr Cardiol Rep  2018;20:121.     PUBMED  | CROSSREF  16. Rau CD, Lusis AJ, Wang Y. Genetics of common forms of heart failure:  challenges and potential solutions. Curr Opin Cardiol 2015;30:222- 7.      PUBMED  | CROSSREF  17. Hassani H, Silva ES, Unger S, TajMazinani M, Mac Feely S. Artificial  intelligence (AI) or intelligence augmentation (IA): what is the future?  AI 2020;1:143-55.     CROSSREF  18. Mintz Y, Brodie R. Introduction to artificial intelligence in medicine.  Minim Invasive Ther Allied Technol 2019;28:73-81.     PUBMED  | CROSSREF  19. Rajkomar A, Dean J, Kohane I. Machine learning in medicine. N Engl J  Med 2019;380:1347-58.     PUBMED  | CROSSREF  20. Rajula HS, Verlato G, Manchia M, Antonucci N, Fanos V . Comparison  of conventional statistical methods with machine learning in  medicine: diagnosis, drug development, and treatment. Medicina  (Kaunas) 2020;56:455.     PUBMED  | CROSSREF  21. Weller DL, Love TM, Wiedmann M. Interpretability versus accuracy: a  comparison of machine learning models built using different algorithms,  performance measures, and features to predict E. coli  levels in agricultural  water. Front Artif Intell 2021;4:628441.     PUBMED  | CROSSREF 22. Latif J, Xiao C, Imran A, Tu S. Medical imaging using machine  learning and deep learning algorithms: a review. In: Proceedings of  2019 2nd International Conference on Computing, Mathematics and  Engineering Technologies (iCoMET); 2019 January 30\u201331; Sukkur,  Pakistan. New York: IEEE; 2019. p.1\u20135.      23. Johnson KW , Torres Soto J, Glicksberg BS, et al. Artificial intelligence  in cardiology. J Am Coll Cardiol 2018;71:2668-79.     PUBMED  | CROSSREF  24. Noorbakhsh-Sabet N, Zand R, Zhang Y, Abedi V . Artificial intelligence  transforms the future of health care. Am J Med 2019;132:795-801.      PUBMED  | CROSSREF  25. McCulloch WS, Pitts W . A logical calculus of the ideas immanent in  nervous activity. 1943. Bull Math Biol 1990;52:99-115 .     PUBMED  | CROSSREF  26. Lee EJ, Kim YH, Kim N, Kang DW . Deep into the brain: artificial  intelligence in stroke imaging. J Stroke 2017;19:277-85.     PUBMED  |  CROSSREF  27. Choi E, Schuetz A, Stewart WF, Sun J. Using recurrent neural network  models for early detection of heart failure onset. J Am Med Inform  Assoc 2017;24:361- 70.     PUBMED  | CROSSREF 28. Rao S, Li Y, Ramakrishnan R, et al. An explainable transformer-based  deep learning model for the prediction of incident heart failure. IEEE J  Biomed Health Inform 2022;26:3362- 72.     PUBMED  | CROSSREF  29. Gozalo-Brizuela R, Garrido-Merchan EC. ChatGPT is not all you need.  A state of the art review of large Generative AI models. arXiv. 2023  January 11. Available from: https://doi.org/10.48550/arXiv.2301.04655.      CROSSREF  30. Kebaili A, Lapuyade-Lahorgue J, Ruan S. Deep learning approaches for  data augmentation in medical imaging: a review. J Imaging 2023;9:81.      PUBMED  | CROSSREF  31. Seah JC, Tang JS, Kitchen A, Gaillard F, Dixon AF. Chest radiographs  in congestive heart failure: visualizing neural network learning.  Radiology 2019;290:514-22.     PUBMED  | CROSSREF  32. Harvey D, Lobban F, Rayson P, Warner A, Jones S. Natural language  processing methods and bipolar disorder: scoping review. JMIR Ment  Health 2022;9:e35928.     PUBMED  | CROSSREF  33. Guo A, Pasque M, Loh F, Mann DL, Payne PR. Heart failure diagnosis,  readmission, and mortality prediction using machine learning and  artificial intelligence models. Curr Epidemiol Rep 2020;7:212-9.      CROSSREF  34. Choi E, Schuetz A, Stewart WF, Sun J. Medical concept representation  learning from electronic health records and its application on heart  failure prediction. arXiv. 2017 June 20. Available from: https://doi. org/10.48550/arXiv.1602.03686 .     CROSSREF  35. Choi DJ, Park JJ, Ali T, Lee S. Artificial intelligence for the diagnosis of  heart failure. NPJ Digit Med 2020;3:54.     PUBMED  | CROSSREF  36. Nainwal A, Kumar Y, Jha B. Morphological changes in congestive heart  failure ECG. In: Proceedings of 2016 2nd International Conference on  Advances in Computing, Communication, & Automation (ICACCA)  (Fall); 2016 September 30\u2013October 1; Bareilly, India. New York: IEEE;  2016. p.1\u20134.      37. Hendry PB, Krisdinarti L, Erika M. Scoring system based on  electrocardiogram features to predict the type of heart failure in patients  with chronic heart failure. Cardiol Rev 2016;7:110-6.     PUBMED  | CROSSREF  38. Attia ZI, Kapa S, Lopez-Jimenez F, et al. Screening for cardiac  contractile dysfunction using an artificial intelligence-enabled  electrocardiogram. Nat Med 2019;25:70-4.     PUBMED  | CROSSREF  39. Kwon JM, Kim KH, Eisen HJ, et al. Artificial intelligence assessment  for early detection of heart failure with preserved ejection fraction  based on electrocardiographic features. Eur Heart J Digit Health  2020;2:106-16.     PUBMED  | CROSSREF  40. Choi J, Lee S, Chang M, Lee Y, Oh GC, Lee HY. Deep learning of ECG  waveforms for diagnosis of heart failure with a reduced left ventricular  ejection fraction. Sci Rep 2022;12:1-10.     CROSSREF  41. Kwon JM, Kim KH, Jeon KH, et al. Development and validation of  deep-learning algorithm for electrocardiography-based heart failure  identification. Korean Circ J 2019;49:629-39.     PUBMED  | CROSSREF  42. Unterhuber M, Rommel KP, Kresoja KP, et al. Deep learning detects heart  failure with preserved ejection fraction using a baseline electrocardiogram.  Eur Heart J Digit Health 2021;2:699- 703.     PUBMED  | CROSSREF  43. Bui AL, Horwich TB, Fonarow GC. Epidemiology and risk profile of  heart failure. Nat Rev Cardiol 2011;8:30-41.     PUBMED  | CROSSREF  44. Lee SE, Lee HY, Cho HJ, et al. Clinical characteristics and outcome of  acute heart failure in Korea: results from the Korean Acute Heart Failure  Registry (KorAHF). Korean Circ J 2017;47:341-53.     PUBMED  | CROSSREF  45. Golas SB, Shibahara T, Agboola S, et al. A machine learning model to  predict the risk of 30-day readmissions in patients with heart failure:  a retrospective analysis of electronic medical records data. BMC Med  Inform Decis Mak 2018;18:44.     PUBMED  | CROSSREF 18Role of AI in Heart Failure https://doi.org/10.36628/ijhf.2023.0050 https://e-heartfailure.org 46. Kwon JM, Kim KH, Jeon KH, et al. Artificial intelligence algorithm  for predicting mortality of patients with acute heart failure. PLoS One  2019;14:e0219302.     PUBMED  | CROSSREF  47. Boehmer JP, Hariharan R, Devecchi FG, et al. A multisensor algorithm  predicts heart failure events in patients with implanted devices: results  from the MultiSENSE study. JACC Heart Fail 2017;5:216-25.     PUBMED  |  CROSSREF  48. Shah SJ, Katz DH, Selvaraj S, et al. Phenomapping for novel  classification of heart failure with preserved ejection fraction.  Circulation 2015;131:269- 79.     PUBMED  | CROSSREF  49. Gevaert AB, Tibebu S, Mamas MA, et al. Clinical phenogroups are  more effective than left ventricular ejection fraction categories in  stratifying heart failure outcomes. ESC Heart Fail 2021;8:2741-54.      PUBMED  | CROSSREF  50. Ahmad T, Lund LH, Rao P, et al. Machine learning methods improve  prognostication, identify clinically distinct phenotypes, and detect  heterogeneity in response to therapy in a large cohort of heart failure  patients. J Am Heart Assoc 2018;7:e008081.     PUBMED  | CROSSREF  51. Bazoukis G, Stavrakis S, Zhou J, et al. Machine learning versus  conventional clinical methods in guiding management of heart failure  patients-a systematic review. Heart Fail Rev 2021;26:23-34.     PUBMED  |  CROSSREF  52. Jing L, Ulloa Cerna AE, Good CW , et al. A machine learning approach to  management of heart failure populations. JACC Heart Fail 2020;8:578-87.      PUBMED  | CROSSREF  53. Sullivan K, Mamas MA, Van Spall HG. Machine learning could  facilitate optimal titration of guideline-directed medical therapy in  heart failure. J Am Coll Cardiol 2019;74:1424-5.     PUBMED  | CROSSREF  54. Daubert C, Behar N, Martins RP, Mabo P, Leclercq C. Avoiding non- responders to cardiac resynchronization therapy: a practical guide. Eur  Heart J 2017;38:1463- 72.     PUBMED  | CROSSREF  55. Cikes M, Sanchez-Martinez S, Claggett B, et al. Machine learning- based phenogrouping in heart failure to identify responders to cardiac  resynchronization therapy. Eur J Heart Fail 2019;21:74-85.     PUBMED  |  CROSSREF  56. Deng Y, Cheng S, Huang H, et al. Machine learning-based  phenomapping in patients with heart failure and secondary prevention  implantable cardioverter-defibrillator implantation: a proof-of-concept  study. Rev Cardiovasc Med 2023;24:37.     CROSSREF  57. Shakibfar S, Krause O, Lund-Andersen C, et al. Predicting electrical  storms by remote monitoring of implantable cardioverter-defibrillator  patients using machine learning. Europace 2019;21:268- 74.     PUBMED  |  CROSSREF  58. ElRefai M, Abouelasaad M, Wiles BM, et al. Role of deep learning methods in screening for subcutaneous implantable cardioverter  defibrillator in heart failure. Ann Noninvasive Electrocardiol  2023;28:e13028.     PUBMED  | CROSSREF  59. Dunn AJ, ElRefai MH, Roberts PR, Coniglio S, Wiles BM, Zemkoho  AB. Deep learning methods for screening patients\u2019 S-ICD implantation  eligibility. Artif Intell Med 2021;119:102139.     PUBMED  | CROSSREF  60. Yasmin F, Shah SM, Naeem A, et al. Artificial intelligence in the  diagnosis and detection of heart failure: the past, present, and future.  Rev Cardiovasc Med 2021;22:1095-113.     PUBMED  | CROSSREF  61. Cho J, Lee B, Kwon JM, et al. Artificial intelligence algorithm  for screening heart failure with reduced ejection fraction using  electrocardiography. ASAIO J 2021;67:314-21.     PUBMED  | CROSSREF  62. Bhatia A, Maddox TM. Remote patient monitoring in heart failure:  factors for clinical efficacy. Int J Heart Fail 2020;3:31-50.     PUBMED  |  CROSSREF  63. Kwon JM, Jo YY, Lee SY, et al. Artificial intelligence-enhanced  smartwatch ECG for heart failure-reduced ejection fraction detection  by generating 12-lead ECG. Diagnostics (Basel) 2022;12:654.     PUBMED  |  CROSSREF  64. Stehlik J, Schmalfuss C, Bozkurt B, et al. Continuous wearable  monitoring analytics predict heart failure hospitalization: the LINK- HF multicenter study. Circ Heart Fail 2020;13:e006513.     PUBMED  |  CROSSREF  65. Breck E, Polyzotis N, Roy S, Whang S, Zinkevich M. Data validation for  machine learning. In: Proceedings of the 2nd SysML Conference; Palo  Alto, CA, USA; 2019.      66. Emmanuel T, Maupong T, Mpoeleng D, Semong T, Mphago B, Tabona  O. A survey on missing data in machine learning. J Big Data 2021;8:140.      PUBMED  | CROSSREF  67. Su J, Vargas DV , Sakurai K. One pixel attack for fooling deep neural  networks. IEEE Trans Evol Comput 2019;23:828-41.     CROSSREF  68. Dombrowski AK, Alber M, Anders C, Ackermann M, M\u00fcller KR, Kessel  P. Explanations can be manipulated and geometry is to blame. In:  33rd Conference on Neural Information Processing Systems (NeurIPS  2019); Vancouver, Canada; 2019.      69. Ghorbani A, Abid A, Zou J. Interpretation of neural networks is fragile.  Proc Conf AAAI Artif Intell 2019;33:3681-8.     CROSSREF  70. Pal A, Umapathi LK, Sankarasubbu M. Med-HALT: medical domain  hallucination test for large language models. arXiv. 2023 October 14.  Available from: https://doi.org/10.48550/arXiv.2307.15343.     CROSSREF  71. Nori H, King N, McKinney SM, Carignan D, Horvitz E. Capabilities of  GPT-4 on medical challenge problems. arXiv. 2023 April 12. Available  from: https://doi.org/10.48550/arXiv.2303.13375.     CROSSREF 19Role of AI in Heart Failure https://doi.org/10.36628/ijhf.2023.0050 https://e-heartfailure.org", "9": "Exploring symptoms in chronic heart failure Abstract Symptoms in patients with chronic heart failure (CHF) are the cry for help, reflecting not only the physical aspects of the disease but the impact on lifestyle, anxiety, depression and expectations of the patient. Studies consistently show a difference in patients\u2019 self-assessed functional classification compared to investigator reported NYHA classification. Moreover, patient self-assessed symptoms have recentlybeen shown to independently predict hospitalisation and mortality over 5 years. Recognition of symptoms and appreciation of theirimportance justifies the use of a structured assessment in order to provide optimal medical care for patients with CHF. A model of how to structure symptom assessment equally with signs is presented in this paper. D2005 European Society of Cardiology. Published by Elsevier B.V. All rights reserved. Keywords: Symptoms; Signs; Heart failure; NYHA; Adherence 1. Background Few patients present to a health professional com- plaining of a specific disease. Most patients seek helpbecause they have symptoms which reflect how they feeland what they can do and how they are viewed by others[1]. The current predominant theoretical frame of reference from health providers assumes that symptomsare to be interpreted as reflections of disordered somatic(biochemical, neurophysiological, etc.) processes. The task of the clinician is therefore to bdecode Qthe patients\u2019 symptoms to their biological referents in order todiagnose a disease entity [2,3]. However, most clinicians recognize that many symptoms are poorly related to anyobvious somatic disorder, which complicates the diag-nostic process. As a consequence, in order to identifypatients with worsening CHF properly and offer correcttreatment, the development of diagnostic tools such as echocardiography, coronary angiography and plasma BNP are used to confirm or exclude the disease. However,little consideration is given to trying to understand howpatients\u2019 experiences should be integrated into currentpractice recommendations, reflecting a paucity of scien-tific information. Obviously, symptoms are an important aspect of CHF and are frequently evaluated in research. The New York Heart Association (NYHA) classification has been used for over three decades as a summary measure of theclinicians\u2019 impression of symptoms in patients with CHF[4]. NYHA class predicts outcome in patients with heart failure. However, this classification is based not only onfunctional limitation due to symptoms but is alsoinfluenced by knowledge of the severity of cardiac dysfunction, prior medical history and the likely prog- nosis. However, the degree and extent of dyspnoea and fatigue are often poorly documented in patient records.This may reflect the lack of objective methods formeasuring symptoms and their variable relationship withenvironment, activity and mood. These factors and theability to induce temporary relief of severe symptomsmay have reduced the importance of symptoms as atarget of therapy for clinical trialists. Symptoms are subjective, and clinicians should recog- nise and value their importance to patients. They reflecthow the patient feels. They are the cry for help,reflecting not only the physical aspects of the diseasebut the associated impact on lifestyle, anxiety, depressionand expectations of the patient. For these reasons,symptoms will vary markedly amongst patients andwithin the same patient from one time to another. Worsening conditions will often provoke emotional responses that make the patient feel more severelyaffected by symptoms. Once re-stabilised, even if notimproved, given time to adjust lifestyle and expectations,symptoms may abate even if functional capacity does notrecover. Patients learn to live with their symptoms andthereby report less severity. However, the perceiveddiscomfort of symptoms, as well as the actual limitation they cause are both of interest to health professionals. Relief of symptoms is an important target of therapy forpatients with CHF [5]as recognised by the European agency for the evaluation of medical products (EMEA) aswell as the American Food and Drug administration(FDA) [6]. 1388-9842/$ - see front matter D2005 European Society of Cardiology. Published by Elsevier B.V. All rights reserved. doi:10.1016/j.ejheart.2005.07.003The European Journal of Heart Failure 7 (2005) 699\u2013703 www.elsevier.com/locate/heafai2. Which symptoms? Breathlessness and fatigue are the classical symptoms of heart failure [7\u20139] . Probably because of the NYHA classification, other symptoms are rarely documented inpatients with CHF, but as many as 23 differentsymptoms have been reported by patients during theirlast 6 months of life [9]. Symptoms such as difficulty concentrating and bodily pain (other than chest pain) are common [10]. Women and men with CHF experience similar symptoms, but they are perceived in differentways; physical and social restrictions affecting daily lifeactivities are most problematic for men, whereas restric-tions affecting the ability to support family and friendsare most difficult for women [11\u201313] . 3. Symptom assessment Symptoms reflect the patient\u2019s personal subjective experience, which is then interpreted, subjectively, byhealth professionals. Not surprisingly, there is disparitybetween the assessment of symptoms by patients comparedto physicians and nurses [14\u201316] . According to Tiesinga et al.[17], nurse assessment of the intensity of patients fatigue relates poorly with the patients own perceptions,while the patients\u2019 relatives assessed fatigue more accu-rately. Obviously, knowledge about personal factors isimportant when assessing symptoms. Of even greaterconcern is the poor reproducibility of symptom assessmentby physicians [16]. It has often been assumed that dyspnoea is a sensation that varies only in the degree of intensity, but certain descriptors of shortness of breath have been reported to bemore likely to be endorsed by patients with specificconditions [17]. For example, patients with chronic obstructive pulmonary disease (COPD) chose, bMy breath- ing requires effort Q, whereas patients with heart failure chose, bI feel that I am suffocating Q, to characterize their personal experiences of dyspnoea [18,19] . When compar- ing descriptors of breathlessness among men and women, we found that the women did not choose any particulardescriptor whereas men scored the following threedescriptors significantly higher; My breath does not go in all the way ,I feel that I am suffocating andI cannot get enough air [14]. Furthermore, the physicians recognised and assessed symptoms of CHF with greater accuracy inmen. A major reason for failing to make an accurate diagnosis in CHF is that symptom presentations mirror our cultural and social contexts. The clinical understanding ofsymptoms associated with coronary disease is derivedprimarily from studies in male patients. Clinical trials oftenfocus on patients with left ventricular systolic dysfunctionleading to a higher proportion of men. This may under-value the importance of heart failure and its symptomburden in women.4. Self-assessed symptoms The clinicians\u2019 task is difficult because symptoms are subjective and meaningful. Studies consistently show adifference in patients\u2019 self-assessed functional classifica-tion compared to investigator reported NYHA classifica-tion [20,21] .(Fig. 1 ). Recently, the COMET trial reported that the severity of patient self-assessed symptoms, independently predicted hospitalisation and mortality over 5 years [21]. Breathlessness, fatigue and angina were rated by the patients ( n=3029) using a 5-point scale as follows: (1) Asymptomatic; (2) Walking upstairs at normalpace; (3) Walking at normal pace on the flat; (4) Walkingslowly on the flat or during washing or dressing and (5)At rest. In a multivariate Cox regression analysisincluding 16 baseline covariates, amongst symptoms, breathlessness predicted an increase in mortality and all- cause hospitalisation, whilst fatigue predicted the develop-ment of worsening heart failure. Clearly, symptomsreported by patients are not only important targets fortherapy in their own right, but also indicate the need fortreatment to improve prognosis. Patient reported symptoms are readily available, inex- pensive to acquire, valid (because they reflect the patients\u2019 experience), predict outcome and may be less operator- dependent than physical signs. Helping the physician andnurse to understand the structure of the patients\u2019 realityshould improve the therapeutic alliance between patientsand caregivers. 5. Disease and illness A distinction between disease and illness must be made. Disease is defined as an abnormality in thestructure and function of body organs and systems andcan often be identified by signs of bodily disorder such asoedema or reduced ejection fraction [22]. Illness means experienced reduction in states of well-being and socialfunction manifesting as symptoms [22]. Disease and NYHA% 020406080100 III II IIV Self assessed function Fig. 1. Patients\u2019 self-assessed functional classification compared to conventional NYHA classification (modified after Ref. [20]).Editorial 700  18790844, 2005, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1016/j.ejheart.2005.07.003 by Higher Education Commission,, Wiley Online Library on [13/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License illness do not have a one-to-one relationship, signs can be identified without experiences of symptoms and similardegrees of organ pathology can generate quite differentsymptoms, as is well known in heart failure [23,24] . Illness may occur in the absence of detectable disease.Accordingly, the course of the disease may be verydifferent from that of the accompanying illness. A modelof clinical practice, integrating both the disease and illness perspectives, has been developed by the medical anthro- pologists Byron J. Good and Mary-Jo Delvecchio-Good[2]. They state that whatever the biological correlates or grounds of a disease, illness becomes an interpretedpersonal experience for the patient. At present, the diseaseis primarily considered as an object for therapeuticattention for the care provider. We found this modeluseful in exploring symptoms in a structured way and have therefore modified it in order to match care and treatment for patients with CHF. The model is describedstep by step in Table 1 . The first step; The pathological entity identifies the symptoms, such as breathlessness, and tiredness or signssuch as ankle swelling. The next step; Structure of relevance means information that reveals the meaning of illness to a patient, for example the patient explains that he or she cannot manage the stairs at home because of the breathlessness. The elicitation procedure in the disease perspective is when the physician confirms thesuspected diagnosis with for example echocardiography,from the illness perspective it means listening to thepatient\u2019s personal explanation of the symptoms and signs.The interpretative goal is diagnosis and explanation from the disease point of view and from the illness perspectiveit means the health professional\u2019s understanding of thepatient\u2019s interpretation of their condition and the treat-ment. And finally, The therapeutic goal which is to intervene in the disease process in the disease-orientedapproach while, from the illness perspective it meanstrying to reach concordance between health professionals and patients\u2019 view on illness and treatment. 6. Adherence to prescribed treatment Studies suggest that as many as 30\u201350% of medicines prescribed for the treatment of CHF are not taken asprescribed [25\u201327] . The reasons for this lack of adherence are largely unknown, but research indicates that lack of symptom relief when taking medicines maybe one explanation [28,29] . The clinician\u2019s assessment of the needs and effects of treatment and the patient\u2019ssubjective perception are often not the same. The lattervary between individuals and also within an individual,depending on psychological and social factors that requirecareful assessment and communication between caregiver and patient. Even when patients consider that they are adhering to treatment and self-care guidelines, many fallshort because of a breakdown in communicationsbetween patients and healthcare providers [30].F o r instance, many patients are given a 1 week supply ofmedication when they leave hospital. Some patients maythink, very reasonably, that once they have finished theirdischarge medication that the course of treatment is complete, just like taking an anti-biotic. It can also be very confusing when patients are faced with their pre-admission medication (left at home) and their dischargemedication [31]. Multidisciplinary management pro- grammes improve quality of life, reduce mortality anddelay subsequent hospitalisations in patients with CHF[32,33] . However, these interventions are often vaguely described as boptimal pharmacological treatment, educa- tion and counselling of the patients Qand are therefore difficult to reproduce and develop further [32\u201334] . Non- adherence is often not about patients disobeying orforgetting, and cannot be solved solely with pharmaco-logical information but has to be approached by trying toreach the patients\u2019 way of thinking and adapt to theirway of understanding. New approaches are being evaluated for the care and treatment of patients with CHF; such as home tele- monitoring and nurse telephone support [35], and also models which tailor the intervention from a patient\u2019ssubjective reports about his or her condition [36]. The latter approach emphasizes the need of the healthprovider to further explore the relationship between apatient\u2019s particular expression of distress and physiolog-ical disorder. Table 1 Interpretation of signs and symptoms in CHF (modified after Ref. [2]) Disease-signs Illness-symptoms Pathological entity Somatic lesion or dysfunction, e.g. edemaIllness reality of the patient, e.g. breathlessness and tired Structure of relevance Relevant data those that reveal somatic disorder, e.g. weight gainRelevant data those that reveal meaning of illness, e.g. many stairs at home Elicitation procedure Review of systems; laboratory tests, e.g. echocardiographyEvaluate the patient\u2019s explanatory models, e.g. old age Interpretative goal Diagnosis, e.g. worsening heart failureUnderstanding, e.g. worsening heart failure Therapeutic goal Intervene in somatic disease process, e.g. pharmacologicaltreatmentIntervene in order to create concordance between patient andhealth provider, e.g. pedagogical conversations on the basis of the collected dataEditorial 701  18790844, 2005, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1016/j.ejheart.2005.07.003 by Higher Education Commission,, Wiley Online Library on [13/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 7. Summary Symptoms are important for the interpretation and understanding of patients with CHF. They reflect eitherthe disease itself or the patient\u2019s perception of the illness. Recognition of symptoms and appreciation of their importance should be the reason for a structured assessmentin order to provide optimal care for patients with CHF. References [1] Eisenberg L, Kleiman A, editors. The relevance of social science for medicine. London 7D. Reidal Publishing Company, 1980. [2] Good BJ, Delvecchio-Good MJ. The meaning of symptoms: a cultural hermeneutic model for clinical practice. In: Eisenberg L, Kleinman A, editors. The relevance of social science for medicine. London 7D. Reidal Publishing Company, 1980. p. 165\u201396. [3] Foucault M. The birth of the clinic An archaeology of the medical perception (Naissance de la Clinique first published 1963 by Presses Universitaires de France). . London 7Routledge Classics; 2003. [4] Bennett JA, Riegel B, Bittner V , Nichols J. Validity and reliability of the NYHA classes for measuring research outcomes in patients withcardiac disease. Heart Lung 2002;31:262\u201370. [5] Swedberg K, Cleland J, Dargie H, Drexler H, Follath F, Komajda M, et al. Guidelines for the diagnosis and treatment of chronic heartfailure. Eur Heart J 2005;26:1115\u201340. [6] European Medicines Agency. Evaluation of Medicines for human use. http://www.emea.eu.int/pdfs/human/ewp/298603en.pdf . [7] Lynn J, Teno JM, Phillips RS, et al. Perceptions by family members of the dying experience of older and seriously ill patients. SUPPORT Investigators. Study to understand prognoses and preferences for outcomes and risks of treatments. Ann Intern Med1997;126:97\u2013106. [8] Parshall MP, Welsh DJ, Brockopp DY, Heiser RM, Schooler MP, Cassidy KB. Dyspnea duration, distress, and intensity in emergency department visits for heart failure. Heart Lung 2001;30:47\u201356. [9] Nordgren L, S frensen S. Symptoms experienced in the last six months of life in patients with end-stage heart failure. Scand J Caring Sci 2003;2:213\u20137. [10] Zambroski CH, Moser DK, Bhat G, Ziegler C. Impact of symptom prevalence and symptom burden on quality of life in patients with heart failure. Eur J Cardiovasc Nurs in press. [11] Friedman MM. Gender differences in the health related quality of life of older adults with heart failure. Heart Lung 2003;32:320\u20137. [12] Ekman I, Ehrenberg A. Fatigue in chronic heart failure, does gender make a difference? Eur J Cardiovasc Nurs 2003;1:77\u201382. [13] Str fmberg A, M 3rtensson J. Gender differences in patients with heart failure. Eur J Cardiovasc Nurs 2003;2:7\u201318. [14] Ekman I, Olofsson M, Boman K, Aires N, Swedberg K. Gender makes a difference in the description of dyspnoea in patients with chronic heart failure. Eur J Cardiovasc Nurs 2005;4:117\u201321. [15] Ekman I, Ehrenberg A. Fatigued elderly patients with chronic heart failure: do patient reports and nursing documentation correspond? Nurs Diagn 2002;13:127\u201336. [16] Gadsboll N, Hoilund-Carlsen PF, Nielsen GG, et al. Symptoms and signs of heart failure in patients with myocardial infarction: reproducibility and relationship to chest X-Ray, radionuclide ventriculography and right heart catheterisation. Eur Heart J1989;10:1017\u201328. [17] Tiesenga L, Dijkstra A, Dassen TWN, Halfens RJD, van den Heuve W.J.A. Are nurses able to assess fatigue, exertion fatigue and types of fatigue in residential home patients? Scand J Caring Sci 2002;16:129\u201336.[18] Simon PM, Schwartzstein RM, Weiss JW, Fencl V, Teghtsoonian M, Weinberger SE. Distinguishable types of dyspnea in patients withshortness of breath. Am Rev Respir Dis 1990;142:1009\u201314. [19] Mahler DA, Harver A, Lentine T, Scott JA, Beck K, Schwartzstein RM. Descriptors of breathlessness in cardiorespiratory diseases. Am JRespir Crit Care Med 1996;154:1357\u201363. [20] B. Andersson, G. Brunlof, P.A. Lundberg, G. Lindstedt. Nurse- managed clinic provides a good foundation for heart failure patients. Lakartidningen 2002:2640-2, 2645-8. [21] Ekman I, Cleland JCF, Swedberg K, Charlesworth A, Metra M, Poole-Wilson PA. Symptoms in patients with heart failure are prognostic predictors. Insights from COMET. J Card Fail 2005; 11(4):288\u201392. [22] Eisenberg L. Disease and illness: distinctions between professional and popular ideas of sickness. Cult Med Psychiatry 1977;1:9\u201323. [23] Russell SD, McNeer FR, Higginbotham MB. Duke University Clinical Studies (DUCC) Exercise Group Wilson Circ. 1995. Exer-tional dyspnea in heart failure: a symptom unrelated to pulmonary function at rest or during exercise. Am Heart J 1998;135:398\u2013405. [24] Shah MR, Hasselblad V , Stinnett SS, Kramer JM, Grossman S, Gheorghiade M, et al. Dissociation between hemodynamic changesand symptom improvement in patients with advanced congestive heart failure. Eur J Heart Fail 2002;4:297\u2013304. [25] Evangelista L, Doering LV, Dracup K, Westlake C, Hamilton M, Fonarow GC. Compliance behaviors of elderly patients with advancedheart failure. J Cardiovasc Nurs 2003;18(3):197\u2013206. [26] Struthers AD, Anderson G, MacFadyen RJ, Fraser C, MacDonald TM. Nonadherence with ACE inhibitors is common and can bedetected in clinical practice by routine serum ACE activity. Congest Heart Fail 2001;7(1):43\u20136. [27] Bohachick P, Burke LE, Sereika S, Murali S, Dunbar-Jacob J. Adherence to angiotensin-converting enzyme inhibitor therapy forheart failure. Prog Cardiovasc Nurs 2002;17(4):160\u20136. [28] Pound P, Britten N, Morgan M, Yardley L, Pope C, Daker-White G, et al. Resisting medicines: a synthesis of qualitative studies of medicinetaking. Soc Sci Med 2005;61:133\u201355. [29] Ekman I, Andersson G, Boman K, Charlesworth A, Cleland JGF, Poole-Wilson P, et al. Adherence and perception of medication in patients with chronic heart failure during a five year randomised trial.Pat Educ Counsel in press. [30] Horowitz CR, Rein SB, Leventhal H. A story of maladies, misconceptions and mishaps: effective management of heart failure.Soc Sci Med 2004;58:631\u201343. [31] Komajda M, Follath F, Swedberg K, Cleland J, Aguilar JC, Cohen- Solal A, et al. The EuroHeart failure survey programme\u2014a survey on the quality of care among patients with heart failure in Europe: Part 2.Treatment. Eur Heart J 2003;24:464\u201374. [32] Stromberg A, Martensson J, Fridlund B, et al. Nurse-led heart failure clinics improve survival and self-care behaviour in patients with heart failure: results from a prospective, randomised trial. Eur Heart J2003;24:1014\u201323. [33] Thompson DR, Roebuck A, Stewart S. Effects of a nurse-led, clinic and home-based intervention on recurrent hospital use in chronic heart failure. Eur J Heart Fail 2005;16(7):377\u201384. [34] Ekman I, Swedberg K. (Editorial) Home-based management of patients with chronic heart failure\u2014focus on content not just form!. Eur Heart J 2002;23:1323\u20135. [35] Cleland JGF, Louis AA, Rigby AS, Janssens U, Balk AHMM. Noninvasive home telemonitoring for patients with heart failure at high risk for recurrent admission and death. J Am Coll Cardiol 2005;45:1654\u201364. [36] Jaarsma T, Van Der Wal MH, Hogenhuis J, Lesman I, Luttik ML, Veeger NJ, et al. Design and methodology of the COACH study: a multicenter randomised coordinating study evaluating outcomes of advising and counselling in heart failure. Eur J Heart Fail2004;1:227\u201333.Editorial 702  18790844, 2005, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1016/j.ejheart.2005.07.003 by Higher Education Commission,, Wiley Online Library on [13/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License Inger Ekman Department of Nursing, The Sahlgrenska Academy at Go \u00a8teborg University, Box 457, SE 405 30 Go \u00a8teborg, Sweden E-mail address: inger.ekman@fhs.gu.se. Corresponding author. Fax: +46317736050. John G.F. Cleland Department of Cardiology, University of Hull, Kingston upon Hull, UKBert Andersson Department of Cardiology, Sahlgrenska University hospital/Sahlgrenska, Go\u00a8teborg, Sweden Karl Swedberg Department of Medicine, Sahlgrenska University hospital/ O\u00a8stra, Go \u00a8teborg, Sweden 3 July 2005Editorial 703  18790844, 2005, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1016/j.ejheart.2005.07.003 by Higher Education Commission,, Wiley Online Library on [13/02/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License "}